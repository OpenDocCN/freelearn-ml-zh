- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Conformal Prediction for Classification
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 符合预测的分类
- en: This chapter dives deeper into the topic of conformal prediction for classification
    problems. We will explore the concept of classifier calibration and demonstrate
    how conformal prediction compares to other calibration methods before introducing
    Venn-ABERS predictors as specialized techniques within conformal prediction. Additionally,
    we will provide an overview of open source tools that can be utilized to implement
    conformal prediction for classifier calibration.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将更深入地探讨分类问题的符合预测。我们将探讨分类器校准的概念，并在介绍符合预测中的专用技术Venn-ABERS预测器之前，展示符合预测与其他校准方法的比较。此外，我们还将概述可用于实现分类器校准的符合预测的开源工具。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Classifier calibration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器校准
- en: Evaluating calibration performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估校准性能
- en: Various approaches to classifier calibration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器校准的各种方法
- en: Conformal prediction for classifier calibration
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符合预测的分类器校准
- en: Open source tools for conformal prediction in classification problems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于分类问题中的符合预测的开源工具
- en: Classifier calibration
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类器校准
- en: Most statistical, machine learning, and deep learning models output predicted
    class labels, and the models are typically evaluated in terms of their accuracy.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数统计、机器学习和深度学习模型输出预测的类别标签，模型通常根据其准确性进行评估。
- en: Accuracy is a prevalent measure for assessing the performance of a machine learning
    classification model. It quantifies the ratio of instances that are correctly
    identified to the overall count in the dataset. In other words, accuracy tells
    us how often the model’s predictions align with the true labels of the data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性是评估机器学习分类模型性能的常用指标。它量化了正确识别的实例与数据集中总数之比。换句话说，准确性告诉我们模型预测与数据真实标签一致的程度。
- en: The accuracy score measures how often the model’s predictions match the true
    observed labels. It is calculated as the fraction of correct predictions out of
    all predictions made. Accuracy scores between 0 and 1 quantify how accurate the
    model’s predictions are compared to the ground truth data. A higher accuracy score
    close to 1 signifies that the model is performing very accurately overall, with
    most of its predictions being correct. A lower accuracy approaching 0 indicates
    poor performance, with the majority of the model’s predictions being incorrect
    compared to the true labels.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性得分衡量模型预测与真实观察标签匹配的频率。它是所有预测中正确预测的比例。0到1之间的准确性得分量化了模型预测与真实数据相比的准确性。接近1的较高准确性得分表示模型整体表现非常准确，大多数预测都是正确的。接近0的较低准确性表示性能较差，与真实标签相比，模型的大多数预测都是错误的。
- en: The closer the accuracy is to 1, the better the model is performing. The closer
    it is to 0, the worse the model is at predicting the true labels in the data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性越接近1，模型的表现越好。越接近0，模型在预测数据中的真实标签方面的表现越差。
- en: Accuracy is a straightforward and intuitive metric that is easy to understand
    and interpret. However, it may not always be the most suitable metric, especially
    when dealing with imbalanced datasets. In imbalanced datasets, where the number
    of instances in different classes is significantly different, accuracy alone may
    be misleading. In an imbalanced dataset, a classifier that consistently predicts
    the majority class can attain a high accuracy based on the class distribution,
    even if it doesn’t identify the minority class.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性是一个简单直观的指标，易于理解和解释。然而，它可能并不总是最合适的指标，尤其是在处理不平衡数据集时。在不平衡数据集中，不同类别的实例数量差异很大，仅凭准确性可能具有误导性。在不平衡数据集中，一个始终预测多数类的分类器可以根据类别分布获得高准确性，即使它没有识别出少数类。
- en: In these scenarios, it’s crucial to look at other evaluation measures, such
    as precision, recall, F1 score, or ROC-AUC, to gain a fuller insight into the
    model’s efficacy.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，查看其他评估指标，如精确度、召回率、F1分数或ROC-AUC，对于全面了解模型的有效性至关重要。
- en: Depending on the specific problem and the requirements, other metrics and considerations,
    such as the cost of false positives or false negatives, might be more relevant.
    Therefore, it is essential to assess the model’s performance using multiple evaluation
    metrics and consider the context in which the classification model will be applied.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据具体问题和要求，其他指标和考虑因素，如假阳性和假阴性的成本，可能更为相关。因此，使用多个评估指标评估模型性能并考虑分类模型将应用到的上下文是至关重要的。
- en: 'Accuracy alone may be insufficient, particularly in critical applications,
    for several reasons:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 单纯的准确性可能不足，尤其是在关键应用中，原因有以下几点：
- en: '**Imbalanced datasets**: In scenarios where the dataset is imbalanced, accuracy
    can be misleading. If the majority class dominates the dataset, a model that predicts
    only the majority class can achieve high accuracy but fails to capture the minority
    class effectively. This can be problematic in critical applications where correctly
    identifying rare events or detecting anomalies is crucial.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不平衡数据集**：在数据集不平衡的情况下，准确性可能会误导。如果大多数类别主导数据集，那么仅预测大多数类别的模型可以达到高准确性，但无法有效地捕捉少数类别。在正确识别罕见事件或检测异常至关重要的关键应用中，这可能会成为问题。'
- en: '**Cost of errors**: In many real-world applications, the cost of false positives
    and false negatives can vary significantly. Accuracy treats all errors equally
    and does not consider the consequences of misclassifications. For instance, in
    a medical diagnosis, a false negative (failing to detect a disease) can be far
    more critical than a false positive. In such cases, accuracy alone does not provide
    sufficient information about the model’s performance in terms of the actual impact
    on decision-making and outcomes.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误成本**：在许多实际应用中，假阳性和假阴性的成本可能差异很大。准确性将所有错误视为同等，并且不考虑误分类的后果。例如，在医疗诊断中，一个假阴性（未能检测到疾病）可能比一个假阳性（错误地检测到疾病）要严重得多。在这种情况下，仅准确性并不能提供关于模型性能的充分信息，即对决策和结果的实际影响。'
- en: '**Probability estimation**: Accuracy does not take into account the confidence
    or uncertainty of the model’s predictions. It is essential to assess the model’s
    ability to provide well-calibrated probability estimates. Calibration refers to
    the alignment between predicted probabilities and the true probabilities of events.
    A poorly calibrated model may provide overly confident or unreliable probability
    estimates, which can lead to incorrect decisions or the misinterpretation of risks.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率估计**：准确性不考虑模型预测的置信度或不确定性。评估模型提供良好校准的概率估计的能力是至关重要的。校准是指预测概率与事件的真实概率之间的对齐。一个校准不良的模型可能会提供过度自信或不可靠的概率估计，这可能导致错误的决策或对风险的误解。'
- en: '**Decision threshold**: Accuracy does not consider the decision threshold used
    for classification. Different decision thresholds can result in varying trade-offs
    between precision and recall. Depending on the application, certain misclassification
    errors may be more tolerable than others. Evaluating only accuracy does not provide
    insights into the model’s performance at different decision thresholds.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策阈值**：准确性不考虑用于分类的决策阈值。不同的决策阈值会导致精确度和召回率之间的不同权衡。根据应用，某些误分类错误可能比其他错误更可容忍。仅评估准确性并不能提供关于模型在不同决策阈值下性能的见解。'
- en: Let’s get to understanding the concepts of classifier calibration next.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来了解分类器校准的概念。
- en: Understanding the concepts of classifier calibration
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解分类器校准的概念
- en: In the previous chapters, we defined and discussed the concept of classifier
    calibration.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们定义并讨论了分类器校准的概念。
- en: Classifier calibration involves adjusting the predicted probabilities from a
    classification model so that they better reflect the true likelihood of each class.
    The goal is to make the predictions better calibrated.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器校准包括调整分类模型的预测概率，以便它们更好地反映每个类的真实可能性。目标是使预测更加校准。
- en: A well-calibrated classifier is one where the predicted probabilities match
    the empirical probabilities. For example, if the model predicts “class A” with
    60% probability across 100 examples, then class A should occur approximately 60
    times out of those 100 predictions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个校准良好的分类器是指预测概率与经验概率相匹配的分类器。例如，如果模型在100个示例中预测“类别A”的概率为60%，那么在100个预测中，类别A应该大约出现60次。
- en: 'More formally, a well calibrated classifier satisfies the following formula:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，一个校准良好的分类器满足以下公式：
- en: P(actual class is c | predicted probability of c is p) ≈ p
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: P(实际类别为c | 预测c的概率为p) ≈ p
- en: This means the observed frequency of class c should be close to p when the model
    predicts class c with probability p.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着当模型以概率p预测类别c时，类别c的观察频率应该接近p。
- en: Calibration adjustment ensures the predicted probabilities are aligned with
    the relative frequencies in the actual data. The predictions are calibrated to
    the empirical evidence so that a predicted probability of `0.7` corresponds to
    a 70% chance based on the data. This calibration is essential for probability
    estimates to be meaningful and reliable.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 校准调整确保预测概率与实际数据中的相对频率相一致。预测被校准到经验证据上，因此预测概率为`0.7`对应于基于数据的70%的可能性。这种校准对于概率估计的有意义和可靠性至关重要。
- en: For instance, consider a binary classifier that predicts whether an email is
    spam or not. For each email, it might predict a probability, say, `0.8`, which
    means it believes there’s an 80% chance that the email is spam. If the classifier
    is well calibrated, then out of all emails that it assigns a spam probability
    of `0.8`, about 80% should be spam.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个二元分类器，它预测一封电子邮件是否为垃圾邮件。对于每封电子邮件，它可能会预测一个概率，比如说`0.8`，这意味着它认为这封电子邮件有80%的可能性是垃圾邮件。如果分类器校准良好，那么在所有被分配`0.8`垃圾邮件概率的电子邮件中，大约80%应该是垃圾邮件。
- en: Without calibration, the output probabilities of a classifier might not correspond
    to the true likelihood of the predicted class, which can be problematic for decision-making.
    Calibration methods adjust these probabilities to better reflect reality. The
    goal is to have the output probabilities of the classifier be as close as possible
    to the true probabilities.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 没有校准，分类器的输出概率可能不会对应于预测类别的真实可能性，这可能会对决策造成问题。校准方法调整这些概率以更好地反映现实。目标是使分类器的输出概率尽可能接近真实概率。
- en: 'Model calibration is crucial because of the following aspects:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型校准至关重要，原因如下：
- en: '**Reliable probability estimates**: Calibrated classifiers provide accurate
    and reliable probability estimates for the predicted classes. Probability estimates
    reflect the model’s confidence in its predictions and can be interpreted as the
    likelihood of a particular class being correct. In many real-world applications,
    such as medical diagnosis, risk assessment, or fraud detection, having well-calibrated
    probability estimates is crucial for making informed decisions and assessing the
    level of uncertainty associated with the predictions.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠的概率估计**：校准分类器为预测类别提供准确和可靠的概率估计。概率估计反映了模型对其预测的信心，可以解释为特定类别正确的可能性。在许多实际应用中，如医疗诊断、风险评估或欺诈检测，拥有良好的概率估计对于做出明智的决策和评估与预测相关的不确定性水平至关重要。'
- en: '**Reliable risk assessment**: In many domains, accurate risk assessment is
    paramount. Calibrated classifiers provide well-calibrated probability estimates
    that reflect the true likelihood of events. This allows for more accurate and
    reliable risk assessment, enabling decision-makers to allocate resources, prioritize
    actions, or estimate the impact of certain events more effectively. For instance,
    in credit scoring, a calibrated classifier can provide accurate estimates of the
    probability of default, aiding in better risk management.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠的风险评估**：在许多领域，准确的风险评估至关重要。校准分类器提供校准良好的概率估计，反映了事件的真正可能性。这允许更准确和可靠的风险评估，使决策者能够更有效地分配资源、优先处理行动或估计某些事件的影响。例如，在信用评分中，校准分类器可以提供准确的违约概率估计，有助于更好的风险管理。'
- en: '**Decision threshold determination**: In classification tasks, decisions are
    often made by setting a threshold on the predicted probabilities. This threshold
    determines the trade-off between precision and recall, or equivalently, between
    false positives and false negatives. Calibrated classifiers help in selecting
    an appropriate decision threshold by aligning the probability estimates with the
    desired trade-off, considering the specific costs or consequences associated with
    different types of errors. This ensures that decision-making aligns with the objectives
    and requirements of the application.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策阈值确定**：在分类任务中，决策通常是通过在预测概率上设置一个阈值来做出的。这个阈值决定了精确度和召回率之间的权衡，或者说，是假阳性与假阴性之间的权衡。校准后的分类器通过将概率估计与期望的权衡相一致，考虑到不同类型错误的具体成本或后果，有助于选择合适的决策阈值。这确保了决策与应用的目标和要求相一致。'
- en: '**Interpretability and trust**: Calibration enhances the interpretability of
    the model’s predictions. Calibrated probability estimates can be used to understand
    the level of confidence the model has in its predictions. This transparency helps
    in building trust with users, stakeholders, and regulatory authorities, particularly
    in domains where decision-making is critical and must be justified. By providing
    well-calibrated probability estimates, the model’s predictions can be better understood
    and validated, instilling confidence in its reliability.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性和信任**：校准增强了模型预测的可解释性。校准后的概率估计可以用来理解模型对其预测的信心水平。这种透明度有助于与用户、利益相关者和监管机构建立信任，特别是在决策至关重要且必须得到证明的领域。通过提供良好的校准概率估计，模型的预测可以更好地被理解和验证，从而增强对其可靠性的信心。'
- en: '**Improved fairness**: Calibrated classifiers can contribute to fairness in
    decision-making processes. By providing well-calibrated probability estimates,
    they can help in identifying and mitigating biases that may arise from the underlying
    training data or model assumptions. This allows for fairer and more equitable
    predictions, ensuring that different groups are treated consistently and without
    undue bias.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提高公平性**：校准后的分类器可以促进决策过程中的公平性。通过提供良好的校准概率估计，它们可以帮助识别和减轻可能源于底层训练数据或模型假设的偏差。这允许做出更公平、更公正的预测，确保不同群体得到一致的对待，且没有不合理的偏见。'
- en: It is essential to evaluate model calibration to ensure that the model’s predictions
    align with the underlying uncertainties in the data. This evaluation helps in
    making informed decisions, understanding the model’s limitations, and managing
    the risks associated with misclassifications or incorrect probability estimates.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型校准对于确保模型的预测与数据中的潜在不确定性相一致至关重要。这种评估有助于做出明智的决策，了解模型的局限性，并管理与误分类或错误的概率估计相关的风险。
- en: Traditionally, many classifiers, such as logistic regression or support vector
    machines, generate probability estimates based on their internal models. However,
    these probability estimates are not always accurate or well calibrated, leading
    to overconfidence or under confidence in the predictions. For instance, a classifier
    may assign probabilities close to `1.0` or `0.0` to certain examples when it should
    have assigned probabilities closer to `0.7` or `0.3`, respectively.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，许多分类器，如逻辑回归或支持向量机，基于其内部模型生成概率估计。然而，这些概率估计并不总是准确或校准良好的，导致对预测过度自信或缺乏信心。例如，分类器可能将接近
    `1.0` 或 `0.0` 的概率分配给某些示例，而它应该分配接近 `0.7` 或 `0.3` 的概率，分别。
- en: To address this issue, various techniques have been proposed to calibrate classifiers
    and improve the reliability of their probability estimates. These techniques aim
    to map the original probability scores to more accurate and calibrated probabilities.
    The goal is to ensure that, on average, the predicted probabilities match the
    observed frequencies or likelihoods of the predicted events.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，已经提出了各种技术来校准分类器并提高其概率估计的可靠性。这些技术旨在将原始概率得分映射到更准确和校准后的概率。目标是确保，平均而言，预测的概率与观察到的预测事件的频率或可能性相匹配。
- en: Evaluating calibration performance
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估校准性能
- en: 'Evaluating the calibration performance of a classifier is crucial to assessing
    the reliability and accuracy of its probability estimates. Calibration evaluation
    allows us to determine how well the predicted probabilities align with the true
    probabilities or likelihoods of the predicted events. Here are some commonly used
    techniques for evaluating the calibration performance of classifiers:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分类器的校准性能对于评估其概率估计的可靠性和准确性至关重要。校准评估使我们能够确定预测概率与预测事件的真实概率或似然度之间的匹配程度。以下是评估分类器校准性能的一些常用技术：
- en: '**Calibration plot**: A calibration plot visually assesses how well a classifier’s
    predicted probabilities match the true class frequencies. The *x* axis shows the
    predicted probabilities for each class, while the *y* axis shows the empirically
    observed frequencies for those predictions.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准图**：校准图通过视觉方式评估分类器的预测概率与真实类频率的匹配程度。*x*轴显示每个类的预测概率，而*y*轴显示这些预测的经验观察频率。'
- en: For a well-calibrated model, the calibration curve should closely match the
    diagonal, representing a 1:1 relationship between predicted and actual probabilities.
    Deviations from the diagonal indicate miscalibration, where the predictions are
    inconsistent with empirical evidence.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于一个校准良好的模型，校准曲线应与对角线紧密匹配，表示预测概率与实际概率之间存在1:1的关系。偏离对角线表明存在误校准，即预测与经验证据不一致。
- en: 'Calibration plots provide an intuitive way to identify if a classifier is over
    confident or under confident in its estimates across different probability ranges.
    The closer the curve aligns with the diagonal, the better calibrated the predicted
    probabilities are. Significant deviations signal that recalibration is needed
    for the model’s outputs to be reliable:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 校准图提供了一种直观的方法来识别分类器在不同概率范围内对其估计的过度自信或不足自信。曲线越接近对角线，预测概率的校准就越好。显著的偏差表明需要对模型的输出进行重新校准，以确保其可靠性：
- en: '![Figure 6.1 – Calibration plot](img/B19925_06_1.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 校准图](img/B19925_06_1.jpg)'
- en: Figure 6.1 – Calibration plot
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 校准图
- en: '**Calibration error**: Calibration error measures the average difference between
    the predicted probabilities and the actual probabilities of the forecasted events.
    It’s determined by the mean absolute deviation between the estimated probabilities
    and the observed probabilities. Lower calibration error values indicate better
    calibration performance.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准误差**：校准误差衡量预测概率与预测事件的实际概率之间的平均差异。它由估计概率与观察概率之间的平均绝对偏差确定。较低的校准误差值表示校准性能更好。'
- en: '**Calibration metrics**: Several metrics can be used to evaluate the calibration
    performance of a classifier. Commonly used metrics include the **expected calibration
    error** (**ECE**), log loss, and the Brier score. ECE measures the calibration
    error by partitioning the predicted probabilities into bins and calculating the
    difference between the average predicted probabilities and the average empirical
    probabilities within each bin. The Brier score assesses the overall accuracy of
    the predicted probabilities, considering both calibration and resolution (sharpness)
    of the probability estimates. The Brier score is a commonly used scoring rule
    for assessing the calibration of probabilistic forecasts. It measures the mean
    squared difference between the predicted probabilities and the actual outcomes.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准指标**：可以使用多个指标来评估分类器的校准性能。常用的指标包括**期望校准误差**（**ECE**）、对数损失和Brier分数。ECE通过将预测概率划分为区间并计算每个区间内平均预测概率与平均经验概率之间的差异来衡量校准误差。Brier分数评估预测概率的整体准确性，考虑了概率估计的校准和解算（锐度）。Brier分数是评估概率预测校准的常用评分规则。它衡量预测概率与实际结果之间的平均平方差异。'
- en: For a set of *N* predictions, the Brier score is calculated as BS =  1 _ N ∑ t=1 N  
    (f t − o t) 2, where *ft,i* is the forecasted probability for an event, *i*, at
    time *t*, and *ot,i* is the actual outcome of an event, *i,* at time *t* (0 or
    1).
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于一组*N*个预测，Brier分数计算为BS = 1 * N ∑ t=1 N (f_t − o_t)^2，其中*ft,i*是时间*t*对事件*i*的预测概率，*ot,i*是时间*t*事件*i*的实际结果（0或1）。
- en: Squaring the errors gives more weight to large mistakes. The average squared
    error is then taken across all predictions.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将误差平方赋予大错误更大的权重。然后对所有预测取平均平方误差。
- en: A lower Brier score indicates better calibration, with a minimum of 0 for a
    perfect probabilistic forecaster. It penalizes both inaccurate and over/underconfident
    predictions.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 较低的Brier分数表示校准更好，对于完美的概率预报员，最小值为0。它惩罚不准确以及过度/不足自信的预测。
- en: '**Cross-validation**: Cross-validation is a technique for estimating the calibration
    performance. It does this by partitioning the dataset into multiple folds and
    training the model on one fold while evaluating calibration on the remaining folds.
    This helps in assessing the calibration performance across different subsets of
    the data and provides a more robust evaluation.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证**：交叉验证是一种估计校准性能的技术。它通过将数据集划分为多个折叠，在一个折叠上训练模型，同时在剩余的折叠上评估校准来实现。这有助于评估不同数据子集的校准性能，并提供更稳健的评估。'
- en: When evaluating the calibration performance, it is important to compare the
    results against an appropriate baseline. A well-calibrated classifier should outperform
    random or uncalibrated probability estimates.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估校准性能时，将结果与适当的基线进行比较是很重要的。一个校准良好的分类器应该优于随机或未校准的概率估计。
- en: Various approaches to classifier calibration
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类器校准的各种方法
- en: Before exploring how conformal prediction can provide calibrated probabilities,
    we will first discuss some common non-conformal calibration techniques and their
    strengths and weaknesses. These include histogram binning, Platt scaling, and
    isotonic regression.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在探讨一致性预测如何提供校准概率之前，我们首先将讨论一些常见的非一致性校准技术及其优缺点。这些包括直方图分箱、Platt缩放和等调回归。
- en: It is important to note that the following methods are not part of the conformal
    prediction framework. We are covering them to build intuition about calibration
    and highlight some of the challenges with conventional calibration approaches.
    This background will motivate the need for and benefits of the conformal prediction
    perspective so that we can obtain reliable probability estimates.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，以下方法不属于一致性预测框架的一部分。我们介绍它们是为了建立对校准的直觉，并突出一些传统校准方法中的挑战。这个背景将激发对一致性预测视角的需求及其好处，以便我们获得可靠的概率估计。
- en: The calibration techniques we will explore, including histogram binning, Platt
    scaling, and isotonic regression, represent widely used approaches for adjusting
    classifier confidence values. However, as we will discuss, they have certain limitations
    regarding model flexibility, computational expense, and generalization.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探索的校准技术，包括直方图分箱、Platt缩放和等调回归，代表了调整分类器置信值值广泛使用的方法。然而，正如我们将讨论的，它们在模型灵活性、计算成本和泛化方面存在某些局限性。
- en: By first understanding these existing calibration methods and their drawbacks,
    we will be equipped to better comprehend the value of conformal prediction’s inherent
    calibration properties. This background provides context into the calibration
    problem before presenting conformal prediction as an attractive modern solution.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通过首先理解这些现有的校准方法和它们的缺点，我们将能够更好地理解一致性预测固有的校准属性的价值。这个背景在介绍一致性预测作为有吸引力的现代解决方案之前，为校准问题提供了背景。
- en: Histogram binning
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直方图分箱
- en: Histogram binning is a technique that’s commonly used in classifier calibration
    to improve the calibration performance of probability estimates. It involves dividing
    the predicted probabilities into bins or intervals and mapping them to more accurate
    and reliable probabilities based on the empirical frequencies or observed proportions
    of the predicted events within each bin. The goal of histogram binning is to align
    the predicted probabilities with the true probabilities of the events, resulting
    in a better-calibrated classifier.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图分箱是一种在分类器校准中常用的技术，用于提高概率估计的校准性能。它涉及将预测概率划分为箱或区间，并根据每个箱内预测事件的经验频率或观察比例，将它们映射到更准确和可靠的概率。直方图分箱的目标是将预测概率与事件的真正概率对齐，从而得到校准更好的分类器。
- en: 'The process of histogram binning can be summarized as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图分箱的过程可以概括如下：
- en: '**Partitioning**: The predicted probabilities are divided into a predefined
    number of bins or intervals. The number of bins can vary based on the dataset
    and the desired granularity of calibration.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分区**：预测概率被划分为预定义的多个箱或区间。箱的数量可以根据数据集和所需的校准粒度而变化。'
- en: '**Bin assignment**: Each instance in the dataset is assigned to the corresponding
    bin based on its predicted probability. For example, if we have five bins with
    equal width intervals (for example, *0-0.2*, *0.2-0.4*, *0.4-0.6*, *0.6-0.8*,
    and *0.8-1.0*), an instance with a predicted probability of 0.45 would be assigned
    to the third bin.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**箱子分配**：数据集中的每个实例根据其预测概率分配到相应的箱子中。例如，如果我们有五个等宽间隔的箱子（例如，*0-0.2*，*0.2-0.4*，*0.4-0.6*，*0.6-0.8*，和*0.8-1.0*），一个预测概率为0.45的实例将被分配到第三个箱子。'
- en: '`0.7`.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`0.7`。'
- en: '**Mapping to calibrated probabilities**: The predicted probabilities within
    each bin are then mapped or adjusted to more accurate and calibrated probabilities
    based on the empirical proportions of positives. This mapping can be performed
    using various techniques, such as isotonic regression or Platt scaling.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**映射到校准概率**：然后根据正例的实证比例，将每个箱子内的预测概率映射或调整为更准确和校准良好的概率。此映射可以使用各种技术执行，例如等调回归或Platt校准。'
- en: '**Overall calibration**: Once the mapping has been applied to all the bins,
    the calibrated probabilities are obtained by combining the probabilities from
    all the bins. The result is a set of calibrated probabilities that better align
    with the true probabilities or likelihoods of the events.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**整体校准**：一旦映射应用于所有箱子，通过结合所有箱子的概率，获得校准概率。结果是校准概率集，更好地与事件的真正概率或似然性对齐。'
- en: 'Here are some potential disadvantages of using histogram binning for classifier
    calibration:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用直方图分箱进行分类器校准的一些潜在缺点：
- en: '**Inflexibility**: Histogram binning divides the prediction space into fixed
    intervals. It lacks the flexibility to model complex, nonlinear miscalibration
    patterns.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不灵活性**：直方图分箱将预测空间划分为固定间隔。它缺乏建模复杂、非线性误校准模式的灵活性。'
- en: '**Data underutilization**: Hard binning discards information within each bin.
    The calibration mapping uses only the bin averages rather than the full distribution.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据未充分利用**：硬分箱会丢弃每个箱子内的信息。校准映射仅使用箱子平均值而不是整个分布。'
- en: '**Sensitivity to the binning scheme**: The calibration quality is dependent
    on the specific binning thresholds chosen, which can be arbitrary. Optimal binning
    is often not known beforehand.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对分箱方案的敏感性**：校准质量取决于所选的具体分箱阈值，这些阈值可能是任意的。最优分箱通常事先未知。'
- en: '**Discontinuities**: Adjacent bins may have very different adjustments, leading
    to abrupt discontinuities in the calibration mapping. This can introduce artifacts.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不连续性**：相邻箱子可能具有非常不同的调整，导致校准映射中的突然不连续性。这可能会引入伪影。'
- en: '**Difficulty extrapolating**: The binning calibration is based only on the
    training data distribution. It may not extrapolate well to unseen data with sparse
    or no coverage.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外推困难**：分箱校准仅基于训练数据分布。它可能无法很好地外推到稀疏或无覆盖的未见数据。'
- en: '**Curse of dimensionality**: Histograms do not scale well to high-dimensional
    feature spaces. The data becomes too sparse within each bin.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维度诅咒**：直方图在处理高维特征空间时扩展性不佳。数据在每个箱子内变得过于稀疏。'
- en: '**Limited model expressiveness**: Histograms can only represent simple, low-order
    calibration relationships. They cannot model complex miscalibration patterns.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型表达能力有限**：直方图只能表示简单、低阶的校准关系。它们无法建模复杂的误校准模式。'
- en: Histogram binning can be simple to implement but provides an inflexible, discontinuous
    calibration mapping. More sophisticated dense modeling and smoothing are often
    required for optimal calibration quality.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图分箱易于实现，但提供的校准映射不够灵活，不连续。通常需要更复杂的密集建模和平滑处理以获得最佳的校准质量。
- en: Platt scaling
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Platt校准
- en: Platt scaling, sometimes referred to as Platt’s method or sigmoid calibration,
    is a post-processing approach that’s employed to refine the output probabilities
    of a binary classification model. It was introduced by John C. Platt in 1999 to
    transform the raw output scores of a support vector machines classifier into well-calibrated
    probabilities.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Platt校准，有时被称为Platt方法或Sigmoid校准，是一种后处理方法，用于细化二元分类模型的输出概率。它由John C. Platt于1999年提出，用于将支持向量机分类器的原始输出分数转换为校准良好的概率。
- en: The goal of Platt scaling is to adjust the predicted scores or logits produced
    by the classifier in such a way that they reflect more accurate estimates of the
    true probabilities. This is achieved by fitting a logistic regression model on
    the classifier’s scores while using a labeled validation set or a holdout set.
    The logistic regression model is trained to map the original scores to calibrated
    probabilities.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放法的目的是调整分类器产生的预测分数或logits，使其更准确地反映真实概率的估计。这是通过在分类器的分数上拟合逻辑回归模型，同时使用标记验证集或保留集来实现的。逻辑回归模型被训练以将原始分数映射到校准概率。
- en: 'The steps involved in Platt scaling are as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放法涉及到的步骤如下：
- en: Collect a labeled validation set or a holdout set that is distinct from the
    training data used to train the classifier.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一个与用于训练分类器的训练数据不同的标记验证集或保留集。
- en: Use the classifier to generate the raw output scores or logits for the instances
    in the validation set.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分类器为验证集中的实例生成原始输出分数或logits。
- en: Fit a logistic regression model on the validation set, treating the raw scores
    as the independent variable and the true class labels as the dependent variable.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在验证集上拟合逻辑回归模型，将原始分数视为自变量，将真实类别标签视为因变量。
- en: Train the logistic regression model using standard techniques such as maximum
    likelihood estimation or gradient descent to estimate the model’s parameters.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标准技术（如最大似然估计或梯度下降）训练逻辑回归模型以估计模型参数。
- en: Once the logistic regression model has been trained, it can be used as a calibration
    function. Given a new instance, the raw score produced by the classifier is input
    into the logistic regression model, which transforms it into a calibrated probability
    estimate.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练了逻辑回归模型，它可以用作校准函数。给定一个新实例，分类器产生的原始分数被输入到逻辑回归模型中，该模型将其转换为校准概率估计。
- en: The logistic regression model essentially learns the transformation from the
    raw scores to calibrated probabilities by estimating the intercept and slope parameters.
    This transformation is represented by the sigmoid function, which maps the scores
    to probabilities between `0` and `1`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型本质上通过估计截距和斜率参数来学习从原始分数到校准概率的转换。这种转换由Sigmoid函数表示，它将分数映射到`0`到`1`之间的概率。
- en: Platt scaling aims to achieve better calibration by adjusting the predicted
    probabilities to match the true probabilities or likelihoods of the events.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放法旨在通过调整预测概率以匹配事件的真正概率或似然性来达到更好的校准。
- en: It’s important to note that Platt scaling assumes that the relationship between
    the raw scores and the true probabilities can be modeled by a logistic function.
    If the underlying relationship is more complex, other calibration methods such
    as conformal prediction may be more suitable.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，Platt缩放法假设原始分数与真实概率之间的关系可以通过逻辑函数建模。如果底层关系更复杂，其他校准方法（如一致性预测）可能更合适。
- en: 'While Platt scaling can be an effective technique for calibrating classifier
    probabilities, it is important to be aware of its limitations and potential disadvantages:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Platt缩放法可以是一种有效的校准分类器概率的技术，但重要的是要了解其局限性和潜在缺点：
- en: '**Requirement for a separate validation set**: Platt scaling requires a labeled
    validation set or holdout set that is distinct from the training data. This means
    additional data may be needed for calibration, which can be a limitation in situations
    where obtaining labeled data is challenging or costly.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对单独验证集的要求**：Platt缩放法需要一个与训练数据不同的标记验证集或保留集。这意味着可能需要额外的数据进行校准，这在获取标记数据困难或成本高昂的情况下可能是一个限制。'
- en: '**Assumption of a logistic relationship**: Platt scaling assumes that the relationship
    between the raw scores and the true probabilities can be accurately modeled by
    a logistic function. If the underlying relationship is more complex or different,
    the logistic regression model may not be able to capture the true calibration
    mapping adequately.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对逻辑关系的假设**：Platt缩放法假设原始分数与真实概率之间的关系可以通过逻辑函数准确建模。如果底层关系更复杂或不同，逻辑回归模型可能无法充分捕捉真实的校准映射。'
- en: '**Sensitivity to extreme scores**: Platt scaling can be sensitive to extreme
    scores or outliers in the validation set. Outliers may disproportionately influence
    the calibration function, leading to potential overfitting or a suboptimal calibration.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对极端分数敏感**：Platt缩放可能对验证集中的极端分数或异常值敏感。异常值可能不成比例地影响校准函数，导致潜在的过拟合或次优校准。'
- en: '**Lack of flexibility for different calibration shapes**: The logistic regression
    model used in Platt scaling is constrained to fit a sigmoid function, which may
    not be suitable for all calibration shapes. If the desired calibration shape deviates
    significantly from a sigmoid curve, Platt scaling may not achieve optimal calibration.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对不同校准形状的灵活性不足**：Platt缩放中使用的逻辑回归模型被限制为拟合一个S形函数，这可能不适合所有校准形状。如果所需的校准形状与S形曲线有显著偏差，Platt缩放可能无法实现最佳校准。'
- en: '**Limited applicability to multiclass problems**: Platt scaling is primarily
    designed for binary classification problems. Extending it to multiclass classification
    can be challenging as it requires adapting the calibration mapping to handle multiple
    classes and their respective probabilities.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对多类问题的适用性有限**：Platt缩放主要设计用于二元分类问题。将其扩展到多类分类可能具有挑战性，因为它需要调整校准映射以处理多个类别及其相应的概率。'
- en: '**Potential overconfidence in extreme probabilities**: Platt scaling may introduce
    overconfidence in extreme predicted probabilities. The calibrated probabilities
    near the boundaries (close to 0 or 1) might be more extreme than they should be,
    leading to overconfident predictions in those regions.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**极端概率中的潜在过度自信**：Platt缩放可能会在极端预测概率中引入过度自信。接近边界（接近0或1）的校准概率可能比应有的更极端，导致在这些区域产生过度自信的预测。'
- en: '**Dependence on the quality of the validation set**: The effectiveness of Platt
    scaling is dependent on the quality and representativeness of the labeled validation
    set. If the validation set does not accurately capture the true distribution of
    the target variable, the resulting calibration may be suboptimal.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖于验证集的质量**：Platt缩放的有效性取决于验证集的质量和代表性。如果验证集未能准确捕捉目标变量的真实分布，则得到的校准可能不是最优的。'
- en: It’s important to consider these disadvantages and assess whether Platt scaling
    is suitable for a specific application or if alternative calibration methods,
    such as methods based on conformal prediction, may be more appropriate based on
    the specific characteristics of the problem and dataset.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这些缺点并评估Platt缩放是否适合特定应用非常重要，或者根据问题的具体特征和数据集，基于一致性预测等方法可能更适合。
- en: Isotonic regression
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 等调回归
- en: Isotonic regression is a non-parametric regression technique that’s used for
    calibration and monotonicity modeling. It is commonly applied to adjust the output
    scores or predicted probabilities of a classifier to improve their calibration.
    Isotonic regression seeks to find a monotonic function that maps the original
    scores to calibrated probabilities while preserving the ordering of the scores.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 等调回归是一种非参数回归技术，用于校准和单调性建模。它通常用于调整分类器的输出分数或预测概率，以提高其校准。等调回归旨在找到一个单调函数，将原始分数映射到校准概率，同时保留分数的顺序。
- en: The primary goal of isotonic regression is to determine a non-decreasing function
    that reduces the sum of squared discrepancies between the predicted probabilities
    and the target probabilities or actual occurrences. By fitting a piecewise linear
    or piecewise constant function to the data, isotonic regression ensures that the
    predicted probabilities are monotonically increasing or non-decreasing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 等调回归的主要目标是确定一个非递减函数，该函数可以减少预测概率与目标概率或实际发生之间的平方差异之和。通过将分段线性或分段常数函数拟合到数据中，等调回归确保预测概率是单调递增或非递减的。
- en: 'The steps involved in isotonic regression are as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 等调回归的步骤如下：
- en: Collect a labeled validation set or a holdout set that is separate from the
    training data.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一个与训练数据分开的标记验证集或保留集。
- en: Use the classifier to generate the raw output scores or probabilities for the
    instances in the validation set.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分类器生成验证集中实例的原始输出分数或概率。
- en: Sort the instances in the validation set based on the raw scores.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据原始分数对验证集中的实例进行排序。
- en: Initialize the isotonic regression function as the identity function, where
    the initial predicted probabilities are equal to the raw scores.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将等调回归函数初始化为恒等函数，其中初始预测概率等于原始分数。
- en: Iteratively update the isotonic regression function by adjusting the predicted
    probabilities to minimize the squared differences between the predicted probabilities
    and the target probabilities. This adjustment is subject to the constraint of
    non-decreasing probabilities.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调整预测概率以最小化预测概率与目标概率之间的平方差，迭代更新等调回归函数。这种调整受非递减概率的约束。
- en: 'Repeat the updating process until convergence or a stopping criterion is reached:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复更新过程，直到收敛或达到停止标准：
- en: '![Figure 6.2 – Isotonic regression](img/B19925_06_2.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 等调回归](img/B19925_06_2.jpg)'
- en: Figure 6.2 – Isotonic regression
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 等调回归
- en: Once the isotonic regression model has been trained, it can be used to map the
    raw scores of new instances to calibrated probabilities. The model ensures that
    the predicted probabilities are monotonically increasing and better aligned with
    the true probabilities or likelihoods of the events.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练好等调回归模型，就可以用它将新实例的原始分数映射到校准概率。该模型确保预测概率单调递增，并与事件的真正概率或似然性更好地对齐。
- en: 'While isotonic regression is a valuable technique for calibrating classifier
    probabilities, it is important to consider its limitations and potential disadvantages:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然等调回归是校准分类器概率的有价值技术，但考虑其局限性和潜在缺点是很重要的：
- en: '**Potential overfitting**: Isotonic regression can suffer from overfitting
    if the calibration function is overly complex or if the calibration dataset is
    small. Regularization techniques, such as using a limited number of segments in
    the piecewise linear function, can help prevent overfitting.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在的过拟合**：如果校准函数过于复杂或校准数据集很小，等调回归可能会过拟合。正则化技术，如使用分段线性函数中的有限段数，可以帮助防止过拟合。'
- en: '**Complexity and computational cost**: Isotonic regression can be resource-intensive,
    especially with vast datasets or when navigating high-dimensional features. As
    the number of data points and unique scores or probabilities grow, so does the
    complexity of isotonic regression. It’s crucial to weigh up the computational
    limitations when using isotonic regression for extensive tasks.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性和计算成本**：等调回归可能资源密集，尤其是在处理大量数据集或导航高维特征时。随着数据点和唯一分数或概率数量的增加，等调回归的复杂性也会增加。在使用等调回归进行大量任务时，权衡计算限制至关重要。'
- en: '**Sensitivity to outliers**: Isotonic regression can be sensitive to outliers
    in the data. Outliers may have a significant impact on the estimated calibration
    function, potentially leading to suboptimal calibration. Careful data preprocessing
    or outlier detection techniques may be necessary to mitigate this issue.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对异常值的敏感性**：等调回归可能对数据中的异常值敏感。异常值可能对估计的校准函数有重大影响，可能导致校准不佳。可能需要仔细的数据预处理或异常值检测技术来减轻这一问题。'
- en: '**Limited flexibility for complex calibration shapes**: Isotonic regression
    assumes a monotonic relationship between the scores and the probabilities, which
    constrains the calibration function to be piecewise constant or piecewise linear.
    This limits the model’s flexibility to capture more complex or nonlinear calibration
    shapes. If the desired calibration shape deviates significantly from monotonicity,
    isotonic regression may not provide an optimal fit.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂校准形状的灵活性有限**：等调回归假设分数与概率之间存在单调关系，这限制了校准函数为分段常数或分段线性。这限制了模型捕捉更复杂或非线性校准形状的能力。如果所需的校准形状与单调性有显著偏差，等调回归可能无法提供最佳拟合。'
- en: '**Need for sufficient data**: Isotonic regression requires a sufficient amount
    of labeled data to estimate the calibration function accurately. If the calibration
    dataset is small or imbalanced, the estimation may be suboptimal. Ensuring a representative
    and adequately sized calibration dataset is important for reliable calibration
    results.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**需要足够的数据**：等调回归需要足够数量的标记数据来准确估计校准函数。如果校准数据集很小或不平衡，估计可能不佳。确保校准数据集具有代表性且大小适当对于可靠的校准结果很重要。'
- en: '**Difficulty in handling multiclass problems**: Isotonic regression is inherently
    designed for binary classification problems, so extending it to multiclass problems
    is not straightforward. Adapting isotonic regression to handle multiple classes
    and their respective probabilities requires careful consideration and modification
    of the algorithm.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理多类问题的困难**：等调回归本质上是为二元分类问题设计的，因此将其扩展到多类问题并不简单。将等调回归调整为处理多个类别及其相应的概率需要仔细考虑和修改算法。'
- en: '**Lack of probabilistic interpretation**: Unlike Platt scaling, which explicitly
    models probabilities using logistic regression, isotonic regression does not provide
    a probabilistic interpretation of the calibrated scores. It focuses solely on
    ensuring monotonicity and may not directly estimate well-calibrated probabilities.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏概率解释**：与使用逻辑回归显式建模概率的 Platt scaling 不同，等调回归不提供校准分数的概率解释。它仅专注于确保单调性，可能无法直接估计校准良好的概率。'
- en: It is important to evaluate these limitations and consider the characteristics
    of the problem at hand when deciding whether isotonic regression is the most appropriate
    calibration method.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定等调回归是否是最合适的校准方法时，评估这些局限性并考虑手头问题的特征是很重要的。
- en: Comparing the advantages and disadvantages of different calibration techniques,
    such as conformal prediction and Platt scaling, can help determine the best approach
    for achieving well-calibrated probabilities in a specific application.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 比较不同校准技术（如一致性预测和 Platt scaling）的优缺点，可以帮助确定在特定应用中实现校准良好的概率的最佳方法。
- en: Conformal prediction for classifier calibration
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分类器校准的一致性预测
- en: Conformal prediction is a powerful framework for probabilistic prediction that
    provides valid and well-calibrated prediction sets and prediction intervals. It
    offers a principled approach to quantify and control the uncertainty associated
    with the predictions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性预测是一个强大的概率预测框架，它提供了有效和校准良好的预测集和预测区间。它提供了一种原则性的方法来量化和控制与预测相关的不确定性。
- en: We have already seen how conformal prediction approaches, such as **inductive
    conformal prediction** (**ICP**) and **transductive conformal prediction** (**TCP**),
    aim to generate sets that have accurate coverage probabilities. To recap, conformal
    prediction computes p-values and constructs prediction sets by comparing the p-values
    of each potential label with a selected significance level.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，如**归纳一致性预测**（**ICP**）和**转导一致性预测**（**TCP**）等一致性预测方法旨在生成具有准确覆盖概率的集合。为了回顾，一致性预测通过比较每个潜在标签的p值与选定的显著性水平来计算p值并构建预测集。
- en: Unlike Platt scaling, histogram binning, and isotonic regression, which focus
    on calibrating the predicted probabilities or scores, conformal prediction takes
    a more comprehensive approach by providing prediction sets that encompass the
    uncertainty associated with the predictions and enhances the reliability and interpretability
    of predictions by providing valid measures of confidence or significance.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Platt scaling、直方图分箱和等调回归等专注于校准预测概率或分数的方法不同，一致性预测通过提供包含与预测相关的不确定性的预测集，采取更全面的方法，并通过提供有效的置信度或显著性度量来增强预测的可靠性和可解释性。
- en: Venn-ABERS conformal prediction
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Venn-ABERS一致性预测
- en: Classical methods such as Platt scaling was initially developed as parametric
    solutions for calibrating classifiers. However, these methods are becoming somewhat
    outdated and have limitations due to their simplistic assumptions, resulting in
    suboptimal calibration of probabilities.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 经典方法如 Platt scaling最初是作为校准分类器的参数解决方案开发的。然而，这些方法正变得有些过时，由于它们的简单假设，存在局限性，导致概率校准不佳。
- en: 'Platt scaling assumes a logistic relationship between scores and probabilities,
    which may not adequately capture the actual calibration shape in practical scenarios.
    It is worth noting that Platt’s original paper in 1999 did not explicitly discuss
    the underlying assumptions of this approach. However, recent research (see *Beta
    calibration: a well-founded and easily implemented improvement on logistic calibration
    for binary classifiers*: https://proceedings.mlr.press/v54/kull17a.html) has revealed
    that these assumptions are essentially equivalent to assuming both normality and
    homoscedasticity, which are overly restrictive assumptions for real-world datasets.
    Real datasets often exhibit more complex and diverse patterns that cannot be accurately
    captured by such assumptions. Therefore, relying solely on Platt scaling with
    its underlying assumptions may result in suboptimal calibration and poorly calibrated
    probabilities.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Platt缩放假设分数和概率之间存在逻辑关系，这在实际场景中可能不足以充分捕捉实际的校准形状。值得注意的是，Platt在1999年的原始论文中并没有明确讨论这种方法的潜在假设。然而，最近的研究（参见
    *Beta校准：对二元分类器的逻辑校准的一种有根据且易于实施的改进*：https://proceedings.mlr.press/v54/kull17a.html）揭示了这些假设本质上等同于假设正态性和同方差性，这对于现实世界的数据集来说是过于严格的假设。现实数据集通常表现出更复杂和多样化的模式，这些模式无法通过此类假设准确捕捉。因此，仅依靠Platt缩放及其潜在假设可能会导致校准不佳和校准概率不佳。
- en: Isotonic regression, as an approach, assumes a monotonic relationship between
    scores and probabilities. However, this assumption may not capture the intricate
    nature of the calibration curve in all cases. Furthermore, isotonic regression
    relies on the assumption of perfect ranking (an ROC AUC of 1) on the test dataset,
    which is rarely achievable in real-world datasets. Additionally, it has been demonstrated
    that isotonic regression can overfit when applied to smaller datasets.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 同质性回归作为一种方法，假设分数和概率之间存在单调关系。然而，这种假设可能无法捕捉所有情况下校准曲线的复杂本质。此外，同质性回归依赖于测试数据集上完美排序（ROC
    AUC为1）的假设，这在现实世界的数据集中很少能够实现。此外，已有研究表明，当应用于较小的数据集时，同质性回归可能会过拟合。
- en: The assumption of a monotonic relationship limits the flexibility of isotonic
    regression to model more complex calibration curves that may exhibit non-monotonic
    patterns. Moreover, the requirement of perfect ranking on the test dataset is
    often unrealistic as datasets typically involve inherent noise and uncertainty.
    This assumption can lead to suboptimal calibration results in practice.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 单调关系的假设限制了同质性回归的灵活性，使其难以模拟可能表现出非单调模式的更复杂的校准曲线。此外，测试数据集上完美排序（ROC AUC为1）的要求通常是不切实际的，因为数据集通常涉及固有的噪声和不确定性。这种假设在实践中可能导致校准结果不佳。
- en: Furthermore, the issue of overfitting with isotonic regression becomes more
    prominent when dealing with smaller datasets. When the dataset’s size is limited,
    isotonic regression may overly adjust to the noise or specific characteristics
    of the training data, resulting in poor generalization performance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当处理较小的数据集时，同质性回归的过拟合问题变得更加突出。当数据集的大小有限时，同质性回归可能会过度调整到噪声或训练数据的特定特征，从而导致泛化性能不佳。
- en: Because of their simplistic assumptions, Platt scaling and isotonic regression
    may not achieve optimal calibration and may not deliver well-calibrated probabilities.
    These methods may struggle to capture nonlinear or more intricate calibration
    patterns, limiting their effectiveness in certain applications.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们的简单假设，Platt缩放和同质性回归可能无法实现最佳校准，并且可能无法提供良好的校准概率。这些方法可能难以捕捉非线性或更复杂的校准模式，限制它们在某些应用中的有效性。
- en: To address the limitations of classical calibrators, such as Platt scaling and
    isotonic regression, a powerful solution called Venn-ABERS has been developed
    by the creator of conformal prediction, Vladimir Vovk , Ivan Petej and Valentina
    Fedorova”, Venn-ABERS is a conformal prediction method that offers mathematical
    guarantees of validity, regardless of the data distribution, dataset size, or
    underlying classification model.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决经典校准器（如Platt缩放和同质性回归）的局限性，符合预测的创造者Vladimir Vovk、Ivan Petej和Valentina Fedorova开发了一种名为Venn-ABERS的强大解决方案。Venn-ABERS是一种符合预测方法，无论数据分布、数据集大小或潜在分类模型如何，都能提供有效性的数学保证。
- en: This work is detailed in the NeurIPS paper titled *Large-scale probabilistic
    predictors with and without guarantees of validity* ([https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html](https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)).
    For a more mathematical understanding, watch the associated presentation, *Large-Scale
    Probabilistic Prediction With and Without Validity Guarantees*, at [https://www.youtube.com/watch?v=ksrUJdb2tA8](https://www.youtube.com/watch?v=ksrUJdb2tA8).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作在NeurIPS论文《带有和没有有效性保证的大规模概率预测器》中有详细描述（[https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html](https://papers.nips.cc/paper_files/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)）。为了更数学化的理解，请观看相关的演示，*带有和没有有效性保证的大规模概率预测*，在[https://www.youtube.com/watch?v=ksrUJdb2tA8](https://www.youtube.com/watch?v=ksrUJdb2tA8)。
- en: 'The name Venn-ABERS is derived from a combination of Venn predictors, another
    class of conformal predictors, and the initials of the authors who contributed
    to a classical paper called *An Empirical Distribution Function for Sampling with
    Incomplete Information* (M. Ayer, H.D. Brunk, G.M. Ewing, W.T. Reid, and E. Silverman:
    [https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full)).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS这个名字来源于Venn预测器，另一类共形预测器，以及为经典论文《具有不完整信息的抽样经验分布函数》（M. Ayer, H.D. Brunk,
    G.M. Ewing, W.T. Reid, 和 E. Silverman：[https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-26/issue-4/An-Empirical-Distribution-Function-for-Sampling-with-Incomplete-Information/10.1214/aoms/1177728423.full)）做出贡献的作者的首字母缩写。
- en: So, how do Venn-ABERS predictors work? Rather than constructing isotonic regression
    once, Venn-ABERS fits isotonic regression twice by assuming that each test object
    can have both label 0 and label 1\. This means that each test object is added
    to the calibration set twice, once with label 0 and once with label 1\. Two separate
    isotonic regressions are then fitted, resulting in two probabilities, *p0* and
    *p1*, for each test object.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Venn-ABERS预测器是如何工作的呢？Venn-ABERS不是一次性构建等调回归，而是通过假设每个测试对象都可以具有标签0和标签1，进行两次等调回归的拟合。这意味着每个测试对象被添加到校准集中两次，一次是标签0，一次是标签1。然后拟合两个独立的等调回归，为每个测试对象得到两个概率，*p0*和*p1*。
- en: It is important to note that both *p0* (lower bound) and *p1* (upper bound)
    represent probabilities of the object belonging to class 1\. These probabilities
    create a prediction interval for the probability of class 1, with mathematical
    guarantees that the actual probability falls within this interval.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，*p0*（下限）和*p1*（上限）都代表对象属于类别1的概率。这些概率为类别1的概率创建了一个预测区间，并提供了数学保证，实际概率落在这个区间内。
- en: Consequently, Venn-ABERS solves the problem beautifully, without requiring assumptions
    about score distributions such as Platt scaling and without suffering from overfitting.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Venn-ABERS完美地解决了这个问题，无需对得分分布（如Platt缩放）做出假设，也不会出现过度拟合的问题。
- en: The Venn-ABERS prediction is a multi-predictor, and the width of the interval
    (*p0, p1*) contains valuable information about the confidence of classification.
    In larger datasets, *p0* and *p1* are typically very close to each other. However,
    for smaller and more challenging datasets, *p0* and *p1* may diverge, indicating
    that certain objects are difficult to classify due to factors such as data distribution,
    insufficient data, or the underlying classifier’s performance.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS的预测是一个多预测器，区间(*p0, p1*)的宽度包含了关于分类置信度的宝贵信息。在较大的数据集中，*p0*和*p1*通常非常接近。然而，对于较小且更具挑战性的数据集，*p0*和*p1*可能会分离，这表明某些对象由于数据分布、数据不足或底层分类器的性能等因素而难以分类。
- en: Importantly, in critical situations, the Venn-ABERS predictor not only outputs
    accurate and well-calibrated probabilities but also issues an “alert” by widening
    the (*p0, p1*) interval. This alert indicates that the decision-making process
    should consider the increased uncertainty.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，在关键情况下，Venn-ABERS预测器不仅输出准确且校准良好的概率，而且通过扩大(*p0, p1*)区间发出“警报”。这个警报表明决策过程应考虑增加的不确定性。
- en: For practical decision-making purposes, the probabilities can be combined into
    a single value using *p = p1 / (1 - p0 + p1)*. This combined probability of class
    *1*, *p*, can then be utilized for decision-making tasks such as loan granting
    or determining whether to disable autopilot in autonomous car. With the inclusion
    of *p*, the decision-making process can be successfully concluded.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际决策目的，可以使用公式*p = p1 / (1 - p0 + p1)*将概率合并成一个单一值。这个类*1*的合并概率*p*可以用于决策任务，如贷款发放或确定是否在自动驾驶汽车中禁用自动驾驶。包含*p*后，决策过程可以成功完成。
- en: Comparing calibration methods
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较校准方法
- en: Given the range of calibration methods, you might be wondering how they are
    compared to each other. We have already seen that classical methods such as Platt
    scaling and isotonic regression rely on restrictive assumptions and, unlike the
    conformal prediction Venn-ABERS method, do not have validity guarantees. An interesting
    question is also how the performance of different methods compares empirically
    across a range of datasets.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到校准方法的范围，你可能想知道它们是如何相互比较的。我们已经看到，像Platt缩放和等调回归这样的经典方法依赖于限制性假设，并且与符合预测的Venn-ABERS方法不同，它们没有有效性保证。一个有趣的问题也是，不同方法在一系列数据集上的性能如何进行实证比较。
- en: Such a study was performed, and the results were summarized in the paper *Probabilistic
    Prediction in scikit-learn* ([http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf)).
    In this paper, a large experimental study was conducted to investigate the calibration
    of scikit-learn models out of the box. In addition, the study looked at whether
    calibration techniques such as Platt scaling, isotonic regression, and Venn-ABERs
    can improve calibration.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这样一项研究已经完成，其结果总结在论文《scikit-learn中的概率预测》*Probabilistic Prediction in scikit-learn*
    ([http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1603345/FULLTEXT01.pdf))中。在这篇论文中，进行了一项大规模的实验研究，以调查scikit-learn模型的开箱即用校准情况。此外，该研究还探讨了诸如Platt缩放、等调回归和Venn-ABERs之类的校准技术是否能够改善校准。
- en: 'The result of the study showed that of the seven algorithms evaluated (logistic
    regression, random forest, AdaBoost, gradient boosting, kNN, naïve Bayes, and
    decision tree), the only model that obtained well-calibrated predictions was logistic
    regression. Calibration enhances all models, especially decision trees, boosted
    trees (such as XGBoost, LightGBM, and CatBoost), and naïve Bayes. This underscores
    the clear advice for professionals: obtained relatively well-calibrated predictions
    was logistic regression.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 研究结果表明，在评估的七个算法（逻辑回归、随机森林、AdaBoost、梯度提升、kNN、朴素贝叶斯和决策树）中，唯一获得良好校准预测的模型是逻辑回归。校准增强了所有模型，尤其是决策树、提升树（如XGBoost、LightGBM和CatBoost）以及朴素贝叶斯。这强调了专业人士的明确建议：获得相对良好的校准预测的是逻辑回归。
- en: Additionally, the study uncovered a notable finding that miscalibrated models
    tend to exhibit a high level of overconfidence. Surprisingly, even logistic regression,
    although to a lesser extent compared to other models, displayed systematic optimism
    in its predictions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该研究揭示了一个值得注意的发现，即校准不当的模型往往表现出高度的过度自信。令人惊讶的是，即使是逻辑回归，尽管与其他模型相比程度较轻，但在其预测中也显示出系统性的乐观。
- en: In other words, these miscalibrated models tended to assign higher probabilities
    or confidence to their predictions than what was warranted by the actual outcomes.
    This overconfidence could potentially lead to misguided decision-making or misplaced
    trust in the reliability of the predictions.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这些校准不当的模型往往赋予其预测更高的概率或信心，高于实际结果所证明的。这种过度自信可能导致决策失误或对预测可靠性的错误信任。
- en: It is crucial to recognize that while logistic regression demonstrated better
    calibration compared to other models, it still exhibited a certain level of systematic
    optimism. This highlights the importance of thoroughly evaluating and calibrating
    models, even those considered to be well-calibrated, to ensure accurate and reliable
    probabilistic predictions.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到，尽管逻辑回归在与其他模型相比表现出更好的校准，但它仍然表现出一定程度的系统性乐观。这突出了彻底评估和校准模型的重要性，即使是那些被认为是校准良好的模型，以确保准确和可靠的概率预测。
- en: When examining the calibration techniques in terms of their benefits for calibration,
    their order of effectiveness is typically observed to be Venn-ABERS, followed
    by Platt scaling and isotonic regression.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当从校准技术的校准效益角度审视时，通常观察到其有效性顺序为Venn-ABERS，其次是Platt缩放和等调回归。
- en: Venn-ABERS tends to demonstrate the most significant improvement in calibration,
    providing notable benefits in terms of achieving well-calibrated predictions.
    Its utilization within the conformal prediction framework allows for reliable
    estimation of uncertainty and enhanced calibration performance.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Venn-ABERS往往在校准方面显示出最显著的改进，在实现良好校准的预测方面提供了显著的好处。在一致性预测框架内使用它，可以可靠地估计不确定性并提高校准性能。
- en: To summarize, the comparison of calibration techniques revealed that Venn-ABERS
    tends to yield the most substantial benefits, followed by Platt scaling and isotonic
    regression. It is important to select the appropriate technique based on the specific
    requirements of the problem at hand, considering factors such as the complexity
    of the calibration curve and the desired level of calibration improvement.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，对校准技术的比较显示，Venn-ABERS往往能带来最显著的好处，其次是Platt缩放和等调回归。根据手头问题的具体要求选择适当的技术非常重要，需要考虑的因素包括校准曲线的复杂性和期望的校准改进水平。
- en: The study’s findings emphasized that miscalibrated models often exhibit overconfidence,
    and even logistic regression, although more calibrated than other models, can
    display systematic optimism. This underlines the necessity of assessing and enhancing
    the calibration of models to avoid unwarranted confidence and make informed decisions
    based on accurate probabilistic predictions. The research further indicated that
    uncalibrated models frequently exhibit overconfidence. This includes logistic
    regression, which tends to be systematically optimistic, although to a lesser
    extent.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 研究的发现强调，校准不当的模型往往表现出过度自信，即使是比其他模型更校准的逻辑回归，也可能表现出系统性的乐观。这突出了评估和增强模型校准的必要性，以避免不必要的自信，并基于准确的概率预测做出明智的决策。研究进一步指出，未校准的模型通常也表现出过度自信。这包括逻辑回归，虽然系统性的乐观程度较低，但仍然存在。
- en: Open source tools for conformal prediction in classification problems
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分类问题中的校准预测的开源工具
- en: While deep-diving into the intricacies of conformal prediction for classification,
    it has become evident that the right tools can significantly enhance our implementation
    efficiency. Recognizing this, the open source community has made remarkable contributions
    by providing various tools tailored for this purpose. In this section, we will
    explore some of the prominent open source tools for conformal prediction that
    can seamlessly integrate into your projects and elevate your predictive capabilities.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究分类问题中的一致性预测的复杂性时，已经很明显，合适的工具可以显著提高我们的实施效率。认识到这一点，开源社区通过提供针对此目的定制的各种工具做出了显著的贡献。在本节中，我们将探讨一些突出的开源校准预测工具，这些工具可以无缝集成到你的项目中，并提升你的预测能力。
- en: Nonconformist
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nonconformist
- en: '`nonconformist` ([https://github.com/donlnz/nonconformist](https://github.com/donlnz/nonconformist))
    is a classical conformal prediction package that can be used for conformal prediction
    in classification problems.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`nonconformist`([https://github.com/donlnz/nonconformist](https://github.com/donlnz/nonconformist))是一个经典的校准预测包，可用于分类问题中的校准预测。'
- en: 'Let’s illustrate how to create an ICP using `nonconformist`. You can find the
    Jupyter notebook containing the relevant code at [https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb):'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过`nonconformist`来展示如何创建一个ICP。你可以在这里找到包含相关代码的Jupyter笔记本：[https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_06.ipynb)：
- en: 'You can find the `nonconformist` documentation here: http://donlnz.github.io/nonconformist/index.html.
    First, we will install `nonconformist` using the standard functionality – that
    is, `pip install`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在这里找到`nonconformist`的文档：http://donlnz.github.io/nonconformist/index.html。首先，我们将使用标准功能安装`nonconformist`——即`pip
    install`：
- en: '[PRE0]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can import the relevant modules as follows:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以按照以下方式导入相关模块：
- en: '[PRE1]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this case, we created an ICP with a margin nonconformity measure; we looked
    at this in previous chapters. This ICP uses logistic regression as the underlying
    classifier:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个案例中，我们创建了一个具有公差度量指标的ICP；我们已在之前的章节中讨论了这一点。此ICP使用逻辑回归作为基础分类器：
- en: '[PRE6]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we must fit the ICP using the proper training set and calibrate it using
    the calibration set:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须使用适当的训练集来拟合ICP，并使用校准集来校准它：
- en: '[PRE7]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Using the trained model, we can obtain the predicted class scores on the calibration
    and test sets:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练好的模型，我们可以在校准集和测试集上获得预测的类别得分：
- en: '[PRE9]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the notebook, we use a bank marketing dataset ([https://archive.ics.uci.edu/dataset/222/bank+marketing](https://archive.ics.uci.edu/dataset/222/bank+marketing))
    related to the direct marketing campaigns of a Portuguese banking institution.
    This dataset contains the following features:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中，我们使用了一个与葡萄牙银行机构的直接营销活动相关的银行营销数据集（[https://archive.ics.uci.edu/dataset/222/bank+marketing](https://archive.ics.uci.edu/dataset/222/bank+marketing)）。此数据集包含以下特征：
- en: '`age` (numeric)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`（数值）'
- en: '`job`: Type of job (categorical: `admin`, `unknown`, `unemployed`, `management`,
    `housemaid`, `entrepreneur`, `student`, `blue-collar`, `self-employed`, `retired`,
    `technician`, or `services`)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job`: 职业类型（分类：`行政`、`未知`、`失业`、`管理`、`家政`、`企业家`、`学生`、`蓝领`、`自雇`、`退休`、`技术人员` 或
    `服务行业`)'
- en: '`marital`: Marital status (categorical: `married`, `divorced`, or `single`;
    note that `divorced` means divorced or widowed)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`marital`: 婚姻状况（分类：`已婚`、`离婚` 或 `单身`；注意，`离婚` 表示离婚或丧偶）'
- en: '`education` (categorical: `unknown`, `secondary`, `primary`, or `tertiary`)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`education`（分类：`未知`、`中学`、`小学` 或 `大学`)'
- en: '`default`: Has credit in default? (binary: `yes` or `no`)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`default`: 是否有信用违约？（二进制：`是` 或 `否`)'
- en: '`balance`: Average yearly balance, in euros (numeric)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`balance`: 平均年度余额，以欧元为单位（数值）'
- en: '`housing`: Has a housing loan? (binary: `yes` or `no`)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`housing`: 是否有住房贷款？（二进制：`是` 或 `否`)'
- en: '`loan`: Has a personal loan? (binary: `yes` or `no`)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loan`: 是否有个人贷款？（二进制：`是` 或 `否`)'
- en: 'The following features are related to the last contact of the current campaign:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以下特征与当前活动的最后联系相关：
- en: '`contact`: Contact communication type (categorical: `unknown`, `telephone`,
    and `cellular`)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contact`: 联系沟通类型（分类：`未知`、`电话` 和 `手机`)'
- en: '`day`: Last contact day of the month (numeric)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`day`: 月份最后联系日（数值）'
- en: '`month`: Last contact month of the year (categorical: `jan`, `feb`, `mar`,
    ..., `nov`, `dec`)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`month`: 年度最后联系月份（分类：`jan`、`feb`、`mar`、...、`nov`、`dec`)'
- en: '`duration`: Last contact duration, in seconds (numeric)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`duration`: 最后联系持续时间，以秒为单位（数值）'
- en: 'The other attributes are as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 其他属性如下：
- en: '`campaign`: Number of contacts performed during this campaign and for this
    client (numeric; this includes the last contact)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`campaign`: 在此活动中为此客户进行的联系次数（数值；这包括最后联系）'
- en: '`pdays`: The number of days that passed by after the client was last contacted
    from a previous campaign (numeric; `-1` means that the client was not previously
    contacted)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pdays`: 客户上次被联系后经过的天数（数值；`-1` 表示客户之前未被联系）'
- en: '`previous`: The number of contacts performed before this campaign and for this
    client (numeric)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`previous`: 在此活动之前为此客户进行的联系次数（数值）'
- en: '`poutcome`: The outcome of the previous marketing campaign (categorical: `unknown`,
    `other`, `failure`, or `success`)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`poutcome`: 上一次营销活动的结果（分类：`未知`、`其他`、`失败` 或 `成功`)'
- en: 'The output variable (the desired target) is `y` – has the client subscribed
    to a term deposit? (Binary: `yes`, `no`.)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 输出变量（期望的目标）是 `y` – 客户是否订阅了定期存款？（二进制：`是`、`否`。）
- en: The objective is to predict the `Class` target variable to indicate whether
    the marketing campaign was successful in terms of whether the client subscribed
    to a term deposit. The dataset is mildly imbalanced with ~12% of clients subscribing
    to a term deposit as a result of the marketing campaign.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是预测 `Class` 目标变量，以指示营销活动是否成功，即客户是否因营销活动而订阅了定期存款。数据集略微不平衡，大约有12%的客户因营销活动而订阅了定期存款。
- en: 'We will use OpenML API to access and read the dataset. As discussed in previous
    chapters, ICP requires a separate calibration set that should not be used to train
    the underlying machine learning classifier. In the following code, we’re creating
    three datasets – *the proper training dataset for the classifier*, *calibration
    datasets to calibrate the classifier using ICP*, and *the test dataset that will
    be used to evaluate the performance*. The dataset contains 45,211 instances; we
    must split it so that it has 1,000 instances for each of the training and calibration
    sets:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we can build the underlying classifier using logistic regression and compute
    the accuracy and ROC AUC on the test set:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s train logistic regression using standard scikit-learn functionality:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we must use the trained logistic regression classifier model to predict
    class labels and obtain class scores on the calibration and test sets:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, compute the classification accuracy and ROC AUC on the test set:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So far, we have only used standard classification functionality. Now, let’s
    build ICP using `nonconformist`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must create ICP classifiers by using a wrapper from `nonconformist`:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This code snippet constructs an ICP using logistic regression as the underlying
    machine learning model. Here’s a breakdown of what’s happening:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`` `LogisticRegression()` ``: This is a classifier from the scikit-learn library
    in Python that’s used for binary classification tasks. It predicts the class score
    of an instance belonging to a particular class.'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`` `ClassifierAdapter(LogisticRegression())` ``: This wraps the logistic regression
    model so that it’s compatible with the nonconformity scorer. The adapter makes
    sure that the underlying classifier’s methods align with the expectations of the
    nonconformity scorer.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`` `ClassifierNc(ClassifierAdapter(LogisticRegression()))` ``: Here, a nonconformity
    scorer is created. Nonconformity scorers, in the context of conformal prediction,
    are used to measure how much an instance deviates from the norm according to the
    training data. In this case, `ClassifierNc` is using `ClassifierAdapter` to create
    a scorer that measures nonconformity based on the logistic regression classifier.'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`` `MarginErrFunc()` ``: This is the nonconformity measure we have looked at
    in previous chapters. In `nonconformist`, the margin error is defined as 0.5 −
    ˆ P(y i ∣ x) − max y!=y i  ˆ P(y ∣ x)  _____________ 2 .'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`` ` [PRE24]'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: icp.fit(X_train, y_train)
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: icp.calibrate(X_calib, y_calib)
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Produce predictions for the test set, with confidence 95%
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: prediction = icp.predict(X_test.values, significance=0.05)
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '```'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that `nonconformist` uses classical conformal prediction and outputs prediction
    sets.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '`nonconformist` is a Python library built on top of scikit-learn that focuses
    on implementing conformal prediction methods for classification tasks. It provides
    a comprehensive set of tools and algorithms to generate prediction intervals,
    estimate uncertainty, and enhance calibration in classification models. Here is
    an overview of the main features and capabilities of the `nonconformist` library:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`nonconformist` 是一个基于 scikit-learn 构建的 Python 库，专注于实现分类任务的一致性预测方法。它提供了一套全面的工具和算法，用于生成预测区间、估计不确定性和增强分类模型中的校准。以下是
    `nonconformist` 库的主要功能和能力概述：'
- en: '`nonconformist` offers various conformal prediction algorithms specifically
    designed for classification. These algorithms include the following:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonconformist` 提供了专门为分类设计的一致性预测算法。这些算法包括以下内容：'
- en: '**Inductive conformal classifier** (**ICC**): This constructs a nonconformity
    measure and a prediction region based on the training set'
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归纳一致性分类器**（**ICC**）：这基于训练集构建非一致性度量和一个预测区域'
- en: '**Transductive conformal classifier** (**TCC**): This incorporates the test
    set into the construction of prediction regions'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传递性一致性分类器**（**TCC**）：这将在预测区域的构建中将测试集纳入其中'
- en: '**Venn predictors**: This generates prediction intervals using nested Venn
    regions to control the number of false positives'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Venn 预测器**：这通过嵌套 Venn 区域生成预测区间，以控制假阳性的数量'
- en: '**Random forest conformal predictor**: This utilizes a random forest model
    as the underlying classifier for conformal prediction'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林一致性预测器**：这利用随机森林模型作为一致性预测的底层分类器'
- en: '`nonconformist` seamlessly integrates with scikit-learn, allowing users to
    leverage scikit-learn’s extensive collection of classifiers. It provides a wrapper
    class that allows scikit-learn classifiers to be used within the conformal prediction
    framework.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonconformist` 与 scikit-learn 无缝集成，使用户能够利用 scikit-learn 丰富的分类器集合。它提供了一个包装类，允许在一致性预测框架中使用
    scikit-learn 分类器。'
- en: '`nonconformist` also offers tools to assess the calibration quality, such as
    reliability diagrams.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonconformist` 还提供了评估校准质量的工具，例如可靠性图。'
- en: '`nonconformist` provides evaluation metrics to assess the performance of conformal
    prediction models. These metrics include accuracy, error rate, p-values, and efficiency
    measures, enabling thorough evaluation and comparison of different models.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonconformist` 提供评估指标来评估一致性预测模型的性能。这些指标包括准确率、错误率、p值和效率度量，使得对不同模型进行彻底的评估和比较成为可能。'
- en: '**Cross-validation support**: The library offers support for performing cross-validation
    with conformal prediction models. This enables robust evaluation and validation
    of the models across different folds of the dataset.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证支持**：该库提供了对使用一致性预测模型进行交叉验证的支持。这使得模型能够在数据集的不同折叠中进行稳健的评估和验证。'
- en: '`nonconformist` is a powerful tool for applying conformal prediction techniques
    to classification problems. With its extensive range of algorithms, compatibility
    with scikit-learn, calibration and uncertainty estimation capabilities, evaluation
    metrics, and cross-validation support, `nonconformist` provides a comprehensive
    framework for implementing and evaluating conformal prediction models in classification
    tasks. It is a valuable resource for researchers and practitioners looking to
    incorporate conformal prediction into their classification projects.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`nonconformist` 是将一致性预测技术应用于分类问题的强大工具。凭借其广泛的算法、与 scikit-learn 的兼容性、校准和不确定性估计能力、评估指标以及交叉验证支持，`nonconformist`
    为实现和评估分类任务中的一致性预测模型提供了一个全面的框架。它是研究人员和实践者将一致性预测纳入其分类项目的宝贵资源。'
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we embarked on an enlightening exploration of conformal prediction
    specifically tailored to classification tasks. We began by underscoring the significance
    of calibration in the realm of classification, emphasizing its role in ensuring
    the reliability and trustworthiness of model predictions. Through our journey,
    we were introduced to various calibration methods, including the various approaches
    to conformal prediction. We observed how conformal prediction uniquely addresses
    the challenges of calibration, providing both a theoretical and practical edge
    over traditional methods.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们开始了一次针对分类任务的共形预测的启发式探索。我们首先强调了校准在分类领域的重要性，强调了它在确保模型预测的可靠性和可信度方面的作用。在我们的旅程中，我们了解了各种校准方法，包括共形预测的各种方法。我们观察到，共形预测独特地解决了校准的挑战，为传统方法提供了理论和实践上的优势。
- en: We also delved into the nuanced realms of Venn-ABERS predictors, shedding light
    on their roles and implications in the calibration process.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还深入探讨了Venn-ABERS预测器的微妙领域，揭示了它们在校准过程中的作用和影响。
- en: Lastly, we underscored the invaluable contribution of the open source community
    in this domain. We highlighted tools such as the `nonconformist` library, which
    serve as essential resources for practitioners who are keen on implementing conformal
    prediction in their classification challenges.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们强调了开源社区在这一领域的宝贵贡献。我们突出了如`nonconformist`库等工具，这些工具对于热衷于在他们的分类挑战中实施共形预测的从业者来说是必不可少的资源。
- en: As we conclude this chapter, it’s evident that calibration, and more specifically
    conformal prediction, plays a pivotal role in enhancing the robustness and reliability
    of classification models. With the tools and knowledge we have at our disposal,
    we’re well equipped to tackle classification problems with greater confidence
    and precision.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 随着本章的结束，很明显，校准，尤其是共形预测，在增强分类模型的鲁棒性和可靠性方面发挥着关键作用。凭借我们手头的工具和知识，我们已充分准备，以更大的信心和精确度应对分类问题。
- en: In the next chapter, we will cover conformal prediction for regression problems.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍回归问题的共形预测。
