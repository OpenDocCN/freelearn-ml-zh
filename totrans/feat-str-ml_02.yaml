- en: 'Chapter 1: An Overview of the Machine Learning Life Cycle'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章：机器学习生命周期概述
- en: '**Machine learning** (**ML**) is a subfield of computer science that involves
    studying and exploring computer algorithms that can learn the structure of data
    using statistical analysis. The dataset that''s used for learning is called training
    data. The output of training is called a model, which can then be used to run
    predictions against a new dataset that the model hasn''t seen before. There are
    two broad categories of machine learning: **supervised learning** and **unsupervised
    learning**. In supervised learning, the training dataset is labeled (the dataset
    will have a target column). The algorithm intends to learn how to predict the
    target column based on other columns (features) in the dataset. Predicting house
    prices, stock market changes, and customer churn are some supervised learning
    examples. In unsupervised learning, on the other hand, the data is not labeled
    (the dataset will not have a target column). In this, the algorithm intends to
    recognize the common patterns in the dataset. One of the methods of generating
    labels for an unlabeled dataset is using unsupervised learning algorithms. Anomaly
    detection is one of the use cases for unsupervised learning.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）是计算机科学的一个子领域，涉及研究和探索可以使用统计分析学习数据结构的计算机算法。用于学习的数据集称为训练数据。训练的输出称为模型，然后可以用来对新数据集进行预测，该数据集模型之前未曾见过。机器学习有两个广泛的类别：**监督学习**和**无监督学习**。在监督学习中，训练数据集被标记（数据集将有一个目标列）。算法旨在根据数据集中的其他列（特征）来学习如何预测目标列。预测房价、股市变化和客户流失是一些监督学习的例子。另一方面，在无监督学习中，数据未标记（数据集将没有目标列）。在这种情况下，算法旨在识别数据集中的共同模式。为未标记数据集生成标签的一种方法是使用无监督学习算法。异常检测是无监督学习的一个用例。'
- en: 'The idea of the first mathematical model for machine learning was presented
    in 1943 by Walter Pitts and Warren McCulloch (*The History of Machine Learning:
    How Did It All Start?* – [https://labelyourdata.com/articles/history-of-machine-learning-how-did-it-all-start](https://labelyourdata.com/articles/history-of-machine-learning-how-did-it-all-start)).
    Later, in the 1950s, Arthur Samuel developed a program for playing championship-level
    computer checkers. Since then, we have come a long way in ML. I would highly recommend
    reading this article if you haven''t.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习第一个数学模型的想法是在 1943 年由沃尔特·皮茨和沃伦·麦卡洛克提出的（[《机器学习的历史：这一切是如何开始的？》](https://labelyourdata.com/articles/history-of-machine-learning-how-did-it-all-start)）。后来，在
    1950 年代，阿瑟·塞缪尔开发了一个玩冠军级电脑跳棋的程序。从那时起，我们在机器学习领域已经取得了长足的进步。如果你还没有阅读这篇文章，我强烈推荐你阅读。
- en: 'Today, as we try to teach real-time decision-making to systems and devices,
    ML engineer and data scientist positions are the hottest jobs on the market. It
    is predicted that the global machine learning market will grow from $8.3 billion
    in 2019 to $117.9 billion by 2027\. As shown in the following diagram, it''s a
    unique skill set that overlaps with multiple domains:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们试图向系统和设备教授实时决策时，机器学习工程师和数据科学家职位是市场上最热门的工作。预计到 2027 年，全球机器学习市场规模将从 2019
    年的 83 亿美元增长到 1179 亿美元。如下所示，这是一组独特的技能集，与多个领域重叠：
- en: '![Figure 1.1 – ML/data science skill sets'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.1 – 机器学习/数据科学技能集'
- en: '](img/B18024_01_01.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_01.jpg)'
- en: Figure 1.1 – ML/data science skill sets
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 机器学习/数据科学技能集
- en: 'In 2007 and 2008, the DevOps movement revolutionized the way software was developed
    and operationalized. It reduced the time to production for software:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2007 年和 2008 年，DevOps 运动彻底改变了软件开发和运营的方式。它缩短了软件的生产时间：
- en: '![Figure 1.2 – DevOps'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.2 – DevOps](img/B18024_01_02.jpg)'
- en: '](img/B18024_01_02.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_01.jpg)'
- en: Figure 1.2 – DevOps
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – DevOps
- en: 'Similarly, to take a model from experimentation to operationalization, we need
    a set of standardized processes that makes this process seamless. Well, the answer
    to that is **machine learning operations** (**MLOps**). Many experts in the industry
    have come across a set of patterns that would reduce the time to production of
    ML models. 2021 is the year of MLOps – there are a lot of new start-ups that are
    trying to cater to the ML needs of the firms that are still behind in the ML journey.
    We can assume that this will expand over time and only get better, just like any
    other process. As we grow with it, there will be a lot of discoveries and ways
    of working, best practices, and more will evolve. In this book, we will talk about
    one of the common tools that''s used to standardize ML and its best practices:
    the feature store.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，要将模型从实验阶段过渡到实际应用，我们需要一套标准化的流程，使这一过程无缝进行。嗯，对此的答案是**机器学习运维**（**MLOps**）。许多行业专家已经发现了一套可以缩短ML模型生产时间的模式。2021年是MLOps的一年——有很多新成立的初创公司正在试图满足那些在ML道路上落后的公司的ML需求。我们可以假设随着时间的推移，这将会不断扩大并变得更好，就像任何其他过程一样。随着我们的成长，将会出现许多发现和工作方式，最佳实践，以及更多将逐步发展。在这本书中，我们将讨论一个用于标准化ML及其最佳实践的常用工具：特征存储。
- en: Before we discuss what a feature store is and how to use it, we need to understand
    the ML life cycle and its common oversights. I want to dedicate this chapter to
    learning about the different stages of the ML life cycle. As part of this chapter,
    we will take up an ML model-building exercise. We won't dive deep into the ML
    model itself, such as its algorithms or how to do feature engineering; instead,
    we will focus on the stages an ML model would typically go through, as well as
    the difficulties involved in model building versus model operationalization. We
    will also discuss the stages that are time-consuming and repetitive. The goal
    of this chapter is to understand the overall ML life cycle and the issues involved
    in operationalizing models. This will set the stage for later chapters, where
    we will discuss feature management, the role of a feature store in ML, and how
    the feature store solves some of the issues we will discuss in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论特征存储是什么以及如何使用它之前，我们需要了解机器学习生命周期及其常见疏忽。我想将本章奉献给学习机器学习生命周期的不同阶段。作为本章的一部分，我们将进行一个ML模型构建练习。我们不会深入探讨ML模型本身，如其算法或如何进行特征工程；相反，我们将关注ML模型通常会经历的阶段，以及模型构建与模型运维中涉及的困难。我们还将讨论耗时且重复的阶段。本章的目标是理解整体机器学习生命周期和模型运维中存在的问题。这将为本章后续章节奠定基础，我们将讨论特征管理、特征存储在ML中的作用，以及特征存储如何解决本章中我们将讨论的一些问题。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The ML life cycle in practice
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践中的机器学习生命周期
- en: An ideal world versus the real world
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想世界与真实世界
- en: The most time-consuming stages of ML
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中最耗时的阶段
- en: Without further ado, let's get our hands dirty with an ML model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 不再拖延，让我们动手实践一个ML模型。
- en: Technical requirements
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow the code examples in this book, you need to be familiar with Python
    and any notebook environment, which could be a local setup such as Jupyter or
    an online notebook environment such as Google Colab or Kaggle. We will be using
    the Python3 interpreter and PIP3 to manage the virtual environment. You can download
    the code examples for this chapter from the following GitHub link: [https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter01](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter01).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本书中的代码示例，您需要熟悉Python和任何笔记本环境，这可以是本地设置，如Jupyter，或在线笔记本环境，如Google Colab或Kaggle。我们将使用Python3解释器和PIP3来管理虚拟环境。您可以从以下GitHub链接下载本章的代码示例：[https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter01](https://github.com/PacktPublishing/Feature-Store-for-Machine-Learning/tree/main/Chapter01)。
- en: The ML life cycle in practice
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中的机器学习生命周期
- en: As Jeff Daniel's character in HBO's *The Newsroom* once said, the first step
    in solving any problem is recognizing there is one. Let's follow this knowledge
    and see if it works for us.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如HBO的《新闻室》中杰夫·丹尼尔斯的角色所说，解决任何问题的第一步是认识到问题的存在。让我们遵循这一知识，看看它对我们是否适用。
- en: 'In this section, we''ll pick a problem statement and execute the ML life cycle
    step by step. Once completed, we''ll retrospect and identify any issues. The following
    diagram shows the different stages of ML:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将选择一个问题陈述并逐步执行机器学习生命周期。一旦完成，我们将回顾并识别任何问题。以下图表显示了机器学习的不同阶段：
- en: '![Figure 1.3 – The ML life cycle'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.3 – 机器学习生命周期'
- en: '](img/B18024_01_03.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_03.jpg)'
- en: Figure 1.3 – The ML life cycle
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 机器学习生命周期
- en: Let's take a look at our problem statement.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下我们的问题陈述。
- en: Problem statement (plan and create)
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述（计划和创建）
- en: 'For this exercise, let''s assume that you own a retail business and would like
    to improve customer experience. First and foremost, you want to find your customer
    segments and customer **lifetime value (LTV)**. If you have worked in the domain,
    you probably know different ways to solve this problem. I will follow a medium
    blog series called *Know Your Metrics – Learn what and how to track with Python*
    by Barış Karaman (https://towardsdatascience.com/data-driven-growth-with-python-part-1-know-your-metrics-812781e66a5b).
    You can go through the article for more details. Feel free to try it out for yourself.
    The dataset is available here: [https://www.kaggle.com/vijayuv/onlineretail](https://www.kaggle.com/vijayuv/onlineretail).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，让我们假设你拥有一家零售业务，并希望提高客户体验。首先，你想要找到你的客户细分和客户**终身价值（LTV）**。如果你在这个领域工作过，你可能知道不同的方法来解决这个问题。我将遵循Barış
    Karaman的中等博客系列*了解你的指标 – 学习如何使用Python跟踪什么和如何跟踪*（https://towardsdatascience.com/data-driven-growth-with-python-part-1-know-your-metrics-812781e66a5b）。你可以阅读这篇文章以获取更多详细信息。欢迎你自己尝试。数据集在此处可用：[https://www.kaggle.com/vijayuv/onlineretail](https://www.kaggle.com/vijayuv/onlineretail)。
- en: Data (preparation and cleaning)
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据（准备和清理）
- en: 'First, let''s install the `pandas` package:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们安装`pandas`包：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s make the dataset available to our notebook environment. To do that,
    download the dataset to your local system, then perform either of the following
    steps, depending on your setup:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将数据集提供给我们的笔记本环境。为此，请将数据集下载到您的本地系统，然后根据您的设置执行以下步骤之一：
- en: '`.csv` file and give it as input to the `pd.read_csv` method.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`.csv`文件作为输入传递给`pd.read_csv`方法。
- en: '**Google Colab**: Upload the dataset by clicking on the folder icon and then
    the upload icon from the left navigation menu.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Colab**：通过点击左侧导航菜单中的文件夹图标和上传图标来上传数据集。'
- en: 'Let''s preview the dataset:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们预览一下数据集：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output of the preceding code block is as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块的结果如下：
- en: '![Figure 1.4 – Dataset preview'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – 数据集预览'
- en: '](img/B18024_01_04.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_04.jpg)'
- en: Figure 1.4 – Dataset preview
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 数据集预览
- en: 'As you can see, the dataset includes customer transaction data. The dataset
    consists of eight columns, apart from the index column, which is unlabeled:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，数据集包括客户交易数据。除了未标记的索引列外，数据集由八个列组成：
- en: '`InvoiceNo`: A unique order ID; the data is of the `integer` type'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InvoiceNo`：唯一的订单ID；数据类型为`整数`'
- en: '`StockCode`: The unique ID of the product; the data is of the `string` type'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StockCode`：产品的唯一ID；数据类型为`字符串`'
- en: '`Description`: The product''s description; the data is of the `string` type'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Description`：产品的描述；数据类型为`字符串`'
- en: '`Quantity`: The number of units of the product that have been ordered'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Quantity`：已订购产品的单位数量'
- en: '`InvoiceDate`: The date when the invoice was generated'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InvoiceDate`：发票生成日期'
- en: '`UnitPrice`: The cost of the product per unit'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`UnitPrice`：每单位产品的成本'
- en: '`CustomerID`: The unique ID of the customer who ordered the product'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CustomerID`：订购产品的客户的唯一ID'
- en: '`Country`: The country where the product was ordered'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Country`：产品订购的国家'
- en: Once you have the dataset, before jumping into feature engineering and model
    building, data scientists usually perform some exploratory analysis. The idea
    here is to check if the dataset you have is sufficient to solve the problem, identify
    missing gaps, check if there is any correlation in the dataset, and more.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了数据集，在跳入特征工程和模型构建之前，数据科学家通常会进行一些探索性分析。这里的想法是检查你拥有的数据集是否足够解决该问题，识别缺失的差距，检查数据集中是否存在任何相关性，等等。
- en: For the exercise, we'll calculate the monthly revenue and look at its seasonality.
    The following code block extracts year and month (`yyyymm`) information from the
    `InvoiceDate` column, calculates the `revenue` property of each transaction by
    multiplying the `UnitPrice` and `Quantity` columns, and aggregates the revenue
    based on the extracted year-month (`yyyymm`) column.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于练习，我们将计算月收入并查看其季节性。以下代码块从`InvoiceDate`列提取年份和月份（`yyyymm`）信息，通过乘以`UnitPrice`和`Quantity`列来计算每笔交易的`revenue`属性，并根据提取的年月（`yyyymm`）列汇总收入。
- en: 'Let''s continue from the preceding code statement:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从上一条代码语句继续：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding code will output the following DataFrame:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将输出以下数据框：
- en: '![Figure 1.5 – Revenue DataFrame'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.5 – 收入数据框'
- en: '](img/B18024_01_05.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_05.jpg)'
- en: Figure 1.5 – Revenue DataFrame
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 收入数据框
- en: 'Let''s visualize the `revenue` DataFrame. I will be using a library called
    `plotly`. The following command will install `plotly` in your notebook environment:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化`revenue`数据框。我将使用一个名为`plotly`的库。以下命令将在您的笔记本环境中安装`plotly`：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s plot a bar graph from the `revenue` DataFrame with the `yyyymm` column
    on the *x* axis and `revenue` on the *y* axis:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制一个条形图，从`revenue`数据框中，将`yyyymm`列放在*x*轴上，将`revenue`放在*y*轴上：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding codes sort the revenue DataFrame on the `yyyymm` column and plot
    a bar graph of `revenue` against the year-month (`yyyymm`) column, as shown in
    the following screenshot. As you can see, September, October, and November are
    high revenue months. It would have been good to validate our assumption against
    a few years of data, but unfortunately, we don''t have that. Before we move on
    to model development, let''s look at one more metric – the monthly active customers
    – and see if it''s co-related to monthly revenue:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码按`yyyymm`列对收入数据框进行排序，并绘制了`revenue`与年月（`yyyymm`）列的条形图，如下面的截图所示。如您所见，九月、十月和十一月是高收入月份。本应验证我们的假设与几年的数据，但不幸的是，我们没有这些数据。在我们继续到模型开发之前，让我们看一下另一个指标——每月活跃客户——并看看它是否与每月收入相关：
- en: '![Figure 1.6 – Monthly revenue'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.6 – 每月收入'
- en: '](img/B18024_01_06.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_06.jpg)'
- en: Figure 1.6 – Monthly revenue
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 – 每月收入
- en: 'Continuing in the same notebook, the following commands will calculate the
    monthly active customers by aggregating a count of unique `CustomerID` on the
    year-month (`yyyymm`) column:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一笔记本中继续，以下命令将通过在年月（`yyyymm`）列上聚合唯一的`CustomerID`计数来计算每月活跃客户：
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The preceding code will produce the following output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '![Figure 1.7 – Monthly active customers DataFrame'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.7 – 每月活跃客户数据框'
- en: '](img/B18024_01_07.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_07.jpg)'
- en: Figure 1.7 – Monthly active customers DataFrame
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – 每月活跃客户数据框
- en: 'Let''s plot the preceding DataFrame in the same way that we did for monthly
    revenue:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以前面的方式绘制前面的数据框：
- en: '[PRE28]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding command plots a bar graph of `No of Active customers` against
    the year-month (`yyyymm`) column. As shown in the following screenshot, `Monthly
    Active customers` is positively related to the monthly revenue shown in the preceding
    screenshot:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令绘制了`No of Active customers`与年月（`yyyymm`）列的条形图。如下面的截图所示，`每月活跃客户`与前面截图所示的每月收入呈正相关：
- en: '![Figure 1.8 – Monthly active customers'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.8 – 每月活跃客户'
- en: '](img/B18024_01_08.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B18024_01_08.jpg)'
- en: Figure 1.8 – Monthly active customers
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 – 每月活跃客户
- en: In the next section, we'll build a customer LTV model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将构建一个客户LTV模型。
- en: Model
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: 'Now that we have finished exploring the data, let''s build the LTV model. **Customer
    lifetime value** (**CLTV**) is defined as *the net profitability associated with
    a customer''s life cycle with the company. Simply put, CLV/LTV is a projection
    for what each customer is worth to a business* (reference: [https://www.toolbox.com/marketing/customer-experience/articles/what-is-customer-lifetime-value-clv/](https://www.toolbox.com/marketing/customer-experience/articles/what-is-customer-lifetime-value-clv/)).
    There are different ways to predict lifetime value. One could be predicting the
    value of a customer, which is a regression problem, while another way could be
    predicting the customer group, which is a classification problem. In this exercise,
    we will use the latter approach.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了数据探索，让我们构建LTV模型。**客户终身价值**（**CLTV**）定义为与客户在公司生命周期中相关的**净盈利**。简单来说，CLV/LTV是对每个客户对业务价值的预测（参考：[https://www.toolbox.com/marketing/customer-experience/articles/what-is-customer-lifetime-value-clv/](https://www.toolbox.com/marketing/customer-experience/articles/what-is-customer-lifetime-value-clv/))。预测终身价值有不同的方法。一种可能是预测客户的值，这是一个回归问题，另一种可能是预测客户群体，这是一个分类问题。在这个练习中，我们将使用后者方法。
- en: 'For this exercise, we will segment customers into the following groups:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们将把客户分为以下几组：
- en: '**Low LTV**: Less active or low revenue customers'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低LTV**：不太活跃或收入较低的客户'
- en: '**Mid-LTV**: Fairly active and moderate revenue customers'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中LTV**：相当活跃且收入适中的客户'
- en: '**High LTV**: High revenue customers – the segment that we don''t want to lose'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高LTV**：高收入客户 – 我们不希望失去的细分市场'
- en: We will be using 3 months worth of data to calculate the **recency** (**R**),
    **frequency** (**F**), and **monetary** (**M**) metrics of the customers to generate
    features. Once we have these features, we will use 6 months worth of data to calculate
    the revenue of every customer and generate LTV cluster labels (low LTV, mid-LTV,
    and high LTV). The generated labels and features will then be used to train an
    XGBoost model that can be used to predict the group of new customers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用3个月的数据来计算客户的**最近度**（**R**）、**频率**（**F**）和**货币**（**M**）指标，以生成特征。一旦我们有了这些特征，我们将使用6个月的数据来计算每个客户的收入并生成LTV聚类标签（低LTV、中LTV和高LTV）。生成的标签和特征将被用于训练一个XGBoost模型，该模型可以用来预测新客户的群体。
- en: Feature engineering
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Let''s continue our work in the same notebook, calculate the R, F, and M values
    for the customers, and group our customers based on a value that''s been calculated
    from the individual R, F, and M scores:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在同一个笔记本中继续我们的工作，计算客户的R、F和M值，并根据从个人R、F和M分数计算出的值对客户进行分组：
- en: '**Recency (R)**: The recency metric represents how many days have passed since
    the customer made their last purchase.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最近度（R）**：最近度指标表示客户上次购买以来过去了多少天。'
- en: '**Frequency (F)**: As the term suggests, F represents how many times the customer
    made a purchase.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率（F）**：正如术语所暗示的，F代表客户进行了多少次购买。'
- en: '**Monetary (M)**: How much revenue a particular customer brought in.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**货币（M）**：特定客户带来的收入。'
- en: 'Since the spending and purchase patterns of customers differ based on demographic
    location, we will only consider the data that belongs to the United Kingdom for
    this exercise. Let''s read the `OnlineRetails.csv` file and filter out the data
    that doesn''t belong to the United Kingdom:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户的消费和购买模式根据人口统计地理位置的不同而有所不同，因此在这个练习中，我们只考虑属于英国的数据。让我们读取`OnlineRetails.csv`文件，并过滤掉不属于英国的数据：
- en: '[PRE34]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In the following code block, we will create two different DataFrames. The first
    one (`uk_data_3m`) will be for `InvoiceDate` between `2011-03-01` and `2011-06-01`.
    This DataFrame will be used to generate the RFM features. The second DataFrame
    (`uk_data_6m`) will be for `InvoiceDate` between `2011-06-01` and `2011-12-01`.
    This DataFrame will be used to generate the target column for model training.
    In this exercise, the target column is LTV groups/clusters. Since we are calculating
    the customer LTV group, a larger time interval would give a better grouping. Hence,
    we will be using 6 months worth of data to generate the LTV group labels:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们将创建两个不同的DataFrame。第一个（`uk_data_3m`）将用于`InvoiceDate`在`2011-03-01`和`2011-06-01`之间的数据。这个DataFrame将用于生成RFM特征。第二个DataFrame（`uk_data_6m`）将用于`InvoiceDate`在`2011-06-01`和`2011-12-01`之间的数据。这个DataFrame将用于生成模型训练的目标列。在这个练习中，目标列是LTV组/聚类。由于我们正在计算客户LTV组，较大的时间间隔将给出更好的分组。因此，我们将使用6个月的数据来生成LTV组标签：
- en: '[PRE43]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now that we have two different DataFrames, let''s calculate the RFM values
    using the `uk_data_3m` DataFrame. The following code block calculates the `revenue`
    column by multiplying `UnitPrice` with `Quantity`. To calculate the RFM values,
    the code block performs three aggregations on `CustomerID`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个不同的 DataFrame，让我们使用 `uk_data_3m` DataFrame 来计算 RFM 值。以下代码块通过将 `UnitPrice`
    与 `Quantity` 相乘来计算 `revenue` 列。为了计算 RFM 值，代码块对 `CustomerID` 执行了三次聚合：
- en: To calculate `max_date` in the DataFrame must be calculated and for every customer,
    we must calculate `R = max_date – x.max()`, where `x.max()` calculates the latest
    `InvoiceDate` of a specific `CustomerID`.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要在 DataFrame 中计算 `max_date`，必须计算每个客户的 `R = max_date – x.max()`，其中 `x.max()`
    计算特定 `CustomerID` 的最新 `InvoiceDate`。
- en: To calculate `count` the number of invoices for a specific `CustomerID`.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算特定 `CustomerID` 的发票数量 `count`。
- en: To calculate `sum` value of `revenue` for a specific `CustomerID`.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算特定 `CustomerID` 的 `revenue` 的 `sum` 值。
- en: 'The following code snippet performs this logic:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段执行此逻辑：
- en: '[PRE49]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Here, we have calculated the R, F, and M values for the customers. Next, we
    need to divide customers into the R, F, and M groups. This grouping defines where
    a customer stands concerning the other customers in terms of the R, F, and M metrics.
    To calculate the R, F, and M groups, we will divide the customers into equal-sized
    groups based on their R, F, and M values, respectively. These were calculated
    in the previous code block. To achieve this, we will use a method called `pd.qcut`
    ([https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html))
    on the DataFrame. Alternatively, you can use any *clustering* methods to divide
    customers into different groups. We will add the R, F, and M groups' values together
    to generate a single value called `RFMScore` that will range from 0 to 9\.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经计算了客户的 R、F 和 M 值。接下来，我们需要将客户分为 R、F 和 M 组。这种分组定义了客户在 R、F 和 M 指标方面相对于其他客户的位置。为了计算
    R、F 和 M 组，我们将根据他们的 R、F 和 M 值将客户分为大小相等的组。这些值在之前的代码块中已经计算。为了实现这一点，我们将使用名为 `pd.qcut`
    ([https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html))
    的方法在 DataFrame 上进行操作。或者，你可以使用任何 *聚类* 方法将客户分为不同的组。我们将把 R、F 和 M 组的值加起来，生成一个范围从 0
    到 9 的单个值，称为 `RFMScore`。
- en: In this exercise, the customers will be divided into four groups. The *elbow
    method* ([https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6](https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6))
    can be used to calculate the optimal number of groups for any dataset. The preceding
    link also contains information about alternative methods you can use to calculate
    the optimal number of groups, so feel free to try it out. I will leave that as
    an exercise for you.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，客户将被分为四个组。可以使用 *肘部方法* ([https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6](https://towardsdatascience.com/clustering-metrics-better-than-the-elbow-method-6926e1f723a6))
    来计算任何数据集的最佳组数。前面的链接还包含了关于你可以使用的其他计算最佳组数的替代方法的信息，所以请随意尝试。我将把它留给你作为练习。
- en: 'The following code block calculates `RFMScore`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '以下代码块计算 `RFMScore`:'
- en: '[PRE61]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The preceding code will generate the following output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将生成以下输出：
- en: '![Figure 1.9 – RFM score summary'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.9 – RFM 分数摘要'
- en: '](img/B18024_01_09.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_09.jpg)'
- en: Figure 1.9 – RFM score summary
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – RFM 分数摘要
- en: This summary data gives us a rough idea of how `RFMScore` is directly proportional
    to the `Recency`, `Frequency`, and `MonetaryValue` metrics. For example, the group
    with `RFMScore=0` has the highest mean recency (the last purchase day of this
    group is the farthest in past), the lowest mean frequency, and the lowest mean
    monetary value. On the other hand, the group with `RFMScore=9` has the lowest
    mean recency, highest mean frequency, and highest mean monetary value.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这份总结数据让我们对 `RFMScore` 如何与 `Recency`、`Frequency` 和 `MonetaryValue` 指标直接成比例有一个大致的了解。例如，`RFMScore=0`
    的组具有最高的平均最近度（该组的最后购买日是过去最远的），最低的平均频率和最低的平均货币价值。另一方面，`RFMScore=9` 的组具有最低的平均最近度，最高的平均频率和最高的平均货币价值。
- en: 'With that, we understand `RFMScore` is positively related to the value a customer
    brings to the business. So, let''s segment customers as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们了解到 `RFMScore` 与客户为业务带来的价值呈正相关。所以，让我们按照以下方式对客户进行细分：
- en: 0-3 => Low value
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0-3 => 低值
- en: 4-6 => Mid value
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4-6 => 中值
- en: 7-9 => High value
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-9 => 高值
- en: 'The following code labels customers as having either a low, mid, or high value:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将客户标记为低、中或高价值：
- en: '[PRE74]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Customer LTV
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户终身价值
- en: 'Now that we have RFM features ready for the customers in the DataFrame that
    contains 3 months worth of data, let''s use 6 months worth of data (`uk_data_6m)`
    to calculate the revenue of the customers, as we did previously, and merge the
    RFM features with the newly created revenue DataFrame:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了包含 3 个月数据的 DataFrame 中的客户 RFM 特征，让我们使用 6 个月的数据（`uk_data_6m`）来计算客户的收入，就像我们之前做的那样，并将
    RFM 特征与新创建的收入 DataFrame 合并：
- en: '[PRE79]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Feel free to plot `revenue_6m` against `RFMScore`. You will see a positive correlation
    between the two.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 随意绘制 `revenue_6m` 与 `RFMScore` 的关系图。您将看到两者之间存在正相关关系。
- en: 'In the flowing code block, we are using the `revenue_6m` columns, which is
    the *lifetime value of a customer*, and creating three groups called *Low LTV*,
    *Mid LTV*, and *High LTV* using K-means clustering. Again, you can verify the
    optimal number of clusters using the *elbow method* mentioned previously:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们使用 `revenue_6m` 列，这是客户的 *终身价值*，并使用 K-means 聚类创建三个组，分别称为 *低 LTV*、*中
    LTV* 和 *高 LTV*。同样，您可以使用之前提到的 *肘部方法* 来验证最佳簇数量：
- en: '[PRE90]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The preceding code block produces the following output:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块生成以下输出：
- en: '![Figure 1.10 – LTV cluster summary'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.10 – LTV 簇摘要'
- en: '](img/B18024_01_10.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_10.jpg)'
- en: Figure 1.10 – LTV cluster summary
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – LTV 簇摘要
- en: As you can see, the cluster with label 1 contains the group of customers whose
    lifetime value is very high since the mean revenue of the group is $14,123.309,
    whereas there are only 21 such customers. The cluster with label 0 contains the
    group of customers whose lifetime value is low since the mean revenue of the group
    is only $828.67, whereas there are 1,170 such customers. This grouping gives us
    an idea of which customers should always be kept happy.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，标签为 1 的簇包含了一组终身价值非常高的客户，因为该组的平均收入为 14,123.309，而这样的客户只有 21 位。标签为 0 的簇包含了一组终身价值较低的客户，因为该组的平均收入仅为
    828.67，而这样的客户有 1,170 位。这种分组让我们知道哪些客户应该始终保持满意。
- en: The feature set and model
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征集和模型
- en: 'Let''s build an XGBoost model using the features we have calculated so far
    so that the model can predict the LTV group of the customers, given the input
    features. The following is the final feature set that will be used as input for
    the model:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用到目前为止计算出的特征来构建 XGBoost 模型，以便模型可以根据输入特征预测客户的 LTV 组。以下是将作为模型输入使用的最终特征集：
- en: '[PRE96]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The preceding code block produces the following DataFrame. This includes the
    feature set that will be used to train the model:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块生成以下 DataFrame。这包括将用于训练模型的特征集：
- en: '![Figure 1.11 – Feature set for model training'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.11 – 模型训练特征集'
- en: '](img/B18024_01_11.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_11.jpg)'
- en: Figure 1.11 – Feature set for model training
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11 – 模型训练特征集
- en: Now, let's use this feature set to train the `Xgboost` model. The prediction
    label (`y`) is the `LTVCluster` column; the rest of the dataset except for the
    `Revenue_6m` and `CustomerID` columns are the `X` value. `Revenue_6m` will be
    dropped from the feature set as the `LTVCluster` column (`y`) is calculated using
    `Revenue_6m`. For the new customer, we can calculate other features without needing
    at least 6 months worth of data and also predict their `LTVCluster(y)`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用这个特征集来训练 `Xgboost` 模型。预测标签（`y`）是 `LTVCluster` 列；除了 `Revenue_6m` 和 `CustomerID`
    列之外的数据集是 `X` 值。由于 `LTVCluster` 列（`y`）是使用 `Revenue_6m` 计算的，所以 `Revenue_6m` 将从特征集中删除。对于新客户，我们可以在不需要至少
    6 个月的数据的情况下计算其他特征，并预测他们的 `LTVCluster(y)`。
- en: 'The following code will train the `Xgboost` model:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将训练 `Xgboost` 模型：
- en: '[PRE98]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The preceding code block will output the following classification results:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块将输出以下分类结果：
- en: '![Figure 1.12 – Classification report'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.12 – 分类报告'
- en: '](img/B18024_01_12.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18024_01_12.jpg)'
- en: Figure 1.12 – Classification report
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 分类报告
- en: Now, let's assume that we are happy with the model and want to take it to the
    next level – that is, to production.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设我们对模型很满意，并希望将其提升到下一个层次——那就是生产环境。
- en: Package, release, and monitor
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包含、发布和监控
- en: 'So far, we have spent a lot of time looking at data analysis, exploration,
    cleaning, and model building since that is what a data scientist should concentrate
    on. But once all that work has been done, can the model be deployed without any
    additional work? The answer is no. We are still far away from deployment. We must
    do the following things before we can deploy the model:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经花费了大量时间研究数据分析、探索、清洗和模型构建，因为这是数据科学家应该关注的事情。但是一旦所有这些工作都完成了，模型是否可以不进行任何额外的工作就部署？答案是不了。我们离部署还远着呢。在我们能够部署模型之前，我们必须做以下事情：
- en: We must create a scheduled data pipeline that performs data cleaning and feature
    engineering.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们必须创建一个执行数据清洗和特征工程的数据管道。
- en: We need a way to fetch features during prediction. If it's an online/transactional
    model, there should be a way to fetch features at low latency. Since customers'
    R, F, and M values change frequently, let's say that we want to run two different
    campaigns for mid-value and high-value segments on the website. There will be
    a need to score customers in near-real time.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要一个方法在预测期间获取特征。如果是一个在线/交易模型，应该有一种方法以低延迟获取特征。由于客户的R、F和M值经常变化，比如说，我们想在网站上针对中值和高值细分市场运行两个不同的活动。将需要近实时地对客户进行评分。
- en: Find a way to reproduce the model using the historical data.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到一种方法使用历史数据重现模型。
- en: Perform model packaging and versioning.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行模型打包和版本控制。
- en: Find a way to AB test the model.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到一种方法进行模型的A/B测试。
- en: Find a way to monitor model and data drift.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到一种方法监控模型和数据漂移。
- en: As we don't have any of these ready, let's stop here and look back at what we
    have done, if there is a way to do this better, and see if there are any common
    oversights.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有准备好这些，让我们停下来回顾一下我们已经做了什么，看看是否有更好的方法，以及是否有任何常见的疏忽。
- en: In the next section, we'll look at *what we think we have built (ideal world)
    versus what we have built (real world)*.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨*我们认为我们构建了什么（理想世界）与实际构建了什么（现实世界）*。
- en: An ideal world versus the real world
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理想世界与现实世界
- en: Now that we have spent a good amount of time building this beautiful data product
    that can help the business treat customers differently based on the value they
    bring to the table, let's look at what we expect from this versus what it can
    do.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经花费了大量时间构建了这个美丽的数据产品，可以帮助业务根据客户带来的价值来区别对待客户，让我们看看我们对它的期望与它能做什么之间的差异。
- en: Reusability and sharing
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可复用性和共享
- en: Reusability is one of the common problems in the IT industry. We have this great
    data for a product in front of us, the graphs we built during exploration, and
    the features we generated for our model. These can be reused by other data scientists,
    analysts, and data engineers. With the state it is in currently, can it be reused?
    The answer is maybe. Data scientists can share the notebook itself, can create
    a presentation, and so on. But there is no way for somebody to discover if they
    are looking for, say, customer segmentation or RFM features, which could be very
    useful in other models. So, if another data scientist or ML engineer is building
    a model that needs the same features, the only option they are left with is to
    reinvent the same wheel. The new model may be built with the same, more accurate,
    or less accurate RFM features based on how the data scientist generates it. However,
    it could be a case where the development of the second model could have been accelerated
    if there was a better way to discover and reuse the work. Also, as the saying
    goes, *two heads are better than one*. A collaboration would have benefitted both
    the data scientist and the business.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 可复用性是IT行业中的常见问题之一。我们面前有关于产品的这些优秀数据，包括我们在探索过程中构建的图表和为我们的模型生成的特征。这些可以被其他数据科学家、分析师和数据工程师复用。就目前的状态而言，它们可以被复用吗？答案是可能。数据科学家可以共享笔记本本身，可以创建演示文稿等等。但是，没有人能够发现他们是否在寻找，比如说，客户细分或RFM特征，这些在其他模型中可能非常有用。所以，如果另一个数据科学家或ML工程师正在构建需要相同特征的模型，他们唯一的选择就是重新发明轮子。新模型可能基于数据科学家如何生成它，使用相同的、更准确或更不准确的RFM特征。然而，可能存在第二种模型的发展本可以通过更好的发现和复用工作来加速的情况。此外，正如俗话所说，*三个臭皮匠，顶个诸葛亮*。合作将使数据科学家和业务双方都受益。
- en: Everything in a notebook
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记本中的所有内容
- en: Data science is a unique skill that is different from software engineering.
    Though some of the data scientists might have a software engineer background,
    the needs of the role itself may push them away from software engineering skills.
    As the data scientists spend more time in the data exploration and model building
    phases, the **integrated development environments** (**IDEs**) may not be sufficient
    as the amount of data they are dealing with is huge. The data processing phase
    will run for days if we have to explore, do feature engineering, and do model
    building on our personal Mac or PC. Also, they need to have the flexibility to
    use different programming languages such as Python, Scala, R, SQL, and others
    to add commands dynamically during analysis. That is one of the reasons why there
    are so many notebook platform providers, including Jupyter, Databricks, and SageMaker.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是一项独特的技能，与软件工程不同。尽管一些数据科学家可能拥有软件工程师的背景，但这个角色的需求本身可能会使他们远离软件工程技能。随着数据科学家在数据探索和模型构建阶段投入更多时间，**集成开发环境**（**IDEs**）可能不足以应对他们处理的大量数据。如果我们必须在个人Mac或PC上进行数据探索、特征工程和模型构建，数据处理阶段可能会持续数天。此外，他们还需要有灵活性，能够使用不同的编程语言，如Python、Scala、R、SQL等，在分析过程中动态添加命令。这就是为什么有那么多笔记本平台提供商，包括Jupyter、Databricks和SageMaker的原因之一。
- en: Since data product/model development is different from traditional software
    development, it is always impossible to ship the experimental code to production
    without any additional work. Most data scientists start their work in a notebook
    and build everything in the same way as we did in the previous section. A few
    standard practices and tools such as feature store will not only help them break
    down the model building process into multiple production-ready notebooks but can
    also help them avoid re-processing data, debugging issues, and code reuse.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据产品/模型开发与传统的软件开发不同，在没有额外工作的前提下，将实验代码部署到生产环境总是不可能的。大多数数据科学家从笔记本开始他们的工作，并以我们之前章节中的方式构建一切。一些标准实践和工具，如特征存储，不仅可以帮助他们将模型构建过程分解成多个生产就绪的笔记本，还可以帮助他们避免重新处理数据、调试问题和代码重用。
- en: Now that we understand the reality of ML development, let's briefly go through
    the most time-consuming stages of ML.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了机器学习开发的现实情况，让我们简要地回顾一下机器学习中最耗时的阶段。
- en: The most time-consuming stages of ML
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习最耗时的阶段
- en: In the first section of this chapter, we went through the different stages of
    the ML life cycle. Let's look at some of the stages in more detail and consider
    their level of complexity and the time we should spend on each of them.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一节中，我们介绍了机器学习生命周期的不同阶段。让我们更详细地看看其中的一些阶段，并考虑它们的复杂程度以及我们应该在每个阶段上花费多少时间。
- en: Figuring out the dataset
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定数据集
- en: Once we have a problem statement, the next step is to figure out the dataset
    we need to solve the problem. In the example we followed, we knew where the dataset
    was and it was given. However, in the real world, it is not that simple. Since
    each organization has its own way of data warehousing, it may be simple or take
    forever to find the data you need. Most organizations run data catalog services
    such as Amundsen, Atlan, and Azure Data Catalog to make their dataset easily discoverable.
    But again, the tools are as good as the way they are used or the people using
    them. So, the point I'm making here is that it's always easy to find the data
    you are looking for. Apart from this, considering the access control for the data,
    even if you figure out the dataset that's needed for the problem, it is highly
    likely that you may not have access to it unless you have used it before. Figuring
    out access will be another major roadblock.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了问题陈述，下一步就是确定我们需要的数据集来解决问题。在我们所遵循的例子中，我们知道数据集在哪里，并且它是已知的。然而，在现实世界中，事情并不那么简单。由于每个组织都有自己的数据仓库方式，找到所需的数据可能既简单也可能需要很长时间。大多数组织运行数据目录服务，如Amundsen、Atlan和Azure
    Data Catalog，以便他们的数据集易于发现。但同样，工具的好坏取决于它们的使用方式或使用它们的人。因此，我想说的是，找到你想要的数据总是很容易的。除此之外，考虑到数据访问控制，即使你确定了解决问题所需的数据集，除非你之前已经使用过它，否则你很可能无法访问它。确定访问权限将是另一个主要的障碍。
- en: Data exploration and feature engineering
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据探索和特征工程
- en: 'Data exploration: once you figure out the dataset, the next biggest task is
    to *figure out the dataset again!* You read that right – for a data scientist,
    the next biggest task is to make sure that the dataset they''ve picked is the
    right dataset to solve the problem. This would involve data cleaning, augmenting
    missing data, transforming data, plotting different graphs, finding a correlation,
    finding out data skew, and more. The best part is that if the data scientists
    find that something is not right, they will go back to the previous step, which
    is to look for more datasets, try them out again, and go back.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索：一旦你确定了数据集，下一个最大的任务是“再次确定数据集”！你读对了——对于数据科学家来说，下一个最大的任务是确保他们选择的数据集是解决问题的关键。这会涉及到数据清洗，补充缺失数据，转换数据，绘制不同的图表，找到相关性，发现数据偏斜等等。最好的部分是，如果数据科学家发现某些事情不对劲，他们会回到上一步，也就是寻找更多的数据集，再次尝试，然后返回。
- en: 'Feature engineering is not easy either; domain knowledge becomes key to building
    the feature set to train the model. If you are a data scientist who has been working
    on the pricing and promotion models for the past few years, you would know what
    dataset and features would result in a better model than a data scientist who
    has been working on customer value models for the past few years and vice versa.
    Let''s try out an exercise and see if feature engineering is easy or not and if
    domain knowledge plays a key role. Have a look at the following screenshot and
    see if you can recognize the animals:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程同样不容易；领域知识成为构建特征集以训练模型的关键。如果你是一位过去几年一直在从事定价和促销模型工作的数据科学家，你就会知道哪些数据集和特征会比过去几年一直在从事客户价值模型工作的数据科学家得到更好的模型。让我们尝试一个练习，看看特征工程是否容易，以及领域知识是否起关键作用。看看下面的截图，看看你是否能识别出这些动物：
- en: '![Figure 1.13 – A person holding a dog and a cat'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.13 – A person holding a dog and a cat](img/B18024_01_13.jpg)'
- en: '](img/B18024_01_13.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18024_01_13.jpg](img/B18024_01_13.jpg)'
- en: Figure 1.13 – A person holding a dog and a cat
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 – 持有狗和猫的人
- en: I'm sure you know what these animals are, but let's take a step back and see
    how we correctly identified the animals. When we looked at the figure, our subconscious
    did feature engineering. It could have picked features such as *it has a couple
    of ears*, a *couple of eyes*, *a nose*, *a head*, and *a tail*. Instead, it picked
    much more sophisticated features, such as *the shape of its face*, *the shape
    of its eyes*, *the shape of its nose*, and *the color and texture of its fur*.
    If it had picked the first set of features, both animals would have turned out
    to be the same, which is an example of bad feature engineering and a bad model.
    Since it chose the latter, we identified it as different animals. Again, this
    is an example of good feature engineering and a good model.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你知道这些动物是什么，但让我们退一步看看我们是如何正确识别这些动物的。当我们看图时，我们的潜意识进行了特征工程。它可能会选择一些特征，比如“它有两只耳朵”，两只“眼睛”，一个“鼻子”，一个“头”，和一个“尾巴”。然而，它选择了更复杂的特点，比如“它的脸型”，“它的眼睛形状”，“它的鼻子形状”，以及“它的毛发的颜色和质感”。如果它选择了第一组特征，这两种动物就会变成相同的，这是一个糟糕的特征工程和糟糕模型的例子。由于它选择了后者，我们将其识别为不同的动物。再次，这是一个好的特征工程和好的模型的例子。
- en: But another question we need to answer would be, when did we develop expertise
    in animal identification? Well, maybe it's from our kindergarten teachers. We
    all remember some version of the first 100 animals that we learned about from
    our teachers, parents, brothers, and sisters. We didn't get all of them right
    at first but eventually, we did. We gained expertise over time.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们还需要回答的另一个问题是，我们是在什么时候发展出动物识别的专业知识的？嗯，可能是因为我们的幼儿园老师。我们都记得从老师、父母、兄弟姐妹那里学到的第一百种动物的一些版本。我们一开始并没有全部正确，但最终我们做到了。随着时间的推移，我们获得了专业知识。
- en: Now, what if, instead of a picture of a cat and a dog, it was a picture of two
    snakes and our job was to identify which one of them is venomous and which is
    not. Though all of us could identify them as snakes, almost none of us would be
    able to identify which one is venomous and which is not. Unless the person has
    been a snake charmer before.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们不是看到猫和狗的图片，而是看到两条蛇的图片，我们的任务是识别哪条是有毒的，哪条是无毒的。虽然我们都能识别出它们是蛇，但几乎没有人能识别出哪条是有毒的，哪条是无毒的。除非这个人以前是蛇笛手。
- en: Hence, domain expertise becomes crucial in feature engineering. Just like the
    data exploration stage, if we are not happy with the features, we are back to
    square one, which involves looking for more data and better features.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在特征工程中，领域专业知识变得至关重要。就像数据探索阶段一样，如果我们对特征不满意，我们就回到了起点，这涉及到寻找更多数据和更好的特征。
- en: Modeling to production and monitoring
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型到生产与监控
- en: Once we've figured out the aforementioned stage, taking the model to production
    is very time-consuming unless the right infrastructure is ready and waiting. For
    a model to run in production, it needs a processing platform that will run the
    data cleaning and feature engineering code. It also needs an orchestration framework
    to run the feature engineering pipeline in a scheduled or event-based way. We
    also need a way to store and retrieve features securely at low latency in some
    cases. If the model is transactional, the model must be packaged so that it can
    be accessed by the consumers securely, maybe as a REST endpoint. Also, the deployed
    model should be scalable to serve the incoming traffic.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了上述阶段，除非有合适的基础设施准备就绪并等待，否则将模型投入生产将非常耗时。为了使模型在生产中运行，它需要一个处理平台来运行数据清洗和特征工程代码。它还需要一个编排框架以计划或基于事件的方式运行特征工程管道。在某些情况下，我们还需要一种安全地以低延迟存储和检索特征的方法。如果模型是事务性的，模型必须打包以便消费者可以安全访问，可能作为一个REST端点。此外，部署的模型应该具有可扩展性，以服务即将到来的流量。
- en: Model and data monitoring are crucial aspects too. As model performance directly
    affects the business, you must know what metrics would determine that the model
    needs to be retrained in advance. Other than model monitoring, the dataset also
    needs to be monitored for skews. For example, in an e-commerce business, traffic
    patterns and purchase patterns may change frequently based on seasonality, trends,
    and other factors. Identifying these changes early will affect the business positively.
    Hence, data and feature monitoring are key in taking the model to production.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 模型和数据监控也是至关重要的方面。由于模型性能直接影响业务，你必须知道哪些指标会决定模型需要提前重新训练。除了模型监控之外，数据集也需要监控偏差。例如，在电子商务业务中，流量模式和购买模式可能会根据季节性、趋势和其他因素频繁变化。及早识别这些变化将对业务产生积极影响。因此，数据和特征监控是模型投入生产的关键。
- en: Summary
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the different stages in the ML life cycle. We
    picked a problem statement, performed data exploration, plotted a few graphs,
    did feature engineering and customer segmentation, and built a customer lifetime
    value model. We looked at the oversights and discussed the most time-consuming
    stages of ML. I wanted to get you onto the same page as I am and set a good foundation
    for the rest of this book.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了机器学习生命周期中的不同阶段。我们选择了一个问题陈述，进行了数据探索，绘制了一些图表，进行了特征工程和客户细分，并构建了客户终身价值模型。我们审视了疏忽之处，并讨论了机器学习中最耗时的阶段。我希望你们能和我站在同一页面上，为本书的其余部分打下良好的基础。
- en: In the next chapter, we will set the stage for the need for a feature store
    and how it could improve the ML process. We will also discuss the need to bring
    features into production and some of the traditional ways of doing so.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将设定需要特征存储的背景，以及它如何可以改进机器学习过程。我们还将讨论将特征引入生产的需求以及一些传统的实现方式。
- en: 'Chapter 1: An Overview of the Machine Learning Life Cycle'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章：机器学习生命周期的概述
- en: 'Chapter 1: An Overview of the Machine Learning Life Cycle'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章：机器学习生命周期的概述
