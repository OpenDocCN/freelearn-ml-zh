<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer102">
			<h1 id="_idParaDest-96"><em class="italic"><a id="_idTextAnchor097"/>Chapter 5</em>: Exploratory Data Analysis with DataRobot</h1>
			<p>In this chapter, we will cover tasks related to exploring and analyzing your dataset with DataRobot. DataRobot performs many functions that you will need to perform this analysis, but it is still up to you to make sense of it.</p>
			<p>By the end of this chapter, you will have learned how to utilize DataRobot to perform <strong class="bold">exploratory data analysis</strong> (<strong class="bold">EDA</strong>). In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Data ingestion and data cataloging</li>
				<li>Data quality assessment</li>
				<li>EDA</li>
				<li>Setting the target feature and correlation analysis</li>
				<li>Feature selection</li>
			</ul>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor098"/>Data ingestion and data cataloging</h1>
			<p>Now that we have our datasets ready, we have two choices to bring them into DataRobot. We can <a id="_idIndexMarker242"/>go to either the <strong class="bold">Create New Project / Drag Dataset</strong> page (<em class="italic">Figure 1.5</em>) or the <strong class="bold">AI Catalog</strong> page (<em class="italic">Figure 1.17</em>). If the dataset is relatively small, we <a id="_idIndexMarker243"/>may prefer to start with the <strong class="bold">Create New Project</strong> method. After a few iterations, when the dataset has stabilized, you can move it into the <strong class="bold">AI Catalog</strong> page so that it can be reused in other projects.</p>
			<p>Let's start by uploading our automobile dataset as a local file that we created in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>. You can name the project <strong class="source-inline">Automobile Example 1</strong>, as <a id="_idIndexMarker244"/>shown in the following screenshot:</p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="Images/Figure_5.1_B17159.jpg" alt="Figure 5.1 – Uploading dataset for a new project&#13;&#10;" width="1156" height="630"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – Uploading dataset for a new project</p>
			<p>You will notice that DataRobot <a id="_idIndexMarker245"/>automatically starts analyzing the data and performs a quick exploratory analysis. You can see that it found <strong class="source-inline">30</strong> features and <strong class="source-inline">205</strong> rows of data. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you are using an Excel file that has multiple sheets, make sure that the data you want is in the first sheet.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor099"/>Data quality assessment</h1>
			<p>DataRobot will also perform a data quality assessment and notify you if it finds any data issues, as shown <a id="_idIndexMarker246"/>in the following screenshot: </p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="Images/Figure_5.2_B17159.jpg" alt="Figure 5.2 – Data quality issues&#13;&#10;" width="673" height="413"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2 – Data quality issues</p>
			<p>In this case, it has found outliers in eight features. You can look into the details to see if these look acceptable or if you need to drop or otherwise fix these outliers. We will do this as we explore <a id="_idIndexMarker247"/>and analyze each of these features in the following section.</p>
			<p>Notice that it also looked for any disguised missing values or excess zeros in any feature. These can be hard to detect manually and can be problematic for your models, so it is important to fix these issues if they come up. For example, you saw in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot,</em> that we already fixed the issue of excess zeros in the <strong class="source-inline">normalized-losses</strong> feature. If we had not done that previously, DataRobot would alert us to fix this or filter out those rows before proceeding. It will also perform additional analysis once a target feature is selected.</p>
			<p>You will carry out the same process with the Appliances Energy dataset.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor100"/>EDA</h1>
			<p>As you saw in the previous section, DataRobot automatically performed an initial analysis of the <a id="_idIndexMarker248"/>dataset. Let's see how we will review this data and gain insights from it. If you scroll down the page, you will see a table of features and an overview of their characteristics, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="Images/Figure_5.3_B17159.jpg" alt="Figure 5.3 – Data analysis overview&#13;&#10;" width="1086" height="687"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.3 – Data analysis overview</p>
			<p>You can see that in this table, DataRobot has computed and listed any data quality concerns regarding a feature, what type of variable it is, how many unique values are in the dataset, and how many values are missing. These are all very important characteristics, and you need to review all of them to make sure that you understand what they are telling you.</p>
			<p>For example, is the variable type selected by DataRobot what you expected? If you look at <strong class="source-inline">num_of_doors</strong>, you will notice that this is categorical. Even though this is correct because the data contained <a id="_idIndexMarker249"/>is in the form of text, you know that this is really numbers. You might want to fix this (just as we did for <strong class="source-inline">num_of_cylinders</strong> in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>). Doing this ahead of time will reduce rework and wasted effort downstream. Similarly, you will notice that <strong class="source-inline">num_of_doors</strong> has two missing values. If this number were higher, we would have tried to address the missing values, as discussed in <a href="B17159_04_Final_NM_ePub.xhtml#_idTextAnchor087"><em class="italic">Chapter 4</em></a>, <em class="italic">Preparing Data for DataRobot</em>. Also, pay attention to unique values. For some features, we expect many unique values, while for others, we do not. Check if what DataRobot found is consistent with your expectations. If not, try to determine the reason for this. Pay special attention when a categorical variable has a large number of unique values. We will soon discuss how to address this issue.</p>
			<p>For numeric features, you will also see summary statistics such as <strong class="bold">Mean</strong>, <strong class="bold">Median</strong>, <strong class="bold">Std Dev</strong> (for standard deviation), <strong class="bold">Min</strong>, and <strong class="bold">Max</strong>. Review these for each feature to see if they all look reasonable. If you click on any feature row, it will expand and show more detail, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="Images/Figure_5.4_B17159.jpg" alt="Figure 5.4 – Feature details for &quot;symboling&quot;&#13;&#10;" width="1147" height="613"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.4 – Feature details for "symboling"</p>
			<p>Here, you can see a histogram of all the values. You can now see how this data is distributed. One <a id="_idIndexMarker250"/>aspect to pay special attention to is the area where you don't have much data. For example, you can see that the amount of training data available for the value <strong class="source-inline">-2</strong> is very limited, so we should expect there to be problems trying to predict these values. Now, let's look at the details of <strong class="source-inline">normalized_losses</strong> in the following screenshot:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="Images/Figure_5.5_B17159.jpg" alt="Figure 5.5 – Feature details for &quot;normalized_losses&quot;&#13;&#10;" width="1158" height="620"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5 – Feature details for "normalized_losses"</p>
			<p>In this view, we can see that there seem to be very few losses around <strong class="bold">140</strong> and <strong class="bold">180</strong>. If this were a <a id="_idIndexMarker251"/>large dataset, this would be a cause for concern. Since our dataset is very small, it is not surprising to see such gaps. Also, note that these are average losses per year and not losses experienced by an individual car. Next, in the following screenshot, we will look at the <strong class="source-inline">make</strong> feature to see how it is distributed:</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="Images/Figure_5.6_B17159.jpg" alt="Figure 5.6 – Feature details for &quot;make&quot;&#13;&#10;" width="1439" height="704"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.6 – Feature details for "make"</p>
			<p>Since <strong class="source-inline">make</strong> is a categorical feature, you can see how frequently each value shows up. Remember that <a id="_idIndexMarker252"/>we had already consolidated some car types that had very little data into <strong class="source-inline">other</strong>. If we hadn't done that, we would notice here that some types have very few data points and need to be addressed or they will not do well during training. Let's look at <strong class="source-inline">fuel_type</strong> to see what we can glean from this data, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="Images/Figure_5.7_B17159.jpg" alt="Figure 5.7 – Feature details for &quot;fuel_type&quot;&#13;&#10;" width="1138" height="642"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.7 – Feature details for "fuel_type"</p>
			<p>Here, we notice that <strong class="source-inline">diesel</strong> cars are not well represented, and this might be normal for cars. Anytime <a id="_idIndexMarker253"/>we see such imbalances, we should try to see if they can be addressed. Now, when we look at the <strong class="source-inline">engine_location</strong> feature, as shown in the following screenshot, we see that we have a problem:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="Images/Figure_5.8_B17159.jpg" alt="Figure 5.8 – Feature details for engine_location&#13;&#10;" width="978" height="633"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.8 – Feature details for engine_location</p>
			<p>As you can see in the preceding screenshot, the <strong class="source-inline">rear</strong> feature is barely registering on the dataset. From a practical standpoint, what this means is that the algorithms will ignore this feature. If you <a id="_idIndexMarker254"/>did not look carefully, you might assume that <strong class="source-inline">engine_location</strong> has no impact on your target, but as you can tell from this screenshot, our dataset is not large enough to make that determination. Let's now look in the following screenshot at <strong class="source-inline">engine_type</strong> to see what we find here:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="Images/Figure_5.9_B17159.jpg" alt="Figure 5.9 – Feature details for &quot;engine_type&quot;&#13;&#10;" width="1152" height="641"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.9 – Feature details for "engine_type"</p>
			<p>In this case, we find that one type dominates and some of the types are barely represented. Looking at this distribution, you might want to create another feature where <a id="_idIndexMarker255"/>you transform this into a binary value, <strong class="bold">0</strong> for <strong class="source-inline">ohc</strong> and <strong class="bold">1</strong> for every other type. This will also create some balance in the dataset.</p>
			<p>Please bear in mind that this might or might not prove to be useful. You have to try it out in your models and see what works. Let's now look in the following screenshot at <strong class="source-inline">num_of_cylinders</strong> and <strong class="source-inline">cylinder_count</strong>, a feature that we created during data preparation:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="Images/Figure_5.10_B17159.jpg" alt="Figure 5.10 – Feature details for &quot;num_of_cylinders&quot; and &quot;cylinder_count&quot;&#13;&#10;" width="921" height="1024"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.10 – Feature details for "num_of_cylinders" and "cylinder_count"</p>
			<p>As you can see, even though it is the same data, transforming the values provides a different <a id="_idIndexMarker256"/>impression compared to what you get when you first look at the histograms. The numeric values are a more accurate representation of the data and should result in a better model compared to the categorical values.</p>
			<p>Hopefully, we have highlighted what DataRobot provides automatically and what kinds of insights can be gained by looking at the graphs generated by DataRobot. We are now ready to set our target feature and do additional analysis.</p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor101"/>Setting the target feature and correlation analysis</h1>
			<p>By the time you reach this stage, you should already have a pretty good idea of the problem you are trying <a id="_idIndexMarker257"/>to solve and what should be the target feature. It is not unusual to use different features as targets for different use cases. Also, sometimes you will set a transformed feature as<a id="_idIndexMarker258"/> a target (for example, log of a feature). For the Automobile dataset, we want to predict the <strong class="bold">price</strong> of cars. Once you select the target feature, as shown in the following screenshot, it will analyze that feature and provide some recommendations:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="Images/Figure_5.11_B17159.jpg" alt="Figure 5.11 – Setting target feature&#13;&#10;" width="854" height="373"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.11 – Setting target feature</p>
			<p>You can see from the preceding screenshot that it is showing how the price is distributed. DataRobot also cautions that some of the target values are missing. Ideally, we would filter out the rows with missing target values before uploading the dataset. You will also notice that DataRobot has characterized this as a regression problem. Another thing to note is that it has picked the optimization metric to be <strong class="bold">Gamma Deviance</strong>. You can read more about this metric in <a href="B17159_02_Final_NM_ePub.xhtml#_idTextAnchor039"><em class="italic">Chapter 2</em></a>, <em class="italic">Machine Learning Basics</em>, or you can explore it in more detail in DataRobot's help sections. For now, it looks like a good choice, given the wide variance of price values.</p>
			<p>Before we click on the <strong class="bold">Start</strong> button, we should explore the advanced options. The reason for this is that once you click the <strong class="bold">Start</strong> button, you cannot make changes to the options. Having <a id="_idIndexMarker259"/>said that, it is often hard to make all the right choices <a id="_idIndexMarker260"/>without completely understanding the data. One way to overcome this issue is to ignore the advanced options for now and go ahead with the exploration. </p>
			<p>Once we know what we want, we can create a new project and select the appropriate options. You can see that this is an iterative process, and we will often try something and come back and redo some of it. Also, notice that <strong class="bold">Modeling Mode</strong> in <em class="italic">Figure 5.11</em> is set to <strong class="bold">Quick</strong>. This is normally a good choice to get started. With that in mind, we can actually skip the options and go ahead and click the <strong class="bold">Start</strong> button. You will notice that DataRobot will get started on performing additional analysis, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="Images/Figure_5.12_B17159.jpg" alt="Figure 5.12 – Feature analysis&#13;&#10;" width="1126" height="606"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.12 – Feature analysis</p>
			<p>You will notice that in addition to performing additional analysis, DataRobot will actually start building the models. This might be surprising since we are still doing analysis, but fear not—these are not the final models. Let DataRobot build these models, as some of these will provide <a id="_idIndexMarker261"/>useful insights into our data. We will most likely <a id="_idIndexMarker262"/>discard these models later on, but they will prove useful in our journey. Once DataRobot has finished doing all the tasks, you will see an <strong class="bold">Autopilot has finished</strong> message, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="Images/Figure_5.13_B17159.jpg" alt="Figure 5.13 – Initial analysis complete&#13;&#10;" width="1208" height="551"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.13 – Initial analysis complete</p>
			<p>You will now notice that DataRobot has populated an <strong class="bold">Importance</strong> column for all the features. This is the relative importance of a feature in reference to the target feature. We can also check to see if there are additional data quality issues that have been found. For that, let's click on the <strong class="bold">View info</strong> dropdown in the <strong class="bold">Data Quality Assessment</strong> box. You will then see the options, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="Images/Figure_5.14_B17159.jpg" alt="Figure 5.14 – Data Quality Assessment&#13;&#10;" width="353" height="505"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.14 – Data Quality Assessment</p>
			<p>We saw some of the issues previously, but we now see that there are features that potentially have <a id="_idIndexMarker263"/>target leakage. If target leakage exists, we will filter those features out. By looking at the warning signs associated with each feature, we discover <a id="_idIndexMarker264"/>that these features are <strong class="source-inline">horsepower</strong> and <strong class="source-inline">engine_size</strong>. Since these are important features and have an obvious impact on price, we will retain these features. We also see another warning symbol in the header row, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="Images/Figure_5.15_B17159.jpg" alt="Figure 5.15 – Missing target values&#13;&#10;" width="886" height="170"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.15 – Missing target values</p>
			<p>Clicking on the symbol, we see that DataRobot has already filtered out rows where the price is missing. This is good, as it means we don't have to recreate our dataset and upload it <a id="_idIndexMarker265"/>again into DataRobot. You will also notice in the following screenshot that a new tab called <strong class="bold">Feature Associations</strong> is now present at the top left <a id="_idIndexMarker266"/>of the screen. This is a critical tab for our data analysis task. Let's click on this tab to look at what DataRobot has found:</p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="Images/Figure_5.16_B17159.jpg" alt="Figure 5.16 – Feature Association&#13;&#10;" width="1003" height="822"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.16 – Feature Association</p>
			<p>DataRobot calls these <em class="italic">associations</em> instead of <em class="italic">correlations</em>, and the reason is that DataRobot uses <strong class="bold">mutual information</strong> (<strong class="bold">MI</strong>) instead of correlation coefficients. The benefits of using MI are that it is able to better reflect non-linear relationships and can also handle <a id="_idIndexMarker267"/>categorical features. If you perform correlation analysis, you will find that the results are very <a id="_idIndexMarker268"/>similar in the case of linear relationships. In addition <a id="_idIndexMarker269"/>to finding the relationships, DataRobot also tries to find any clusters of interrelated features. You will notice that different clusters are color-coded differently. These offer additional insights into your problem. For example, you will see that there is a cluster of features related to the <strong class="source-inline">engine</strong> that includes a group of tightly correlated features such as <strong class="source-inline">engine_size</strong>, <strong class="source-inline">bore</strong>, <strong class="source-inline">cylinder_size</strong>, and <strong class="source-inline">stroke</strong>. Understanding these relationships as a collective can be very important to solving a business problem. In this particular case, it tells you that you cannot modify one of these in isolation.</p>
			<p>Changing the bore will affect many other features, even if your model does not end up with those features. Ignoring these aspects is what typically leads to downstream problems, so please pay special attention to these relationships.</p>
			<p>You can gain additional insights by sorting the associations by their importance, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="Images/Figure_5.17_B17159.jpg" alt="Figure 5.17 – Feature associations sorted by importance&#13;&#10;" width="646" height="661"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.17 – Feature associations sorted by importance</p>
			<p>The preceding screenshot shows the features sorted by their impact on the target feature. This tells you which features are most likely to be prominent in your model. One thing to look <a id="_idIndexMarker270"/>for is how this lines up with the causal model that you <a id="_idIndexMarker271"/>built during the problem understanding stage. Is it consistent? If not, where are the differences and surprises? These typically lead to new insights into your problem. It is also useful to look at the MI values in totality. For this, you can click on the <strong class="bold">Export</strong> button to export all MI values as a <strong class="source-inline">.csv</strong> file. You can then analyze them in tools such as Excel, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="Images/Figure_5.18_B17159.jpg" alt="Figure 5.18 – MI values&#13;&#10;" width="369" height="566"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.18 – MI values</p>
			<p>This gives you a better feel for the relative scale of these values. In this view, we can see that aspiration <a id="_idIndexMarker272"/>has very little impact on price. This seems a little counterintuitive and merits some additional investigation. For this, we can look at this association in <a id="_idIndexMarker273"/>more detail by clicking on the <strong class="bold">View Feature Association Pairs</strong> button. You can now select <strong class="source-inline">price</strong> and <strong class="source-inline">aspiration</strong> to see the association details, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="Images/Figure_5.19_B17159.jpg" alt="Figure 5.19 – Association pair details&#13;&#10;" width="1101" height="509"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.19 – Association pair details</p>
			<p>Here, we can see that for the same value of <strong class="source-inline">aspiration</strong>, the price can vary quite a bit. Still, we can <a id="_idIndexMarker274"/>see that on average, <strong class="source-inline">turbo</strong> has a higher price. Based on this, we will keep it in the mix for modeling. We should also discuss with the domain experts <a id="_idIndexMarker275"/>to see why it is not correlating in a stronger fashion with <strong class="source-inline">price</strong>. These discussions can lead to creating other features that might clarify this relationship. On the other hand, the relationship between <strong class="source-inline">price</strong> and <strong class="source-inline">num_of_doors</strong> doesn't look very interesting. </p>
			<p>It is a good idea to review the association pairs to see what insights can be gained. At a minimum, review the ones with very high or very low values. Specifically, look for non-linear relationships. For example, let's look at the association between <strong class="source-inline">curb_weight</strong> and <strong class="source-inline">highway_mpg</strong>, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="Images/Figure_5.20_B17159.jpg" alt="Figure 5.20 – Association between curb_weight and highway_mpg&#13;&#10;" width="1121" height="535"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.20 – Association between curb_weight and highway_mpg</p>
			<p>Here, you will notice that as <strong class="source-inline">curb_weight</strong> increases, the <strong class="bold">miles per gallon</strong> (<strong class="bold">MPG</strong>)  value decreases, which <a id="_idIndexMarker276"/>makes intuitive sense. We also see that the curve <a id="_idIndexMarker277"/>starts flattening at higher weights. This could be due to <a id="_idIndexMarker278"/>many reasons, as other factors affecting MPG do not increase with weight.</p>
			<p>Note that while this may or may not affect the predictive accuracy of the model, understanding these relationships is key to determining actions to be taken based on the model. For example, weight reduction might not provide much MPG benefit for weights larger than <strong class="bold">3500</strong>. We can also investigate the association between <strong class="source-inline">curb_weight</strong> and <strong class="source-inline">drive _wheels</strong>, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="Images/Figure_5.21_B17159.jpg" alt="Figure 5.21 – Association between curb_weight and drive_wheels&#13;&#10;" width="1142" height="487"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.21 – Association between curb_weight and drive_wheels</p>
			<p>In the preceding screenshot, we can see that <strong class="source-inline">curb_weight</strong> is impacted by the choice of <strong class="source-inline">drive_wheels</strong>. It is possible that if we use both these features in our model, the model will give a <a id="_idIndexMarker279"/>much higher preference to <strong class="source-inline">curb_weight</strong> and <a id="_idIndexMarker280"/>might find not much value in using <strong class="source-inline">drive_wheels</strong>. Business users might therefore interpret <strong class="source-inline">drive_wheels</strong> as not very important. </p>
			<p>As you can see, this is not true since <strong class="source-inline">curb_weight</strong> is itself influenced by <strong class="source-inline">drive_wheels</strong>. It has been observed that an accurate model can sometimes give a false impression if you are not careful. DataRobot can do this analysis and produce these graphs, but it is up to you to understand and interpret these correctly.</p>
			<p>Let's look again at some of the individual feature graphs we looked at before. For this, let's look at the feature details shown in <em class="italic">Figure 5.13</em> and click on <strong class="source-inline">curb_weight</strong>. This will show us details about the feature, as shown in the following screenshot:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="Images/Figure_5.22_B17159.jpg" alt="Figure 5.22 – Feature details for curb_weight&#13;&#10;" width="1227" height="682"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.22 – Feature details for curb_weight</p>
			<p>You will notice that we now have some more information in this graph. Specifically, we can now see how <a id="_idIndexMarker281"/>price varies with <strong class="source-inline">curb_weight</strong> as well as how the <strong class="source-inline">curb_weight</strong> value is distributed. Looking at these relationships can give you additional <a id="_idIndexMarker282"/>insights into your problem, especially when the relationship is non-linear. For example, let's look at the details for <strong class="source-inline">highway_mpg</strong> in the following screenshot:</p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="Images/Figure_5.23_B17159.jpg" alt="Figure 5.23 – Feature details for highway_mpg&#13;&#10;" width="1245" height="677"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.23 – Feature details for highway_mpg</p>
			<p>As you can see, the price drops exponentially as the MPG value increases. Given this non-linearity, which <a id="_idIndexMarker283"/>also seems to be present in other features, it might be useful to try creating a new target feature by taking a log of the price. Similarly, by <a id="_idIndexMarker284"/>looking at the other features, you can get ideas on feature transformations that might prove beneficial. Some of you might be wondering why we should do this since the new algorithms can handle non-linearity. While that is true, it is still better to transform your non-linear problems if it makes sense from a business-understanding perspective. Also, it allows the algorithm to focus its computational energy in other areas that might otherwise be overlooked.</p>
			<p>Now that we have understood the features and have transformed them as needed, we can focus on selecting a feature set to start the modeling process.</p>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor102"/>Feature selection</h1>
			<p>The basic idea behind feature selection is to select features that show high importance for the target. In addition, we <a id="_idIndexMarker285"/>want to remove any features that are highly cross-correlated (or have high MI values) to other features. The selected set of features are represented as feature lists in DataRobot. If you click on the <strong class="bold">Feature Lists</strong> menu on the top left of the page, as shown in the following screenshot, you will see the feature lists that DataRobot has created for the dataset:</p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="Images/Figure_5.24_B17159.jpg" alt="Figure 5.24 – Feature Lists&#13;&#10;" width="880" height="363"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.24 – Feature Lists</p>
			<p>Here, you will see a list that contains all the raw features, ones that have selections based on univariate <a id="_idIndexMarker286"/>analysis (that is, analysis of features one at a time), and also ones that have the most important features. The <strong class="bold">DR Reduced Features M8</strong> list or the <strong class="bold">Univariate Selections</strong> list look like good starting points. Click on the <strong class="bold">Project Data</strong> menu to go back to the data view. Now, let's inspect the univariate list by selecting  <strong class="bold">Univariate Selections</strong> from the <strong class="bold">Feature List</strong> dropdown, as illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="Images/Figure_5.25_B17159.jpg" alt="Figure 5.25 – Selecting a feature list&#13;&#10;" width="795" height="274"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.25 – Selecting a feature list</p>
			<p>You can now inspect the list of features that have been selected. You can modify this list and create new feature lists by dropping any features that you do not want to include in this list. As you can <a id="_idIndexMarker287"/>see, DataRobot has done much of the feature selection for you to get things started. You can remove some more now, or you can remove them in the next iteration after you have built an initial set of models.</p>
			<p>Interestingly, DataRobot has already built some models with some of these lists, which we will explore in the next chapter.</p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor103"/>Summary</h1>
			<p>In this chapter, we learned how to bring data into DataRobot. We learned how to assess data quality and to perform EDA by using DataRobot's features. We saw how DataRobot makes it very easy to explore data, set up target features, and perform correlation (or, more accurately, association analysis).</p>
			<p>We learned how to leverage DataRobot's output to gain a better understanding of our problem and dataset, and then how to create feature lists to be used in model building. You could do these tasks in Python or R and they are not very difficult, but they do consume some time. This time is better served in focusing on understanding the problem and the dataset.</p>
			<p>In the next chapter, we will jump into something that most of you must be waiting for: building models.</p>
		</div>
	</div></body></html>