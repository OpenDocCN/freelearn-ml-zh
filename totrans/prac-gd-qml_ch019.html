<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<meta charset="utf-8"/>
<meta content="pandoc" name="generator"/>
<title>ch019.xhtml</title>
<link href="../styles/stylesheet1.css" rel="stylesheet" type="text/css"/>
<!-- kobo-style -->
<style id="koboSpanStyle" type="text/css" xmlns="http://www.w3.org/1999/xhtml">.koboSpan { -webkit-text-combine: inherit; }</style>
</head>
<body epub:type="bodymatter">
<section class="level1 chapterHead" data-number="18" id="chapter-10-quantum-neural-networks">
<h1 class="H1---Chapter chapterHead" data-number="18"><span class="titlemark"><span class="koboSpan" id="kobo.1.1" xmlns="http://www.w3.org/1999/xhtml">Chapter 10</span></span><br/>
<span id="x1-18100010"><span class="koboSpan" id="kobo.2.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Neural Networks</span></span></h1>
<div class="flushright">
<p><em><span class="koboSpan" id="kobo.3.1" xmlns="http://www.w3.org/1999/xhtml">The mind is not a vessel to be filled, but a fire to be kindled.</span></em><br/><span class="koboSpan" id="kobo.4.1" xmlns="http://www.w3.org/1999/xhtml">
— Plutarch</span></p>
</div>
<p><span class="koboSpan" id="kobo.5.1" xmlns="http://www.w3.org/1999/xhtml">In the previous chapter, we explored our first family of quantum machine learning models: quantum support vector machines. </span><span class="koboSpan" id="kobo.5.2" xmlns="http://www.w3.org/1999/xhtml">Now it is time for us to take one step further and consider yet another family of models, that of </span><span id="dx1-181001"/><strong><span class="koboSpan" id="kobo.6.1" xmlns="http://www.w3.org/1999/xhtml">Quantum</span></strong> <strong><span class="koboSpan" id="kobo.7.1" xmlns="http://www.w3.org/1999/xhtml">Neural Networks</span></strong><span class="koboSpan" id="kobo.8.1" xmlns="http://www.w3.org/1999/xhtml"> (</span><strong><span class="koboSpan" id="kobo.9.1" xmlns="http://www.w3.org/1999/xhtml">QNNs</span></strong><span class="koboSpan" id="kobo.10.1" xmlns="http://www.w3.org/1999/xhtml">).</span></p>
<p><span class="koboSpan" id="kobo.11.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, you will learn how the notion of a quantum neural network can arise naturally from the ideas behind classical neural networks. </span><span class="koboSpan" id="kobo.11.2" xmlns="http://www.w3.org/1999/xhtml">Of course, you will also learn how quantum neural networks work and how they can be trained. </span><span class="koboSpan" id="kobo.11.3" xmlns="http://www.w3.org/1999/xhtml">Then, you will explore how quantum neural networks can actually be implemented, run, and trained using the two quantum frameworks that we have been working with so far: Qiskit and PennyLane.</span></p>
<p><span class="koboSpan" id="kobo.12.1" xmlns="http://www.w3.org/1999/xhtml">These are the contents of this chapter:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.13.1" xmlns="http://www.w3.org/1999/xhtml">Building and training quantum neural networks</span></p></li>
<li><p><span class="koboSpan" id="kobo.14.1" xmlns="http://www.w3.org/1999/xhtml">Quantum neural networks in PennyLane</span></p></li>
<li><p><span class="koboSpan" id="kobo.15.1" xmlns="http://www.w3.org/1999/xhtml">Quantum neural networks in Qiskit: a commentary</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.16.1" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines and quantum neural networks are probably the two most popular families of QML models, so, by the end of this chapter, you will already have a solid foundation in quantum machine learning.</span></p>
<p><span class="koboSpan" id="kobo.17.1" xmlns="http://www.w3.org/1999/xhtml">To get started, let’s understand how quantum neural networks work and how they can be effectively trained. </span><span class="koboSpan" id="kobo.17.2" xmlns="http://www.w3.org/1999/xhtml">Let’s get to it!</span></p>
<section class="level2 sectionHead" data-number="18.1" id="building-and-training-a-quantum-neural-network">
<h1 class="sectionHead" data-number="18.1"><span class="titlemark"><span class="koboSpan" id="kobo.18.1" xmlns="http://www.w3.org/1999/xhtml">10.1 </span></span> <span id="x1-18200010.1"><span class="koboSpan" id="kobo.19.1" xmlns="http://www.w3.org/1999/xhtml">Building and training a quantum neural network</span></span></h1>
<p><span class="koboSpan" id="kobo.20.1" xmlns="http://www.w3.org/1999/xhtml">Just like quantum support </span><span id="dx1-182001"/><span class="koboSpan" id="kobo.21.1" xmlns="http://www.w3.org/1999/xhtml">vector machines, quantum neural networks are what we called ”CQ models” back in </span><em><span class="koboSpan" id="kobo.22.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.23.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><span class="koboSpan" id="kobo.24.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.25.1" xmlns="http://www.w3.org/1999/xhtml">What is Quantum Machine</span></em> <em><span class="koboSpan" id="kobo.26.1" xmlns="http://www.w3.org/1999/xhtml">Learning?</span></em><span class="koboSpan" id="kobo.27.1" xmlns="http://www.w3.org/1999/xhtml">, — models with purely classical inputs and outputs that use quantum computing at some stage. </span><span class="koboSpan" id="kobo.27.2" xmlns="http://www.w3.org/1999/xhtml">However, unlike QSVMs, quantum neural networks are not a ”particular case” of any classical model, although their behavior is inspired by that of classical neural networks. </span><span class="koboSpan" id="kobo.27.3" xmlns="http://www.w3.org/1999/xhtml">What is more, as we will soon see, quantum neural networks are ”purely quantum” models, in the sense that their execution will only require classical computing for the preparation of circuits and the statistical analysis of measurements. </span><span class="koboSpan" id="kobo.27.4" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, just like QSVMs, quantum neural networks will depend on classical parameters that will be optimized classically.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-178">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.28.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.29.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.30.1" xmlns="http://www.w3.org/1999/xhtml">As you surely know by now, (quantum) machine learning is a vast field in which terms hardly ever have a unique meaning. </span><span class="koboSpan" id="kobo.30.2" xmlns="http://www.w3.org/1999/xhtml">The term ”quantum neural network” can, in practice, be used to refer to any QML model that is inspired by the behavior of a classical neural network. </span><span class="koboSpan" id="kobo.30.3" xmlns="http://www.w3.org/1999/xhtml">Therefore, you should bear in mind that people may also use this name to refer to models different from the ones that we are considering to be quantum neural networks.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.31.1" xmlns="http://www.w3.org/1999/xhtml">That should be enough of an introduction. </span><span class="koboSpan" id="kobo.31.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now get into the details. </span><span class="koboSpan" id="kobo.31.3" xmlns="http://www.w3.org/1999/xhtml">What actually are quantum neural networks and how do they relate to classical neural networks?</span></p>
<section class="level3 subsectionHead" data-number="18.1.1" id="a-journey-from-classical-neural-networks-to-quantum-neural-networks">
<h2 class="subsectionHead" data-number="18.1.1"><span class="titlemark"><span class="koboSpan" id="kobo.32.1" xmlns="http://www.w3.org/1999/xhtml">10.1.1 </span></span> <span id="x1-18300010.1.1"><span class="koboSpan" id="kobo.33.1" xmlns="http://www.w3.org/1999/xhtml">A journey from classical neural networks to quantum neural networks</span></span></h2>
<p><span class="koboSpan" id="kobo.34.1" xmlns="http://www.w3.org/1999/xhtml">If we do a small exercise of abstraction, we can think of the action of a classical neural network as consisting of the following stages:</span></p>
<ol>
<li><div id="x1-183002x1">
<p><strong><span class="koboSpan" id="kobo.35.1" xmlns="http://www.w3.org/1999/xhtml">Data preparation</span></strong><span class="koboSpan" id="kobo.36.1" xmlns="http://www.w3.org/1999/xhtml">: This </span><span id="dx1-183003"/><span class="koboSpan" id="kobo.37.1" xmlns="http://www.w3.org/1999/xhtml">simply amounts to taking some (classical) input data and maybe carrying out some (simple) transformations on it. </span><span class="koboSpan" id="kobo.37.2" xmlns="http://www.w3.org/1999/xhtml">These may include normalizing or scaling the input data.</span></p>
</div></li>
<li><div id="x1-183005x2">
<p><strong><span class="koboSpan" id="kobo.38.1" xmlns="http://www.w3.org/1999/xhtml">Data processing</span></strong><span class="koboSpan" id="kobo.39.1" xmlns="http://www.w3.org/1999/xhtml">: Feeding the data </span><span id="dx1-183006"/><span class="koboSpan" id="kobo.40.1" xmlns="http://www.w3.org/1999/xhtml">through a sequence of layers that ”transform” the data as it flows through them. </span><span class="koboSpan" id="kobo.40.2" xmlns="http://www.w3.org/1999/xhtml">The behavior of this processing depends on some optimizable parameters, which are adjusted in training.</span></p>
</div></li>
<li><div id="x1-183008x3">
<p><strong><span class="koboSpan" id="kobo.41.1" xmlns="http://www.w3.org/1999/xhtml">Data output</span></strong><span class="koboSpan" id="kobo.42.1" xmlns="http://www.w3.org/1999/xhtml">: Returning the </span><span id="dx1-183009"/><span class="koboSpan" id="kobo.43.1" xmlns="http://www.w3.org/1999/xhtml">output through a final layer.</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.44.1" xmlns="http://www.w3.org/1999/xhtml">Let’s see how we can take this scheme and use it to define an analogous quantum model.</span></p>
<ol>
<li><div id="x1-183011x1">
<p><strong><span class="koboSpan" id="kobo.45.1" xmlns="http://www.w3.org/1999/xhtml">Data preparation</span></strong><span class="koboSpan" id="kobo.46.1" xmlns="http://www.w3.org/1999/xhtml">: Quantum </span><span id="dx1-183012"/><span class="koboSpan" id="kobo.47.1" xmlns="http://www.w3.org/1999/xhtml">neural networks are given classical inputs (in the form of an array of numbers), but quantum computers don’t work on classical data — they work on quantum states! </span><span class="koboSpan" id="kobo.47.2" xmlns="http://www.w3.org/1999/xhtml">So how can we take these classical inputs and embed them into the space of quantum states?</span></p>
<p><span class="koboSpan" id="kobo.48.1" xmlns="http://www.w3.org/1999/xhtml">That is a problem that we have already dealt with in </span><em><span class="koboSpan" id="kobo.49.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <a href="ch018.xhtml#x1-1660009.2"><em><span class="koboSpan" id="kobo.50.1" xmlns="http://www.w3.org/1999/xhtml">9.2</span></em></a><span class="koboSpan" id="kobo.51.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.51.2" xmlns="http://www.w3.org/1999/xhtml">In order to encode the classical input of a QNN into a quantum state, we just have to use any feature map of our choice. </span><span class="koboSpan" id="kobo.51.3" xmlns="http://www.w3.org/1999/xhtml">As you know, we may also need to normalize or scale the data, of course.</span></p>
<p><span class="koboSpan" id="kobo.52.1" xmlns="http://www.w3.org/1999/xhtml">And that is how we actually ”prepare the data” for a quantum neural network: feeding it into a feature map.</span></p>
</div></li>
<li><div id="x1-183014x2">
<p><strong><span class="koboSpan" id="kobo.53.1" xmlns="http://www.w3.org/1999/xhtml">Data processing</span></strong><span class="koboSpan" id="kobo.54.1" xmlns="http://www.w3.org/1999/xhtml">: At this point, we have </span><span id="dx1-183015"/><span class="koboSpan" id="kobo.55.1" xmlns="http://www.w3.org/1999/xhtml">successfully transformed our classical input into a ”quantum input,” in the form of a quantum state that encodes our classical data according to a certain feature map. </span><span class="koboSpan" id="kobo.55.2" xmlns="http://www.w3.org/1999/xhtml">Now, we need to figure out a way to process this input by drawing some inspiration from the processing in a classical neural network.</span></p>
<p><span class="koboSpan" id="kobo.56.1" xmlns="http://www.w3.org/1999/xhtml">Trying to replicate the full, exact behavior of a classical neural network in a quantum neural network might prove not to be ideal given the state of current quantum hardware. </span><span class="koboSpan" id="kobo.56.2" xmlns="http://www.w3.org/1999/xhtml">Instead, we can look at the bigger picture.</span></p>
<p><span class="koboSpan" id="kobo.57.1" xmlns="http://www.w3.org/1999/xhtml">In essence, the processing stage of a classical neural network consists in the application of some transformations that depend, exclusively, on some optimizable parameters. </span><span class="koboSpan" id="kobo.57.2" xmlns="http://www.w3.org/1999/xhtml">And that is an idea that we can very easily export to a quantum computer. </span><span class="koboSpan" id="kobo.57.3" xmlns="http://www.w3.org/1999/xhtml">We can simply define the ”processing” stage of a quantum neural network as…the application of a circuit that depends on some optimizable parameters! </span><span class="koboSpan" id="kobo.57.4" xmlns="http://www.w3.org/1999/xhtml">In addition to this, as we will see later in this section, this circuit can be structured in layers in a way that somewhat reassembles the spirit of a classical neural network. </span><span class="koboSpan" id="kobo.57.5" xmlns="http://www.w3.org/1999/xhtml">This circuit will be said to be a </span><strong><span class="koboSpan" id="kobo.58.1" xmlns="http://www.w3.org/1999/xhtml">variational form</span></strong><span class="koboSpan" id="kobo.59.1" xmlns="http://www.w3.org/1999/xhtml"> — they are just like the ones we studied back in </span><em><span class="koboSpan" id="kobo.60.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.61.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><span class="koboSpan" id="kobo.62.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.63.1" xmlns="http://www.w3.org/1999/xhtml">VQE:</span></em> <em><span class="koboSpan" id="kobo.64.1" xmlns="http://www.w3.org/1999/xhtml">Variational Quantum Eigensolver</span></em><span class="koboSpan" id="kobo.65.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-183017x3">
<p><strong><span class="koboSpan" id="kobo.66.1" xmlns="http://www.w3.org/1999/xhtml">Data output</span></strong><span class="koboSpan" id="kobo.67.1" xmlns="http://www.w3.org/1999/xhtml">: Once we have a </span><span id="dx1-183018"/><span class="koboSpan" id="kobo.68.1" xmlns="http://www.w3.org/1999/xhtml">processed state, we need to return a classical output. </span><span class="koboSpan" id="kobo.68.2" xmlns="http://www.w3.org/1999/xhtml">And this shall be the result of some measurement operation; this operation can be whichever one suits our problem best!</span></p>
<p><span class="koboSpan" id="kobo.69.1" xmlns="http://www.w3.org/1999/xhtml">For instance, if we wanted to build a binary classifier with a quantum neural network, a natural choice for this measurement operation could be, for example, taking the expectation value of the first qubit when measured on the computational basis. </span><span class="koboSpan" id="kobo.69.2" xmlns="http://www.w3.org/1999/xhtml">Remember that the expectation value of a qubit simply corresponds to the probability of obtaining </span><span class="koboSpan" id="kobo.70.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.71.1" xmlns="http://www.w3.org/1999/xhtml"> upon measuring the qubit on the computational basis.</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.72.1" xmlns="http://www.w3.org/1999/xhtml">And those are all the ingredients that make up a quantum neural network.</span></p>
<p><span class="koboSpan" id="kobo.73.1" xmlns="http://www.w3.org/1999/xhtml">As a matter of fact, feature maps and variational forms are both examples of </span><strong><span class="koboSpan" id="kobo.74.1" xmlns="http://www.w3.org/1999/xhtml">variational circuits</span></strong><span class="koboSpan" id="kobo.75.1" xmlns="http://www.w3.org/1999/xhtml">: quantum </span><span id="dx1-183019"/><span class="koboSpan" id="kobo.76.1" xmlns="http://www.w3.org/1999/xhtml">circuits that are controlled by some classical parameters. </span><span class="koboSpan" id="kobo.76.2" xmlns="http://www.w3.org/1999/xhtml">The only actual difference between a feature map and a variational form is their purpose: feature maps depend on the input data and are used to encode it, while variational forms depend on optimizable parameters and are used to transform a quantum input state.</span></p>
<p><span class="koboSpan" id="kobo.77.1" xmlns="http://www.w3.org/1999/xhtml">This difference in purpose will materialize in the fact that we will often use different circuits for feature maps and variational forms. </span><span class="koboSpan" id="kobo.77.2" xmlns="http://www.w3.org/1999/xhtml">A good feature map need not be a good variational form, and vice versa.</span></p>
<p><span class="koboSpan" id="kobo.78.1" xmlns="http://www.w3.org/1999/xhtml">You should keep in mind that — like all things QML — the terms ”feature map” and ”variational form” are not entirely universal, and different authors may refer to them with different expressions. </span><span class="koboSpan" id="kobo.78.2" xmlns="http://www.w3.org/1999/xhtml">For example, variational forms are commonly referred to as </span><strong><span class="koboSpan" id="kobo.79.1" xmlns="http://www.w3.org/1999/xhtml">ansatzs</span></strong><span class="koboSpan" id="kobo.80.1" xmlns="http://www.w3.org/1999/xhtml">, as we did back in </span><em><span class="koboSpan" id="kobo.81.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.82.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><span class="koboSpan" id="kobo.83.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.84.1" xmlns="http://www.w3.org/1999/xhtml">VQE: Variational</span></em> <em><span class="koboSpan" id="kobo.85.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Eigensolver</span></em><span class="koboSpan" id="kobo.86.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox important" id="tcolobox-179">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.87.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.88.1" xmlns="http://www.w3.org/1999/xhtml">A quantum neural network takes a classical input </span><span class="koboSpan" id="kobo.89.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.90.1" xmlns="http://www.w3.org/1999/xhtml"> and maps it to a quantum state through a feature map </span><span class="koboSpan" id="kobo.91.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="F" class="math inline" src="../media/file1320.png" style="vertical-align:middle" title="F"/></span><span class="koboSpan" id="kobo.92.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.92.2" xmlns="http://www.w3.org/1999/xhtml">The resulting state then goes through a variational form </span><span class="koboSpan" id="kobo.93.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="V" class="math inline" src="../media/file379.png" style="vertical-align:middle" title="V"/></span><span class="koboSpan" id="kobo.94.1" xmlns="http://www.w3.org/1999/xhtml">: a variational circuit dependent on some optimizable parameters </span><span class="koboSpan" id="kobo.95.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{\theta}" class="math inline" src="../media/file1321.png" style="vertical-align:middle" title="\overset{\rightarrow}{\theta}"/></span><span class="koboSpan" id="kobo.96.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.96.2" xmlns="http://www.w3.org/1999/xhtml">The output of the quantum neural network is the result of a measurement operation on the final state. </span><span class="koboSpan" id="kobo.96.3" xmlns="http://www.w3.org/1999/xhtml">All this can be seen, schematically, in the following figure:</span></p>
<div class="center">
<p><span class="koboSpan" id="kobo.97.1" xmlns="http://www.w3.org/1999/xhtml"><img alt=" n⃗ |FV0⟩((⃗x𝜃)) " src="../media/file1322.jpg"/></span></p>
</div>
</div>
</div>
<p><span class="koboSpan" id="kobo.98.1" xmlns="http://www.w3.org/1999/xhtml">Thanks to our study of quantum support vector machines, we are already very familiar with feature maps, but we have yet to get acquainted with variational forms; that is what we will devote the next subsection to.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.1.2" id="variational-forms">
<h2 class="subsectionHead" data-number="18.1.2"><span class="titlemark"><span class="koboSpan" id="kobo.99.1" xmlns="http://www.w3.org/1999/xhtml">10.1.2 </span></span> <span id="x1-18400010.1.2"><span class="koboSpan" id="kobo.100.1" xmlns="http://www.w3.org/1999/xhtml">Variational forms</span></span></h2>
<p><span class="koboSpan" id="kobo.101.1" xmlns="http://www.w3.org/1999/xhtml">In principle, a </span><span id="dx1-184001"/><span class="koboSpan" id="kobo.102.1" xmlns="http://www.w3.org/1999/xhtml">variational form could be any </span><span id="dx1-184002"/><span class="koboSpan" id="kobo.103.1" xmlns="http://www.w3.org/1999/xhtml">variational circuit of your choice, but, in general, variational forms for QNNs follow a ”layered structure,” trying to mimic the spirit of classical neural networks. </span><span class="koboSpan" id="kobo.103.2" xmlns="http://www.w3.org/1999/xhtml">We can now make this idea precise.</span></p>
<p><span class="koboSpan" id="kobo.104.1" xmlns="http://www.w3.org/1999/xhtml">If we </span><span id="dx1-184003"/><span class="koboSpan" id="kobo.105.1" xmlns="http://www.w3.org/1999/xhtml">wanted to define a </span><span id="dx1-184004"/><span class="koboSpan" id="kobo.106.1" xmlns="http://www.w3.org/1999/xhtml">variational form with </span><span class="koboSpan" id="kobo.107.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.108.1" xmlns="http://www.w3.org/1999/xhtml"> layers, we could consider </span><span class="koboSpan" id="kobo.109.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.110.1" xmlns="http://www.w3.org/1999/xhtml"> vectors of independent parameters </span><span class="koboSpan" id="kobo.111.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{\theta}}_{1},\ldots,{\overset{\rightarrow}{\theta}}_{k}" class="math inline" src="../media/file1323.png" style="vertical-align:middle" title="{\overset{\rightarrow}{\theta}}_{1},\ldots,{\overset{\rightarrow}{\theta}}_{k}"/></span><span class="koboSpan" id="kobo.112.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.112.2" xmlns="http://www.w3.org/1999/xhtml">In order to define each layer </span><span class="koboSpan" id="kobo.113.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.114.1" xmlns="http://www.w3.org/1999/xhtml">, we may take a variational circuit </span><span class="koboSpan" id="kobo.115.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="G_{j}" class="math inline" src="../media/file1324.png" style="vertical-align:middle" title="G_{j}"/></span><span class="koboSpan" id="kobo.116.1" xmlns="http://www.w3.org/1999/xhtml"> dependent on the parameters </span><span class="koboSpan" id="kobo.117.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{\theta}}_{j}" class="math inline" src="../media/file1325.png" style="vertical-align:middle" title="{\overset{\rightarrow}{\theta}}_{j}"/></span><span class="koboSpan" id="kobo.118.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.118.2" xmlns="http://www.w3.org/1999/xhtml">A common approach is to prepare variational forms by stacking these variational circuits consecutively and separating them by some circuits </span><span class="koboSpan" id="kobo.119.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="U_{}" class="math inline" src="../media/file1326.png" style="vertical-align:middle" title="U_{}"/></span></p>
<p><span class="koboSpan" id="kobo.120.1" xmlns="http://www.w3.org/1999/xhtml">entˆt</span><span class="koboSpan" id="kobo.121.1" xmlns="http://www.w3.org/1999/xhtml"><img alt=",independentofanyparameters,meanttocreateentanglementbetweenthequbits.Justasin{\textit{Figure~}\text{10.1}}." class="math inline" src="../media/file1327.png" style="vertical-align:middle" title=",independentofanyparameters,meanttocreateentanglementbetweenthequbits.Justasin{\textit{Figure~}\text{10.1}}."/></span></p>
<figure>
<span class="koboSpan" id="kobo.122.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 10.1: A variational form with k layers, each defined by a variational circuit G_{j} dependent on some parameters {\overset{\rightarrow}{\theta}}_{j}. The circuits U_{} entˆtareusedtocreateentanglement,andthestate \left| \psi_{} \right. enc\rangle denotes the output of the feature map " src="../media/file1331.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure10.1"><strong><span class="koboSpan" id="kobo.123.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.1</span></strong><span class="koboSpan" id="kobo.124.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.125.1" xmlns="http://www.w3.org/1999/xhtml">A variational form with </span><span class="koboSpan" id="kobo.126.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.127.1" xmlns="http://www.w3.org/1999/xhtml"> layers, each defined by a variational circuit </span><span class="koboSpan" id="kobo.128.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="G_{j}" class="math inline" src="../media/file1324.png" style="vertical-align:middle" title="G_{j}"/></span><span class="koboSpan" id="kobo.129.1" xmlns="http://www.w3.org/1999/xhtml"> dependent on some parameters </span><span class="koboSpan" id="kobo.130.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{\theta}}_{j}" class="math inline" src="../media/file1325.png" style="vertical-align:middle" title="{\overset{\rightarrow}{\theta}}_{j}"/></span><span class="koboSpan" id="kobo.131.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.131.2" xmlns="http://www.w3.org/1999/xhtml">The circuits </span><span class="koboSpan" id="kobo.132.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="U_{}" class="math inline" src="../media/file1326.png" style="vertical-align:middle" title="U_{}"/></span><span class="koboSpan" id="kobo.133.1" xmlns="http://www.w3.org/1999/xhtml"> entˆt</span><span class="koboSpan" id="kobo.134.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="areusedtocreateentanglement,andthestate" class="math inline" src="../media/file1328.png" style="vertical-align:middle" title="areusedtocreateentanglement,andthestate"/></span> <span class="koboSpan" id="kobo.135.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| \psi_{} \right." class="math inline" src="../media/file1329.png" style="vertical-align:middle" title="\left| \psi_{} \right."/></span><span class="koboSpan" id="kobo.136.1" xmlns="http://www.w3.org/1999/xhtml"> enc</span><span class="koboSpan" id="kobo.137.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\rangle" class="math inline" src="../media/file1330.png" style="vertical-align:middle" title="\rangle"/></span><span class="koboSpan" id="kobo.138.1" xmlns="http://www.w3.org/1999/xhtml"> denotes the output of the feature map </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.139.1" xmlns="http://www.w3.org/1999/xhtml">We have now outlined one of the most common structures of variational forms, but variational forms are best</span><span id="dx1-184007"/><span class="koboSpan" id="kobo.140.1" xmlns="http://www.w3.org/1999/xhtml"> illustrated by examples. </span><span class="koboSpan" id="kobo.140.2" xmlns="http://www.w3.org/1999/xhtml">There are lots of variational forms out there, and there is no way we could collect them all in this book — in truth, there would be no point either. </span><span class="koboSpan" id="kobo.140.3" xmlns="http://www.w3.org/1999/xhtml">For this reason, we will restrict ourselves to presenting just three variational forms, some of which we will use later in the book:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.141.1" xmlns="http://www.w3.org/1999/xhtml">Two-local</span></strong><span class="koboSpan" id="kobo.142.1" xmlns="http://www.w3.org/1999/xhtml">: The </span><strong><span class="koboSpan" id="kobo.143.1" xmlns="http://www.w3.org/1999/xhtml">two-local variational form</span></strong><span class="koboSpan" id="kobo.144.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.145.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.146.1" xmlns="http://www.w3.org/1999/xhtml"> repetitions on </span><span class="koboSpan" id="kobo.147.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.148.1" xmlns="http://www.w3.org/1999/xhtml"> qubits relies on </span><span class="koboSpan" id="kobo.149.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n \times (k + 1)" class="math inline" src="../media/file1332.png" style="vertical-align:middle" title="n \times (k + 1)"/></span><span class="koboSpan" id="kobo.150.1" xmlns="http://www.w3.org/1999/xhtml"> optimizable </span><span id="dx1-184008"/><span class="koboSpan" id="kobo.151.1" xmlns="http://www.w3.org/1999/xhtml">parameters, which we will denote as </span><span class="koboSpan" id="kobo.152.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta_{rj}" class="math inline" src="../media/file1333.png" style="vertical-align:middle" title="\theta_{rj}"/></span><span class="koboSpan" id="kobo.153.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.154.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r = 0,\ldots,k" class="math inline" src="../media/file1334.png" style="vertical-align:middle" title="r = 0,\ldots,k"/></span><span class="koboSpan" id="kobo.155.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.156.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j = 1,\ldots n" class="math inline" src="../media/file1335.png" style="vertical-align:middle" title="j = 1,\ldots n"/></span><span class="koboSpan" id="kobo.157.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.157.2" xmlns="http://www.w3.org/1999/xhtml">Its circuit is </span><span id="dx1-184009"/><span class="koboSpan" id="kobo.158.1" xmlns="http://www.w3.org/1999/xhtml">constructed as per the following procedure:</span></p>
<div class="algorithmic">
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.159.1" xmlns="http://www.w3.org/1999/xhtml">procedure</span></strong> <span class="cmcsc-10x-x-109"><span class="koboSpan" id="kobo.160.1" xmlns="http://www.w3.org/1999/xhtml">T</span><span class="small-caps"><span class="koboSpan" id="kobo.161.1" xmlns="http://www.w3.org/1999/xhtml">w</span></span><span class="small-caps"><span class="koboSpan" id="kobo.162.1" xmlns="http://www.w3.org/1999/xhtml">o</span></span><span class="koboSpan" id="kobo.163.1" xmlns="http://www.w3.org/1999/xhtml">L</span><span class="small-caps"><span class="koboSpan" id="kobo.164.1" xmlns="http://www.w3.org/1999/xhtml">o</span></span><span class="small-caps"><span class="koboSpan" id="kobo.165.1" xmlns="http://www.w3.org/1999/xhtml">c</span></span><span class="small-caps"><span class="koboSpan" id="kobo.166.1" xmlns="http://www.w3.org/1999/xhtml">a</span></span><span class="small-caps"><span class="koboSpan" id="kobo.167.1" xmlns="http://www.w3.org/1999/xhtml">l</span></span></span><span class="koboSpan" id="kobo.168.1" xmlns="http://www.w3.org/1999/xhtml">(</span><span class="koboSpan" id="kobo.169.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n,k,\theta" class="math inline" src="../media/file1336.png" style="vertical-align:middle" title="n,k,\theta"/></span><span class="koboSpan" id="kobo.170.1" xmlns="http://www.w3.org/1999/xhtml">) </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.171.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.172.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r = 0,\ldots,k" class="math inline" src="../media/file1334.png" style="vertical-align:middle" title="r = 0,\ldots,k"/></span> <strong><span class="koboSpan" id="kobo.173.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <span id="textcolor5"><span class="koboSpan" id="kobo.174.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\vartriangleright" class="math inline" src="../media/file655.png" style="vertical-align:middle" title="\vartriangleright"/></span> <em/> </span><span id="textcolor6"><em><span class="koboSpan" id="kobo.175.1" xmlns="http://www.w3.org/1999/xhtml">Add the</span></em> <span class="koboSpan" id="kobo.176.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r" class="math inline" src="../media/file1337.png" style="vertical-align:middle" title="r"/></span><em><span class="koboSpan" id="kobo.177.1" xmlns="http://www.w3.org/1999/xhtml">-th</span></em> <em><span class="koboSpan" id="kobo.178.1" xmlns="http://www.w3.org/1999/xhtml">layer.</span></em></span><span class="koboSpan" id="kobo.179.1" xmlns="http://www.w3.org/1999/xhtml">    </span><span id="textcolor7"> <em/> <span class="koboSpan" id="kobo.180.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\vartriangleleft" class="math inline" src="../media/file1338.png" style="vertical-align:middle" title="\vartriangleleft"/></span></span> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.181.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.182.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j = 1,\ldots,n" class="math inline" src="../media/file980.png" style="vertical-align:middle" title="j = 1,\ldots,n"/></span> <strong><span class="koboSpan" id="kobo.183.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.184.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a </span><span class="koboSpan" id="kobo.185.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Y}(\theta_{rj})" class="math inline" src="../media/file1339.png" style="vertical-align:middle" title="R_{Y}(\theta_{rj})"/></span><span class="koboSpan" id="kobo.186.1" xmlns="http://www.w3.org/1999/xhtml"> gate on qubit </span><span class="koboSpan" id="kobo.187.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.188.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.189.1" xmlns="http://www.w3.org/1999/xhtml"> - </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <span id="textcolor8"><span class="koboSpan" id="kobo.190.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\vartriangleright" class="math inline" src="../media/file655.png" style="vertical-align:middle" title="\vartriangleright"/></span> <em/> </span><span id="textcolor9"><em><span class="koboSpan" id="kobo.191.1" xmlns="http://www.w3.org/1999/xhtml">Create entanglement between layers.</span></em></span><span class="koboSpan" id="kobo.192.1" xmlns="http://www.w3.org/1999/xhtml">    </span><span id="textcolor10"> <em/> <span class="koboSpan" id="kobo.193.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\vartriangleleft" class="math inline" src="../media/file1338.png" style="vertical-align:middle" title="\vartriangleleft"/></span></span> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.194.1" xmlns="http://www.w3.org/1999/xhtml">if</span></strong> <span class="koboSpan" id="kobo.195.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r &lt; k" class="math inline" src="../media/file1340.png" style="vertical-align:middle" title="r &lt; k"/></span> <strong><span class="koboSpan" id="kobo.196.1" xmlns="http://www.w3.org/1999/xhtml">then</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.197.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.198.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="t = 1,\ldots,n - 1" class="math inline" src="../media/file1341.png" style="vertical-align:middle" title="t = 1,\ldots,n - 1"/></span> <strong><span class="koboSpan" id="kobo.199.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.200.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a CNOT gate with control on qubit </span><span class="koboSpan" id="kobo.201.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="t" class="math inline" src="../media/file48.png" style="vertical-align:middle" title="t"/></span><span class="koboSpan" id="kobo.202.1" xmlns="http://www.w3.org/1999/xhtml"> and target on qubit </span><span class="koboSpan" id="kobo.203.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="t + 1" class="math inline" src="../media/file1342.png" style="vertical-align:middle" title="t + 1"/></span><span class="koboSpan" id="kobo.204.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.205.1" xmlns="http://www.w3.org/1999/xhtml"> -</span><span class="koboSpan" id="kobo.206.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="-" class="math inline" src="../media/file1343.png" style="vertical-align:middle" title="-"/></span> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.207.1" xmlns="http://www.w3.org/1999/xhtml"> -</span><span class="koboSpan" id="kobo.208.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="-" class="math inline" src="../media/file1343.png" style="vertical-align:middle" title="-"/></span> </span>
</div>
<p><span class="koboSpan" id="kobo.209.1" xmlns="http://www.w3.org/1999/xhtml">In </span><em><span class="koboSpan" id="kobo.210.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure10.2"><em><span class="koboSpan" id="kobo.211.1" xmlns="http://www.w3.org/1999/xhtml">10.2</span></em></a><span class="koboSpan" id="kobo.212.1" xmlns="http://www.w3.org/1999/xhtml"> we have depicted the output of this procedure for </span><span class="koboSpan" id="kobo.213.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n = 4" class="math inline" src="../media/file837.png" style="vertical-align:middle" title="n = 4"/></span><span class="koboSpan" id="kobo.214.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.215.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k = 3" class="math inline" src="../media/file1344.png" style="vertical-align:middle" title="k = 3"/></span><span class="koboSpan" id="kobo.216.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.216.2" xmlns="http://www.w3.org/1999/xhtml">Sound familiar? </span><span class="koboSpan" id="kobo.216.3" xmlns="http://www.w3.org/1999/xhtml">The two-local variational form uses the same circuit as the angle encoding feature map for its layers, and then it relies on a cascade of controlled-NOT operations in order to create entanglement.</span></p>
<p><span class="koboSpan" id="kobo.217.1" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, how the two-local </span><span id="dx1-184010"/><span class="koboSpan" id="kobo.218.1" xmlns="http://www.w3.org/1999/xhtml">variational form with </span><span class="koboSpan" id="kobo.219.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.220.1" xmlns="http://www.w3.org/1999/xhtml"> repetitions has </span><span class="koboSpan" id="kobo.221.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k + 1" class="math inline" src="../media/file1345.png" style="vertical-align:middle" title="k + 1"/></span><span class="koboSpan" id="kobo.222.1" xmlns="http://www.w3.org/1999/xhtml"> layers, not </span><span class="koboSpan" id="kobo.223.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.224.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.224.2" xmlns="http://www.w3.org/1999/xhtml">This tiny detail can </span><span id="dx1-184011"/><span class="koboSpan" id="kobo.225.1" xmlns="http://www.w3.org/1999/xhtml">sometimes be misleading.</span></p>
<p><span class="koboSpan" id="kobo.226.1" xmlns="http://www.w3.org/1999/xhtml">The two-local variational form is very versatile, and it can be used with any measurement operation.</span></p>
<figure>
<span class="koboSpan" id="kobo.227.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 10.2: Two-local variational form on four qubits and two repetitions" src="../media/file1346.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure10.2"><strong><span class="koboSpan" id="kobo.228.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.2</span></strong><span class="koboSpan" id="kobo.229.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.230.1" xmlns="http://www.w3.org/1999/xhtml">Two-local variational form on four qubits and two repetitions</span></figcaption>
</figure></li>
<li><p><strong><span class="koboSpan" id="kobo.231.1" xmlns="http://www.w3.org/1999/xhtml">Tree tensor</span></strong><span class="koboSpan" id="kobo.232.1" xmlns="http://www.w3.org/1999/xhtml">: The </span><strong><span class="koboSpan" id="kobo.233.1" xmlns="http://www.w3.org/1999/xhtml">tree tensor</span></strong><span class="koboSpan" id="kobo.234.1" xmlns="http://www.w3.org/1999/xhtml"> variational </span><span id="dx1-184014"/><span class="koboSpan" id="kobo.235.1" xmlns="http://www.w3.org/1999/xhtml">form with </span><span class="koboSpan" id="kobo.236.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k + 1" class="math inline" src="../media/file1345.png" style="vertical-align:middle" title="k + 1"/></span><span class="koboSpan" id="kobo.237.1" xmlns="http://www.w3.org/1999/xhtml"> layers can be </span><span id="dx1-184015"/><span class="koboSpan" id="kobo.238.1" xmlns="http://www.w3.org/1999/xhtml">applied on </span><span class="koboSpan" id="kobo.239.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n = 2^{k}" class="math inline" src="../media/file1347.png" style="vertical-align:middle" title="n = 2^{k}"/></span><span class="koboSpan" id="kobo.240.1" xmlns="http://www.w3.org/1999/xhtml"> qubits. </span><span class="koboSpan" id="kobo.240.2" xmlns="http://www.w3.org/1999/xhtml">Each layer has half the number of parameters as the previous one, so the variational form relies on </span><span class="koboSpan" id="kobo.241.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{k} + 2^{k - 1} + \cdots + 1" class="math inline" src="../media/file1348.png" style="vertical-align:middle" title="2^{k} + 2^{k - 1} + \cdots + 1"/></span><span class="koboSpan" id="kobo.242.1" xmlns="http://www.w3.org/1999/xhtml"> optimizable parameters of the form</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.243.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta_{rs},\qquad r = 0,\ldots,k,\qquad s = 0,\ldots,2^{k - r} - 1." class="math display" src="../media/file1349.png" style="vertical-align:middle" title="\theta_{rs},\qquad r = 0,\ldots,k,\qquad s = 0,\ldots,2^{k - r} - 1."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.244.1" xmlns="http://www.w3.org/1999/xhtml">The procedure that defines is somewhat more opaque than that of the two-local variational form, and it reads as follows:</span></p>
<div class="algorithmic">
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.245.1" xmlns="http://www.w3.org/1999/xhtml">procedure</span></strong> <span class="cmcsc-10x-x-109"><span class="koboSpan" id="kobo.246.1" xmlns="http://www.w3.org/1999/xhtml">T</span><span class="small-caps"><span class="koboSpan" id="kobo.247.1" xmlns="http://www.w3.org/1999/xhtml">r</span></span><span class="small-caps"><span class="koboSpan" id="kobo.248.1" xmlns="http://www.w3.org/1999/xhtml">e</span></span><span class="small-caps"><span class="koboSpan" id="kobo.249.1" xmlns="http://www.w3.org/1999/xhtml">e</span></span><span class="koboSpan" id="kobo.250.1" xmlns="http://www.w3.org/1999/xhtml">T</span><span class="small-caps"><span class="koboSpan" id="kobo.251.1" xmlns="http://www.w3.org/1999/xhtml">e</span></span><span class="small-caps"><span class="koboSpan" id="kobo.252.1" xmlns="http://www.w3.org/1999/xhtml">n</span></span><span class="small-caps"><span class="koboSpan" id="kobo.253.1" xmlns="http://www.w3.org/1999/xhtml">s</span></span><span class="small-caps"><span class="koboSpan" id="kobo.254.1" xmlns="http://www.w3.org/1999/xhtml">o</span></span><span class="small-caps"><span class="koboSpan" id="kobo.255.1" xmlns="http://www.w3.org/1999/xhtml">r</span></span></span><span class="koboSpan" id="kobo.256.1" xmlns="http://www.w3.org/1999/xhtml">(</span><span class="koboSpan" id="kobo.257.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k,\theta" class="math inline" src="../media/file1350.png" style="vertical-align:middle" title="k,\theta"/></span><span class="koboSpan" id="kobo.258.1" xmlns="http://www.w3.org/1999/xhtml">) </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.259.1" xmlns="http://www.w3.org/1999/xhtml"> On each qubit </span><span class="koboSpan" id="kobo.260.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.261.1" xmlns="http://www.w3.org/1999/xhtml">, apply a rotation </span><span class="koboSpan" id="kobo.262.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Y}(\theta_{0j})" class="math inline" src="../media/file1351.png" style="vertical-align:middle" title="R_{Y}(\theta_{0j})"/></span><span class="koboSpan" id="kobo.263.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.264.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.265.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r = 1,\ldots,k" class="math inline" src="../media/file1352.png" style="vertical-align:middle" title="r = 1,\ldots,k"/></span> <strong><span class="koboSpan" id="kobo.266.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.267.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.268.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="s = 0,\ldots,2^{k - r} - 1" class="math inline" src="../media/file1353.png" style="vertical-align:middle" title="s = 0,\ldots,2^{k - r} - 1"/></span> <strong><span class="koboSpan" id="kobo.269.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.270.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a CNOT operation with target on qubit </span><span class="koboSpan" id="kobo.271.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1 + s2^{r}" class="math inline" src="../media/file1354.png" style="vertical-align:middle" title="1 + s2^{r}"/></span><span class="koboSpan" id="kobo.272.1" xmlns="http://www.w3.org/1999/xhtml"> and controlled by qubit </span><span class="koboSpan" id="kobo.273.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1 + s2^{r} + 2^{r - 1}" class="math inline" src="../media/file1355.png" style="vertical-align:middle" title="1 + s2^{r} + 2^{r - 1}"/></span><span class="koboSpan" id="kobo.274.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.275.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a rotation </span><span class="koboSpan" id="kobo.276.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Y}(\theta_{r,s})" class="math inline" src="../media/file1356.png" style="vertical-align:middle" title="R_{Y}(\theta_{r,s})"/></span><span class="koboSpan" id="kobo.277.1" xmlns="http://www.w3.org/1999/xhtml"> on qubit </span><span class="koboSpan" id="kobo.278.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1 + s2^{r}" class="math inline" src="../media/file1354.png" style="vertical-align:middle" title="1 + s2^{r}"/></span><span class="koboSpan" id="kobo.279.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.280.1" xmlns="http://www.w3.org/1999/xhtml"> -</span><span class="koboSpan" id="kobo.281.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="-" class="math inline" src="../media/file1343.png" style="vertical-align:middle" title="-"/></span> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.282.1" xmlns="http://www.w3.org/1999/xhtml"> - </span></span>
</div>
<p><span class="koboSpan" id="kobo.283.1" xmlns="http://www.w3.org/1999/xhtml">An image is worth a </span><span id="dx1-184016"/><span class="koboSpan" id="kobo.284.1" xmlns="http://www.w3.org/1999/xhtml">thousand words, so, please, refer to </span><em><span class="koboSpan" id="kobo.285.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure10.3"><em><span class="koboSpan" id="kobo.286.1" xmlns="http://www.w3.org/1999/xhtml">10.3</span></em></a><span class="koboSpan" id="kobo.287.1" xmlns="http://www.w3.org/1999/xhtml"> for a depiction of the output of this procedure for </span><span class="koboSpan" id="kobo.288.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k = 3" class="math inline" src="../media/file1344.png" style="vertical-align:middle" title="k = 3"/></span><span class="koboSpan" id="kobo.289.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.290.1" xmlns="http://www.w3.org/1999/xhtml">The tree tensor </span><span id="dx1-184017"/><span class="koboSpan" id="kobo.291.1" xmlns="http://www.w3.org/1999/xhtml">variational form fits best in </span><span id="dx1-184018"/><span class="koboSpan" id="kobo.292.1" xmlns="http://www.w3.org/1999/xhtml">quantum neural networks designed to work as binary classifiers. </span><span class="koboSpan" id="kobo.292.2" xmlns="http://www.w3.org/1999/xhtml">The most natural measurement operation that can be used in conjunction with it is the obtention of the expected value of the first qubit, as measured in the computational basis.</span></p>
<p><span class="koboSpan" id="kobo.293.1" xmlns="http://www.w3.org/1999/xhtml">As a curiosity, the name of the tree tensor variational form comes from mathematical objects that are used for the simulation of physics systems and also in some machine learning models. </span><span class="koboSpan" id="kobo.293.2" xmlns="http://www.w3.org/1999/xhtml">See the survey paper by Román Orús for model details </span><span class="cite"><span class="koboSpan" id="kobo.294.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xorus2014practical"><span class="koboSpan" id="kobo.295.1" xmlns="http://www.w3.org/1999/xhtml">71</span></a><span class="koboSpan" id="kobo.296.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.297.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.298.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 10.3: Tree tensor variational form on 8 = 2^{3} qubits" src="../media/file1358.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure10.3"><strong><span class="koboSpan" id="kobo.299.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.3</span></strong><span class="koboSpan" id="kobo.300.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.301.1" xmlns="http://www.w3.org/1999/xhtml">Tree tensor variational form on </span><span class="koboSpan" id="kobo.302.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8 = 2^{3}" class="math inline" src="../media/file1357.png" style="vertical-align:middle" title="8 = 2^{3}"/></span><span class="koboSpan" id="kobo.303.1" xmlns="http://www.w3.org/1999/xhtml"> qubits</span></figcaption>
</figure></li>
<li><p><strong><span class="koboSpan" id="kobo.304.1" xmlns="http://www.w3.org/1999/xhtml">Strongly entangling layers</span></strong><span class="koboSpan" id="kobo.305.1" xmlns="http://www.w3.org/1999/xhtml">: The </span><span id="dx1-184021"/><span class="koboSpan" id="kobo.306.1" xmlns="http://www.w3.org/1999/xhtml">strongly entangling layers </span><span id="dx1-184022"/><span class="koboSpan" id="kobo.307.1" xmlns="http://www.w3.org/1999/xhtml">variational form acts on </span><span class="koboSpan" id="kobo.308.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.309.1" xmlns="http://www.w3.org/1999/xhtml"> qubits and can have </span><span id="dx1-184023"/><span class="koboSpan" id="kobo.310.1" xmlns="http://www.w3.org/1999/xhtml">any number </span><span class="koboSpan" id="kobo.311.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.312.1" xmlns="http://www.w3.org/1999/xhtml"> of layers. </span><span class="koboSpan" id="kobo.312.2" xmlns="http://www.w3.org/1999/xhtml">Each layer </span><span class="koboSpan" id="kobo.313.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="l" class="math inline" src="../media/file514.png" style="vertical-align:middle" title="l"/></span><span class="koboSpan" id="kobo.314.1" xmlns="http://www.w3.org/1999/xhtml"> is given a </span><strong><span class="koboSpan" id="kobo.315.1" xmlns="http://www.w3.org/1999/xhtml">range</span></strong> <span class="koboSpan" id="kobo.316.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="r_{l}" class="math inline" src="../media/file1359.png" style="vertical-align:middle" title="r_{l}"/></span><span class="koboSpan" id="kobo.317.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.317.2" xmlns="http://www.w3.org/1999/xhtml">In total, the variational form uses </span><span class="koboSpan" id="kobo.318.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3nk" class="math inline" src="../media/file1360.png" style="vertical-align:middle" title="3nk"/></span><span class="koboSpan" id="kobo.319.1" xmlns="http://www.w3.org/1999/xhtml"> parameters of the form</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.320.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta_{ljx},\qquad l = 1,\ldots,k,\qquad j = 1,\ldots,n,\qquad x = 1,2,3." class="math display" src="../media/file1361.png" style="vertical-align:middle" title="\theta_{ljx},\qquad l = 1,\ldots,k,\qquad j = 1,\ldots,n,\qquad x = 1,2,3."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.321.1" xmlns="http://www.w3.org/1999/xhtml">The form is defined by the following algorithm:</span></p>
<div class="algorithmic">
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.322.1" xmlns="http://www.w3.org/1999/xhtml">procedure</span></strong> <span class="cmcsc-10x-x-109"><span class="koboSpan" id="kobo.323.1" xmlns="http://www.w3.org/1999/xhtml">S</span><span class="small-caps"><span class="koboSpan" id="kobo.324.1" xmlns="http://www.w3.org/1999/xhtml">t</span></span><span class="small-caps"><span class="koboSpan" id="kobo.325.1" xmlns="http://www.w3.org/1999/xhtml">r</span></span><span class="small-caps"><span class="koboSpan" id="kobo.326.1" xmlns="http://www.w3.org/1999/xhtml">o</span></span><span class="small-caps"><span class="koboSpan" id="kobo.327.1" xmlns="http://www.w3.org/1999/xhtml">n</span></span><span class="small-caps"><span class="koboSpan" id="kobo.328.1" xmlns="http://www.w3.org/1999/xhtml">g</span></span><span class="small-caps"><span class="koboSpan" id="kobo.329.1" xmlns="http://www.w3.org/1999/xhtml">l</span></span><span class="small-caps"><span class="koboSpan" id="kobo.330.1" xmlns="http://www.w3.org/1999/xhtml">y</span></span><span class="koboSpan" id="kobo.331.1" xmlns="http://www.w3.org/1999/xhtml">E</span><span class="small-caps"><span class="koboSpan" id="kobo.332.1" xmlns="http://www.w3.org/1999/xhtml">n</span></span><span class="small-caps"><span class="koboSpan" id="kobo.333.1" xmlns="http://www.w3.org/1999/xhtml">t</span></span><span class="small-caps"><span class="koboSpan" id="kobo.334.1" xmlns="http://www.w3.org/1999/xhtml">a</span></span><span class="small-caps"><span class="koboSpan" id="kobo.335.1" xmlns="http://www.w3.org/1999/xhtml">n</span></span><span class="small-caps"><span class="koboSpan" id="kobo.336.1" xmlns="http://www.w3.org/1999/xhtml">g</span></span><span class="small-caps"><span class="koboSpan" id="kobo.337.1" xmlns="http://www.w3.org/1999/xhtml">l</span></span><span class="small-caps"><span class="koboSpan" id="kobo.338.1" xmlns="http://www.w3.org/1999/xhtml">i</span></span><span class="small-caps"><span class="koboSpan" id="kobo.339.1" xmlns="http://www.w3.org/1999/xhtml">n</span></span><span class="small-caps"><span class="koboSpan" id="kobo.340.1" xmlns="http://www.w3.org/1999/xhtml">g</span></span><span class="koboSpan" id="kobo.341.1" xmlns="http://www.w3.org/1999/xhtml">L</span><span class="small-caps"><span class="koboSpan" id="kobo.342.1" xmlns="http://www.w3.org/1999/xhtml">a</span></span><span class="small-caps"><span class="koboSpan" id="kobo.343.1" xmlns="http://www.w3.org/1999/xhtml">y</span></span><span class="small-caps"><span class="koboSpan" id="kobo.344.1" xmlns="http://www.w3.org/1999/xhtml">e</span></span><span class="small-caps"><span class="koboSpan" id="kobo.345.1" xmlns="http://www.w3.org/1999/xhtml">r</span></span><span class="small-caps"><span class="koboSpan" id="kobo.346.1" xmlns="http://www.w3.org/1999/xhtml">s</span></span></span><span class="koboSpan" id="kobo.347.1" xmlns="http://www.w3.org/1999/xhtml">(</span><span class="koboSpan" id="kobo.348.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n,k,r,\theta" class="math inline" src="../media/file1362.png" style="vertical-align:middle" title="n,k,r,\theta"/></span><span class="koboSpan" id="kobo.349.1" xmlns="http://www.w3.org/1999/xhtml">) </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.350.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.351.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="l = 1,\ldots,k" class="math inline" src="../media/file1363.png" style="vertical-align:middle" title="l = 1,\ldots,k"/></span> <strong><span class="koboSpan" id="kobo.352.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.353.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.354.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j = 1,\ldots,n" class="math inline" src="../media/file980.png" style="vertical-align:middle" title="j = 1,\ldots,n"/></span> <strong><span class="koboSpan" id="kobo.355.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.356.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a rotation </span><span class="koboSpan" id="kobo.357.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}(\theta_{lj1})" class="math inline" src="../media/file1364.png" style="vertical-align:middle" title="R_{Z}(\theta_{lj1})"/></span><span class="koboSpan" id="kobo.358.1" xmlns="http://www.w3.org/1999/xhtml"> on qubit </span><span class="koboSpan" id="kobo.359.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.360.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.361.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a rotation </span><span class="koboSpan" id="kobo.362.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Y}(\theta_{lj2})" class="math inline" src="../media/file1365.png" style="vertical-align:middle" title="R_{Y}(\theta_{lj2})"/></span><span class="koboSpan" id="kobo.363.1" xmlns="http://www.w3.org/1999/xhtml"> on qubit </span><span class="koboSpan" id="kobo.364.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.365.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.366.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a rotation </span><span class="koboSpan" id="kobo.367.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}(\theta_{lj3})" class="math inline" src="../media/file1366.png" style="vertical-align:middle" title="R_{Z}(\theta_{lj3})"/></span><span class="koboSpan" id="kobo.368.1" xmlns="http://www.w3.org/1999/xhtml"> on qubit </span><span class="koboSpan" id="kobo.369.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.370.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.371.1" xmlns="http://www.w3.org/1999/xhtml"> - </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"> <strong><span class="koboSpan" id="kobo.372.1" xmlns="http://www.w3.org/1999/xhtml">for all</span></strong> <span class="koboSpan" id="kobo.373.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j = 1,\ldots,n" class="math inline" src="../media/file980.png" style="vertical-align:middle" title="j = 1,\ldots,n"/></span> <strong><span class="koboSpan" id="kobo.374.1" xmlns="http://www.w3.org/1999/xhtml">do</span></strong> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.375.1" xmlns="http://www.w3.org/1999/xhtml"> Apply a CNOT operation controlled by qubit </span><span class="koboSpan" id="kobo.376.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.377.1" xmlns="http://www.w3.org/1999/xhtml"> and with target on qubit </span><span class="koboSpan" id="kobo.378.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\lbrack(j + r_{l} - 1)\ \operatorname{mod}\ N\rbrack + 1" class="math inline" src="../media/file1367.png" style="vertical-align:middle" title="\lbrack(j + r_{l} - 1)\ \operatorname{mod}\ N\rbrack + 1"/></span><span class="koboSpan" id="kobo.379.1" xmlns="http://www.w3.org/1999/xhtml">. </span></span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.380.1" xmlns="http://www.w3.org/1999/xhtml"> -</span><span class="koboSpan" id="kobo.381.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="-" class="math inline" src="../media/file1343.png" style="vertical-align:middle" title="-"/></span> </span><br/>
<span class="label-5.475pt"> </span> <span class="algorithmic"><span class="koboSpan" id="kobo.382.1" xmlns="http://www.w3.org/1999/xhtml"> - </span></span>
</div>
<p><span class="koboSpan" id="kobo.383.1" xmlns="http://www.w3.org/1999/xhtml">You may find a </span><span id="dx1-184024"/><span class="koboSpan" id="kobo.384.1" xmlns="http://www.w3.org/1999/xhtml">representation of a sample of this form in </span><em><span class="koboSpan" id="kobo.385.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure10.4"><em><span class="koboSpan" id="kobo.386.1" xmlns="http://www.w3.org/1999/xhtml">10.4</span></em></a><span class="koboSpan" id="kobo.387.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.388.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 10.4: Strongly entangling layers form on four qubits and two layers with respective ranges 1 and 2" src="../media/file1368.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure10.4"><strong><span class="koboSpan" id="kobo.389.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.4</span></strong><span class="koboSpan" id="kobo.390.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.391.1" xmlns="http://www.w3.org/1999/xhtml">Strongly entangling layers form on four qubits and two layers with respective ranges </span><span class="koboSpan" id="kobo.392.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.393.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.394.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span></figcaption>
</figure></li>
</ul>
<p><span class="koboSpan" id="kobo.395.1" xmlns="http://www.w3.org/1999/xhtml">As a final remark, our choice to use mostly </span><span class="koboSpan" id="kobo.396.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Y" class="math inline" src="../media/file11.png" style="vertical-align:middle" title="Y"/></span><span class="koboSpan" id="kobo.397.1" xmlns="http://www.w3.org/1999/xhtml"> rotations in the </span><span id="dx1-184027"/><span class="koboSpan" id="kobo.398.1" xmlns="http://www.w3.org/1999/xhtml">previous examples of variational forms is </span><span id="dx1-184028"/><span class="koboSpan" id="kobo.399.1" xmlns="http://www.w3.org/1999/xhtml">somewhat arbitrary. </span><span class="koboSpan" id="kobo.399.2" xmlns="http://www.w3.org/1999/xhtml">We could’ve also used </span><span class="koboSpan" id="kobo.400.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.401.1" xmlns="http://www.w3.org/1999/xhtml"> rotations, for example. </span><span class="koboSpan" id="kobo.401.2" xmlns="http://www.w3.org/1999/xhtml">The same goes for our choice to use controlled-</span><span class="koboSpan" id="kobo.402.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.403.1" xmlns="http://www.w3.org/1999/xhtml"> operations in the entanglement circuits. </span><span class="koboSpan" id="kobo.403.2" xmlns="http://www.w3.org/1999/xhtml">We could have used a different controlled operation, for instance. </span><span class="koboSpan" id="kobo.403.3" xmlns="http://www.w3.org/1999/xhtml">In addition to this, in the two-local variational form, there are more options for the distribution of gates in the entanglement circuit beyond the one that we have considered. </span><span class="koboSpan" id="kobo.403.4" xmlns="http://www.w3.org/1999/xhtml">Our entanglement circuit is said to have a ”linear” arrangement of gates, but other possibilities are shown in </span><em><span class="koboSpan" id="kobo.404.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure10.5"><em><span class="koboSpan" id="kobo.405.1" xmlns="http://www.w3.org/1999/xhtml">10.5</span></em></a><span class="koboSpan" id="kobo.406.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.407.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(a) Linear" src="../media/file1369.png"/></span>
<figcaption aria-hidden="true"><span id="Figure10.5a"><strong><span class="koboSpan" id="kobo.408.1" xmlns="http://www.w3.org/1999/xhtml">(a)</span></strong></span><span class="koboSpan" id="kobo.409.1" xmlns="http://www.w3.org/1999/xhtml"> Linear</span></figcaption>
</figure>
<figure>
<span class="koboSpan" id="kobo.410.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(b) Circular" src="../media/file1370.jpg"/></span>
<figcaption aria-hidden="true"><span id="Figure10.5b"><strong><span class="koboSpan" id="kobo.411.1" xmlns="http://www.w3.org/1999/xhtml">(b)</span></strong></span><span class="koboSpan" id="kobo.412.1" xmlns="http://www.w3.org/1999/xhtml"> Circular</span></figcaption>
</figure>
<figure>
<span class="koboSpan" id="kobo.413.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(c) Full" src="../media/file1371.jpg"/></span>
<figcaption aria-hidden="true"><span id="Figure10.5c"><strong><span class="koboSpan" id="kobo.414.1" xmlns="http://www.w3.org/1999/xhtml">(c)</span></strong></span><span class="koboSpan" id="kobo.415.1" xmlns="http://www.w3.org/1999/xhtml"> Full</span></figcaption>
</figure>
<p><span id="Figure10.5"><strong><span class="koboSpan" id="kobo.416.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.5</span></strong></span><span class="koboSpan" id="kobo.417.1" xmlns="http://www.w3.org/1999/xhtml">: Different entanglement circuits</span></p>
<p><span class="koboSpan" id="kobo.418.1" xmlns="http://www.w3.org/1999/xhtml">This is all we </span><span id="dx1-184034"/><span class="koboSpan" id="kobo.419.1" xmlns="http://www.w3.org/1999/xhtml">need to know, for now, about </span><span id="dx1-184035"/><span class="koboSpan" id="kobo.420.1" xmlns="http://www.w3.org/1999/xhtml">variational forms. </span><span class="koboSpan" id="kobo.420.2" xmlns="http://www.w3.org/1999/xhtml">Combined with our previous knowledge of feature maps, this ends our </span><span id="dx1-184036"/><span class="koboSpan" id="kobo.421.1" xmlns="http://www.w3.org/1999/xhtml">analysis of the elements of a quantum neural network…almost. </span><span class="koboSpan" id="kobo.421.2" xmlns="http://www.w3.org/1999/xhtml">We still have to dive deeper into that seemingly innocent measurement operation at the end of every quantum neural network.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.1.3" id="a-word-about-measurements">
<h2 class="subsectionHead" data-number="18.1.3"><span class="titlemark"><span class="koboSpan" id="kobo.422.1" xmlns="http://www.w3.org/1999/xhtml">10.1.3 </span></span> <span id="x1-18500010.1.3"><span class="koboSpan" id="kobo.423.1" xmlns="http://www.w3.org/1999/xhtml">A word about measurements</span></span></h2>
<p><span class="koboSpan" id="kobo.424.1" xmlns="http://www.w3.org/1999/xhtml">As we saw back in </span><em><span class="koboSpan" id="kobo.425.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.426.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><span class="koboSpan" id="kobo.427.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.428.1" xmlns="http://www.w3.org/1999/xhtml">VQE: Variational Quantum Eigensolver</span></em><span class="koboSpan" id="kobo.429.1" xmlns="http://www.w3.org/1999/xhtml">, any physical observable can be represented by a Hermitian operator in such a way that all the possible outcomes of the </span><span id="dx1-185001"/><span class="koboSpan" id="kobo.430.1" xmlns="http://www.w3.org/1999/xhtml">measurement of the observable can be matched to the different eigenvalues of the operator. </span><span class="koboSpan" id="kobo.430.2" xmlns="http://www.w3.org/1999/xhtml">If you haven’t done so already, please, have a look at </span><em><span class="koboSpan" id="kobo.431.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <a href="ch015.xhtml#x1-1210007.1.1"><em><span class="koboSpan" id="kobo.432.1" xmlns="http://www.w3.org/1999/xhtml">7.1.1</span></em></a><span class="koboSpan" id="kobo.433.1" xmlns="http://www.w3.org/1999/xhtml"> if you are not familiar with this.</span></p>
<p><span class="koboSpan" id="kobo.434.1" xmlns="http://www.w3.org/1999/xhtml">When we measure a single qubit in the computational basis, the coordinate matrix with respect to the computational basis of the associated Hermitian operator could well be either of</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.435.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \\ \end{pmatrix},\qquad Z = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; {- 1} \\ \end{pmatrix}." class="math display" src="../media/file1372.png" style="vertical-align:middle" title="M = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \\ \end{pmatrix},\qquad Z = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; {- 1} \\ \end{pmatrix}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.436.1" xmlns="http://www.w3.org/1999/xhtml">Both of these operators</span><span id="dx1-185002"/><span class="koboSpan" id="kobo.437.1" xmlns="http://www.w3.org/1999/xhtml"> represent the measurement of a qubit, but they differ in the eigenvalues that they associate to the distinct outputs. </span><span class="koboSpan" id="kobo.437.2" xmlns="http://www.w3.org/1999/xhtml">The first operator associates the eigenvalues </span><span class="koboSpan" id="kobo.438.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.439.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.440.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.441.1" xmlns="http://www.w3.org/1999/xhtml"> to the qubit’s value being </span><span class="koboSpan" id="kobo.442.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.443.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.444.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.445.1" xmlns="http://www.w3.org/1999/xhtml"> respectively, while the second observable associates the eigenvalues </span><span class="koboSpan" id="kobo.446.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.447.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.448.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.449.1" xmlns="http://www.w3.org/1999/xhtml"> to these outcomes.</span></p>
<div class="tcolorbox questionx" id="tcolobox-180">
<span id="x1-185004x10.1.3"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.450.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 10.1</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.451.1" xmlns="http://www.w3.org/1999/xhtml">The purpose of this exercise is for you to get more familiar with Dirac notation. </span><span class="koboSpan" id="kobo.451.2" xmlns="http://www.w3.org/1999/xhtml">Show that the two previous Hermitian operators may be written, respectively, as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.452.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1\left| 0 \right\rangle\left\langle 0 \right| + 0\left| 1 \right\rangle\left\langle 1 \right| = \left| 1 \right\rangle\left\langle 1 \right|,\quad\left| 0 \right\rangle\left\langle 0 \right| - \left| 1 \right\rangle\left\langle 1 \right|." class="math display" src="../media/file1373.png" style="vertical-align:middle" title="1\left| 0 \right\rangle\left\langle 0 \right| + 0\left| 1 \right\rangle\left\langle 1 \right| = \left| 1 \right\rangle\left\langle 1 \right|,\quad\left| 0 \right\rangle\left\langle 0 \right| - \left| 1 \right\rangle\left\langle 1 \right|."/></span></td>
</tr>
</tbody>
</table>
<p><em><span class="koboSpan" id="kobo.453.1" xmlns="http://www.w3.org/1999/xhtml">Hint</span></em><span class="koboSpan" id="kobo.454.1" xmlns="http://www.w3.org/1999/xhtml">: Remember that the product of a ket (column vector) and a bra (row vector) is a matrix. </span><span class="koboSpan" id="kobo.454.2" xmlns="http://www.w3.org/1999/xhtml">We saw an example of this back in </span><em><span class="koboSpan" id="kobo.455.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <em/> <a href="ch015.xhtml#x1-1240007.2.1"><em><span class="koboSpan" id="kobo.456.1" xmlns="http://www.w3.org/1999/xhtml">7.2.1</span></em></a><span class="koboSpan" id="kobo.457.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.458.1" xmlns="http://www.w3.org/1999/xhtml">As we will see later on in the chapter, frameworks such as PennyLane allow you to work with measurement operations defined by any Hermitian operator. </span><span class="koboSpan" id="kobo.458.2" xmlns="http://www.w3.org/1999/xhtml">This can give you a lot of flexibility when defining the measurement operation of a neural network. </span><span class="koboSpan" id="kobo.458.3" xmlns="http://www.w3.org/1999/xhtml">For instance, in an </span><span class="koboSpan" id="kobo.459.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.460.1" xmlns="http://www.w3.org/1999/xhtml">-qubit circuit, you will be able to instruct PennyLane to compute the expectation value of the observable </span><span class="koboSpan" id="kobo.461.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M \otimes \cdots \otimes M" class="math inline" src="../media/file1374.png" style="vertical-align:middle" title="M \otimes \cdots \otimes M"/></span><span class="koboSpan" id="kobo.462.1" xmlns="http://www.w3.org/1999/xhtml">, which has as its coordinate representation in the computational basis the matrix</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.463.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\begin{pmatrix} 0 &amp; &amp; &amp; \\ &amp; \ddots &amp; &amp; \\ &amp; &amp; 0 &amp; \\ &amp; &amp; &amp; 1 \\ \end{pmatrix}_{2^{n} \times 2^{n}}." class="math display" src="../media/file1375.png" style="vertical-align:middle" title="\begin{pmatrix} 0 &amp; &amp; &amp; \\  &amp; \ddots &amp; &amp; \\  &amp; &amp; 0 &amp; \\  &amp; &amp; &amp; 1 \\ \end{pmatrix}_{2^{n} \times 2^{n}}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.464.1" xmlns="http://www.w3.org/1999/xhtml">Alternatively, you may want to consider the observable </span><span class="koboSpan" id="kobo.465.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Z \otimes \cdots \otimes Z" class="math inline" src="../media/file1376.png" style="vertical-align:middle" title="Z \otimes \cdots \otimes Z"/></span><span class="koboSpan" id="kobo.466.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.466.2" xmlns="http://www.w3.org/1999/xhtml">It is easy to see how this observable will return </span><span class="koboSpan" id="kobo.467.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="+ 1" class="math inline" src="../media/file1377.png" style="vertical-align:middle" title="+ 1"/></span><span class="koboSpan" id="kobo.468.1" xmlns="http://www.w3.org/1999/xhtml"> if an even number of qubits are measured as </span><span class="koboSpan" id="kobo.469.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.470.1" xmlns="http://www.w3.org/1999/xhtml">, and </span><span class="koboSpan" id="kobo.471.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.472.1" xmlns="http://www.w3.org/1999/xhtml"> otherwise. </span><span class="koboSpan" id="kobo.472.2" xmlns="http://www.w3.org/1999/xhtml">That’s the reason why </span><span class="koboSpan" id="kobo.473.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Z \otimes \cdots \otimes Z" class="math inline" src="../media/file1376.png" style="vertical-align:middle" title="Z \otimes \cdots \otimes Z"/></span><span class="koboSpan" id="kobo.474.1" xmlns="http://www.w3.org/1999/xhtml"> is </span><span id="dx1-185005"/><span class="koboSpan" id="kobo.475.1" xmlns="http://www.w3.org/1999/xhtml">referred to as the </span><strong><span class="koboSpan" id="kobo.476.1" xmlns="http://www.w3.org/1999/xhtml">parity</span></strong><span class="koboSpan" id="kobo.477.1" xmlns="http://www.w3.org/1999/xhtml"> observable.</span></p>
<p><span class="koboSpan" id="kobo.478.1" xmlns="http://www.w3.org/1999/xhtml">Of course, you will also be able to take the measurement operation to be a good old expectation value on the first qubit. </span><span class="koboSpan" id="kobo.478.2" xmlns="http://www.w3.org/1999/xhtml">But, the point is, there’s also a plethora of options available to you, should you want to explore them!</span></p>
<p><span class="koboSpan" id="kobo.479.1" xmlns="http://www.w3.org/1999/xhtml">As we </span><span id="dx1-185006"/><span class="koboSpan" id="kobo.480.1" xmlns="http://www.w3.org/1999/xhtml">mentioned before, observables are the final building blocks of every quantum neural network architecture. </span><span class="koboSpan" id="kobo.480.2" xmlns="http://www.w3.org/1999/xhtml">Quantum neural networks accept an input, which usually consists of classical data being fed through a feature map. </span><span class="koboSpan" id="kobo.480.3" xmlns="http://www.w3.org/1999/xhtml">The resulting quantum state is then transformed by a variational form and, lastly, some (classical) numerical data is obtained through a measurement operation. </span><span class="koboSpan" id="kobo.480.4" xmlns="http://www.w3.org/1999/xhtml">In this way, we have a ”black box” transforming some numerical inputs into outputs, that is, a model that — just like any other classical ML model — can be trained.</span></p>
<p><span class="koboSpan" id="kobo.481.1" xmlns="http://www.w3.org/1999/xhtml">We have now defined what quantum neural networks are and learned how to construct them, at least in theory. </span><span class="koboSpan" id="kobo.481.2" xmlns="http://www.w3.org/1999/xhtml">That means we have a model. </span><span class="koboSpan" id="kobo.481.3" xmlns="http://www.w3.org/1999/xhtml">But this is quantum machine learning, so a model is not enough: we need to train it. </span><span class="koboSpan" id="kobo.481.4" xmlns="http://www.w3.org/1999/xhtml">And in order to do so, we will need, among other things, an optimization algorithm.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.1.4" id="gradient-computation-and-the-parameter-shift-rule">
<h2 class="subsectionHead" data-number="18.1.4"><span class="titlemark"><span class="koboSpan" id="kobo.482.1" xmlns="http://www.w3.org/1999/xhtml">10.1.4 </span></span> <span id="x1-18600010.1.4"><span class="koboSpan" id="kobo.483.1" xmlns="http://www.w3.org/1999/xhtml">Gradient computation and the parameter shift rule</span></span></h2>
<p><span class="koboSpan" id="kobo.484.1" xmlns="http://www.w3.org/1999/xhtml">Although it is not the only option, the optimization algorithms that we shall use for quantum neural networks will be </span><span id="dx1-186001"/><span class="koboSpan" id="kobo.485.1" xmlns="http://www.w3.org/1999/xhtml">gradient descent algorithms; in particular, we will use the Adam optimizer. </span><span class="koboSpan" id="kobo.485.2" xmlns="http://www.w3.org/1999/xhtml">But, as we saw in </span><em><span class="koboSpan" id="kobo.486.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.487.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><em><span class="koboSpan" id="kobo.488.1" xmlns="http://www.w3.org/1999/xhtml">,</span></em> <em><span class="koboSpan" id="kobo.489.1" xmlns="http://www.w3.org/1999/xhtml">What is Quantum Machine Learning?</span></em><span class="koboSpan" id="kobo.490.1" xmlns="http://www.w3.org/1999/xhtml">, this algorithm needs to obtain the gradient of the expected value of a loss function in terms of the optimizable parameters.</span></p>
<p><span class="koboSpan" id="kobo.491.1" xmlns="http://www.w3.org/1999/xhtml">Since our model uses a quantum circuit, the computation of these gradients is not entirely trivial. </span><span class="koboSpan" id="kobo.491.2" xmlns="http://www.w3.org/1999/xhtml">We shall now go briefly over the three main kinds of differentiation methods in which these gradient computations may be carried out:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.492.1" xmlns="http://www.w3.org/1999/xhtml">Numerical approximation</span></strong><span class="koboSpan" id="kobo.493.1" xmlns="http://www.w3.org/1999/xhtml">: Of course, we have a </span><span id="dx1-186002"/><span class="koboSpan" id="kobo.494.1" xmlns="http://www.w3.org/1999/xhtml">method that always works. </span><span class="koboSpan" id="kobo.494.2" xmlns="http://www.w3.org/1999/xhtml">It may not always be the most efficient one, but it’s always there. </span><span class="koboSpan" id="kobo.494.3" xmlns="http://www.w3.org/1999/xhtml">In order to compute gradients, we may just estimate them numerically. </span><span class="koboSpan" id="kobo.494.4" xmlns="http://www.w3.org/1999/xhtml">In order to do this, of course, we will have to run our quantum neural network plenty of times.</span></p>
<p><span class="koboSpan" id="kobo.495.1" xmlns="http://www.w3.org/1999/xhtml">Just to exemplify this a little bit, if we had a real-valued function taking </span><span class="koboSpan" id="kobo.496.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.497.1" xmlns="http://www.w3.org/1999/xhtml"> real inputs </span><span class="koboSpan" id="kobo.498.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. f:R^{n}\rightarrow R \right." class="math inline" src="../media/file1378.png" style="vertical-align:middle" title="\left. f:R^{n}\rightarrow R \right."/></span><span class="koboSpan" id="kobo.499.1" xmlns="http://www.w3.org/1999/xhtml">, we could approximate its partial derivatives as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.500.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\frac{\partial f}{\partial x_{j}} = \frac{f(x_{1},\ldots,x_{j} + h,\ldots,x_{n}) - f(x_{1},\ldots,x_{n})}{h}" class="math display" src="../media/file1379.png" style="vertical-align:middle" title="\frac{\partial f}{\partial x_{j}} = \frac{f(x_{1},\ldots,x_{j} + h,\ldots,x_{n}) - f(x_{1},\ldots,x_{n})}{h}"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.501.1" xmlns="http://www.w3.org/1999/xhtml">for a </span><span id="dx1-186003"/><span class="koboSpan" id="kobo.502.1" xmlns="http://www.w3.org/1999/xhtml">sufficiently small value of </span><span class="koboSpan" id="kobo.503.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="h" class="math inline" src="../media/file519.png" style="vertical-align:middle" title="h"/></span><span class="koboSpan" id="kobo.504.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.504.2" xmlns="http://www.w3.org/1999/xhtml">That’s, of course, the most naive way to numerically approximate a derivative, but hopefully it’s enough to give you an intuition of how this works.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.505.1" xmlns="http://www.w3.org/1999/xhtml">Automatic differentiation</span></strong><span class="koboSpan" id="kobo.506.1" xmlns="http://www.w3.org/1999/xhtml">: Given the current state of real </span><span id="dx1-186004"/><span class="koboSpan" id="kobo.507.1" xmlns="http://www.w3.org/1999/xhtml">quantum hardware, odds are that most of the quantum neural networks that you will train will run on simulators. </span><span class="koboSpan" id="kobo.507.2" xmlns="http://www.w3.org/1999/xhtml">As non-ideal as this may be, it comes with some advantages. </span><span class="koboSpan" id="kobo.507.3" xmlns="http://www.w3.org/1999/xhtml">Most notably, on simulated quantum neural networks, a classical computer may compute exact gradients using techniques similar to those employed on classical neural networks. </span><span class="koboSpan" id="kobo.507.4" xmlns="http://www.w3.org/1999/xhtml">If you are interested, the book Aurélien Géron </span><span class="cite"><span class="koboSpan" id="kobo.508.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xhandsonml"><span class="koboSpan" id="kobo.509.1" xmlns="http://www.w3.org/1999/xhtml">104</span></a><span class="koboSpan" id="kobo.510.1" xmlns="http://www.w3.org/1999/xhtml">, Chapter 10]</span></span><span class="koboSpan" id="kobo.511.1" xmlns="http://www.w3.org/1999/xhtml"> and the one by Shai Shalev-Shwartz and Shai Ben-David </span><span class="cite"><span class="koboSpan" id="kobo.512.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xunderml"><span class="koboSpan" id="kobo.513.1" xmlns="http://www.w3.org/1999/xhtml">105</span></a><span class="koboSpan" id="kobo.514.1" xmlns="http://www.w3.org/1999/xhtml">, </span><span class="tcrm-1095"><span class="koboSpan" id="kobo.515.1" xmlns="http://www.w3.org/1999/xhtml">§</span></span><span class="koboSpan" id="kobo.516.1" xmlns="http://www.w3.org/1999/xhtml">20.6]</span></span><span class="koboSpan" id="kobo.517.1" xmlns="http://www.w3.org/1999/xhtml"> discuss these techniques for classical neural networks.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.518.1" xmlns="http://www.w3.org/1999/xhtml">The parameter shift rule</span></strong><span class="koboSpan" id="kobo.519.1" xmlns="http://www.w3.org/1999/xhtml">: The standard </span><span id="dx1-186005"/><span class="koboSpan" id="kobo.520.1" xmlns="http://www.w3.org/1999/xhtml">automatic differentiation techniques can only be used on simulators. </span><span class="koboSpan" id="kobo.520.2" xmlns="http://www.w3.org/1999/xhtml">Fortunately, there is still another way to compute gradients when executing quantum neural networks on real hardware: using the </span><strong><span class="koboSpan" id="kobo.521.1" xmlns="http://www.w3.org/1999/xhtml">parameter shift rule</span></strong><span class="koboSpan" id="kobo.522.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.522.2" xmlns="http://www.w3.org/1999/xhtml">As the </span><span id="dx1-186006"/><span class="koboSpan" id="kobo.523.1" xmlns="http://www.w3.org/1999/xhtml">name suggests, this technique enables us to compute gradients by using the same circuit in the quantum neural network, yet shifting the values of the optimizable parameters. </span><span class="koboSpan" id="kobo.523.2" xmlns="http://www.w3.org/1999/xhtml">The parameter shift rule can’t always be applied, but it works on many common cases and can be used in conjunction with other techniques, such as numerical approximation.</span></p>
<p><span class="koboSpan" id="kobo.524.1" xmlns="http://www.w3.org/1999/xhtml">We won’t get into the details of how this method works, but you may have a look at a research paper by Maria Schuld and others </span><span class="cite"><span class="koboSpan" id="kobo.525.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xpshift-schuld"><span class="koboSpan" id="kobo.526.1" xmlns="http://www.w3.org/1999/xhtml">109</span></a><span class="koboSpan" id="kobo.527.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.528.1" xmlns="http://www.w3.org/1999/xhtml"> for more information. </span><span class="koboSpan" id="kobo.528.2" xmlns="http://www.w3.org/1999/xhtml">For example, if you had a circuit consisting of a single rotation gate </span><span class="koboSpan" id="kobo.529.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{X}(\theta)" class="math inline" src="../media/file1380.png" style="vertical-align:middle" title="R_{X}(\theta)"/></span><span class="koboSpan" id="kobo.530.1" xmlns="http://www.w3.org/1999/xhtml"> and the measurement of its expectation value </span><span class="koboSpan" id="kobo.531.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="E(\theta)" class="math inline" src="../media/file1381.png" style="vertical-align:middle" title="E(\theta)"/></span><span class="koboSpan" id="kobo.532.1" xmlns="http://www.w3.org/1999/xhtml">, you would be able to compute its derivative with respect to </span><span class="koboSpan" id="kobo.533.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta" class="math inline" src="../media/file89.png" style="vertical-align:middle" title="\theta"/></span><span class="koboSpan" id="kobo.534.1" xmlns="http://www.w3.org/1999/xhtml"> as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.535.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\nabla}_{\theta}E(\theta) = \frac{1}{2}\left( {E\left( {\theta + \frac{\pi}{2}} \right) - E\left( {\theta - \frac{\pi}{2}} \right)} \right)." class="math display" src="../media/file1382.png" style="vertical-align:middle" title="{\nabla}_{\theta}E(\theta) = \frac{1}{2}\left( {E\left( {\theta + \frac{\pi}{2}} \right) - E\left( {\theta - \frac{\pi}{2}} \right)} \right)."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.536.1" xmlns="http://www.w3.org/1999/xhtml">This is similar to what happens with some trigonometric functions: for instance, you can express the derivative of the sine function in terms of shifted values of the same sine </span><span id="dx1-186007"/><span class="koboSpan" id="kobo.537.1" xmlns="http://www.w3.org/1999/xhtml">function.</span></p>
<p><span class="koboSpan" id="kobo.538.1" xmlns="http://www.w3.org/1999/xhtml">For our purposes, it will suffice to know that it exists and can be used. </span><span class="koboSpan" id="kobo.538.2" xmlns="http://www.w3.org/1999/xhtml">Of course, the parameter shift rule can also be used on simulators!</span></p></li>
</ul>
<div class="tcolorbox important" id="tcolobox-181">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.539.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.540.1" xmlns="http://www.w3.org/1999/xhtml">When quantum neural networks are run on simulators, gradients can be computed using automatic differentiation techniques analogous to those of classical machine learning. </span><span class="koboSpan" id="kobo.540.2" xmlns="http://www.w3.org/1999/xhtml">When they are run on either real hardware or simulators, these gradients can also be computed — at least on many cases — using the parameter shift rule.</span></p>
<p><span class="koboSpan" id="kobo.541.1" xmlns="http://www.w3.org/1999/xhtml">Alternatively, numerical approximation is always an effective way to compute gradients.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.542.1" xmlns="http://www.w3.org/1999/xhtml">As we have mentioned, all of these methods are already fully implemented in PennyLane, and we will try them all out in the following section.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-182">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.543.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.544.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.545.1" xmlns="http://www.w3.org/1999/xhtml">Everything looks good and promising, but quantum neural networks also pose some challenges when it comes to training them. </span><span class="koboSpan" id="kobo.545.2" xmlns="http://www.w3.org/1999/xhtml">Most notably, they are </span><span id="dx1-186008"/><span class="koboSpan" id="kobo.546.1" xmlns="http://www.w3.org/1999/xhtml">known to be vulnerable to </span><strong><span class="koboSpan" id="kobo.547.1" xmlns="http://www.w3.org/1999/xhtml">barren plateaus</span></strong><span class="koboSpan" id="kobo.548.1" xmlns="http://www.w3.org/1999/xhtml">: situations in which the training gradients vanish and, thus, the training can no longer progress (see the paper by McClean et. </span><span class="koboSpan" id="kobo.548.2" xmlns="http://www.w3.org/1999/xhtml">al for further explanation </span><span class="cite"><span class="koboSpan" id="kobo.549.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xmcclean2018barren"><span class="koboSpan" id="kobo.550.1" xmlns="http://www.w3.org/1999/xhtml">67</span></a><span class="koboSpan" id="kobo.551.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.552.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.552.2" xmlns="http://www.w3.org/1999/xhtml">It is also known that the kind of measurement operation used and the depth of the QNN play a role in how likely these barren plateaus are to be found. </span><span class="koboSpan" id="kobo.552.3" xmlns="http://www.w3.org/1999/xhtml">This is studied, for instance, in a paper by Cerezo and collaborators </span><span class="cite"><span class="koboSpan" id="kobo.553.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xcerezo2021cost"><span class="koboSpan" id="kobo.554.1" xmlns="http://www.w3.org/1999/xhtml">24</span></a><span class="koboSpan" id="kobo.555.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.556.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.556.2" xmlns="http://www.w3.org/1999/xhtml">In any case, you should be vigilant when training your QNNs, and follow the literature for possible solutions should barren plateaus threaten the learning of your models.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.557.1" xmlns="http://www.w3.org/1999/xhtml">We now have all the ingredients necessary to construct and train quantum neural networks. </span><span class="koboSpan" id="kobo.557.2" xmlns="http://www.w3.org/1999/xhtml">But before we get to do that in practice, we will discuss a few techniques and tips that will help you get the most of our brand new quantum machine learning models.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.1.5" id="practical-usage-of-quantum-neural-networks">
<h2 class="subsectionHead" data-number="18.1.5"><span class="titlemark"><span class="koboSpan" id="kobo.558.1" xmlns="http://www.w3.org/1999/xhtml">10.1.5 </span></span> <span id="x1-18700010.1.5"><span class="koboSpan" id="kobo.559.1" xmlns="http://www.w3.org/1999/xhtml">Practical usage of quantum neural networks</span></span></h2>
<p><span class="koboSpan" id="kobo.560.1" xmlns="http://www.w3.org/1999/xhtml">The following are a </span><span id="dx1-187001"/><span class="koboSpan" id="kobo.561.1" xmlns="http://www.w3.org/1999/xhtml">collection of ideas that you should keep in mind when designing QNN models and training them. </span><span class="koboSpan" id="kobo.561.2" xmlns="http://www.w3.org/1999/xhtml">You can think of it as a summary of the previous sections, with a few highlights from </span><em><span class="koboSpan" id="kobo.562.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.563.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><em><span class="koboSpan" id="kobo.564.1" xmlns="http://www.w3.org/1999/xhtml">, What is Quantum</span></em> <em><span class="koboSpan" id="kobo.565.1" xmlns="http://www.w3.org/1999/xhtml">Machine Learning?</span></em><span class="koboSpan" id="kobo.566.1" xmlns="http://www.w3.org/1999/xhtml">:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.567.1" xmlns="http://www.w3.org/1999/xhtml">Make wise choices</span></strong><span class="koboSpan" id="kobo.568.1" xmlns="http://www.w3.org/1999/xhtml">: When you set out to design a QNN, you have three important decisions to make: you have to pick a feature map, a variational form, and a measurement operation. </span><span class="koboSpan" id="kobo.568.2" xmlns="http://www.w3.org/1999/xhtml">Be intentional about these choices and consider the problem and the data that you are working with. </span><span class="koboSpan" id="kobo.568.3" xmlns="http://www.w3.org/1999/xhtml">Your decisions can influence how likely you are to find barren plateaus, for instance. </span><span class="koboSpan" id="kobo.568.4" xmlns="http://www.w3.org/1999/xhtml">A good recommendation is to check the literature for similar problems and to build up from there.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.569.1" xmlns="http://www.w3.org/1999/xhtml">Size matters</span></strong><span class="koboSpan" id="kobo.570.1" xmlns="http://www.w3.org/1999/xhtml">: When you use a well-designed variational form, in general, the power of the resulting quantum neural network will be directly related to the number of optimizable parameters it has. </span><span class="koboSpan" id="kobo.570.2" xmlns="http://www.w3.org/1999/xhtml">Use too many parameters, and you may have a model that overfits. </span><span class="koboSpan" id="kobo.570.3" xmlns="http://www.w3.org/1999/xhtml">Use very few, and your model may end up underfitting.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.571.1" xmlns="http://www.w3.org/1999/xhtml">Optimize optimization</span></strong><span class="koboSpan" id="kobo.572.1" xmlns="http://www.w3.org/1999/xhtml">: For most problems, the Adam optimizer can be your go-to choice for training a quantum neural network. </span><span class="koboSpan" id="kobo.572.2" xmlns="http://www.w3.org/1999/xhtml">Remember that, as we discussed in </span><em><span class="koboSpan" id="kobo.573.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.574.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><em><span class="koboSpan" id="kobo.575.1" xmlns="http://www.w3.org/1999/xhtml">, What is Quantum</span></em> <em><span class="koboSpan" id="kobo.576.1" xmlns="http://www.w3.org/1999/xhtml">Machine Learning?</span></em><span class="koboSpan" id="kobo.577.1" xmlns="http://www.w3.org/1999/xhtml">, you will have to pick a learning rate and a batch size when using Adam.</span></p>
<p><span class="koboSpan" id="kobo.578.1" xmlns="http://www.w3.org/1999/xhtml">A smaller learning rate will make the algorithm more accurate, but also slower. </span><span class="koboSpan" id="kobo.578.2" xmlns="http://www.w3.org/1999/xhtml">Analogously, a higher batch size should make the optimization more effective, to the detriment of execution time.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.579.1" xmlns="http://www.w3.org/1999/xhtml">Feed your QNN properly</span></strong><span class="koboSpan" id="kobo.580.1" xmlns="http://www.w3.org/1999/xhtml">: The data that is fed to a quantum neural network should be normalized according to the requirements of the feature map in use. </span><span class="koboSpan" id="kobo.580.2" xmlns="http://www.w3.org/1999/xhtml">In addition, depending on the dimensions of the input data, you may want to rely on dimensionality reduction techniques.</span></p>
<p><span class="koboSpan" id="kobo.581.1" xmlns="http://www.w3.org/1999/xhtml">Of course, the more data you have, the better. </span><span class="koboSpan" id="kobo.581.2" xmlns="http://www.w3.org/1999/xhtml">Nonetheless, one additional fact that you may want to take into account is that, under some conditions, quantum neural networks have been </span><span id="dx1-187002"/><span class="koboSpan" id="kobo.582.1" xmlns="http://www.w3.org/1999/xhtml">shown to need fewer data samples than classical neural networks in order to be successfully trained </span><span class="cite"><span class="koboSpan" id="kobo.583.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xqnn-lowdata"><span class="koboSpan" id="kobo.584.1" xmlns="http://www.w3.org/1999/xhtml">112</span></a><span class="koboSpan" id="kobo.585.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.586.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
</ul>
<div class="tcolorbox learnmore" id="tcolobox-183">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.587.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.588.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.589.1" xmlns="http://www.w3.org/1999/xhtml">If you want to further boost the power of your quantum neural networks, you may want to </span><span id="dx1-187003"/><span class="koboSpan" id="kobo.590.1" xmlns="http://www.w3.org/1999/xhtml">consider the </span><strong><span class="koboSpan" id="kobo.591.1" xmlns="http://www.w3.org/1999/xhtml">data reuploading</span></strong><span class="koboSpan" id="kobo.592.1" xmlns="http://www.w3.org/1999/xhtml"> technique </span><span class="cite"><span class="koboSpan" id="kobo.593.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xperez2020data"><span class="koboSpan" id="kobo.594.1" xmlns="http://www.w3.org/1999/xhtml">110</span></a><span class="koboSpan" id="kobo.595.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.596.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.596.2" xmlns="http://www.w3.org/1999/xhtml">In a vanilla QNN, you have a feature map </span><span class="koboSpan" id="kobo.597.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="F" class="math inline" src="../media/file1320.png" style="vertical-align:middle" title="F"/></span><span class="koboSpan" id="kobo.598.1" xmlns="http://www.w3.org/1999/xhtml"> dependent on some input data </span><span class="koboSpan" id="kobo.599.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.600.1" xmlns="http://www.w3.org/1999/xhtml">, which is then followed by a variational form </span><span class="koboSpan" id="kobo.601.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="V" class="math inline" src="../media/file379.png" style="vertical-align:middle" title="V"/></span><span class="koboSpan" id="kobo.602.1" xmlns="http://www.w3.org/1999/xhtml"> dependent on some optimizable parameters </span><span class="koboSpan" id="kobo.603.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{\theta_{0}}" class="math inline" src="../media/file1383.png" style="vertical-align:middle" title="\overset{\rightarrow}{\theta_{0}}"/></span><span class="koboSpan" id="kobo.604.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.604.2" xmlns="http://www.w3.org/1999/xhtml">Data reuploading simply consists in repeating this scheme — any number of times you want — before performing the measurement operation of the QNN. </span><span class="koboSpan" id="kobo.604.3" xmlns="http://www.w3.org/1999/xhtml">The feature maps use the same input data in each repetition, but each instance of the variational form takes its own, independent, optimizable parameters.</span></p>
<p><span class="koboSpan" id="kobo.605.1" xmlns="http://www.w3.org/1999/xhtml">This is represented in the following diagram, which shows data reuploading with </span><span class="koboSpan" id="kobo.606.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.607.1" xmlns="http://www.w3.org/1999/xhtml"> repetitions:</span></p>
<div class="center">
<p><span class="koboSpan" id="kobo.608.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="|FVFV0⟩((((n⃗x⃗𝜃⃗x⃗𝜃)1)k)) ... " src="../media/file1384.jpg"/></span></p>
</div>
<p><span class="koboSpan" id="kobo.609.1" xmlns="http://www.w3.org/1999/xhtml">This has been shown, both in practice and in theory </span><span class="cite"><span class="koboSpan" id="kobo.610.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xdatare-schuld"><span class="koboSpan" id="kobo.611.1" xmlns="http://www.w3.org/1999/xhtml">113</span></a><span class="koboSpan" id="kobo.612.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.613.1" xmlns="http://www.w3.org/1999/xhtml">, to offer some advantages over the simpler, standard approach at the cost of increasing the depth of the circuits that are used. </span><span class="koboSpan" id="kobo.613.2" xmlns="http://www.w3.org/1999/xhtml">In any case, it is good to have it in mind when implementing your own QNNs.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.614.1" xmlns="http://www.w3.org/1999/xhtml">This concludes our theoretical discussion of quantum neural networks. </span><span class="koboSpan" id="kobo.614.2" xmlns="http://www.w3.org/1999/xhtml">Now it’s time for us to get our hands dirty with the actual implementation of all the fancy artifacts and techniques that we have discussed. </span><span class="koboSpan" id="kobo.614.3" xmlns="http://www.w3.org/1999/xhtml">In this regard, we will focus mostly on PennyLane. </span><span class="koboSpan" id="kobo.614.4" xmlns="http://www.w3.org/1999/xhtml">Let’s begin!</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="18.2" id="quantum-neural-networks-in-pennylane">
<h1 class="sectionHead" data-number="18.2"><span class="titlemark"><span class="koboSpan" id="kobo.615.1" xmlns="http://www.w3.org/1999/xhtml">10.2 </span></span> <span id="x1-18800010.2"><span class="koboSpan" id="kobo.616.1" xmlns="http://www.w3.org/1999/xhtml">Quantum neural networks in PennyLane</span></span></h1>
<p><span class="koboSpan" id="kobo.617.1" xmlns="http://www.w3.org/1999/xhtml">We are now ready to </span><span id="dx1-188001"/><span class="koboSpan" id="kobo.618.1" xmlns="http://www.w3.org/1999/xhtml">implement and train our first quantum neural network with PennyLane. </span><span class="koboSpan" id="kobo.618.2" xmlns="http://www.w3.org/1999/xhtml">The PennyLane framework is great for many applications, but it shines the most when it comes to the implementation of quantum neural network models. </span><span class="koboSpan" id="kobo.618.3" xmlns="http://www.w3.org/1999/xhtml">This is all due to its flexibility and good integration with classical machine learning frameworks. </span><span class="koboSpan" id="kobo.618.4" xmlns="http://www.w3.org/1999/xhtml">We, in particular, are going to be using PennyLane in conjunction with TensorFlow to train a QNN-based binary classifier. </span><span class="koboSpan" id="kobo.618.5" xmlns="http://www.w3.org/1999/xhtml">All that effort that we invested in </span><em><span class="koboSpan" id="kobo.619.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.620.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><em><span class="koboSpan" id="kobo.621.1" xmlns="http://www.w3.org/1999/xhtml">, What is Quantum Machine Learning?</span></em><span class="koboSpan" id="kobo.622.1" xmlns="http://www.w3.org/1999/xhtml">, is finally going to pay off!</span></p>
<div class="tcolorbox important" id="tcolobox-184">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.623.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.624.1" xmlns="http://www.w3.org/1999/xhtml">Remember that we are using </span><strong><span class="koboSpan" id="kobo.625.1" xmlns="http://www.w3.org/1999/xhtml">version 2.9.1</span></strong><span class="koboSpan" id="kobo.626.1" xmlns="http://www.w3.org/1999/xhtml"> of the TensorFlow package and </span><strong><span class="koboSpan" id="kobo.627.1" xmlns="http://www.w3.org/1999/xhtml">version 0.26</span></strong><span class="koboSpan" id="kobo.628.1" xmlns="http://www.w3.org/1999/xhtml"> of PennyLane.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.629.1" xmlns="http://www.w3.org/1999/xhtml">Let’s begin by importing PennyLane, NumPy, and TensorFlow and setting some seeds for these packages, just to make sure that our results are reproducible. </span><span class="koboSpan" id="kobo.629.2" xmlns="http://www.w3.org/1999/xhtml">We can achieve this with the following piece of code:</span></p>
<p><span id="x1-188002"/></p>
<pre class="lstlisting" id="listing-233"><span class="koboSpan" id="kobo.630.1" xmlns="http://www.w3.org/1999/xhtml">

import pennylane as qml 
 
import numpy as np 
 
import tensorflow as tf 
 
 
 
seed = 4321 
 
np.random.seed(seed) 
 
tf.random.set_seed(seed)
</span></pre>
<p><span class="koboSpan" id="kobo.631.1" xmlns="http://www.w3.org/1999/xhtml">Keep in mind that you may still get slightly different results from ours if you are using different package versions. </span><span class="koboSpan" id="kobo.631.2" xmlns="http://www.w3.org/1999/xhtml">However, the results you obtain will be fully reproducible in your own machine.</span></p>
<p><span class="koboSpan" id="kobo.632.1" xmlns="http://www.w3.org/1999/xhtml">Before we get to our problem, there’s one last detail that we need to sort out. </span><span class="koboSpan" id="kobo.632.2" xmlns="http://www.w3.org/1999/xhtml">PennyLane works with doubles while TensorFlow uses ordinary floats. </span><span class="koboSpan" id="kobo.632.3" xmlns="http://www.w3.org/1999/xhtml">This isn’t always an issue, but it’s a good idea to ask TensorFlow to work with </span><span id="dx1-188010"/><span class="koboSpan" id="kobo.633.1" xmlns="http://www.w3.org/1999/xhtml">doubles just as PennyLane does. </span><span class="koboSpan" id="kobo.633.2" xmlns="http://www.w3.org/1999/xhtml">We can accomplish this as follows:</span></p>
<pre class="lstlisting" id="listing-234"><span class="koboSpan" id="kobo.634.1" xmlns="http://www.w3.org/1999/xhtml">

tf.keras.backend.set_floatx(’float64’)
</span></pre>
<p><span class="koboSpan" id="kobo.635.1" xmlns="http://www.w3.org/1999/xhtml">With this out of the way, let’s meet our problem.</span></p>
<section class="level3 subsectionHead" data-number="18.2.1" id="preparing-data-for-a-qnn">
<h2 class="subsectionHead" data-number="18.2.1"><span class="titlemark"><span class="koboSpan" id="kobo.636.1" xmlns="http://www.w3.org/1999/xhtml">10.2.1 </span></span> <span id="x1-18900010.2.1"><span class="koboSpan" id="kobo.637.1" xmlns="http://www.w3.org/1999/xhtml">Preparing data for a QNN</span></span></h2>
<p><span class="koboSpan" id="kobo.638.1" xmlns="http://www.w3.org/1999/xhtml">As we have </span><span id="dx1-189001"/><span class="koboSpan" id="kobo.639.1" xmlns="http://www.w3.org/1999/xhtml">already mentioned, we are going to train a QNN model to implement a binary classifier. </span><span class="koboSpan" id="kobo.639.2" xmlns="http://www.w3.org/1999/xhtml">Our recurrent use of binary classifiers is no coincidence, for binary classifiers are perhaps the simplest machine learning models to train. </span><span class="koboSpan" id="kobo.639.3" xmlns="http://www.w3.org/1999/xhtml">Later in the book, however, we will explore more exciting use cases and architectures.</span></p>
<p><span class="koboSpan" id="kobo.640.1" xmlns="http://www.w3.org/1999/xhtml">For our example problem, we are going to use one of the toy datasets provided by the scikit-learn package: the ”Breast cancer Wisconsin dataset” </span><span class="cite"><span class="koboSpan" id="kobo.641.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#XDua:2019"><span class="koboSpan" id="kobo.642.1" xmlns="http://www.w3.org/1999/xhtml">32</span></a><span class="koboSpan" id="kobo.643.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.644.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.644.2" xmlns="http://www.w3.org/1999/xhtml">This dataset has a total of </span><span class="koboSpan" id="kobo.645.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="569" class="math inline" src="../media/file1385.png" style="vertical-align:middle" title="569"/></span><span class="koboSpan" id="kobo.646.1" xmlns="http://www.w3.org/1999/xhtml"> samples with </span><span class="koboSpan" id="kobo.647.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="30" class="math inline" src="../media/file620.png" style="vertical-align:middle" title="30"/></span><span class="koboSpan" id="kobo.648.1" xmlns="http://www.w3.org/1999/xhtml"> numerical variables each. </span><span class="koboSpan" id="kobo.648.2" xmlns="http://www.w3.org/1999/xhtml">These variables describe features that can be used to characterize whether a breast mass is benign or malignant. </span><span class="koboSpan" id="kobo.648.3" xmlns="http://www.w3.org/1999/xhtml">The label of each sample can be either </span><span class="koboSpan" id="kobo.649.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.650.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><span class="koboSpan" id="kobo.651.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.652.1" xmlns="http://www.w3.org/1999/xhtml">, corresponding to malignant or benign, respectively. </span><span class="koboSpan" id="kobo.652.2" xmlns="http://www.w3.org/1999/xhtml">You may find the documentation of this dataset online at </span><a class="url" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset"><span class="koboSpan" id="kobo.653.1" xmlns="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset</span></a><span class="koboSpan" id="kobo.654.1" xmlns="http://www.w3.org/1999/xhtml"> (the original documentation of the dataset can also be found at </span><a class="url" href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"><span class="koboSpan" id="kobo.655.1" xmlns="http://www.w3.org/1999/xhtml">https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)</span></a><span class="koboSpan" id="kobo.656.1" xmlns="http://www.w3.org/1999/xhtml">).</span></p>
<p><span class="koboSpan" id="kobo.657.1" xmlns="http://www.w3.org/1999/xhtml">We can get this dataset by calling the </span><code><span class="koboSpan" id="kobo.658.1" xmlns="http://www.w3.org/1999/xhtml">load_breast_cancer</span></code><span class="koboSpan" id="kobo.659.1" xmlns="http://www.w3.org/1999/xhtml"> function from </span><code><span class="koboSpan" id="kobo.660.1" xmlns="http://www.w3.org/1999/xhtml">sklearn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.661.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.662.1" xmlns="http://www.w3.org/1999/xhtml">datasets</span></code><span class="koboSpan" id="kobo.663.1" xmlns="http://www.w3.org/1999/xhtml">, setting the optional argument </span><code><span class="koboSpan" id="kobo.664.1" xmlns="http://www.w3.org/1999/xhtml">return_X_y</span></code><span class="koboSpan" id="kobo.665.1" xmlns="http://www.w3.org/1999/xhtml"> to true in order to retrieve the labels in addition to the samples. </span><span class="koboSpan" id="kobo.665.2" xmlns="http://www.w3.org/1999/xhtml">For that, we can use the following instructions:</span></p>
<pre class="lstlisting" id="listing-235"><span class="koboSpan" id="kobo.666.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.datasets import load_breast_cancer 
 
 
 
x,y = load_breast_cancer(return_X_y = True)
</span></pre>
<p><span class="koboSpan" id="kobo.667.1" xmlns="http://www.w3.org/1999/xhtml">When we trained QSVMs, since we were not going to make any comparisons between models, a training and test dataset sufficed. </span><span class="koboSpan" id="kobo.667.2" xmlns="http://www.w3.org/1999/xhtml">In our case, however, we are going to train our models with early stopping on the validation loss. </span><span class="koboSpan" id="kobo.667.3" xmlns="http://www.w3.org/1999/xhtml">This means — in case you don’t remember — that we will be keeping track of the validation loss and we will halt the training as soon as it doesn’t improve — according to some criteria that we will define. </span><span class="koboSpan" id="kobo.667.4" xmlns="http://www.w3.org/1999/xhtml">What is more, we will keep the model configuration that best minimized the validation loss. </span><span class="koboSpan" id="kobo.667.5" xmlns="http://www.w3.org/1999/xhtml">Using the test </span><span id="dx1-189005"/><span class="koboSpan" id="kobo.668.1" xmlns="http://www.w3.org/1999/xhtml">dataset for this purpose wouldn’t be good practice, for then the test dataset would have played a role in the training and it would not give a good estimate of the true error; that’s why we will need a separate validation dataset.</span></p>
<p><span class="koboSpan" id="kobo.669.1" xmlns="http://www.w3.org/1999/xhtml">We can split our dataset into a training, validation, and test dataset as follows:</span></p>
<pre class="lstlisting" id="listing-236"><span class="koboSpan" id="kobo.670.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.model_selection import train_test_split 
 
 
 
x_tr, x_test, y_tr, y_test = train_test_split( 
 
    x, y, train_size = 0.8) 
 
x_val, x_test, y_val, y_test = train_test_split( 
 
    x_test, y_test, train_size = 0.5)
</span></pre>
<p><span class="koboSpan" id="kobo.671.1" xmlns="http://www.w3.org/1999/xhtml">All the variables in the dataset are non-zero, but they are not normalized. </span><span class="koboSpan" id="kobo.671.2" xmlns="http://www.w3.org/1999/xhtml">In order to use them with any of our feature maps, we shall normalize the training data between </span><span class="koboSpan" id="kobo.672.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.673.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.674.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.675.1" xmlns="http://www.w3.org/1999/xhtml"> using </span><code><span class="koboSpan" id="kobo.676.1" xmlns="http://www.w3.org/1999/xhtml">MaxAbsScaler</span></code><span class="koboSpan" id="kobo.677.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<pre class="lstlisting" id="listing-237"><span class="koboSpan" id="kobo.678.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.preprocessing import MaxAbsScaler 
 
 
 
scaler = MaxAbsScaler() 
 
x_tr = scaler.fit_transform(x_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.679.1" xmlns="http://www.w3.org/1999/xhtml">And we then normalize the test and validation datasets in the same proportions as the training dataset:</span></p>
<pre class="lstlisting" id="listing-238"><span class="koboSpan" id="kobo.680.1" xmlns="http://www.w3.org/1999/xhtml">

x_test = scaler.transform(x_test) 
 
x_val = scaler.transform(x_val) 
 
 
 
# Restrict all the values to be between 0 and 1. 
 
</span><span class="koboSpan" id="kobo.680.2" xmlns="http://www.w3.org/1999/xhtml">x_test = np.clip(x_test, 0, 1) 
 
x_val = np.clip(x_val, 0, 1)
</span></pre>
<p><span class="koboSpan" id="kobo.681.1" xmlns="http://www.w3.org/1999/xhtml">Just as we did when we trained a QSVM in the previous chapter!</span></p>
<p><span class="koboSpan" id="kobo.682.1" xmlns="http://www.w3.org/1999/xhtml">So far, we have simply done some fairly </span><span id="dx1-189022"/><span class="koboSpan" id="kobo.683.1" xmlns="http://www.w3.org/1999/xhtml">standard data preprocessing, without having to think too much about the actual architecture of our future quantum neural network. </span><span class="koboSpan" id="kobo.683.2" xmlns="http://www.w3.org/1999/xhtml">But that changes now. </span><span class="koboSpan" id="kobo.683.3" xmlns="http://www.w3.org/1999/xhtml">We have a problem to address: our dataset has </span><span class="koboSpan" id="kobo.684.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="30" class="math inline" src="../media/file620.png" style="vertical-align:middle" title="30"/></span><span class="koboSpan" id="kobo.685.1" xmlns="http://www.w3.org/1999/xhtml"> variables, and that can be a pretty large number for current quantum hardware. </span><span class="koboSpan" id="kobo.685.2" xmlns="http://www.w3.org/1999/xhtml">Since we don’t have access to quantum computers with </span><span class="koboSpan" id="kobo.686.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="30" class="math inline" src="../media/file620.png" style="vertical-align:middle" title="30"/></span><span class="koboSpan" id="kobo.687.1" xmlns="http://www.w3.org/1999/xhtml"> qubits, we may consider the following choices:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.688.1" xmlns="http://www.w3.org/1999/xhtml">Use the amplitude encoding feature map on </span><span class="koboSpan" id="kobo.689.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="5" class="math inline" src="../media/file296.png" style="vertical-align:middle" title="5"/></span><span class="koboSpan" id="kobo.690.1" xmlns="http://www.w3.org/1999/xhtml"> qubits, which can accommodate up to </span><span class="koboSpan" id="kobo.691.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{5} = 32" class="math inline" src="../media/file1386.png" style="vertical-align:middle" title="2^{5} = 32"/></span><span class="koboSpan" id="kobo.692.1" xmlns="http://www.w3.org/1999/xhtml"> variables</span></p></li>
<li><p><span class="koboSpan" id="kobo.693.1" xmlns="http://www.w3.org/1999/xhtml">Use any of the other feature maps that we have used, but in conjunction with a dimensionality reduction technique</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.694.1" xmlns="http://www.w3.org/1999/xhtml">We will go for the latter choice. </span><span class="koboSpan" id="kobo.694.2" xmlns="http://www.w3.org/1999/xhtml">You can try the other possibility on your own: it’s fairly straightforward if you use the </span><code><span class="koboSpan" id="kobo.695.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.696.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.697.1" xmlns="http://www.w3.org/1999/xhtml">AmplitudeEmbedding</span></code><span class="koboSpan" id="kobo.698.1" xmlns="http://www.w3.org/1999/xhtml"> template that we studied back in </span><em><span class="koboSpan" id="kobo.699.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch018.xhtml#x1-1600009"><em><span class="koboSpan" id="kobo.700.1" xmlns="http://www.w3.org/1999/xhtml">9</span></em></a><em><span class="koboSpan" id="kobo.701.1" xmlns="http://www.w3.org/1999/xhtml">, Quantum Support Vector</span></em> <em><span class="koboSpan" id="kobo.702.1" xmlns="http://www.w3.org/1999/xhtml">Machines</span></em><span class="koboSpan" id="kobo.703.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox questionx" id="tcolobox-185">
<span id="x1-189024x10.2.1"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.704.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 10.2</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.705.1" xmlns="http://www.w3.org/1999/xhtml">As you follow along this section, try to implement a QNN using all the original variables with amplitude encoding on five qubits.</span></p><span class="koboSpan" id="kobo.706.1" xmlns="http://www.w3.org/1999/xhtml">
Keep in mind that, when feeding the data to the </span><code><span class="koboSpan" id="kobo.707.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.708.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span>
<code><span class="koboSpan" id="kobo.709.1" xmlns="http://www.w3.org/1999/xhtml">AmplitudeEmbedding</span></code><span class="koboSpan" id="kobo.710.1" xmlns="http://www.w3.org/1999/xhtml"> object through the features argument, instead of using the </span><code><span class="koboSpan" id="kobo.711.1" xmlns="http://www.w3.org/1999/xhtml">inputs</span></code><span class="koboSpan" id="kobo.712.1" xmlns="http://www.w3.org/1999/xhtml"> variable, you should use </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.713.1" xmlns="http://www.w3.org/1999/xhtml">[</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.714.1" xmlns="http://www.w3.org/1999/xhtml">a</span></code></span><span style="color:#000000"> </span><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.715.1" xmlns="http://www.w3.org/1999/xhtml">for</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.716.1" xmlns="http://www.w3.org/1999/xhtml">a</span></code></span><span style="color:#000000"> </span><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.717.1" xmlns="http://www.w3.org/1999/xhtml">in</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.718.1" xmlns="http://www.w3.org/1999/xhtml">inputs</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.719.1" xmlns="http://www.w3.org/1999/xhtml">]</span></code></span></span><span class="koboSpan" id="kobo.720.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.720.2" xmlns="http://www.w3.org/1999/xhtml">This is needed because of some internal type conversions that PennyLane needs to perform.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.721.1" xmlns="http://www.w3.org/1999/xhtml">Training a quantum neural network on a simulator is a very computationally-intensive task. </span><span class="koboSpan" id="kobo.721.2" xmlns="http://www.w3.org/1999/xhtml">We don’t want anyone’s computer to crash, so, just to make sure everyone can run this example smoothly, we will restrict ourselves to using </span><span class="koboSpan" id="kobo.722.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.723.1" xmlns="http://www.w3.org/1999/xhtml">-qubit circuits. </span><span class="koboSpan" id="kobo.723.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we will use a dimensionality reduction technique to shrink the number of variables to </span><span class="koboSpan" id="kobo.724.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.725.1" xmlns="http://www.w3.org/1999/xhtml">, and then set up a QNN with a feature map that will take the resulting </span><span class="koboSpan" id="kobo.726.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.727.1" xmlns="http://www.w3.org/1999/xhtml"> input variables.</span></p>
<p><span class="koboSpan" id="kobo.728.1" xmlns="http://www.w3.org/1999/xhtml">As we did in the </span><span id="dx1-189025"/><span class="koboSpan" id="kobo.729.1" xmlns="http://www.w3.org/1999/xhtml">previous chapter, we will use principal component analysis in order to reduce the number of variables in our dataset to </span><span class="koboSpan" id="kobo.730.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.731.1" xmlns="http://www.w3.org/1999/xhtml">:</span></p>
<pre class="lstlisting" id="listing-239"><span class="koboSpan" id="kobo.732.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.decomposition import PCA 
 
pca = PCA(n_components = 4) 
 
 
 
xs_tr = pca.fit_transform(x_tr) 
 
xs_test = pca.transform(x_test) 
 
xs_val = pca.transform(x_val)
</span></pre>
<p><span class="koboSpan" id="kobo.733.1" xmlns="http://www.w3.org/1999/xhtml">Now that we have our data fully ready, we need to choose how our quantum neural network is going to work. </span><span class="koboSpan" id="kobo.733.2" xmlns="http://www.w3.org/1999/xhtml">This is exactly the focus of the next subsection.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.2.2" id="building-the-network">
<h2 class="subsectionHead" data-number="18.2.2"><span class="titlemark"><span class="koboSpan" id="kobo.734.1" xmlns="http://www.w3.org/1999/xhtml">10.2.2 </span></span> <span id="x1-19000010.2.2"><span class="koboSpan" id="kobo.735.1" xmlns="http://www.w3.org/1999/xhtml">Building the network</span></span></h2>
<p><span class="koboSpan" id="kobo.736.1" xmlns="http://www.w3.org/1999/xhtml">For our case, we will </span><span id="dx1-190001"/><span class="koboSpan" id="kobo.737.1" xmlns="http://www.w3.org/1999/xhtml">choose the ZZ feature map and the two-local variational form. </span><span class="koboSpan" id="kobo.737.2" xmlns="http://www.w3.org/1999/xhtml">Neither is built into PennyLane, so we have to provide our own implementation of these variational circuits. </span><span class="koboSpan" id="kobo.737.3" xmlns="http://www.w3.org/1999/xhtml">PennyLane includes, however, a version of the two-local form with circular entanglement (</span><code><span class="koboSpan" id="kobo.738.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.739.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.740.1" xmlns="http://www.w3.org/1999/xhtml">BasicEntanglerLayers</span></code><span class="koboSpan" id="kobo.741.1" xmlns="http://www.w3.org/1999/xhtml">), in case you want to use it in your QNNs. </span><span class="koboSpan" id="kobo.741.2" xmlns="http://www.w3.org/1999/xhtml">To implement the circuits that we need, we can just use the pseudocode that we provided in </span><em><span class="koboSpan" id="kobo.742.1" xmlns="http://www.w3.org/1999/xhtml">Section</span></em> <em/> <a href="#x1-18400010.1.2"><em><span class="koboSpan" id="kobo.743.1" xmlns="http://www.w3.org/1999/xhtml">10.1.2</span></em></a><span class="koboSpan" id="kobo.744.1" xmlns="http://www.w3.org/1999/xhtml"> and do something like the following:</span></p>
<pre class="lstlisting" id="listing-240"><span class="koboSpan" id="kobo.745.1" xmlns="http://www.w3.org/1999/xhtml">

from itertools import combinations 
 
 
 
def ZZFeatureMap(nqubits, data): 
 
 
 
    # Number of variables that we will load: 
 
    # could be smaller than the number of qubits. 
 
    </span><span class="koboSpan" id="kobo.745.2" xmlns="http://www.w3.org/1999/xhtml">nload = min(len(data), nqubits) 
 
 
 
    for i in range(nload): 
 
        qml.Hadamard(i) 
 
        qml.RZ(2.0 * data[i], wires = i) 
 
 
 
    for pair in list(combinations(range(nload), 2)): 
 
        q0 = pair[0] 
 
        q1 = pair[1] 
 
 
 
        qml.CZ(wires = [q0, q1]) 
 
        qml.RZ(2.0 * (np.pi - data[q0]) * 
 
            (np.pi - data[q1]), wires = q1) 
 
        qml.CZ(wires = [q0, q1]) 
 
 
 
def TwoLocal(nqubits, theta, reps = 1): 
 
 
 
    for r in range(reps): 
 
        for i in range(nqubits): 
 
            qml.RY(theta[r * nqubits + i], wires = i) 
 
        for i in range(nqubits - 1): 
 
            qml.CNOT(wires = [i, i + 1]) 
 
 
 
    for i in range(nqubits): 
 
        qml.RY(theta[reps * nqubits + i], wires = i)
</span></pre>
<p><span class="koboSpan" id="kobo.746.1" xmlns="http://www.w3.org/1999/xhtml">Remember that we </span><span id="dx1-190033"/><span class="koboSpan" id="kobo.747.1" xmlns="http://www.w3.org/1999/xhtml">already implemented the ZZ feature map in PennyLane in the previous chapter.</span></p>
<p><span class="koboSpan" id="kobo.748.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we have talked about observables, and how these are represented by Hermitian operators in quantum mechanics. </span><span class="koboSpan" id="kobo.748.2" xmlns="http://www.w3.org/1999/xhtml">PennyLane allows us to work directly with these Hermitian representations.</span></p>
<p><span class="koboSpan" id="kobo.749.1" xmlns="http://www.w3.org/1999/xhtml">Remember how every circuit in PennyLane returns the result of some measurement operation? </span><span class="koboSpan" id="kobo.749.2" xmlns="http://www.w3.org/1999/xhtml">For instance, you may use </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.750.1" xmlns="http://www.w3.org/1999/xhtml">return</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.751.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.752.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.753.1" xmlns="http://www.w3.org/1999/xhtml">probs</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.754.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.755.1" xmlns="http://www.w3.org/1999/xhtml">wires</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.756.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.757.1" xmlns="http://www.w3.org/1999/xhtml">[0])</span></code></span></span><span class="koboSpan" id="kobo.758.1" xmlns="http://www.w3.org/1999/xhtml"> at the end of the definition of a </span><span id="dx1-190034"/><span class="koboSpan" id="kobo.759.1" xmlns="http://www.w3.org/1999/xhtml">circuit in order to get the probabilities of every possible measurement outcome on the computational basis. </span><span class="koboSpan" id="kobo.759.2" xmlns="http://www.w3.org/1999/xhtml">Well, it turns out that PennyLane offers a few more possibilities. </span><span class="koboSpan" id="kobo.759.3" xmlns="http://www.w3.org/1999/xhtml">For instance, given any Hermitian matrix </span><span class="koboSpan" id="kobo.760.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="A" class="math inline" src="../media/file183.png" style="vertical-align:middle" title="A"/></span><span class="koboSpan" id="kobo.761.1" xmlns="http://www.w3.org/1999/xhtml"> (encoded as a numpy array </span><code><span class="koboSpan" id="kobo.762.1" xmlns="http://www.w3.org/1999/xhtml">A</span></code><span class="koboSpan" id="kobo.763.1" xmlns="http://www.w3.org/1999/xhtml">), we may retrieve the expectation value of </span><span class="koboSpan" id="kobo.764.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="A" class="math inline" src="../media/file183.png" style="vertical-align:middle" title="A"/></span><span class="koboSpan" id="kobo.765.1" xmlns="http://www.w3.org/1999/xhtml"> on an array of wires </span><code><span class="koboSpan" id="kobo.766.1" xmlns="http://www.w3.org/1999/xhtml">w</span></code><span class="koboSpan" id="kobo.767.1" xmlns="http://www.w3.org/1999/xhtml"> at the end of a circuit simply by calling </span><span class="lstinline"><span style="color:#A71D5D"><code><span class="koboSpan" id="kobo.768.1" xmlns="http://www.w3.org/1999/xhtml">return</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.769.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.770.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.771.1" xmlns="http://www.w3.org/1999/xhtml">expval</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.772.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.773.1" xmlns="http://www.w3.org/1999/xhtml">A</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.774.1" xmlns="http://www.w3.org/1999/xhtml">,</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.775.1" xmlns="http://www.w3.org/1999/xhtml">wires</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.776.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.777.1" xmlns="http://www.w3.org/1999/xhtml">w</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.778.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code></span></span><span class="koboSpan" id="kobo.779.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.779.2" xmlns="http://www.w3.org/1999/xhtml">Of course, the dimensions of </span><span class="koboSpan" id="kobo.780.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="A" class="math inline" src="../media/file183.png" style="vertical-align:middle" title="A"/></span><span class="koboSpan" id="kobo.781.1" xmlns="http://www.w3.org/1999/xhtml"> must be compatible with the length of </span><code><span class="koboSpan" id="kobo.782.1" xmlns="http://www.w3.org/1999/xhtml">w</span></code><span class="koboSpan" id="kobo.783.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.783.2" xmlns="http://www.w3.org/1999/xhtml">This is useful in our case, for in order to get the expectation value on the first qubit, we will just have to compute the expectation value of the Hermitian</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.784.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \\ \end{pmatrix}." class="math display" src="../media/file1387.png" style="vertical-align:middle" title="M = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 0 \\ \end{pmatrix}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.785.1" xmlns="http://www.w3.org/1999/xhtml">The matrix </span><span class="koboSpan" id="kobo.786.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M" class="math inline" src="../media/file704.png" style="vertical-align:middle" title="M"/></span><span class="koboSpan" id="kobo.787.1" xmlns="http://www.w3.org/1999/xhtml"> can be constructed as follows:</span></p>
<pre class="lstlisting" id="listing-241"><span class="koboSpan" id="kobo.788.1" xmlns="http://www.w3.org/1999/xhtml">

state_0 = [[1], [0]] 
 
M = state_0 * np.conj(state_0).T
</span></pre>
<p><span class="koboSpan" id="kobo.789.1" xmlns="http://www.w3.org/1999/xhtml">In this construction, we have used the fact that </span><span class="koboSpan" id="kobo.790.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="M = \left| 0 \right\rangle\left\langle 0 \right|" class="math inline" src="../media/file1388.png" style="vertical-align:middle" title="M = \left| 0 \right\rangle\left\langle 0 \right|"/></span><span class="koboSpan" id="kobo.791.1" xmlns="http://www.w3.org/1999/xhtml">, as we discussed in an exercise earlier in this chapter. </span><span class="koboSpan" id="kobo.791.2" xmlns="http://www.w3.org/1999/xhtml">This will give us, as output,</span><span id="dx1-190037"/><span class="koboSpan" id="kobo.792.1" xmlns="http://www.w3.org/1999/xhtml"> a value between </span><span class="koboSpan" id="kobo.793.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.794.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.795.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.796.1" xmlns="http://www.w3.org/1999/xhtml">, which is perfect to construct a classifier: as usual, we will assign class </span><span class="koboSpan" id="kobo.797.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.798.1" xmlns="http://www.w3.org/1999/xhtml"> to every data instance with a value of </span><span class="koboSpan" id="kobo.799.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.5" class="math inline" src="../media/file1166.png" style="vertical-align:middle" title="0.5"/></span><span class="koboSpan" id="kobo.800.1" xmlns="http://www.w3.org/1999/xhtml"> or higher, and class </span><span class="koboSpan" id="kobo.801.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.802.1" xmlns="http://www.w3.org/1999/xhtml"> to all the rest.</span></p>
<p><span class="koboSpan" id="kobo.803.1" xmlns="http://www.w3.org/1999/xhtml">Now we have all the pieces gathered in order to implement our quantum neural network. </span><span class="koboSpan" id="kobo.803.2" xmlns="http://www.w3.org/1999/xhtml">We are going to construct it as a quantum node with two arguments: </span><code><span class="koboSpan" id="kobo.804.1" xmlns="http://www.w3.org/1999/xhtml">inputs</span></code><span class="koboSpan" id="kobo.805.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.806.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code><span class="koboSpan" id="kobo.807.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.807.2" xmlns="http://www.w3.org/1999/xhtml">The first argument is mandatory: in order for PennyLane to be able to train a quantum neural network with TensorFlow, its first argument must accept an array with all the inputs to the network, and the name of this argument must be </span><code><span class="koboSpan" id="kobo.808.1" xmlns="http://www.w3.org/1999/xhtml">inputs</span></code><span class="koboSpan" id="kobo.809.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.809.2" xmlns="http://www.w3.org/1999/xhtml">After this argument, we may add as many as we want. </span><span class="koboSpan" id="kobo.809.3" xmlns="http://www.w3.org/1999/xhtml">These can correspond to any parameters of the circuit, and, of course, they need to include the optimizable parameters in the variational form.</span></p>
<p><span class="koboSpan" id="kobo.810.1" xmlns="http://www.w3.org/1999/xhtml">Thus, we may implement our quantum neural network as follows:</span></p>
<pre class="lstlisting" id="listing-242"><span class="koboSpan" id="kobo.811.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 4 
 
dev = qml.device("default.qubit", wires=nqubits) 
 
 
 
def qnn_circuit(inputs, theta): 
 
    ZZFeatureMap(nqubits, inputs) 
 
    TwoLocal(nqubits = nqubits, theta = theta, reps = 1) 
 
    return qml.expval(qml.Hermitian(M, wires = [0])) 
 
 
 
qnn = qml.QNode(qnn_circuit, dev, interface="tf")
</span></pre>
<p><span class="koboSpan" id="kobo.812.1" xmlns="http://www.w3.org/1999/xhtml">To keep things simple, we have </span><span id="dx1-190047"/><span class="koboSpan" id="kobo.813.1" xmlns="http://www.w3.org/1999/xhtml">chosen to use just one repetition of the variational form. </span><span class="koboSpan" id="kobo.813.2" xmlns="http://www.w3.org/1999/xhtml">If your dataset is more complex, you may want to increase this number in order to have more trainable parameters.</span></p>
<p><span class="koboSpan" id="kobo.814.1" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, how we have added the argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.815.1" xmlns="http://www.w3.org/1999/xhtml">interface</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.816.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.817.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.818.1" xmlns="http://www.w3.org/1999/xhtml">tf</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.819.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.820.1" xmlns="http://www.w3.org/1999/xhtml"> to the quantum node initializer. </span><span class="koboSpan" id="kobo.820.2" xmlns="http://www.w3.org/1999/xhtml">This is so that the quantum node will work with tensors (TensorFlow’s data object) in lieu of with arrays, just to allow PennyLane to communicate smoothly with TensorFlow. </span><span class="koboSpan" id="kobo.820.3" xmlns="http://www.w3.org/1999/xhtml">Had we used the </span><code><span class="koboSpan" id="kobo.821.1" xmlns="http://www.w3.org/1999/xhtml">@qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.822.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.823.1" xmlns="http://www.w3.org/1999/xhtml">qnode</span></code><span class="koboSpan" id="kobo.824.1" xmlns="http://www.w3.org/1999/xhtml"> decorator, we would’ve had to include the argument in its call.</span></p>
<p><span class="koboSpan" id="kobo.825.1" xmlns="http://www.w3.org/1999/xhtml">This defines the quantum node that implements our quantum neural network. </span><span class="koboSpan" id="kobo.825.2" xmlns="http://www.w3.org/1999/xhtml">Now we need to figure out a way to train it, and, for that purpose, we will rely on TensorFlow. </span><span class="koboSpan" id="kobo.825.3" xmlns="http://www.w3.org/1999/xhtml">We’ll do exactly that in the next subsection.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.2.3" id="using-tensorflow-with-pennylane">
<h2 class="subsectionHead" data-number="18.2.3"><span class="titlemark"><span class="koboSpan" id="kobo.826.1" xmlns="http://www.w3.org/1999/xhtml">10.2.3 </span></span> <span id="x1-19100010.2.3"><span class="koboSpan" id="kobo.827.1" xmlns="http://www.w3.org/1999/xhtml">Using TensorFlow with PennyLane</span></span></h2>
<p><span class="koboSpan" id="kobo.828.1" xmlns="http://www.w3.org/1999/xhtml">In </span><em><span class="koboSpan" id="kobo.829.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.830.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><em><span class="koboSpan" id="kobo.831.1" xmlns="http://www.w3.org/1999/xhtml">, What is Quantum Machine Learning?</span></em><span class="koboSpan" id="kobo.832.1" xmlns="http://www.w3.org/1999/xhtml">, we already learned how TensorFlow can be used to train a </span><span id="dx1-191001"/><span class="koboSpan" id="kobo.833.1" xmlns="http://www.w3.org/1999/xhtml">classical neural network. </span><span class="koboSpan" id="kobo.833.2" xmlns="http://www.w3.org/1999/xhtml">Well, thanks to PennyLane’s great interoperability, we will now be able to train our quantum neural network with TensorFlow almost as if it were a classical one.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-186">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.834.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.835.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.836.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane can also be integrated with other classical machine learning frameworks such as PyTorch. </span><span class="koboSpan" id="kobo.836.2" xmlns="http://www.w3.org/1999/xhtml">In addition, it provides its own tools to train models based on the NumPy package, but these are more limited.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.837.1" xmlns="http://www.w3.org/1999/xhtml">Remember how we could </span><span id="dx1-191002"/><span class="koboSpan" id="kobo.838.1" xmlns="http://www.w3.org/1999/xhtml">construct TensorFlow models using Keras layers and joining them in sequential models? </span><span class="koboSpan" id="kobo.838.2" xmlns="http://www.w3.org/1999/xhtml">Look at this:</span></p>
<pre class="lstlisting" id="listing-243"><span class="koboSpan" id="kobo.839.1" xmlns="http://www.w3.org/1999/xhtml">

weights = {"theta": 8} 
 
qlayer = qml.qnn.KerasLayer(qnn, weights, output_dim=1)
</span></pre>
<p><span class="koboSpan" id="kobo.840.1" xmlns="http://www.w3.org/1999/xhtml">That is how you can create a Keras layer containing our quantum neural network — just as if it were any other layer in a classical model! </span><span class="koboSpan" id="kobo.840.2" xmlns="http://www.w3.org/1999/xhtml">In order to do this, we’ve had to call </span><code><span class="koboSpan" id="kobo.841.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.842.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.843.1" xmlns="http://www.w3.org/1999/xhtml">qnn</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.844.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.845.1" xmlns="http://www.w3.org/1999/xhtml">KerasLayer</span></code><span class="koboSpan" id="kobo.846.1" xmlns="http://www.w3.org/1999/xhtml">, and we’ve had to pass a few things to it. </span><span class="koboSpan" id="kobo.846.2" xmlns="http://www.w3.org/1999/xhtml">First, of course, we’ve sent the quantum node with the neural network. </span><span class="koboSpan" id="kobo.846.3" xmlns="http://www.w3.org/1999/xhtml">Then, a dictionary is indexed by the names of all the node arguments that take the optimizable parameters, and specifies, for each of these arguments, the number of parameters that they take. </span><span class="koboSpan" id="kobo.846.4" xmlns="http://www.w3.org/1999/xhtml">Since we only have one such argument, </span><code><span class="koboSpan" id="kobo.847.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code><span class="koboSpan" id="kobo.848.1" xmlns="http://www.w3.org/1999/xhtml">, and it should contain </span><span class="koboSpan" id="kobo.849.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.850.1" xmlns="http://www.w3.org/1999/xhtml"> optimizable parameters (that is, it will be an array of length </span><span class="koboSpan" id="kobo.851.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.852.1" xmlns="http://www.w3.org/1999/xhtml">), we have sent in </span><code><span class="koboSpan" id="kobo.853.1" xmlns="http://www.w3.org/1999/xhtml">{</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.854.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.855.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.856.1" xmlns="http://www.w3.org/1999/xhtml">:</span></code></span><span style="color:#0086E5"> </span></p>
<p><code><span class="koboSpan" id="kobo.857.1" xmlns="http://www.w3.org/1999/xhtml">8}</span></code><span class="koboSpan" id="kobo.858.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.858.2" xmlns="http://www.w3.org/1999/xhtml">Lastly, we’ve had to specify the dimension of the output of the quantum node; since it only returns a numerical expectation value, this dimension is </span><span class="koboSpan" id="kobo.859.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.860.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.861.1" xmlns="http://www.w3.org/1999/xhtml">Once we have a quantum layer, we can create a Keras model easily:</span></p>
<pre class="lstlisting" id="listing-244"><span class="koboSpan" id="kobo.862.1" xmlns="http://www.w3.org/1999/xhtml">

model = tf.keras.models.Sequential([qlayer])
</span></pre>
<p><span class="koboSpan" id="kobo.863.1" xmlns="http://www.w3.org/1999/xhtml">The ability to integrate quantum nodes into neural networks with such a level of flexibility will enable us to easily construct more complex model architectures in the following chapter.</span></p>
<p><span class="koboSpan" id="kobo.864.1" xmlns="http://www.w3.org/1999/xhtml">Having our model ready, we now have to pick an optimizer and a loss function, and then we can compile the model just like any classical model. </span><span class="koboSpan" id="kobo.864.2" xmlns="http://www.w3.org/1999/xhtml">In our case, we will use the binary cross entropy loss (because we are training a binary classifier, after all) and we will rely on the Adam optimizer with a learning rate of </span><span class="koboSpan" id="kobo.865.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.005" class="math inline" src="../media/file1389.png" style="vertical-align:middle" title="0.005"/></span><span class="koboSpan" id="kobo.866.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.866.2" xmlns="http://www.w3.org/1999/xhtml">For the remaining parameters of the optimizer, we will trust the default values. </span><span class="koboSpan" id="kobo.866.3" xmlns="http://www.w3.org/1999/xhtml">Our code is, then, as follows:</span></p>
<pre class="lstlisting" id="listing-245"><span class="koboSpan" id="kobo.867.1" xmlns="http://www.w3.org/1999/xhtml">

opt = tf.keras.optimizers.Adam(learning_rate = 0.005) 
 
model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy())
</span></pre>
<p><span class="koboSpan" id="kobo.868.1" xmlns="http://www.w3.org/1999/xhtml">In addition to this, we will use early </span><span id="dx1-191008"/><span class="koboSpan" id="kobo.869.1" xmlns="http://www.w3.org/1999/xhtml">stopping on the validation loss with a patience of two epochs by using the following instructions:</span></p>
<pre class="lstlisting" id="listing-246"><span class="koboSpan" id="kobo.870.1" xmlns="http://www.w3.org/1999/xhtml">

earlystop = tf.keras.callbacks.EarlyStopping( 
 
    monitor = "val_loss", patience = 2, verbose = 1, 
 
    restore_best_weights = True)
</span></pre>
<p><span class="koboSpan" id="kobo.871.1" xmlns="http://www.w3.org/1999/xhtml">And we are now ready to send the final instruction to get our model trained.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-187">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.872.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.873.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.874.1" xmlns="http://www.w3.org/1999/xhtml">You may remember that, at some point in this chapter, we discussed the different ways in which gradients involving quantum neural networks could be computed. </span><span class="koboSpan" id="kobo.874.2" xmlns="http://www.w3.org/1999/xhtml">And you might wonder why we haven’t had to deal with that in order to get our model trained.</span></p>
<p><span class="koboSpan" id="kobo.875.1" xmlns="http://www.w3.org/1999/xhtml">It turns out that PennyLane already picks the best differentiation method for us in order to compute gradients. </span><span class="koboSpan" id="kobo.875.2" xmlns="http://www.w3.org/1999/xhtml">Each quantum node can use certain differentiation methods — for instance, nodes with devices that act as interfaces to real hardware can’t use automatic differentiation methods, but nodes with simulators can, and most do.</span></p>
<p><span class="koboSpan" id="kobo.876.1" xmlns="http://www.w3.org/1999/xhtml">Later in this section, we will discuss in detail all the differentiation methods that can be used in PennyLane.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.877.1" xmlns="http://www.w3.org/1999/xhtml">To train our model, we just have to call the </span><code><span class="koboSpan" id="kobo.878.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.879.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.879.2" xmlns="http://www.w3.org/1999/xhtml">Since we will be using early stopping, we will be generous with the number of epochs and set it to </span><span class="koboSpan" id="kobo.880.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="50" class="math inline" src="../media/file1390.png" style="vertical-align:middle" title="50"/></span><span class="koboSpan" id="kobo.881.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.881.2" xmlns="http://www.w3.org/1999/xhtml">Also, we will fix a batch size of </span><span class="koboSpan" id="kobo.882.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="20" class="math inline" src="../media/file588.png" style="vertical-align:middle" title="20"/></span><span class="koboSpan" id="kobo.883.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.883.2" xmlns="http://www.w3.org/1999/xhtml">For that, we can use the following piece of code:</span></p>
<pre class="lstlisting" id="listing-247"><span class="koboSpan" id="kobo.884.1" xmlns="http://www.w3.org/1999/xhtml">

history = model.fit(xs_tr, y_tr, epochs = 50, shuffle = True, 
 
    validation_data = (xs_val, y_val), 
 
    batch_size = 20, 
 
    callbacks = [earlystop])
</span></pre>
<p><span class="koboSpan" id="kobo.885.1" xmlns="http://www.w3.org/1999/xhtml">The output that you will get upon running this </span><span id="dx1-191016"/><span class="koboSpan" id="kobo.886.1" xmlns="http://www.w3.org/1999/xhtml">instruction will be similar to the following:</span></p>
<pre class="listings"><span class="koboSpan" id="kobo.887.1" xmlns="http://www.w3.org/1999/xhtml">

 
Epoch 1/50 
23/23 [====] - 22s 944ms/step - loss: 0.8069 - val_loss: 0.7639 
Epoch 2/50 
23/23 [====] - 21s 932ms/step - loss: 0.7485 - val_loss: 0.7174 
Epoch 3/50 
23/23 [====] - 21s 930ms/step - loss: 0.7022 - val_loss: 0.6819 
Epoch 4/50 
23/23 [====] - 22s 957ms/step - loss: 0.6685 - val_loss: 0.6554 
Epoch 5/50 
23/23 [====] - 21s 925ms/step - loss: 0.6433 - val_loss: 0.6362 
Epoch 6/50 
23/23 [====] - 21s 915ms/step - loss: 0.6249 - val_loss: 0.6232 
Epoch 7/50 
23/23 [====] - 21s 916ms/step - loss: 0.6122 - val_loss: 0.6141 
Epoch 8/50 
23/23 [====] - 21s 931ms/step - loss: 0.6029 - val_loss: 0.6081 
Epoch 9/50 
23/23 [====] - 21s 931ms/step - loss: 0.5961 - val_loss: 0.6052 
Epoch 10/50 
23/23 [====] - 22s 951ms/step - loss: 0.5918 - val_loss: 0.6027 
Epoch 11/50 
23/23 [====] - 22s 948ms/step - loss: 0.5889 - val_loss: 0.6007 
Epoch 12/50 
23/23 [====] - 22s 964ms/step - loss: 0.5865 - val_loss: 0.5997 
Epoch 13/50 
23/23 [====] - 21s 926ms/step - loss: 0.5855 - val_loss: 0.5998 
Epoch 14/50 
23/23 [====] - 22s 956ms/step - loss: 0.5841 - val_loss: 0.5993 
Epoch 15/50 
23/23 [====] - 22s 958ms/step - loss: 0.5835 - val_loss: 0.5994 
Epoch 16/50 
23/23 [====] - 22s 946ms/step - loss: 0.5831 - val_loss: 0.5997 
Epoch 16: early stopping 
Restoring model weights from the end of the best epoch: 14.
    
</span></pre>
<div class="tcolorbox learnmore" id="tcolobox-188">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.888.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.889.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.890.1" xmlns="http://www.w3.org/1999/xhtml">If you followed all that we’ve done so far without having asked TensorFlow to work with doubles, everything would work just fine — although you would get slightly different results. </span><span class="koboSpan" id="kobo.890.2" xmlns="http://www.w3.org/1999/xhtml">Nonetheless, if you try to fit a model using the Lightning simulator, you do need to ask TensorFlow to use doubles.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.891.1" xmlns="http://www.w3.org/1999/xhtml">Note that we have manually shrunk the </span><span id="dx1-191052"/><span class="koboSpan" id="kobo.892.1" xmlns="http://www.w3.org/1999/xhtml">progress bar so that the output could fit within the width of the page. </span><span class="koboSpan" id="kobo.892.2" xmlns="http://www.w3.org/1999/xhtml">Also, keep in mind that the execution time may vary from device to device, but, in total, the training shouldn’t take more than </span><span class="koboSpan" id="kobo.893.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="20" class="math inline" src="../media/file588.png" style="vertical-align:middle" title="20"/></span><span class="koboSpan" id="kobo.894.1" xmlns="http://www.w3.org/1999/xhtml"> minutes on an average</span><br/><span class="koboSpan" id="kobo.895.1" xmlns="http://www.w3.org/1999/xhtml">
computer.</span></p>
<p><span class="koboSpan" id="kobo.896.1" xmlns="http://www.w3.org/1999/xhtml">Just by looking at the raw output, we can already see that the model is indeed learning, because there is a very significant drop in both the training and validation losses as the training progresses. </span><span class="koboSpan" id="kobo.896.2" xmlns="http://www.w3.org/1999/xhtml">It could be argued that there might be a tiny amount of overfitting, because the drop in the training loss is slightly greater than that in the validation loss. </span><span class="koboSpan" id="kobo.896.3" xmlns="http://www.w3.org/1999/xhtml">In any case, let’s wait until we have a look at the accuracies before coming to any final conclusions.</span></p>
<p><span class="koboSpan" id="kobo.897.1" xmlns="http://www.w3.org/1999/xhtml">In this case, the training has only run for </span><span class="koboSpan" id="kobo.898.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.899.1" xmlns="http://www.w3.org/1999/xhtml"> epochs, so it’s easy to get insights from the output returned by TensorFlow. </span><span class="koboSpan" id="kobo.899.2" xmlns="http://www.w3.org/1999/xhtml">Nonetheless, in the real world, training processes can go on for up to very large numbers of epochs, and, needless to say, in those situations the console output isn’t particularly informative. </span><span class="koboSpan" id="kobo.899.3" xmlns="http://www.w3.org/1999/xhtml">In general, it’s always a good practice to plot both the training and validation losses against the number of epochs, just to get a better insight into the performance of the </span><span id="dx1-191053"/><span class="koboSpan" id="kobo.900.1" xmlns="http://www.w3.org/1999/xhtml">training process. </span><span class="koboSpan" id="kobo.900.2" xmlns="http://www.w3.org/1999/xhtml">We can do this with the following instructions:</span></p>
<pre class="lstlisting" id="listing-248"><span class="koboSpan" id="kobo.901.1" xmlns="http://www.w3.org/1999/xhtml">

import matplotlib.pyplot as plt 
 
 
 
def plot_losses(history): 
 
    tr_loss = history.history["loss"] 
 
    val_loss = history.history["val_loss"] 
 
    epochs = np.array(range(len(tr_loss))) + 1 
 
    plt.plot(epochs, tr_loss, label = "Training loss") 
 
    plt.plot(epochs, val_loss, label = "Validation loss") 
 
    plt.xlabel("Epoch") 
 
    plt.legend() 
 
    plt.show() 
 
 
 
plot_losses(history)
</span></pre>
<p><span class="koboSpan" id="kobo.902.1" xmlns="http://www.w3.org/1999/xhtml">We’ve decided to define a function just so that we can reuse it in future training processes. </span><span class="koboSpan" id="kobo.902.2" xmlns="http://www.w3.org/1999/xhtml">The resulting plot is shown in </span><em><span class="koboSpan" id="kobo.903.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure10.6"><em><span class="koboSpan" id="kobo.904.1" xmlns="http://www.w3.org/1999/xhtml">10.6</span></em></a><span class="koboSpan" id="kobo.905.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.906.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 10.6: Training and validation loss functions for every epoch" src="../media/file1391.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure10.6"><strong><span class="koboSpan" id="kobo.907.1" xmlns="http://www.w3.org/1999/xhtml">Figure 10.6</span></strong><span class="koboSpan" id="kobo.908.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.909.1" xmlns="http://www.w3.org/1999/xhtml">Training and validation loss functions for every epoch</span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.910.1" xmlns="http://www.w3.org/1999/xhtml">And now it’s time for our final test. </span><span class="koboSpan" id="kobo.910.2" xmlns="http://www.w3.org/1999/xhtml">Let’s check the accuracy of our model on all our datasets to see if its </span><span id="dx1-191069"/><span class="koboSpan" id="kobo.911.1" xmlns="http://www.w3.org/1999/xhtml">performance is acceptable. </span><span class="koboSpan" id="kobo.911.2" xmlns="http://www.w3.org/1999/xhtml">This can be done with the following piece of code:</span></p>
<pre class="lstlisting" id="listing-249"><span class="koboSpan" id="kobo.912.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.metrics import accuracy_score 
 
 
 
tr_acc = accuracy_score(model.predict(xs_tr) &gt;= 0.5, y_tr) 
 
val_acc = accuracy_score(model.predict(xs_val) &gt;= 0.5, y_val) 
 
test_acc = accuracy_score(model.predict(xs_test) &gt;= 0.5, y_test) 
 
 
 
print("Train accuracy:", tr_acc) 
 
print("Validation accuracy:", val_acc) 
 
print("Test accuracy:", test_acc)
</span></pre>
<p><span class="koboSpan" id="kobo.913.1" xmlns="http://www.w3.org/1999/xhtml">Upon running this, we get a training accuracy of </span><span class="koboSpan" id="kobo.914.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="71\%" class="math inline" src="../media/file1392.png" style="vertical-align:middle" title="71\%"/></span><span class="koboSpan" id="kobo.915.1" xmlns="http://www.w3.org/1999/xhtml">, a validation accuracy of </span><span class="koboSpan" id="kobo.916.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="72\%" class="math inline" src="../media/file1393.png" style="vertical-align:middle" title="72\%"/></span><span class="koboSpan" id="kobo.917.1" xmlns="http://www.w3.org/1999/xhtml">, and a test accuracy of </span><span class="koboSpan" id="kobo.918.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="72\%" class="math inline" src="../media/file1393.png" style="vertical-align:middle" title="72\%"/></span><span class="koboSpan" id="kobo.919.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.919.2" xmlns="http://www.w3.org/1999/xhtml">These results don’t reflect any kind of overfitting.</span></p>
<p><span class="koboSpan" id="kobo.920.1" xmlns="http://www.w3.org/1999/xhtml">Instead of implementing your own variational forms, you may prefer to use one of PennyLane’s built-in circuits. </span><span class="koboSpan" id="kobo.920.2" xmlns="http://www.w3.org/1999/xhtml">For instance, you could use the </span><code><span class="koboSpan" id="kobo.921.1" xmlns="http://www.w3.org/1999/xhtml">StronglyEntanglingLayers</span></code><span class="koboSpan" id="kobo.922.1" xmlns="http://www.w3.org/1999/xhtml"> class. </span><span class="koboSpan" id="kobo.922.2" xmlns="http://www.w3.org/1999/xhtml">You should keep in mind, however, that the resulting variational form — as opposed to our own </span><span id="dx1-191079"/><span class="koboSpan" id="kobo.923.1" xmlns="http://www.w3.org/1999/xhtml">implementation of two-local — won’t take a one-dimensional array of inputs, but a three dimensional one! </span><span class="koboSpan" id="kobo.923.2" xmlns="http://www.w3.org/1999/xhtml">In particular, this form on </span><span class="koboSpan" id="kobo.924.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.925.1" xmlns="http://www.w3.org/1999/xhtml"> qubits with </span><span class="koboSpan" id="kobo.926.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="l" class="math inline" src="../media/file514.png" style="vertical-align:middle" title="l"/></span><span class="koboSpan" id="kobo.927.1" xmlns="http://www.w3.org/1999/xhtml"> layers will take as input a three-dimensional array of size </span><span class="koboSpan" id="kobo.928.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n \times l \times 3" class="math inline" src="../media/file1394.png" style="vertical-align:middle" title="n \times l \times 3"/></span><span class="koboSpan" id="kobo.929.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.929.2" xmlns="http://www.w3.org/1999/xhtml">Remember how, in this variational form, we need </span><span class="koboSpan" id="kobo.930.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="3" class="math inline" src="../media/file472.png" style="vertical-align:middle" title="3"/></span><span class="koboSpan" id="kobo.931.1" xmlns="http://www.w3.org/1999/xhtml"> arguments for the rotation gates, and there are </span><span class="koboSpan" id="kobo.932.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.933.1" xmlns="http://www.w3.org/1999/xhtml"> such gates in each of the </span><span class="koboSpan" id="kobo.934.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="l" class="math inline" src="../media/file514.png" style="vertical-align:middle" title="l"/></span><span class="koboSpan" id="kobo.935.1" xmlns="http://www.w3.org/1999/xhtml"> layers (you can take another look at </span><em><span class="koboSpan" id="kobo.936.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <em/> <a href="#Figure10.4"><em><span class="koboSpan" id="kobo.937.1" xmlns="http://www.w3.org/1999/xhtml">10.4</span></em></a><span class="koboSpan" id="kobo.938.1" xmlns="http://www.w3.org/1999/xhtml">).</span></p>
<p><span class="koboSpan" id="kobo.939.1" xmlns="http://www.w3.org/1999/xhtml">If you are ever in doubt, you may call the </span><code><span class="koboSpan" id="kobo.940.1" xmlns="http://www.w3.org/1999/xhtml">StronglyEntanglingLayers</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.941.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.942.1" xmlns="http://www.w3.org/1999/xhtml">shape</span></code><span class="koboSpan" id="kobo.943.1" xmlns="http://www.w3.org/1999/xhtml"> function specifying the number of layers and the number of qubits in the respective arguments </span><code><span class="koboSpan" id="kobo.944.1" xmlns="http://www.w3.org/1999/xhtml">n_layers</span></code><span class="koboSpan" id="kobo.945.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.946.1" xmlns="http://www.w3.org/1999/xhtml">n_wires</span></code><span class="koboSpan" id="kobo.947.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.947.2" xmlns="http://www.w3.org/1999/xhtml">This will return a three-tuple with the shape that the variational form expects.</span></p>
<p><span class="koboSpan" id="kobo.948.1" xmlns="http://www.w3.org/1999/xhtml">For example, we could redefine our previous QNN to use this variational form as follows:</span></p>
<pre class="lstlisting" id="listing-250"><span class="koboSpan" id="kobo.949.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 4 
 
dev = qml.device("default.qubit", wires=nqubits) 
 
 
 
nreps = 2 
 
weights_dim = qml.StronglyEntanglingLayers.shape( 
 
    n_layers = nreps, n_wires = nqubits) 
 
nweights = 3 * nreps * nqubits 
 
 
 
def qnn_circuit_strong(inputs, theta): 
 
 
 
    ZZFeatureMap(nqubits, inputs) 
 
    theta1 = tf.reshape(theta, weights_dim) 
 
    qml.StronglyEntanglingLayers(weights = theta1, 
 
                                 wires = range(nqubits)) 
 
 
 
    return qml.expval(qml.Hermitian(M, wires = [0])) 
 
 
 
qnn_strong = qml.QNode(qnn_circuit_strong, dev) 
 
 
 
weights_strong = {"theta": nweights}
</span></pre>
<p><span class="koboSpan" id="kobo.950.1" xmlns="http://www.w3.org/1999/xhtml">In this piece of code, we have stored in </span><code><span class="koboSpan" id="kobo.951.1" xmlns="http://www.w3.org/1999/xhtml">nreps</span></code><span class="koboSpan" id="kobo.952.1" xmlns="http://www.w3.org/1999/xhtml"> the number of repetitions that we want in each instance of the </span><span id="dx1-191100"/><span class="koboSpan" id="kobo.953.1" xmlns="http://www.w3.org/1999/xhtml">variational form, in </span><code><span class="koboSpan" id="kobo.954.1" xmlns="http://www.w3.org/1999/xhtml">weights_dim</span></code><span class="koboSpan" id="kobo.955.1" xmlns="http://www.w3.org/1999/xhtml"> the dimensions of the input that the variational form expects, and in </span><code><span class="koboSpan" id="kobo.956.1" xmlns="http://www.w3.org/1999/xhtml">nweights</span></code><span class="koboSpan" id="kobo.957.1" xmlns="http://www.w3.org/1999/xhtml"> the number of inputs that each instance of the variational form will take. </span><span class="koboSpan" id="kobo.957.2" xmlns="http://www.w3.org/1999/xhtml">The rest is pretty self-explanatory. </span><span class="koboSpan" id="kobo.957.3" xmlns="http://www.w3.org/1999/xhtml">Inside the circuit, we’ve had to reshape the </span><code><span class="koboSpan" id="kobo.958.1" xmlns="http://www.w3.org/1999/xhtml">theta</span></code><span class="koboSpan" id="kobo.959.1" xmlns="http://www.w3.org/1999/xhtml"> array of parameters to make it fit into the shape that the variational form expects; in order to do this, we’ve used the </span><code><span class="koboSpan" id="kobo.960.1" xmlns="http://www.w3.org/1999/xhtml">tf</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.961.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.962.1" xmlns="http://www.w3.org/1999/xhtml">reshape</span></code><span class="koboSpan" id="kobo.963.1" xmlns="http://www.w3.org/1999/xhtml"> function, which can reshape TensorFlow’s tensors while preserving all their metadata. </span><span class="koboSpan" id="kobo.963.2" xmlns="http://www.w3.org/1999/xhtml">The </span><code><span class="koboSpan" id="kobo.964.1" xmlns="http://www.w3.org/1999/xhtml">weights_strong</span></code><span class="koboSpan" id="kobo.965.1" xmlns="http://www.w3.org/1999/xhtml"> dictionary that we defined at the end is the one that we would send to TensorFlow when constructing the Keras layer.</span></p>
<p><span class="koboSpan" id="kobo.966.1" xmlns="http://www.w3.org/1999/xhtml">We’ve already learned how you can train a quantum neural network using PennyLane and TensorFlow. </span><span class="koboSpan" id="kobo.966.2" xmlns="http://www.w3.org/1999/xhtml">We shall now discuss a few technical details in depth before bringing this section to an end.</span></p>
</section>
<section class="level3 subsectionHead" data-number="18.2.4" id="gradient-computation-in-pennylane">
<h2 class="subsectionHead" data-number="18.2.4"><span class="titlemark"><span class="koboSpan" id="kobo.967.1" xmlns="http://www.w3.org/1999/xhtml">10.2.4 </span></span> <span id="x1-19200010.2.4"><span class="koboSpan" id="kobo.968.1" xmlns="http://www.w3.org/1999/xhtml">Gradient computation in PennyLane</span></span></h2>
<p><span class="koboSpan" id="kobo.969.1" xmlns="http://www.w3.org/1999/xhtml">As we have already mentioned, when you train a model with PennyLane, the framework itself figures out the best way in which to </span><span id="dx1-192001"/><span class="koboSpan" id="kobo.970.1" xmlns="http://www.w3.org/1999/xhtml">compute gradients. </span><span class="koboSpan" id="kobo.970.2" xmlns="http://www.w3.org/1999/xhtml">Different quantum nodes may be compatible with different methods of differentiation based on a variety of factors, most notably the kind of device they use.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-189">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.971.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.972.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content"><span class="koboSpan" id="kobo.973.1" xmlns="http://www.w3.org/1999/xhtml">
For an up-to-date reference of the differentiation methods that the </span><code><span class="koboSpan" id="kobo.974.1" xmlns="http://www.w3.org/1999/xhtml">default</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.975.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span>
<code><span class="koboSpan" id="kobo.976.1" xmlns="http://www.w3.org/1999/xhtml">qubit</span></code><span class="koboSpan" id="kobo.977.1" xmlns="http://www.w3.org/1999/xhtml"> simulator supports, you may check the online documentation at </span><a class="url" href="https://docs.pennylane.ai/en/stable/introduction/interfaces.html#supported-configurations"><span class="koboSpan" id="kobo.978.1" xmlns="http://www.w3.org/1999/xhtml">https://docs.pennylane.ai/en/stable/introduction/interfaces.html#supported-configurations</span></a><span class="koboSpan" id="kobo.979.1" xmlns="http://www.w3.org/1999/xhtml">.
</span><p><span class="koboSpan" id="kobo.980.1" xmlns="http://www.w3.org/1999/xhtml">You will see that the compatibility of a quantum node with a differentiation method not only depends on the device itself but also on the return type of the node and the machine learning interface (in our case, the interface was TensorFlow).</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.981.1" xmlns="http://www.w3.org/1999/xhtml">These are the </span><span id="dx1-192002"/><span class="koboSpan" id="kobo.982.1" xmlns="http://www.w3.org/1999/xhtml">differentiation methods that can be used in PennyLane:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.983.1" xmlns="http://www.w3.org/1999/xhtml">Backpropagation</span></strong><span class="koboSpan" id="kobo.984.1" xmlns="http://www.w3.org/1999/xhtml">: Just the good old </span><span id="dx1-192003"/><span class="koboSpan" id="kobo.985.1" xmlns="http://www.w3.org/1999/xhtml">backpropagation method that is used in classical neural networks. </span><span class="koboSpan" id="kobo.985.2" xmlns="http://www.w3.org/1999/xhtml">Of course, this differentiation method only works on simulators that are compatible with automatic differentiation, because that is what is needed in order to analytically compute the gradients.</span></p>
<p><span class="koboSpan" id="kobo.986.1" xmlns="http://www.w3.org/1999/xhtml">The name of this method in PennyLane is </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.987.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.988.1" xmlns="http://www.w3.org/1999/xhtml">backprop</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.989.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.990.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.991.1" xmlns="http://www.w3.org/1999/xhtml">Adjoint differentiation</span></strong><span class="koboSpan" id="kobo.992.1" xmlns="http://www.w3.org/1999/xhtml">: This is a more </span><span id="dx1-192004"/><span class="koboSpan" id="kobo.993.1" xmlns="http://www.w3.org/1999/xhtml">efficient version of backpropagation that relies on some of the nice computational ”oddities” of quantum computing, such as the fact that all the quantum circuits are implemented by unitary matrices, which are trivially invertible. </span><span class="koboSpan" id="kobo.993.2" xmlns="http://www.w3.org/1999/xhtml">Like backpropagation, this method only works on the simulators that are compatible with automatic differentiation, but it is more restrictive.</span></p>
<p><span class="koboSpan" id="kobo.994.1" xmlns="http://www.w3.org/1999/xhtml">The name of this method in PennyLane is </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.995.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.996.1" xmlns="http://www.w3.org/1999/xhtml">adjoint</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.997.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.998.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.999.1" xmlns="http://www.w3.org/1999/xhtml">Finite differences</span></strong><span class="koboSpan" id="kobo.1000.1" xmlns="http://www.w3.org/1999/xhtml">: Ever took a </span><span id="dx1-192005"/><span class="koboSpan" id="kobo.1001.1" xmlns="http://www.w3.org/1999/xhtml">numerical analysis course at college? </span><span class="koboSpan" id="kobo.1001.2" xmlns="http://www.w3.org/1999/xhtml">Then this will sound familiar. </span><span class="koboSpan" id="kobo.1001.3" xmlns="http://www.w3.org/1999/xhtml">This method implements the old-school way of computing a numerical approximation of a gradient that we discussed in the previous section. </span><span class="koboSpan" id="kobo.1001.4" xmlns="http://www.w3.org/1999/xhtml">It works on almost every quantum node.</span></p>
<p><span class="koboSpan" id="kobo.1002.1" xmlns="http://www.w3.org/1999/xhtml">The name of this method in PennyLane is </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1003.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1004.1" xmlns="http://www.w3.org/1999/xhtml">finite</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1005.1" xmlns="http://www.w3.org/1999/xhtml">-</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1006.1" xmlns="http://www.w3.org/1999/xhtml">diff</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1007.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1008.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.1009.1" xmlns="http://www.w3.org/1999/xhtml">Parameter shift rule</span></strong><span class="koboSpan" id="kobo.1010.1" xmlns="http://www.w3.org/1999/xhtml">: PennyLane fully </span><span id="dx1-192006"/><span class="koboSpan" id="kobo.1011.1" xmlns="http://www.w3.org/1999/xhtml">implements the parameter-shift rule that we introduced previously. </span><span class="koboSpan" id="kobo.1011.2" xmlns="http://www.w3.org/1999/xhtml">It works on most quantum nodes.</span></p>
<p><span class="koboSpan" id="kobo.1012.1" xmlns="http://www.w3.org/1999/xhtml">The name of this method in PennyLane is </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1013.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1014.1" xmlns="http://www.w3.org/1999/xhtml">parameter</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1015.1" xmlns="http://www.w3.org/1999/xhtml">-</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1016.1" xmlns="http://www.w3.org/1999/xhtml">shift</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1017.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1018.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.1019.1" xmlns="http://www.w3.org/1999/xhtml">Device gradient computation</span></strong><span class="koboSpan" id="kobo.1020.1" xmlns="http://www.w3.org/1999/xhtml">: Some devices </span><span id="dx1-192007"/><span class="koboSpan" id="kobo.1021.1" xmlns="http://www.w3.org/1999/xhtml">provide their own way of computing gradients. </span><span class="koboSpan" id="kobo.1021.2" xmlns="http://www.w3.org/1999/xhtml">The name of the corresponding differentiation method is </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1022.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1023.1" xmlns="http://www.w3.org/1999/xhtml">device</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1024.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1025.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.1026.1" xmlns="http://www.w3.org/1999/xhtml">There are a couple of things that deserve clarification; the first of them is how a simulator could not be compatible with automatic differentiation. </span><span class="koboSpan" id="kobo.1026.2" xmlns="http://www.w3.org/1999/xhtml">Oversimplifying a little bit, most simulators work by computing the evolution of the quantum state of a circuit and returning an output that is differentiable with respect to the parameters. </span><span class="koboSpan" id="kobo.1026.3" xmlns="http://www.w3.org/1999/xhtml">The operations required to do all of this are themselves differentiable, and hence it’s possible to use automatic differentiation on quantum nodes that use that simulator. </span><span class="koboSpan" id="kobo.1026.4" xmlns="http://www.w3.org/1999/xhtml">But simulators may work differently. </span><span class="koboSpan" id="kobo.1026.5" xmlns="http://www.w3.org/1999/xhtml">For instance, a simulator could return individual shots in a way that ”breaks” the differentiability of the computation.</span></p>
<p><span class="koboSpan" id="kobo.1027.1" xmlns="http://www.w3.org/1999/xhtml">Another thing that may have caught your </span><span id="dx1-192008"/><span class="koboSpan" id="kobo.1028.1" xmlns="http://www.w3.org/1999/xhtml">attention is that the finite difference method can be used on ”most” quantum nodes, but not on all of them. </span><span class="koboSpan" id="kobo.1028.2" xmlns="http://www.w3.org/1999/xhtml">That’s because some quantum nodes may return outputs that don’t make it possible for the finite differences method to work with them. </span><span class="koboSpan" id="kobo.1028.3" xmlns="http://www.w3.org/1999/xhtml">For instance, if a node returns an array of samples, the differentiability is broken. </span><span class="koboSpan" id="kobo.1028.4" xmlns="http://www.w3.org/1999/xhtml">If instead, it returned an expectation value — even if it were just an empirical approximation obtained from a collection of samples — then a gradient would exist and the finite differences method could be used to compute it.</span></p>
<div class="tcolorbox questionx" id="tcolobox-190">
<span id="x1-192010x10.2.4"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.1029.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 10.3</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.1030.1" xmlns="http://www.w3.org/1999/xhtml">List all the PennyLane differentiation methods that can be used on quantum hardware and all the differentiation methods that can be used on simulators.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.1031.1" xmlns="http://www.w3.org/1999/xhtml">The way in which you can ask PennyLane to use a specific differentiation method — let’s say one named </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1032.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1033.1" xmlns="http://www.w3.org/1999/xhtml">method</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1034.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1035.1" xmlns="http://www.w3.org/1999/xhtml"> — is by passing the optional argument </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.1036.1" xmlns="http://www.w3.org/1999/xhtml">diff_method</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1037.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1038.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1039.1" xmlns="http://www.w3.org/1999/xhtml">method</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1040.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1041.1" xmlns="http://www.w3.org/1999/xhtml"> to the quantum node decorator or initializer. </span><span class="koboSpan" id="kobo.1041.2" xmlns="http://www.w3.org/1999/xhtml">That is, if you use the QNode decorator, you should write</span></p>
<pre class="lstlisting" id="listing-251"><span class="koboSpan" id="kobo.1042.1" xmlns="http://www.w3.org/1999/xhtml">

@qml.qnode(device, interface = "tf", diff_method = "method") 
 
def qnn(): 
 
    # Circuit goes here.
</span></pre>
<p><span class="koboSpan" id="kobo.1043.1" xmlns="http://www.w3.org/1999/xhtml">Alternatively, if you decided to assemble a circuit </span><code><span class="koboSpan" id="kobo.1044.1" xmlns="http://www.w3.org/1999/xhtml">circuit</span></code><span class="koboSpan" id="kobo.1045.1" xmlns="http://www.w3.org/1999/xhtml"> and a device </span><code><span class="koboSpan" id="kobo.1046.1" xmlns="http://www.w3.org/1999/xhtml">device</span></code><span class="koboSpan" id="kobo.1047.1" xmlns="http://www.w3.org/1999/xhtml"> into a quantum node directly, you should call the following:</span></p>
<pre class="lstlisting" id="listing-252"><span class="koboSpan" id="kobo.1048.1" xmlns="http://www.w3.org/1999/xhtml">

qnn = qml.QNode(circuit, device, interface = "tf", 
 
                diff_method = "method")
</span></pre>
<p><span class="koboSpan" id="kobo.1049.1" xmlns="http://www.w3.org/1999/xhtml">By default, </span><code><span class="koboSpan" id="kobo.1050.1" xmlns="http://www.w3.org/1999/xhtml">diff_method</span></code><span class="koboSpan" id="kobo.1051.1" xmlns="http://www.w3.org/1999/xhtml"> is set to </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1052.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1053.1" xmlns="http://www.w3.org/1999/xhtml">best</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1054.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1055.1" xmlns="http://www.w3.org/1999/xhtml">, which, as we’ve said before, lets PennyLane choose on our behalf the best differentiation method.</span></p>
<p><span class="koboSpan" id="kobo.1056.1" xmlns="http://www.w3.org/1999/xhtml">In our particular case, PennyLane has been using the </span><span id="dx1-192016"/><span class="koboSpan" id="kobo.1057.1" xmlns="http://www.w3.org/1999/xhtml">backpropagation differentiation method all this time — without us even noticing!</span></p>
<div class="tcolorbox learnmore" id="tcolobox-191">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1058.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1059.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.1060.1" xmlns="http://www.w3.org/1999/xhtml">If you want to know which differentiation method PennyLane uses by default on a device </span><code><span class="koboSpan" id="kobo.1061.1" xmlns="http://www.w3.org/1999/xhtml">dev</span></code><span class="koboSpan" id="kobo.1062.1" xmlns="http://www.w3.org/1999/xhtml"> and on a certain interface </span><code><span class="koboSpan" id="kobo.1063.1" xmlns="http://www.w3.org/1999/xhtml">inter</span></code><span class="koboSpan" id="kobo.1064.1" xmlns="http://www.w3.org/1999/xhtml"> (in our case, </span><span class="lstinline"><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1065.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1066.1" xmlns="http://www.w3.org/1999/xhtml">tensorflow</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1067.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span></span><span class="koboSpan" id="kobo.1068.1" xmlns="http://www.w3.org/1999/xhtml">), you can just call the following function:</span></p>
<pre class="lstlisting" id="listing-253"><span class="koboSpan" id="kobo.1069.1" xmlns="http://www.w3.org/1999/xhtml">

qml.QNode.best_method_str(dev, inter)
</span></pre>
</div>
</div>
<p><span class="koboSpan" id="kobo.1070.1" xmlns="http://www.w3.org/1999/xhtml">Our quantum node is compatible with all the differentiation methods except with device differentiation, because </span><code><span class="koboSpan" id="kobo.1071.1" xmlns="http://www.w3.org/1999/xhtml">default</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1072.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1073.1" xmlns="http://www.w3.org/1999/xhtml">qubit</span></code><span class="koboSpan" id="kobo.1074.1" xmlns="http://www.w3.org/1999/xhtml"> doesn’t implement its own special way of computing gradients. </span><span class="koboSpan" id="kobo.1074.2" xmlns="http://www.w3.org/1999/xhtml">Thus, just to better understand the differences in performance, we can try out all the differentiation methods and see how they behave.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-192">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1075.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1076.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content"><span class="koboSpan" id="kobo.1077.1" xmlns="http://www.w3.org/1999/xhtml">
You may remember that, when using the Lightning simulator, we do need to ask TensorFlow to use doubles all across the Keras model instead of floats — it’s not an option, but a necessity. </span><span class="koboSpan" id="kobo.1077.2" xmlns="http://www.w3.org/1999/xhtml">The same happens when we use differentiation methods other than backpropagation with </span><code><span class="koboSpan" id="kobo.1078.1" xmlns="http://www.w3.org/1999/xhtml">default</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1079.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span>
<code><span class="koboSpan" id="kobo.1080.1" xmlns="http://www.w3.org/1999/xhtml">qubit</span></code><span class="koboSpan" id="kobo.1081.1" xmlns="http://www.w3.org/1999/xhtml">.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.1082.1" xmlns="http://www.w3.org/1999/xhtml">Let’s begin with adjoint differentiation. </span><span class="koboSpan" id="kobo.1082.2" xmlns="http://www.w3.org/1999/xhtml">In order to retrain our model with this differentiation method, we will rerun all our previous code, but changing the quantum node definition to the following:</span></p>
<pre class="lstlisting" id="listing-254"><span class="koboSpan" id="kobo.1083.1" xmlns="http://www.w3.org/1999/xhtml">

qnn = qml.QNode(qnn_circuit, dev, 
 
    interface="tf", diff_method="adjoint")
</span></pre>
<p><span class="koboSpan" id="kobo.1084.1" xmlns="http://www.w3.org/1999/xhtml">Reasonably enough, instead of rerunning all your code, you may want to add the execution of alternative differentiation methods as part of it — particularly if you are keeping your code in a notebook. </span><span class="koboSpan" id="kobo.1084.2" xmlns="http://www.w3.org/1999/xhtml">If you want to do so while </span><span id="dx1-192020"/><span class="koboSpan" id="kobo.1085.1" xmlns="http://www.w3.org/1999/xhtml">ensuring that the training is done in identical conditions (the same environment and seeds), these are the lines that you would have to run:</span></p>
<pre class="lstlisting" id="listing-255"><span class="koboSpan" id="kobo.1086.1" xmlns="http://www.w3.org/1999/xhtml">

method = "adjoint" # Set it to whatever you want! 
 
 
 
</span><span class="koboSpan" id="kobo.1086.2" xmlns="http://www.w3.org/1999/xhtml">tf.random.set_seed(seed) 
 
 
 
qnn = qml.QNode(qnn_circuit, dev, interface="tf", 
 
                diff_method = method) 
 
qlayer = qml.qnn.KerasLayer(qnn, weights, output_dim=1) 
 
model = tf.keras.models.Sequential([qlayer]) 
 
opt = tf.keras.optimizers.Adam(learning_rate = 0.005) 
 
model.compile(opt, loss=tf.keras.losses.BinaryCrossentropy()) 
 
history = model.fit(xs_tr, y_tr, epochs = 50, shuffle = True, 
 
    validation_data = (xs_val, y_val), 
 
    batch_size = 20, 
 
    callbacks = [earlystop])
</span></pre>
<p><span class="koboSpan" id="kobo.1087.1" xmlns="http://www.w3.org/1999/xhtml">Upon running this, you will get the exact same training behavior that we got with backpropagation — the same evolution of the training and validation losses and, of course, the same accuracies. </span><span class="koboSpan" id="kobo.1087.2" xmlns="http://www.w3.org/1999/xhtml">Where there is a noticeable change, however, is in training time. </span><span class="koboSpan" id="kobo.1087.3" xmlns="http://www.w3.org/1999/xhtml">In our case, training with backpropagation took a rough average of </span><span class="koboSpan" id="kobo.1088.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="21" class="math inline" src="../media/file1395.png" style="vertical-align:middle" title="21"/></span><span class="koboSpan" id="kobo.1089.1" xmlns="http://www.w3.org/1999/xhtml"> seconds per epoch. </span><span class="koboSpan" id="kobo.1089.2" xmlns="http://www.w3.org/1999/xhtml">Using adjoint differentiation, in contrast, the training took, on average, </span><span class="koboSpan" id="kobo.1090.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="10" class="math inline" src="../media/file161.png" style="vertical-align:middle" title="10"/></span><span class="koboSpan" id="kobo.1091.1" xmlns="http://www.w3.org/1999/xhtml"> seconds per epoch. </span><span class="koboSpan" id="kobo.1091.2" xmlns="http://www.w3.org/1999/xhtml">That’s a big gain!</span></p>
<p><span class="koboSpan" id="kobo.1092.1" xmlns="http://www.w3.org/1999/xhtml">Actually, if you wanted to further reduce the training time, you should try the Lightning simulator with the adjoint method. </span><span class="koboSpan" id="kobo.1092.2" xmlns="http://www.w3.org/1999/xhtml">Depending on the hardware configuration of your computer, it can yield very significant boosts in performance.</span></p>
<p><span class="koboSpan" id="kobo.1093.1" xmlns="http://www.w3.org/1999/xhtml">Let’s now train our model with the two remaining differentiation methods, which are the hardware-compatible ones: the parameter-shift rule and finite differences. </span><span class="koboSpan" id="kobo.1093.2" xmlns="http://www.w3.org/1999/xhtml">In order to do that, we will just have to rerun our code changing the value of the differentiation method in the </span><span id="dx1-192035"/><span class="koboSpan" id="kobo.1094.1" xmlns="http://www.w3.org/1999/xhtml">quantum node definition. </span><span class="koboSpan" id="kobo.1094.2" xmlns="http://www.w3.org/1999/xhtml">In order to avoid redundancy, we won’t rewrite everything here — we trust these small changes to you!</span></p>
<p><span class="koboSpan" id="kobo.1095.1" xmlns="http://www.w3.org/1999/xhtml">When retraining with these two models, these are the results we obtained:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.1096.1" xmlns="http://www.w3.org/1999/xhtml">Using the parameter shift rule yielded the very same results as the other differentiation methods. </span><span class="koboSpan" id="kobo.1096.2" xmlns="http://www.w3.org/1999/xhtml">Regarding training time, each epoch took, on average, </span><span class="koboSpan" id="kobo.1097.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="14" class="math inline" src="../media/file1396.png" style="vertical-align:middle" title="14"/></span><span class="koboSpan" id="kobo.1098.1" xmlns="http://www.w3.org/1999/xhtml"> seconds to complete. </span><span class="koboSpan" id="kobo.1098.2" xmlns="http://www.w3.org/1999/xhtml">That’s better than the </span><span class="koboSpan" id="kobo.1099.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="21" class="math inline" src="../media/file1395.png" style="vertical-align:middle" title="21"/></span><span class="koboSpan" id="kobo.1100.1" xmlns="http://www.w3.org/1999/xhtml"> seconds that we got with backpropagation, but not as good as the </span><span class="koboSpan" id="kobo.1101.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="10" class="math inline" src="../media/file161.png" style="vertical-align:middle" title="10"/></span><span class="koboSpan" id="kobo.1102.1" xmlns="http://www.w3.org/1999/xhtml"> seconds that the adjoint method gave us.</span></p></li>
<li><p><span class="koboSpan" id="kobo.1103.1" xmlns="http://www.w3.org/1999/xhtml">When using finite differences differentiation, we got, once again, the same results that the other methods yielded. </span><span class="koboSpan" id="kobo.1103.2" xmlns="http://www.w3.org/1999/xhtml">On average, each epoch took </span><span class="koboSpan" id="kobo.1104.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="10" class="math inline" src="../media/file161.png" style="vertical-align:middle" title="10"/></span><span class="koboSpan" id="kobo.1105.1" xmlns="http://www.w3.org/1999/xhtml"> seconds to complete, which matches the training time of adjoint differentiation.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.1106.1" xmlns="http://www.w3.org/1999/xhtml">Keep in mind that this comparison holds for the particular model that we have considered. </span><span class="koboSpan" id="kobo.1106.2" xmlns="http://www.w3.org/1999/xhtml">The results may vary as the complexity of the models increases and, in particular, hardware-compatible methods may perform more poorly on simulators when training complex QNN architectures.</span></p>
<p><span class="koboSpan" id="kobo.1107.1" xmlns="http://www.w3.org/1999/xhtml">And that’s probably all you need to know about the differentiation methods that are available in PennyLane. </span><span class="koboSpan" id="kobo.1107.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now have a look at what Qiskit has to offer in terms of quantum neural networks.</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="18.3" id="quantum-neural-networks-in-qiskit-a-commentary">
<h1 class="sectionHead" data-number="18.3"><span class="titlemark"><span class="koboSpan" id="kobo.1108.1" xmlns="http://www.w3.org/1999/xhtml">10.3 </span></span> <span id="x1-19300010.3"><span class="koboSpan" id="kobo.1109.1" xmlns="http://www.w3.org/1999/xhtml">Quantum neural networks in Qiskit: a commentary</span></span></h1>
<p><span class="koboSpan" id="kobo.1110.1" xmlns="http://www.w3.org/1999/xhtml">In the previous section, we had a </span><span id="dx1-193001"/><span class="koboSpan" id="kobo.1111.1" xmlns="http://www.w3.org/1999/xhtml">chance to explore in great depth the implementation and training of quantum neural networks in PennyLane. </span><span class="koboSpan" id="kobo.1111.2" xmlns="http://www.w3.org/1999/xhtml">We won’t do an analogous discussion for Qiskit in such a level of detail, but we will at least give you a few ideas about how to get started should you ever need to use Qiskit in order to work with quantum neural networks.</span></p>
<p><span class="koboSpan" id="kobo.1112.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane provides a very homogeneous and flexible experience. </span><span class="koboSpan" id="kobo.1112.2" xmlns="http://www.w3.org/1999/xhtml">No matter if you’re training a simple binary classifier or a complex hybrid architecture like the ones we will study in the following chapter, it’s all done in the same way.</span></p>
<p><span class="koboSpan" id="kobo.1113.1" xmlns="http://www.w3.org/1999/xhtml">Qiskit, by contrast, provides a more ”structural” approach. </span><span class="koboSpan" id="kobo.1113.2" xmlns="http://www.w3.org/1999/xhtml">It gives you a suite of classes that can be used to train </span><span id="dx1-193002"/><span class="koboSpan" id="kobo.1114.1" xmlns="http://www.w3.org/1999/xhtml">different kinds of neural networks and that allow you to define your networks in different ways. </span><span class="koboSpan" id="kobo.1114.2" xmlns="http://www.w3.org/1999/xhtml">It’s difficult to judge whether this is a better or worse approach; in the end, it’s just a matter of taste. </span><span class="koboSpan" id="kobo.1114.3" xmlns="http://www.w3.org/1999/xhtml">On the one hand, training basic models in Qiskit might be simpler than training them in PennyLane because of the ease of use of some of these purpose-built classes. </span><span class="koboSpan" id="kobo.1114.4" xmlns="http://www.w3.org/1999/xhtml">On the other hand, having different ways of accomplishing the same thing — one could argue — might generate some unnecessary complexity.</span></p>
<p><span class="koboSpan" id="kobo.1115.1" xmlns="http://www.w3.org/1999/xhtml">The classes provided by Qiskit for the implementation of quantum neural networks can be imported from </span><code><span class="koboSpan" id="kobo.1116.1" xmlns="http://www.w3.org/1999/xhtml">qiskit_machine_learning</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1117.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1118.1" xmlns="http://www.w3.org/1999/xhtml">neural_networks</span></code><span class="koboSpan" id="kobo.1119.1" xmlns="http://www.w3.org/1999/xhtml"> (please, refer to </span><em><span class="koboSpan" id="kobo.1120.1" xmlns="http://www.w3.org/1999/xhtml">Appendix</span></em> <a href="ch027.xhtml#x1-240000D"><em><span class="koboSpan" id="kobo.1121.1" xmlns="http://www.w3.org/1999/xhtml">D</span></em></a><em><span class="koboSpan" id="kobo.1122.1" xmlns="http://www.w3.org/1999/xhtml">, Installing the Tools</span></em><span class="koboSpan" id="kobo.1123.1" xmlns="http://www.w3.org/1999/xhtml">, for installation instructions). </span><span class="koboSpan" id="kobo.1123.2" xmlns="http://www.w3.org/1999/xhtml">These are some of them:</span></p>
<ul>
<li><p><strong><span class="koboSpan" id="kobo.1124.1" xmlns="http://www.w3.org/1999/xhtml">Two-layer QNN</span></strong><span class="koboSpan" id="kobo.1125.1" xmlns="http://www.w3.org/1999/xhtml">: The </span><code><span class="koboSpan" id="kobo.1126.1" xmlns="http://www.w3.org/1999/xhtml">TwoLayerQNN</span></code><span class="koboSpan" id="kobo.1127.1" xmlns="http://www.w3.org/1999/xhtml"> class can be </span><span id="dx1-193003"/><span class="koboSpan" id="kobo.1128.1" xmlns="http://www.w3.org/1999/xhtml">used to implement a quantum neural network with a single feature map, a variational form, and an observable. </span><span class="koboSpan" id="kobo.1128.2" xmlns="http://www.w3.org/1999/xhtml">It works for any vanilla quantum neural network.</span></p></li>
<li><p><strong><span class="koboSpan" id="kobo.1129.1" xmlns="http://www.w3.org/1999/xhtml">Circuit QNN</span></strong><span class="koboSpan" id="kobo.1130.1" xmlns="http://www.w3.org/1999/xhtml">: The </span><code><span class="koboSpan" id="kobo.1131.1" xmlns="http://www.w3.org/1999/xhtml">CircuitQNN</span></code><span class="koboSpan" id="kobo.1132.1" xmlns="http://www.w3.org/1999/xhtml"> class </span><span id="dx1-193004"/><span class="koboSpan" id="kobo.1133.1" xmlns="http://www.w3.org/1999/xhtml">allows you to implement a quantum neural network from a parametrized circuit. </span><span class="koboSpan" id="kobo.1133.2" xmlns="http://www.w3.org/1999/xhtml">The final state of the circuit will be measured on the computational basis, and each measurement result can be mapped to an integer label through an interpreter function. </span><span class="koboSpan" id="kobo.1133.3" xmlns="http://www.w3.org/1999/xhtml">This can be useful, for instance, if you want to build a classifier.</span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.1134.1" xmlns="http://www.w3.org/1999/xhtml">By the way, in Qiskit lingo, variational </span><span id="dx1-193005"/><span class="koboSpan" id="kobo.1135.1" xmlns="http://www.w3.org/1999/xhtml">forms are called </span><strong><span class="koboSpan" id="kobo.1136.1" xmlns="http://www.w3.org/1999/xhtml">ansatzs</span></strong><span class="koboSpan" id="kobo.1137.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1137.2" xmlns="http://www.w3.org/1999/xhtml">As you surely remember, this is also the name that was used in the context of the VQE algorithm that we studied in </span><em><span class="koboSpan" id="kobo.1138.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <em/> <a href="ch015.xhtml#x1-1190007"><em><span class="koboSpan" id="kobo.1139.1" xmlns="http://www.w3.org/1999/xhtml">7</span></em></a><em><span class="koboSpan" id="kobo.1140.1" xmlns="http://www.w3.org/1999/xhtml">, VQE: Variational Quantum</span></em> <em><span class="koboSpan" id="kobo.1141.1" xmlns="http://www.w3.org/1999/xhtml">Eigensolver</span></em><span class="koboSpan" id="kobo.1142.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1143.1" xmlns="http://www.w3.org/1999/xhtml">If, when designing a neural network in Qiskit, you want to use the ZZ feature map or the two-local variational form, there’s no need for you to re-implement them; they are bundled with Qiskit. </span><span class="koboSpan" id="kobo.1143.2" xmlns="http://www.w3.org/1999/xhtml">You can get them as follows:</span></p>
<pre class="lstlisting" id="listing-256"><span class="koboSpan" id="kobo.1144.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.circuit.library import ZZFeatureMap, TwoLocal 
 
nqubits = 3 # We’ll do it for three qubits. 
 
</span><span class="koboSpan" id="kobo.1144.2" xmlns="http://www.w3.org/1999/xhtml">zzfm = ZZFeatureMap(nqubits, reps = 1) 
 
twol = TwoLocal(nqubits, ’ry’, ’cx’, ’linear’, reps = 1) 
 
# Change rep(etition)s above to suit your needs.
</span></pre>
<p><span class="koboSpan" id="kobo.1145.1" xmlns="http://www.w3.org/1999/xhtml">In the call to the ZZ feature map class, we have set the </span><span id="dx1-193011"/><span class="koboSpan" id="kobo.1146.1" xmlns="http://www.w3.org/1999/xhtml">number of repetitions to </span><span class="koboSpan" id="kobo.1147.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1148.1" xmlns="http://www.w3.org/1999/xhtml"> — any other number would yield a feature map with that number of repetitions of the ZZ feature map scheme. </span><span class="koboSpan" id="kobo.1148.2" xmlns="http://www.w3.org/1999/xhtml">In the call to the two-local class, we have also specified — in addition to the repetitions — the rotation gates, the controlled gates, and the entanglement layout that we want to use.</span></p>
<p><span class="koboSpan" id="kobo.1149.1" xmlns="http://www.w3.org/1999/xhtml">For the sake of example, we can define a </span><code><span class="koboSpan" id="kobo.1150.1" xmlns="http://www.w3.org/1999/xhtml">TwoLayer</span></code><span class="koboSpan" id="kobo.1151.1" xmlns="http://www.w3.org/1999/xhtml"> quantum neural network on three qubits with the ZZ feature map and two-local variational form that we have just instantiated. </span><span class="koboSpan" id="kobo.1151.2" xmlns="http://www.w3.org/1999/xhtml">We can do this as follows:</span></p>
<pre class="lstlisting" id="listing-257"><span class="koboSpan" id="kobo.1152.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.neural_networks import TwoLayerQNN 
 
from qiskit.providers.aer import AerSimulator 
 
 
 
qnn = TwoLayerQNN(nqubits, feature_map = zzfm, ansatz = twol, 
 
                  quantum_instance = AerSimulator(method="statevector"))
</span></pre>
<p><span class="koboSpan" id="kobo.1153.1" xmlns="http://www.w3.org/1999/xhtml">Since we haven’t specified an observable, the resulting QNN will return the expectation value of the </span><span class="koboSpan" id="kobo.1154.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Z \otimes Z \otimes Z" class="math inline" src="../media/file1397.png" style="vertical-align:middle" title="Z \otimes Z \otimes Z"/></span><span class="koboSpan" id="kobo.1155.1" xmlns="http://www.w3.org/1999/xhtml"> observable measured after feeding the execution of the network’s circuit.</span></p>
<p><span class="koboSpan" id="kobo.1156.1" xmlns="http://www.w3.org/1999/xhtml">We can simulate analytically the network that we have just created on some random inputs and optimizable parameters as follows:</span></p>
<pre class="lstlisting" id="listing-258"><span class="koboSpan" id="kobo.1157.1" xmlns="http://www.w3.org/1999/xhtml">

qnn.forward(np.random.rand(qnn.num_inputs), 
 
            np.random.rand(qnn.num_weights))
</span></pre>
<p><span class="koboSpan" id="kobo.1158.1" xmlns="http://www.w3.org/1999/xhtml">The first argument is an array with some (random) classical inputs while the second argument is an array with (random) values for the optimizable parameters. </span><span class="koboSpan" id="kobo.1158.2" xmlns="http://www.w3.org/1999/xhtml">Notice how we’ve used the </span><code><span class="koboSpan" id="kobo.1159.1" xmlns="http://www.w3.org/1999/xhtml">qnum_inputs</span></code><span class="koboSpan" id="kobo.1160.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1161.1" xmlns="http://www.w3.org/1999/xhtml">num_weights</span></code><span class="koboSpan" id="kobo.1162.1" xmlns="http://www.w3.org/1999/xhtml"> properties of the quantum neural network.</span></p>
<p><span class="koboSpan" id="kobo.1163.1" xmlns="http://www.w3.org/1999/xhtml">All the neural </span><span id="dx1-193019"/><span class="koboSpan" id="kobo.1164.1" xmlns="http://www.w3.org/1999/xhtml">network classes that we have presented are subclasses of a </span><code><span class="koboSpan" id="kobo.1165.1" xmlns="http://www.w3.org/1999/xhtml">NeuralNetwork</span></code><span class="koboSpan" id="kobo.1166.1" xmlns="http://www.w3.org/1999/xhtml"> class. </span><span class="koboSpan" id="kobo.1166.2" xmlns="http://www.w3.org/1999/xhtml">For example, should you want to train a neural network as a classifier, you could rely on Qiskit’s </span><code><span class="koboSpan" id="kobo.1167.1" xmlns="http://www.w3.org/1999/xhtml">NeuralNetworkClassifier</span></code><span class="koboSpan" id="kobo.1168.1" xmlns="http://www.w3.org/1999/xhtml"> class. </span><span class="koboSpan" id="kobo.1168.2" xmlns="http://www.w3.org/1999/xhtml">This class can be initialized with a </span><code><span class="koboSpan" id="kobo.1169.1" xmlns="http://www.w3.org/1999/xhtml">NeuralNetwork</span></code><span class="koboSpan" id="kobo.1170.1" xmlns="http://www.w3.org/1999/xhtml"> object and specifying a loss function and an optimizer among other things.</span></p>
<p><span class="koboSpan" id="kobo.1171.1" xmlns="http://www.w3.org/1999/xhtml">In addition to this, there is a subclass of </span><code><span class="koboSpan" id="kobo.1172.1" xmlns="http://www.w3.org/1999/xhtml">NeuralNetworkClassifier</span></code><span class="koboSpan" id="kobo.1173.1" xmlns="http://www.w3.org/1999/xhtml"> that can be used to readily create a trainable neural network classifier directly, providing a feature map, a variational form, an optimizer, a loss, and so on.</span></p>
<p><span class="koboSpan" id="kobo.1174.1" xmlns="http://www.w3.org/1999/xhtml">This subclass is called </span><code><span class="koboSpan" id="kobo.1175.1" xmlns="http://www.w3.org/1999/xhtml">VQC</span></code><span class="koboSpan" id="kobo.1176.1" xmlns="http://www.w3.org/1999/xhtml"> (short for Variational Quantum Classifier) and it can also be imported from the Qiskit module </span><code><span class="koboSpan" id="kobo.1177.1" xmlns="http://www.w3.org/1999/xhtml">qiskit_machine_learning</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1178.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1179.1" xmlns="http://www.w3.org/1999/xhtml">algorithms</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1180.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1181.1" xmlns="http://www.w3.org/1999/xhtml">classifiers</span></code><span class="koboSpan" id="kobo.1182.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1183.1" xmlns="http://www.w3.org/1999/xhtml">If you wanted to create a neural network classifier object from our previous </span><code><span class="koboSpan" id="kobo.1184.1" xmlns="http://www.w3.org/1999/xhtml">qnn</span></code><span class="koboSpan" id="kobo.1185.1" xmlns="http://www.w3.org/1999/xhtml"> object using the default parameters provided by Qiskit, you could run the following instructions:</span></p>
<pre class="lstlisting" id="listing-259"><span class="koboSpan" id="kobo.1186.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.algorithms.classifiers import \ 
 
    NeuralNetworkClassifier 
 
 
 
classifier = NeuralNetworkClassifier(qnn)
</span></pre>
<p><span class="koboSpan" id="kobo.1187.1" xmlns="http://www.w3.org/1999/xhtml">By default, the classifier will use the squared error loss function and rely on the SLSQP optimizer </span><span class="cite"><span class="koboSpan" id="kobo.1188.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xkraft1988software"><span class="koboSpan" id="kobo.1189.1" xmlns="http://www.w3.org/1999/xhtml">62</span></a><span class="koboSpan" id="kobo.1190.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.1191.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1192.1" xmlns="http://www.w3.org/1999/xhtml">Then, if you had some training data </span><code><span class="koboSpan" id="kobo.1193.1" xmlns="http://www.w3.org/1999/xhtml">data_train</span></code><span class="koboSpan" id="kobo.1194.1" xmlns="http://www.w3.org/1999/xhtml"> with labels </span><code><span class="koboSpan" id="kobo.1195.1" xmlns="http://www.w3.org/1999/xhtml">labels_train</span></code><span class="koboSpan" id="kobo.1196.1" xmlns="http://www.w3.org/1999/xhtml">, you could train your newly-created classifier by calling the </span><code><span class="koboSpan" id="kobo.1197.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.1198.1" xmlns="http://www.w3.org/1999/xhtml"> method as follows:</span></p>
<pre class="lstlisting" id="listing-260"><span class="koboSpan" id="kobo.1199.1" xmlns="http://www.w3.org/1999/xhtml">

classifier.fit(data_train, labels_train)
</span></pre>
<p><span class="koboSpan" id="kobo.1200.1" xmlns="http://www.w3.org/1999/xhtml">If you then wanted to compute the outcomes of the trained classifier on some data </span><code><span class="koboSpan" id="kobo.1201.1" xmlns="http://www.w3.org/1999/xhtml">data_test</span></code><span class="koboSpan" id="kobo.1202.1" xmlns="http://www.w3.org/1999/xhtml">, you could use the </span><code><span class="koboSpan" id="kobo.1203.1" xmlns="http://www.w3.org/1999/xhtml">predict</span></code><span class="koboSpan" id="kobo.1204.1" xmlns="http://www.w3.org/1999/xhtml"> method like so:</span></p>
<pre class="lstlisting" id="listing-261"><span class="koboSpan" id="kobo.1205.1" xmlns="http://www.w3.org/1999/xhtml">

outcomes = classifier.predict(data_test)
</span></pre>
<p><span class="koboSpan" id="kobo.1206.1" xmlns="http://www.w3.org/1999/xhtml">Alternatively, if you wanted to compute the accuracy score of the trained model on some test dataset (</span><code><span class="koboSpan" id="kobo.1207.1" xmlns="http://www.w3.org/1999/xhtml">data_test</span></code><span class="koboSpan" id="kobo.1208.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1209.1" xmlns="http://www.w3.org/1999/xhtml">labels_test</span></code><span class="koboSpan" id="kobo.1210.1" xmlns="http://www.w3.org/1999/xhtml">), you could run the following instruction:</span></p>
<pre class="lstlisting" id="listing-262"><span class="koboSpan" id="kobo.1211.1" xmlns="http://www.w3.org/1999/xhtml">

acc = classifier.score(data_test, labels_test)
</span></pre>
<p><span class="koboSpan" id="kobo.1212.1" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, you shouldn’t care too </span><span id="dx1-193027"/><span class="koboSpan" id="kobo.1213.1" xmlns="http://www.w3.org/1999/xhtml">much about the </span><code><span class="koboSpan" id="kobo.1214.1" xmlns="http://www.w3.org/1999/xhtml">NeuralNetworkClassifier</span></code><span class="koboSpan" id="kobo.1215.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1216.1" xmlns="http://www.w3.org/1999/xhtml">VQC</span></code><span class="koboSpan" id="kobo.1217.1" xmlns="http://www.w3.org/1999/xhtml"> classes because, as it turns out, there is an alternative — and, in our opinion, better — way to train QNNs in Qiskit. </span><span class="koboSpan" id="kobo.1217.2" xmlns="http://www.w3.org/1999/xhtml">We will discuss it in the following chapter, and it will involve an interface with an existing machine learning framework, PyTorch. </span><span class="koboSpan" id="kobo.1217.3" xmlns="http://www.w3.org/1999/xhtml">What is more, being able to work with this interface will allow us to explore Qiskit’s ”Torch Runtime”: a Qiskit utility that will enable us to more efficiently train QNNs on IBM’s real quantum hardware. </span><span class="koboSpan" id="kobo.1217.4" xmlns="http://www.w3.org/1999/xhtml">This is the same technique that we used in </span><em><span class="koboSpan" id="kobo.1218.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <em/> <a href="ch013.xhtml#x1-940005"><em><span class="koboSpan" id="kobo.1219.1" xmlns="http://www.w3.org/1999/xhtml">5</span></em></a><em><span class="koboSpan" id="kobo.1220.1" xmlns="http://www.w3.org/1999/xhtml">, QAOA:</span></em> <em><span class="koboSpan" id="kobo.1221.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Approximate Optimization Algorithm</span></em><span class="koboSpan" id="kobo.1222.1" xmlns="http://www.w3.org/1999/xhtml">, to run QAOA executions on quantum hardware. </span><span class="koboSpan" id="kobo.1222.2" xmlns="http://www.w3.org/1999/xhtml">Exciting, isn’t it? </span><span class="koboSpan" id="kobo.1222.3" xmlns="http://www.w3.org/1999/xhtml">Bear with us until the end of the next chapter.</span></p>
</section>
<section class="level2 likesectionHead" data-number="18.4" id="summary-9">
<h1 class="likesectionHead" data-number="18.4"><span id="x1-19400010.3"><span class="koboSpan" id="kobo.1223.1" xmlns="http://www.w3.org/1999/xhtml">Summary</span></span></h1>
<p><span id="Q1-1-270"/></p>
<p><span class="koboSpan" id="kobo.1224.1" xmlns="http://www.w3.org/1999/xhtml">This has been a long journey, hasn’t it? </span><span class="koboSpan" id="kobo.1224.2" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we first introduced quantum neural networks as quantum analogs of classical neural networks. </span><span class="koboSpan" id="kobo.1224.3" xmlns="http://www.w3.org/1999/xhtml">We have seen how the training of a quantum neural network is very similar to that of a classical one, and we’ve also explored the differentiation methods that make this possible.</span></p>
<p><span class="koboSpan" id="kobo.1225.1" xmlns="http://www.w3.org/1999/xhtml">With the theory out of the way, we got our keyboards ready to do some work. </span><span class="koboSpan" id="kobo.1225.2" xmlns="http://www.w3.org/1999/xhtml">We learned how to implement and train a quantum neural network using PennyLane, and we also discussed some technicalities about this framework, such as details about the differentiation methods that it provides.</span></p>
<p><span class="koboSpan" id="kobo.1226.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane comes with some wonderful simulators, but — as we already mentioned in </span><em><span class="koboSpan" id="kobo.1227.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch009.xhtml#x1-400002"><em><span class="koboSpan" id="kobo.1228.1" xmlns="http://www.w3.org/1999/xhtml">2</span></em></a><em><span class="koboSpan" id="kobo.1229.1" xmlns="http://www.w3.org/1999/xhtml">, The Tools of the Trade in Quantum Computing</span></em><span class="koboSpan" id="kobo.1230.1" xmlns="http://www.w3.org/1999/xhtml"> — it’s also integrated with quantum hardware platforms such as Amazon Braket and IBM Quantum. </span><span class="koboSpan" id="kobo.1230.2" xmlns="http://www.w3.org/1999/xhtml">Thus, your ability to train quantum neural networks on actual quantum computers is at your fingertips!</span></p>
<p><span class="koboSpan" id="kobo.1231.1" xmlns="http://www.w3.org/1999/xhtml">We concluded the chapter with a short overview of how to work with quantum neural networks in Qiskit.</span></p>
<p><span class="koboSpan" id="kobo.1232.1" xmlns="http://www.w3.org/1999/xhtml">By now, you have a solid understanding of quantum neural networks. </span><span class="koboSpan" id="kobo.1232.2" xmlns="http://www.w3.org/1999/xhtml">Combined with your previous knowledge of quantum support vector machines, this gives you a fairly solid foundation in quantum machine learning. </span><span class="koboSpan" id="kobo.1232.3" xmlns="http://www.w3.org/1999/xhtml">In the following chapter — which will be very practically-oriented — we will explore more complex model architectures based on quantum neural networks.</span></p>
</section>
</section>
</body>
</html>
