- en: Part II. Module 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分。模块2
- en: '**Scala for Machine Learning**'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Scala机器学习**'
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Leverage Scala and Machine Learning to construct and study systems that can
    learn from data*'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*利用Scala和机器学习构建和研究可以从数据中学习系统的系统*'
- en: Chapter 1. Getting Started
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章。入门
- en: 'It is critical for any computer scientist to understand the different classes
    of machine learning algorithms and be able to select the ones that are relevant
    to the domain of their expertise and dataset. However, the application of these
    algorithms represents a small fraction of the overall effort needed to extract
    an accurate and performing model from input data. A common data mining workflow
    consists of the following sequential steps:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何计算机科学家来说，理解不同类别的机器学习算法并能够选择与其专业领域和数据集相关的算法至关重要。然而，这些算法的应用只是从输入数据中提取准确和性能良好的模型所需整体努力的一小部分。常见的数据挖掘工作流程包括以下顺序步骤：
- en: Defining the problem to solve.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要解决的问题。
- en: Loading the data.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据。
- en: Preprocessing, analyzing, and filtering the input data.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理、分析和过滤输入数据。
- en: Discovering patterns, affinities, clusters, and classes, if needed.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发现模式、亲和力、簇和类（如果需要）。
- en: Selecting the model features and appropriate machine learning algorithm(s).
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择模型特征和合适的机器学习算法（们）。
- en: Refining and validating the model.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精炼和验证模型。
- en: Improving the computational performance of the implementation.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提高实现的计算性能。
- en: In this book, each stage of the process is critical to build the *right* model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，过程的每个阶段对于构建 *正确* 的模型都是至关重要的。
- en: Tip
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'It is impossible to describe the key machine learning algorithms and their
    implementations in detail in a single book. The sheer quantity of information
    and Scala code would overwhelm even the most dedicated readers. Each chapter focuses
    on the mathematics and code that are absolutely essential to the understanding
    of the topic. Developers are encouraged to browse through the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在一本书中详细描述关键机器学习算法及其实现是不可能的。信息量和Scala代码的量甚至会让最热心的读者感到压倒。每一章都专注于理解该主题绝对必要的数学和代码。鼓励开发者浏览以下内容：
- en: The Scala coding convention and standard used in the book in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 书中使用的Scala编码约定和标准在[附录A](part0229.xhtml#aid-6QCGQ2 "附录A.基本概念")中，*基本概念*。
- en: API Scala docs
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API Scala文档
- en: A fully documented source code that is available online
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可在线获取的完整文档源代码
- en: This first chapter introduces you to the taxonomy of machine learning algorithms,
    the tools and frameworks used in the book, and a simple application of logistic
    regression to get your feet wet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这第一章向您介绍了机器学习算法的分类、本书中使用的工具和框架，以及一个简单的逻辑回归应用，让您入门。
- en: Mathematical notation for the curious
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数学符号的趣味
- en: 'Each chapter contains a small section dedicated to the formulation of the algorithms
    for those interested in the mathematical concepts behind the science and art of
    machine learning. These sections are optional and defined within a tip box. For
    example, the mathematical expression of the mean and the variance of a variable
    *X* mentioned in a tip box will be as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章都包含一个小节，专门针对对机器学习科学与艺术背后的数学概念感兴趣的人，阐述算法的公式。这些部分是可选的，并定义在提示框中。例如，提示框中提到的变量
    *X* 的均值和方差的数学表达式如下：
- en: Tip
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Convention and notation**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**约定和符号**'
- en: This book uses zero-based indexing of datasets in the mathematical formulas.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本书在数学公式中使用数据集的零基索引。
- en: 'M1: A set of *N* observations is denoted as *{xi} = x[0], x[1], … , x[N-1]*,
    and the arithmetic mean value for the random value with *xi* as values is defined
    as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: M1：一组 *N* 个观测值表示为 *{xi} = x[0], x[1], … , x[N-1]*，以 *xi* 为值的随机值的算术平均值定义为：
- en: '![Mathematical notation for the curious](img/image01236.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![数学符号的趣味](img/image01236.jpeg)'
- en: Why machine learning?
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么是机器学习？
- en: The explosion in the number of digital devices generates an ever-increasing
    amount of data. The best analogy I can find to describe the need, desire, and
    urgency to extract knowledge from large datasets is the process of extracting
    a precious metal from a mine, and in some cases, extracting blood from a stone.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数字设备的数量激增，产生了越来越多的数据。我能找到的最佳类比来描述从大型数据集中提取知识的需求、愿望和紧迫性，就是从矿山中提取贵金属的过程，在某些情况下，是从石头中提取血液。
- en: Knowledge is quite often defined as a model that can be constantly updated or
    tweaked as new data comes into play. Models are obviously domain-specific ranging
    from credit risk assessment, face recognition, maximization of quality of service,
    classification of pathological symptoms of disease, optimization of computer networks,
    and security intrusion detection, to customers' online behavior and purchase history.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 知识通常被定义为一种可以随着新数据的到来而不断更新或调整的模型。模型显然是特定领域的，从信用风险评估、人脸识别、服务质量最大化、疾病病理症状分类、计算机网络优化、安全入侵检测，到客户的在线行为和购买历史。
- en: Machine learning problems are categorized as classification, prediction, optimization,
    and regression.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题被分为分类、预测、优化和回归。
- en: Classification
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: The purpose of classification is to extract knowledge from historical data.
    For instance, a classifier can be built to identify a disease from a set of symptoms.
    The scientist collects information regarding the body temperature (continuous
    variable), congestion (discrete variables *HIGH*, *MEDIUM*, and *LOW*), and the
    actual diagnostic (flu). This dataset is used to create a model such as *IF temperature
    > 102 AND congestion = HIGH THEN patient has the flu (probability 0.72)*, which
    doctors can use in their diagnostic.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 分类的目的是从历史数据中提取知识。例如，可以构建一个分类器来从一组症状中识别疾病。科学家收集有关体温（连续变量）、拥堵（离散变量 *HIGH*、*MEDIUM*
    和 *LOW*）和实际诊断（流感）的信息。这个数据集用于创建一个模型，例如 *IF temperature > 102 AND congestion = HIGH
    THEN patient has the flu (probability 0.72)*，医生可以使用这个模型进行诊断。
- en: Prediction
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: Once the model is trained using historical observations and validated against
    historical observations, it can be used to predict some outcome. A doctor collects
    symptoms from a patient, such as body temperature and nasal congestion, and anticipates
    the state of his/her health.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型使用历史观察数据训练并经过历史观察数据验证后，它就可以用来预测某些结果。医生收集患者的症状，如体温和鼻塞，并预测其健康状况。
- en: Optimization
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: Some global optimization problems are intractable using traditional linear and
    non-linear optimization methods. Machine learning techniques improve the chances
    that the optimization method converges toward a solution (intelligent search).
    You can imagine that fighting the spread of a new virus requires optimizing a
    process that may evolve over time as more symptoms and cases are uncovered.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一些全局优化问题使用传统的线性和非线性优化方法难以解决。机器学习技术提高了优化方法收敛到解决方案（智能搜索）的机会。你可以想象，对抗新病毒的传播需要优化一个可能随着更多症状和病例的发现而演变的流程。
- en: Regression
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归
- en: Regression is a classification technique that is particularly suitable for a
    continuous model. Linear (least squares), polynomial, and logistic regressions
    are among the most commonly used techniques to fit a parametric model, or function,
    *y= f (x), x={x[i]}*, to a dataset. Regression is sometimes regarded as a specialized
    case of classification for which the output variables are continuous instead of
    categorical.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是一种特别适合连续模型的分类技术。线性（最小二乘法）、多项式和逻辑回归是最常用的技术之一，用于拟合参数模型或函数 *y= f (x), x={x[i]}*
    到数据集。回归有时被视为分类的特殊情况，其中输出变量是连续的而不是分类的。
- en: Why Scala?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择Scala？
- en: Like most functional languages, Scala provides developers and scientists with
    a toolbox to implement iterative computations that can be easily woven into a
    coherent dataflow. To some extent, Scala can be regarded as an extension of the
    popular MapReduce model for distributed computation of large amounts of data.
    Among the capabilities of the language, the following features are deemed essential
    in machine learning and statistical analysis.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数函数式语言一样，Scala为开发人员和科学家提供了一个工具箱，用于实现可以轻松编织成连贯数据流的迭代计算。在一定程度上，Scala可以被视为流行的MapReduce模型在分布式计算大量数据方面的扩展。在语言的功能中，以下特性被认为是机器学习和统计分析中的基本特性。
- en: Abstraction
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 抽象
- en: '**Functors** and **monads** are important concepts in functional programming.
    Monads are derived from the category and group theory that allow developers to
    create a high-level abstraction as illustrated in **Scalaz**, Twitter''s **Algebird**,
    or Google''s **Breeze Scala** libraries. More information about these libraries
    can be found at the following links:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**函子**和**单子**是函数式编程中的重要概念。单子是从范畴论和群论中派生出来的，允许开发者创建如 **Scalaz**、Twitter 的 **Algebird**
    或 Google 的 **Breeze Scala** 库中所示的高级抽象。更多关于这些库的信息可以在以下链接中找到：'
- en: '[https://github.com/scalaz](https://github.com/scalaz)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/scalaz](https://github.com/scalaz)'
- en: '[https://github.com/twitter/algebird](https://github.com/twitter/algebird)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/twitter/algebird](https://github.com/twitter/algebird)'
- en: '[https://github.com/dlwh/breeze](https://github.com/dlwh/breeze)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/dlwh/breeze](https://github.com/dlwh/breeze)'
- en: 'In mathematics, a category **M** is a structure that is defined by:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，一个范畴 **M** 是一个由以下定义的结构：
- en: 'Objects of some type: *{x* *ϵ* *X, y* *ϵ* *Y, z* *ϵ* *Z, …}*'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某些类型的对象：*{x* *ϵ* *X, y* *ϵ* *Y, z* *ϵ* *Z, …}*
- en: 'Morphisms or maps applied to these objects: *x* *ϵ* *X, y* *ϵ* *Y, f: x -›
    y*'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '应用到这些对象上的态射或映射：*x* *ϵ* *X, y* *ϵ* *Y, f: x -› y*'
- en: 'Composition of morphisms: *f: x -› y, g: y -› z => g o f: x -› z*'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '模态的复合：*f: x -› y, g: y -› z => g o f: x -› z*'
- en: '**Covariant**, **contravariant functors**, and **bifunctors** are well-understood
    concepts in algebraic topology that are related to manifold and vector bundles.
    They are commonly used in differential geometry and generation of non-linear models
    from data.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**协变函子**、**逆变函子**和**双函子**是代数拓扑中理解良好的概念，与流形和向量丛相关。它们在微分几何和非线性模型的数据生成中常用。'
- en: Higher-kind projection
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高阶投影
- en: Scientists define observations as sets or vectors of features. Classification
    problems rely on the estimation of the similarity between vectors of observations.
    One technique consists of comparing two vectors by computing the normalized inner
    product. A **co-vector** is defined as a linear map α of a vector to the inner
    product (field).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家将观测定义为特征集或向量。分类问题依赖于观测向量之间相似性的估计。一种技术是通过计算归一化内积来比较两个向量。**协变向量**被定义为将向量映射到内积（域）的线性映射
    α。
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Inner product**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**内积**'
- en: 'M1: The definition of a <.> inner product and a α co-vector is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: M1：内积和 α 协变向量的定义如下：
- en: '![Higher-kind projection](img/image01237.jpeg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![高阶投影](img/image01237.jpeg)'
- en: Let's define a vector as a constructor from any `_ => Vector[_]` field (or `Function1[_,
    Vector]`). A co-vector is then defined as the mapping function of a vector to
    its `Vector[_] => _` field (or `Function1[Vector, _]`).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个向量为一个从任何 `_ => Vector[_]` 域（或 `Function1[_, Vector]`）构造函数。协变向量随后被定义为将向量映射到其
    `Vector[_] => _` 域（或 `Function1[Vector, _]`）的映射函数。
- en: 'Let''s define a two-dimensional (two types or fields) higher kind structure,
    `Hom`, that can be defined as either a vector or co-vector by fixing one of the
    two types:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个二维（两种类型或域）的高阶结构 `Hom`，它可以被定义为向量或协变向量，通过固定两种类型之一：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Tensors and manifolds**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**张量和流形**'
- en: Vectors and co-vectors are classes of tensor (contravariant and covariant).
    Tensors (fields) are used in manifold learning of nonlinear models and in the
    generation of kernel functions. Manifolds are briefly introduced in the *Manifolds*
    section under *Dimension reduction* in [Chapter 4](part0178.xhtml#aid-59O442 "Chapter 4. Unsupervised
    Learning"), *Unsupervised Learning*. The topic of tensor fields and manifold learning
    is beyond the scope of this book.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 向量和协变向量是张量（逆变和协变）的类。张量（域）用于非线性模型的学习和核函数的生成。流形在 [第 4 章](part0178.xhtml#aid-59O442
    "第 4 章。无监督学习") 的 *降维* 部分的 *流形* 简要介绍，*无监督学习*。张量场和流形学习的话题超出了本书的范围。
- en: 'The projections of the higher kind, `Hom`, to the `Right` or `Left` single
    parameter types are known as functors, which are as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 高阶投影的投影，`Hom` 到 `Right` 或 `Left` 单参数类型被称为函子，如下所示：
- en: A covariant functor for the `right` projection
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个针对 `right` 投影的协变函子
- en: A contravariant functor for the `left` projection.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个针对 `left` 投影的逆变函子。
- en: Covariant functors for vectors
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量的协变函子
- en: 'A **covariant functor** of a variable is a map *F: C => C* such that:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '变量上的一个**协变函子**是一个映射 *F: C => C*，使得：'
- en: 'If *f: x -› y* is a morphism on *C*, then *F(x) -› F(y)* is also a morphism
    on *C*'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *f: x -› y* 是 *C* 上的态射，那么 *F(x) -› F(y)* 也是 *C* 上的态射'
- en: 'If *id: x -› x* is the identity morphism on *C*, then *F(id)* is also an identity
    morphism on *C*'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *id: x -› x* 是 *C* 上的恒等态射，那么 *F(id)* 也是 *C* 上的恒等态射'
- en: 'If *g: y -› z* is also a morphism on *C*, then *F(g o f) = F(g) o F(f)*'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *g: y -› z* 也是 *C* 上的一个形态，那么 *F(g o f) = F(g) o F(f)*'
- en: 'The definition of the `F[U => V] := F[U] => F[V]`covariant functor in Scala
    is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Scala中`F[U => V] := F[U] => F[V]`协变函子的定义如下：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For example, let''s consider an observation defined as a `n` dimension vector
    of a `T` type, `Obs[T]`. The constructor for the observation can be represented
    as `Function1[T,Obs]`. Its `ObsFunctor` functor is implemented as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们考虑一个定义为`T`类型的`n`维向量的观察，`Obs[T]`。观察的构造函数可以表示为`Function1[T,Obs]`。它的`ObsFunctor`函子实现如下：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The functor is qualified as a **covariant functor** because the morphism is
    applied to the return type of the element of `Obs` as `Function1[T, Obs]`. The
    `Hom` projection of the two parameters types to a vector is implemented as `(Hom[T])#Left`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于形态应用于`Obs`元素的返回类型`Function1[T, Obs]`，该函子被指定为**协变函子**。两个参数类型的`Hom`投影实现为`(Hom[T])#Left`。
- en: Contravariant functors for co-vectors
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逆变函子用于协变向量
- en: 'A contravariant functor of one variable is a map *F: C => C* such that:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '一个一变量的逆变函子是一个映射 *F: C => C*，使得：'
- en: 'If *f: x -› y* is a morphism on *C*, then *F(y) -> F(x)* is also a morphism
    on *C*'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *f: x -› y* 是 *C* 上的一个形态，那么 *F(y) -> F(x)* 也是 *C* 上的一个形态'
- en: 'If *id: x -› x* is the identity morphism on *C*, then *F(id)* is also an identity
    morphism on *C*'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *id: x -› x* 是 *C* 上的恒等形态，那么 *F(id)* 也是 *C* 上的恒等形态'
- en: 'If *g: y -› z* is also a morphism on *C*, then *F(g o f) = F(f) o F(g)*'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果 *g: y -› z* 也是 *C* 上的一个形态，那么 *F(g o f) = F(f) o F(g)*'
- en: 'The definition of the `F[U => V] := F[V] => F[U]` contravariant functor in
    Scala is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Scala中`F[U => V] := F[V] => F[U]`逆变函子的定义如下：
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note that the input and output types in the `f` morphism are reversed from
    the definition of a covariant functor. The constructor for the co-vector can be
    represented as `Function1[Obs,T]`. Its `CoObsFunctor` functor is implemented as
    follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在`f`形态中的输入和输出类型与协变函子的定义相反。协变向量的构造函数可以表示为`Function1[Obs,T]`。它的`CoObsFunctor`函子实现如下：
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Monads
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Monads
- en: Monads are structures in algebraic topology that are related to the category
    theory. Monads extend the concept of a functor to allow a composition known as
    the **monadic composition** of morphisms on a single type. They enable the chaining
    or weaving of computation into a sequence of steps or pipeline. The collections
    bundled with the Scala standard library (`List`, `Map`, and so on) are constructed
    as monads [1:1].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Monads是代数拓扑中的结构，与范畴论相关。Monads扩展了函子的概念，允许在单个类型上执行称为**单子组合**的形态组合。它们使计算能够链式或编织成一系列步骤或管道。Scala标准库中捆绑的集合（`List`、`Map`等）被构建为Monads
    [1:1]。
- en: 'Monads provide the ability for those collections to perform the following functions:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Monads提供了以下功能的能力：
- en: Create the collection
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建集合
- en: Transform the elements of the collection
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换集合的元素
- en: Flatten nested collections
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展平嵌套集合
- en: 'An example is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个例子：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Monads are therefore critical in machine learning as they enable you to compose
    multiple data transformation functions into a sequence or workflow. This property
    is applicable to any type of complex scientific computation [1:2].
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在机器学习中，Monads至关重要，因为它们允许你将多个数据转换函数组合成一个序列或工作流程。这种属性适用于任何类型的复杂科学计算 [1:2]。
- en: Note
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The monadic composition of kernel functions**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**核函数的单子组合**'
- en: Monads are used in the composition of kernel functions in the *Kernel monadic
    composition section under Kernel functions* section in [Chapter 8](part0200.xhtml#aid-5UNGG2
    "Chapter 8. Kernel Models and Support Vector Machines"), *Kernel Models and Support
    Vector Machines*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](part0200.xhtml#aid-5UNGG2 "第8章。核模型和支持向量机")的“核函数”部分的“核单调组合”部分中，Monads用于核函数的组合，*核模型和支持向量机*。
- en: Scalability
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可伸缩性
- en: As seen previously, functors and monads enable parallelization and chaining
    of data processing functions by leveraging the Scala higher-order methods. In
    terms of implementation, **actors** are one of the core elements that make Scala
    scalable. Actors provide Scala developers with a high level of abstraction to
    build scalable, distributed, and concurrent applications. Actors hide the nitty-gritty
    implementation details of concurrency and the management of the underlying threads
    pool. Actors communicate through asynchronous immutable messages. A distributed
    computing Scala framework such as **Akka** or **Apache Spark** extends the capabilities
    of the Scala standard library to support computation on very large datasets. Akka
    and Apache Spark are described in detail in the last chapter of this book [1:3].
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，通过利用 Scala 的高阶方法，functors 和 monads 可以实现数据处理函数的并行化和链式操作。在实现方面，**演员**是使 Scala
    可扩展的核心元素之一。演员为 Scala 开发者提供了构建可扩展、分布式和并发应用程序的高级抽象。演员隐藏了并发和底层线程池管理的繁琐实现细节。演员通过异步不可变消息进行通信。例如
    **Akka** 或 **Apache Spark** 这样的分布式计算 Scala 框架扩展了 Scala 标准库的功能，以支持在非常大的数据集上进行计算。Akka
    和 Apache Spark 在本书的最后一章中进行了详细描述 [1:3]。
- en: In a nutshell, a workflow is implemented as a sequence of activities or computational
    tasks. These tasks consist of high-order Scala methods such as `flatMap`, `map`,
    `fold`, `reduce`, `collect`, `join`, or `filter` that are applied to a large collection
    of observations. Scala provides developers with the tools to partition datasets
    and execute the tasks through a cluster of actors. Scala also supports message
    dispatching and routing between local and remote actors. A developer can decide
    to deploy a workflow either locally or across multiple CPU cores and servers with
    very few code alterations.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，工作流被实现为一串活动或计算任务。这些任务包括 `flatMap`、`map`、`fold`、`reduce`、`collect`、`join`
    或 `filter` 等高阶 Scala 方法，它们应用于大量观测数据。Scala 为开发者提供了将数据集分区并通过演员集群执行任务的工具。Scala 还支持在本地和远程演员之间进行消息调度和路由。开发者可以决定以很少的代码更改将工作流部署在本地或多个
    CPU 核心和服务器上。
- en: '![Scalability](img/image01238.jpeg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![可扩展性](img/image01238.jpeg)'
- en: Deployment of a workflow for model training as a distributed computation
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型训练工作流作为分布式计算进行部署
- en: In the preceding diagram, a controller, that is, the master node, manages the
    sequence of tasks **1** to **4** similar to a scheduler. These tasks are actually
    executed over multiple worker nodes, which are implemented by actors. The master
    node or actor exchanges messages with the workers to manage the state of the execution
    of the workflow as well as its reliability, as illustrated in the *Scalability
    with Actors* section in [Chapter 12](part0223.xhtml#aid-6KLDE1 "Chapter 12. Scalable
    Frameworks"), *Scalable Frameworks*. High availability of these tasks is implemented
    through a hierarchy of supervising actors.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，一个控制器，即主节点，管理着任务**1**到**4**的顺序，类似于调度器。这些任务实际上是在多个工作节点上执行的，这些节点由演员实现。主节点或演员与工作者交换消息以管理工作流程执行的状
    态以及其可靠性，如[第12章](part0223.xhtml#aid-6KLDE1 "第12章。可扩展框架")的*使用演员的可扩展性*部分所示，*可扩展框架*。通过监督演员的层次结构实现了这些任务的高可用性。
- en: Configurability
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可配置性
- en: Scala supports **dependency injection** using a combination of abstract variables,
    self-referenced composition, and stackable traits. One of the most commonly used
    dependency injection patterns, the **cake pattern**, is described in the *Composing
    mixins to build a workflow* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 支持使用抽象变量、自引用组合和可堆叠特质组合来**依赖注入**。最常用的依赖注入模式之一，即**蛋糕模式**，在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")的*组合混入构建工作流*部分进行了描述，*Hello World!*
- en: Maintainability
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可维护性
- en: Scala embeds **Domain Specific Languages** (**DSL**) natively. DSLs are syntactic
    layers built on top of Scala native libraries. DSLs allow software developers
    to abstract computation in terms that are easily understood by scientists. The
    most notorious application of DSLs is the definition of the emulation of the syntax
    used in the MATLAB program, which data scientists are familiar with.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 本地嵌入**领域特定语言**（**DSL**）。DSL 是建立在 Scala 本地库之上的语法层。DSL 允许软件开发者用科学家容易理解的方式来抽象计算。最著名的
    DSL 应用是定义 MATLAB 程序中使用的语法的仿真，这是数据科学家所熟悉的。
- en: Computation on demand
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按需计算
- en: '**Lazy** methods and values allow developers to execute functions and allocate
    computing resources on demand. The Spark framework relies on lazy variables and
    methods to chain **Resilient Distributed Datasets** (**RDD**).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**懒惰**的方法和价值观允许开发者根据需要执行函数和分配计算资源。Spark框架依赖于懒惰变量和方法来链式处理**弹性分布式数据集**（**RDD**）。'
- en: Model categorization
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型分类
- en: A model can be predictive, descriptive, or adaptive.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型可以是预测性的、描述性的或自适应的。
- en: '**Predictive** models discover patterns in historical data and extract fundamental
    trends and relationships between factors (or features). They are used to predict
    and classify future events or observations. Predictive analytics is used in a
    variety of fields, including marketing, insurance, and pharmaceuticals. Predictive
    models are created through supervised learning using a preselected training set.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测性**模型在历史数据中发现模式，并提取因素（或特征）之间的基本趋势和关系。它们用于预测和分类未来的事件或观察。预测分析在包括市场营销、保险和制药在内的各种领域中使用。预测模型通过使用预选的训练集进行监督学习来创建。'
- en: '**Descriptive** models attempt to find unusual patterns or affinities in data
    by grouping observations into clusters with similar properties. These models define
    the first and important step in knowledge discovery. They are generated through
    unsupervised learning.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述性**模型试图通过将观察结果分组到具有相似属性的聚类中，在数据中找到异常模式或亲和力。这些模型定义了知识发现的第一步和重要步骤。它们通过无监督学习生成。'
- en: A third category of models, known as **adaptive modeling**, is created through
    **reinforcement learning**. Reinforcement learning consists of one or several
    decision-making agents that recommend and possibly execute actions in the attempt
    of solving a problem, optimizing an objective function, or resolving constraints.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第三类模型，称为**自适应建模**，是通过**强化学习**创建的。强化学习包括一个或多个决策代理，它们在尝试解决问题、优化目标函数或解决约束条件的过程中推荐并可能执行动作。
- en: Taxonomy of machine learning algorithms
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法分类法
- en: The purpose of machine learning is to teach computers to execute tasks without
    human intervention. An increasing number of applications such as genomics, social
    networking, advertising, or risk analysis generate a very large amount of data
    that can be analyzed or mined to extract knowledge or insight into a process,
    customer, or organization. Ultimately, machine learning algorithms consist of
    identifying and validating models to optimize a performance criterion using historical,
    present, and future data [1:4].
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目的是教会计算机在没有人类干预的情况下执行任务。越来越多的应用，如基因组学、社交网络、广告或风险评估，产生了大量可以分析或挖掘以提取知识或洞察过程、客户或组织的数据。最终，机器学习算法包括通过使用历史、现在和未来的数据来识别和验证模型，以优化性能标准[1:4]。
- en: Data mining is the process of extracting or identifying patterns in a dataset.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘是从数据集中提取或识别模式的过程。
- en: Unsupervised learning
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: 'The goal of **unsupervised learning** is to discover patterns of regularities
    and irregularities in a set of observations. The process is known as density estimation
    in statistics is broken down into two categories: discovery of data clusters and
    discovery of latent factors. The methodology consists of processing input data
    to understand patterns similar to the natural learning process in infants or animals.
    Unsupervised learning does not require labeled data (or expected values), and
    therefore, it is easy to implement and execute because no expertise is needed
    to validate an output. However, it is possible to label the output of a clustering
    algorithm and use it for future classification.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**的目标是在一组观察中发现规律性和不规则性的模式。这个过程在统计学中被称为密度估计，可以分为两大类：数据聚类发现和潜在因素发现。该方法包括处理输入数据以理解与婴儿或动物自然学习过程相似的规律。无监督学习不需要标记数据（或预期值），因此易于实现和执行，因为不需要专业知识来验证输出。然而，可以对聚类算法的输出进行标记，并将其用于未来的分类。'
- en: Clustering
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类
- en: 'The purpose of **data clustering** is to partition a collection of data into
    a number of clusters or data segments. Practically, a clustering algorithm is
    used to organize observations into clusters by minimizing the distance between
    observations within a cluster and maximizing the distance between observations
    across clusters. A clustering algorithm consists of the following steps:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据聚类**的目的是将一组数据划分为若干个簇或数据段。实际上，聚类算法通过最小化簇内观测值之间的距离和最大化簇间观测值之间的距离来组织观测值到簇中。聚类算法包括以下步骤：'
- en: Creating a model by making an assumption on the input data.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过对输入数据做出假设来创建模型。
- en: Selecting the objective function or goal of the clustering.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择聚类的目标函数或目标。
- en: Evaluating one or more algorithms to optimize the objective function.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估一个或多个算法以优化目标函数。
- en: Data clustering is also known as **data segmentation** or **data partitioning**.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 数据聚类也称为**数据分段**或**数据划分**。
- en: Dimension reduction
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维度缩减
- en: '**Dimension reduction** techniques aim at finding the smallest but most relevant
    set of features needed to build a reliable model. There are many reasons for reducing
    the number of features or parameters in a model, from avoiding overfitting to
    reducing computation costs.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**维度缩减**技术旨在找到构建可靠模型所需的最小但最相关的特征集。在模型中减少特征或参数的数量有很多原因，从避免过拟合到降低计算成本。'
- en: 'There are many ways to classify the different techniques used to extract knowledge
    from data using unsupervised learning. The following taxonomy breaks down these
    techniques according to their purpose, although the list is far from being exhaustive,
    as shown in the following diagram:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用无监督学习从数据中提取知识的不同技术有很多种分类方法。以下分类法根据其目的对这些技术进行了细分，尽管这个列表远非详尽，如下面的图所示：
- en: '![Dimension reduction](img/image01239.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![维度缩减](img/image01239.jpeg)'
- en: Taxonomy of unsupervised learning algorithms
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习算法分类法
- en: Supervised learning
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'The best analogy for supervised learning is **function approximation** or **curve
    fitting**. In its simplest form, supervised learning attempts to find a relation
    or function *f: x → y* using a training set *{x, y}*. Supervised learning is far
    more accurate than any other learning strategy as long as the input (labeled data)
    is available and reliable. The downside is that a domain expert may be required
    to label (or tag) data as a training set.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '监督学习的最佳类比是**函数逼近**或**曲线拟合**。在其最简单形式中，监督学习试图使用训练集 *{x, y}* 找到一个关系或函数 *f: x →
    y*。只要输入（标记数据）可用且可靠，监督学习比任何其他学习策略都要准确。缺点是可能需要一个领域专家来标记（或标记）数据作为训练集。'
- en: 'Supervised machine learning algorithms can be broken into two categories:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习算法可以分为两大类：
- en: Generative models
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型
- en: Discriminative models
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别模型
- en: Generative models
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成模型
- en: 'In order to simplify the description of a statistics formula, we adopt the
    following simplification: the probability of an *X* event is the same as the probability
    of the discrete *X* random variable to have a value *x*: *p(X) = p(X=x)*.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化统计公式的描述，我们采用以下简化：事件 *X* 的概率与离散随机变量 *X* 取值 *x* 的概率相同：*p(X) = p(X=x)*。
- en: The notation for the joint probability is *p(X,Y) = p(X=x,Y=y)*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 联合概率的表示为 *p(X,Y) = p(X=x,Y=y)*。
- en: The notation for the conditional probability is *p(X|Y) = p(X=x|Y=y)*.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率的表示为 *p(X|Y) = p(X=x|Y=y)*。
- en: Generative models attempt to fit a joint probability distribution, *p(X,Y)*,
    of two *X* and *Y* events (or random variables), representing two sets of observed
    and hidden *x* and *y* variables. Discriminative models compute the conditional
    probability, *p(Y|X)*, of an event or random variable *Y* of hidden variables
    *y*, given an event or random variable *X* of observed variables *x*. Generative
    models are commonly introduced through the Bayes' rule. The conditional probability
    of a *Y* event, given an *X* event, is computed as the product of the conditional
    probability of the *X* event, given the *Y* event, and the probability of the
    *X* event normalized by the probability of the *Y* event [1:5].
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型试图拟合两个 *X* 和 *Y* 事件（或随机变量）的联合概率分布，*p(X,Y)*，代表两组观察到的和隐藏的 *x* 和 *y* 变量。判别模型计算隐藏变量
    *y* 的一个事件或随机变量 *Y* 的条件概率，*p(Y|X)*，给定观察变量 *x* 的一个事件或随机变量 *X*。生成模型通常通过贝叶斯定理引入。给定
    *X* 事件的 *Y* 事件的条件概率是通过 *X* 事件在 *Y* 事件给定的条件概率与 *X* 事件概率通过 *Y* 事件概率归一化的乘积来计算的 [1:5]。
- en: Note
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Bayes'' rule**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**贝叶斯定理**'
- en: 'Joint probability for independent random variables, *X=x* and *Y=y*, is given
    by:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 独立随机变量 *X=x* 和 *Y=y* 的联合概率如下：
- en: '![Generative models](img/image01240.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![生成模型](img/image01240.jpeg)'
- en: 'Conditional probability of a random variable, *Y = y*, given *X = x*, is given
    by:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量 *Y = y* 在给定 *X = x* 的条件概率如下：
- en: '![Generative models](img/image01241.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![生成模型](img/image01241.jpeg)'
- en: 'Bayes'' formula is given by:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯公式如下：
- en: '![Generative models](img/image01242.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![生成模型](img/image01242.jpeg)'
- en: The Bayes' rule is the foundation of the Naïve Bayes classifier, as described
    in the *Introducing the multinomial Naïve Bayes* section in [Chapter 5](part0182.xhtml#aid-5DI6C1
    "Chapter 5. Naïve Bayes Classifiers"), *Naïve Bayes Classifiers*.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是朴素贝叶斯分类器的基础，如第5章中“介绍多项式朴素贝叶斯”部分所述，*朴素贝叶斯分类器*。
- en: Discriminative models
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 判别模型
- en: Contrary to generative models, discriminative models compute the conditional
    probability *p(Y|X)* directly, using the same algorithm for training and classification.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与生成模型相反，判别模型直接计算条件概率 *p(Y|X)*，使用相同的算法进行训练和分类。
- en: 'Generative and discriminative models have their respective advantages and disadvantages.
    Novice data scientists learn to match the appropriate algorithm to each problem
    through experimentation. Here is a brief guideline describing which type of models
    make sense according to the objective or criteria of the project:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型和判别模型各有其优势和劣势。新手数据科学家通过实验学习将适当的算法匹配到每个问题。以下是一个简要的指南，描述了根据项目的目标或标准，哪种类型的模型是有意义的：
- en: '| Objective | Generative models | Discriminative models |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 目标 | 生成模型 | 判别模型 |'
- en: '| --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Accuracy | Highly dependent on the training set. | This depends on the training
    set and algorithm configuration (that is, kernel functions) |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 准确性 | 高度依赖于训练集。 | 这取决于训练集和算法配置（即核函数） |'
- en: '| Modeling requirements | There is a need to model both observed and hidden
    variables, which requires a significant amount of training. | The quality of the
    training set does not have to be as rigorous as for generative models. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 建模需求 | 需要建模观察到的和隐藏的变量，这需要大量的训练。 | 训练集的质量不必像生成模型那样严格。 |'
- en: '| Computation cost | This is usually low. For example, any graphical method
    derived from the Bayes'' rule has low overhead. | Most algorithms rely on optimization
    of a convex function with significant performance overhead. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 计算成本 | 这通常很低。例如，任何从贝叶斯定理导出的图形方法都有很低的开销。 | 大多数算法依赖于优化具有显著性能开销的凸函数。 |'
- en: '| Constraints | These models assume some degree of independence among the model
    features. | Most discriminative algorithms accommodate dependencies between features.
    |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 约束 | 这些模型假设模型特征之间存在某种程度的独立性。 | 大多数判别算法可以适应特征之间的依赖关系。 |'
- en: 'We can further refine the taxonomy of supervised learning algorithms by segregating
    arbitrarily between sequential and random variables for generative models and
    breaking down discriminative methods as applied to continuous processes (regression)
    and discrete processes (classification):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将生成模型的顺序和随机变量任意分离，并将判别方法分解为应用于连续过程（回归）和离散过程（分类）来进一步细化监督学习算法的分类：
- en: '![Discriminative models](img/image01243.jpeg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![判别模型](img/image01243.jpeg)'
- en: Taxonomy of supervised learning algorithms
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习算法的分类
- en: Semi-supervised learning
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Semi-supervised learning is used to build models from a dataset with incomplete
    labels. Manifold learning and information geometry algorithms are commonly applied
    to large datasets that are partially labeled. The description of semi-supervised
    learning techniques is beyond the scope of this book.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习用于从带有不完整标签的数据集构建模型。流形学习和信息几何算法通常应用于部分标记的大数据集。半监督学习技术的描述超出了本书的范围。
- en: Reinforcement learning
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is not as well understood as supervised and unsupervised
    learning outside the realms of robotics or game strategy. However, since the 90s,
    genetic-algorithms-based classifiers have become increasingly popular to solve
    problems that require collaboration with a domain expert. For some types of applications,
    reinforcement learning algorithms output a set of recommended actions for the
    adaptive system to execute. In its simplest form, these algorithms estimate the
    best course of action. Most complex systems based on reinforcement learning establish
    and update policies that can be vetoed by an expert, if necessary. The foremost
    challenge developers of reinforcement learning systems face is that the recommended
    action or policy may depend on partially observable states.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习在机器人或游戏策略领域之外，不如监督学习和无监督学习那样被充分理解。然而，自90年代以来，基于遗传算法的分类器在解决需要与领域专家协作的问题上变得越来越受欢迎。对于某些类型的应用，强化学习算法输出一系列推荐的动作供自适应系统执行。在最简单的形式中，这些算法估计最佳的行动方案。大多数基于强化学习的复杂系统都会建立和更新政策，如果需要，专家可以否决。强化学习系统的开发者面临的最主要挑战是，推荐的动作或政策可能取决于部分可观察的状态。
- en: Genetic algorithms are not usually considered part of the reinforcement learning
    toolbox. However, advanced models, such as learning classifier systems, use genetic
    algorithms to classify and reward the most performing rules and policies.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法通常不被认为是强化学习工具箱的一部分。然而，一些高级模型，如学习分类系统，使用遗传算法来分类和奖励表现最佳规则和政策。
- en: 'As with the two previous learning strategies, reinforcement learning models
    can be categorized as Markovian or evolutionary:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 与前两种学习策略一样，强化学习模型可以分为马尔可夫或进化模型：
- en: '![Reinforcement learning](img/image01244.jpeg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![强化学习](img/image01244.jpeg)'
- en: Taxonomy of reinforcement learning algorithms
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习算法的分类
- en: This is a brief overview of machine learning algorithms with a suggested, approximate
    taxonomy. There are almost as many ways to introduce machine learning as there
    are data and computer scientists. We encourage you to browse through the list
    of references at the end of the book to find the documentation appropriate to
    your level of interest and understanding.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对机器学习算法的简要概述，提供了一个建议的、近似的分类法。介绍机器学习的方法几乎和数据和计算机科学家一样多。我们鼓励您浏览本书末尾的参考文献列表，以找到适合您兴趣和理解水平的文档。
- en: Don't reinvent the wheel!
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不要重新发明轮子！
- en: 'There are numerous robust, accurate, and efficient Java libraries for mathematics,
    linear algebra, or optimization that have been widely used for many years:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多稳健、准确和高效的Java库用于数学、线性代数或优化，这些库多年来被广泛使用：
- en: JBlas/Linpack ([https://github.com/mikiobraun/jblas](https://github.com/mikiobraun/jblas))
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JBlas/Linpack ([https://github.com/mikiobraun/jblas](https://github.com/mikiobraun/jblas))
- en: Parallel Colt ([https://github.com/rwl/ParallelColt](https://github.com/rwl/ParallelColt))
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parallel Colt ([https://github.com/rwl/ParallelColt](https://github.com/rwl/ParallelColt))
- en: Apache Commons Math ([http://commons.apache.org/proper/commons-math](http://commons.apache.org/proper/commons-math))
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Commons Math ([http://commons.apache.org/proper/commons-math](http://commons.apache.org/proper/commons-math))
- en: There is absolutely no need to rewrite, debug, and test these components in
    Scala. Developers should consider creating a wrapper or interface to his/her favorite
    and reliable Java library. The book leverages the Apache Commons Math library
    for some specific linear algebra algorithms.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 完全没有必要在Scala中重新编写、调试和测试这些组件。开发者应考虑创建一个包装器或接口，以便使用他们最喜欢的和可靠的Java库。本书利用Apache
    Commons Math库来处理一些特定的线性代数算法。
- en: Tools and frameworks
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具和框架
- en: Before getting your hands dirty, you need to download and deploy a minimum set
    of tools and libraries; there is no need to reinvent the wheel after all. A few
    key components have to be installed in order to compile and run the source code
    described throughout the book. We focus on open source and commonly available
    libraries, although you are invited to experiment with equivalent tools of your
    choice. The learning curve for the frameworks described here is minimal.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在动手实践之前，您需要下载和部署一组最小化的工具和库；毕竟，没有必要重新发明轮子。为了编译和运行本书中描述的源代码，必须安装一些关键组件。我们专注于开源和常见库，尽管您被邀请尝试您选择的等效工具。这里描述的框架的学习曲线非常平缓。
- en: Java
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java
- en: The code described in this book has been tested with JDK 1.7.0_45 and JDK 1.8.0_25
    on Windows x64 and Mac OS X x64\. You need to install the Java Development Kit
    if you have not already done so. Finally, the `JAVA_HOME`, `PATH`, and `CLASSPATH`
    environment variables have to be updated accordingly.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本书描述的代码已在Windows x64和Mac OS X x64上使用JDK 1.7.0_45和JDK 1.8.0_25进行了测试。如果您尚未安装，则需要安装Java开发工具包。最后，必须相应地更新`JAVA_HOME`、`PATH`和`CLASSPATH`环境变量。
- en: Scala
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scala
- en: The code has been tested with Scala 2.10.4 and 2.11.4\. We recommend that you
    use Scala Version 2.10.4 or higher with SBT 0.13 or higher. Let's assume that
    Scala runtime (REPL) and libraries have been properly installed and the `SCALA_HOME`
    and `PATH` environment variables have been updated.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 代码已在Scala 2.10.4和2.11.4上进行了测试。我们建议您使用Scala版本2.10.4或更高版本与SBT 0.13或更高版本一起使用。假设Scala运行时（REPL）和库已经正确安装，并且`SCALA_HOME`和`PATH`环境变量已经更新。
- en: The description and installation instructions of the S**cala plugin for Eclipse**
    (version 4.0 or higher) are available at [http://scala-ide.org/docs/user/gettingstarted.html](http://scala-ide.org/docs/user/gettingstarted.html).
    You can also download the **Scala plugin for IntelliJ IDEA** (version 13 or higher)
    from the JetBrains website at [http://confluence.jetbrains.com/display/SCA/](http://confluence.jetbrains.com/display/SCA/).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[Eclipse的Scala插件](https://scala-ide.org/docs/user/gettingstarted.html)（版本4.0或更高）的描述和安装说明可在[http://scala-ide.org/docs/user/gettingstarted.html](http://scala-ide.org/docs/user/gettingstarted.html)找到。您还可以从JetBrains网站下载[**IntelliJ
    IDEA的Scala插件**](http://confluence.jetbrains.com/display/SCA/)（版本13或更高）。'
- en: The ubiquitous **Simple Build Tool** (**SBT**) will be our primary building
    engine. The syntax of the build file, `sbt/build.sbt`, conforms to the Version
    0.13 and is used to compile and assemble the source code presented throughout
    the book. Sbt can be downloaded as part of Typesafe activator or directly from
    [http://www.scala-sbt.org/download.html](http://www.scala-sbt.org/download.html).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 无处不在的**简单构建工具**（**SBT**）将是我们的主要构建引擎。构建文件`sbt/build.sbt`的语法符合版本0.13，并用于编译和组装本书中展示的源代码。SBT可以作为Typesafe
    activator的一部分下载，或者直接从[http://www.scala-sbt.org/download.html](http://www.scala-sbt.org/download.html)下载。
- en: Apache Commons Math
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Commons Math
- en: Apache Commons Math is a Java library used for numerical processing, algebra,
    statistics, and optimization [1:6].
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Commons Math是一个用于数值处理、代数、统计学和优化的Java库[1:6]。
- en: Description
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述
- en: This is a lightweight library that provides developers with a foundation of
    small, ready-to-use Java classes that can be easily weaved into a machine learning
    problem. The examples used throughout the book require Version 3.5 or higher.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个轻量级库，为开发者提供了一组小型、现成的Java类，这些类可以轻松地编织到机器学习问题中。本书中使用的示例需要版本3.5或更高。
- en: 'The math library supports the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 数学库支持以下内容：
- en: Functions, differentiation, and integral and ordinary differential equations
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数、微分和积分及常微分方程
- en: Statistics distributions
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计分布
- en: Linear and nonlinear optimization
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性和非线性优化
- en: Dense and sparse vectors and matrices
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稠密和稀疏向量和矩阵
- en: Curve fitting, correlation, and regression
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曲线拟合、相关性分析和回归
- en: For more information, visit [http://commons.apache.org/proper/commons-math](http://commons.apache.org/proper/commons-math).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，请访问[http://commons.apache.org/proper/commons-math](http://commons.apache.org/proper/commons-math)。
- en: Licensing
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 许可证
- en: We need Apache Public License 2.0; the terms are available at [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要Apache公共许可证2.0；条款可在[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)找到。
- en: Installation
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装
- en: 'The installation and deployment of the Apache Commons Math library are quite
    simple. The steps are as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Commons Math库的安装和部署相当简单。步骤如下：
- en: Go to the download page at [http://commons.apache.org/proper/commons-math/download_math.cgi](http://commons.apache.org/proper/commons-math/download_math.cgi).
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请访问[下载页面](http://commons.apache.org/proper/commons-math/download_math.cgi)。
- en: Download the latest `.jar` files to the binary section, `commons-math3-3.5-bin.zip`
    (for instance, for Version 3.5).
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最新的`.jar`文件下载到二进制部分，例如`commons-math3-3.5-bin.zip`（针对3.5版本）。
- en: Unzip and install the `.jar` file.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压并安装`.jar`文件。
- en: 'Add `commons-math3-3.5.jar` to the classpath as follows:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下步骤将`commons-math3-3.5.jar`添加到类路径中：
- en: '**For Mac OS X**: `export CLASSPATH=$CLASSPATH:/Commons_Math_path/commons-math3-3.5.jar`'
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于Mac OS X**：`export CLASSPATH=$CLASSPATH:/Commons_Math_path/commons-math3-3.5.jar`'
- en: '**For Windows**: Go to system **Properties** | **Advanced system settings**
    | **Advanced** | **Environment Variables**, then edit the `CLASSPATH` variable'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于Windows系统**：转到系统**属性** | **高级系统设置** | **高级** | **环境变量**，然后编辑`CLASSPATH`变量'
- en: Add the `commons-math3-3.5.jar` file to your IDE environment if needed (that
    is, for Eclipse, go to **Project** | **Properties** | **Java Build Path** | **Libraries**
    | **Add External JARs** and for IntelliJ IDEA, go to **File** | **Project Structure**
    | **Project Settings** | **Libraries**).
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有必要，将`commons-math3-3.5.jar`文件添加到您的IDE环境（例如，对于Eclipse，请转到**项目** | **属性** |
    **Java构建路径** | **库** | **添加外部JARs**，对于IntelliJ IDEA，请转到**文件** | **项目结构** | **项目设置**
    | **库**）。
- en: You can also download `commons-math3-3.5-src.zip` from the **Source** section.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以从**源**部分下载`commons-math3-3.5-src.zip`。
- en: JFreeChart
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JFreeChart
- en: JFreeChart is an open source chart and plotting Java library, widely used in
    the Java programmer community. It was originally created by David Gilbert [1:7].
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: JFreeChart是一个开源的图表和绘图Java库，在Java程序员社区中广泛使用。它最初由David Gilbert [1:7]创建。
- en: Description
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述
- en: The library supports a variety of configurable plots and charts (scatter, dial,
    pie, area, bar, box and whisker, stacked, and 3D). We use JFreeChart to display
    the output of data processing and algorithms throughout the book, but you are
    encouraged to explore this great library on your own, as time permits.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 该库支持多种可配置的图表和图形（散点图、仪表盘、饼图、面积图、条形图、箱线图、堆叠图和3D图）。我们使用JFreeChart在整本书中显示数据处理和算法的输出，但鼓励您在时间允许的情况下自行探索这个优秀的库。
- en: Licensing
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 许可证
- en: It is distributed under the terms of the GNU **Lesser General Public License**
    (**LGPL**), which permits its use in proprietary applications.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 它根据GNU **较小通用公共许可证**（**LGPL**）的条款分发，允许其在专有应用程序中使用。
- en: Installation
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装
- en: 'To install and deploy JFreeChart, perform the following steps:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装和部署JFreeChart，请执行以下步骤：
- en: Visit [http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/).
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)。
- en: Download the latest version from Source Forge at [http://sourceforge.net/projects/jfreechart/files](http://sourceforge.net/projects/jfreechart/files).
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Source Forge下载最新版本[http://sourceforge.net/projects/jfreechart/files](http://sourceforge.net/projects/jfreechart/files)。
- en: Unzip and deploy the `.jar` file.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解压并部署`.jar`文件。
- en: 'Add `jfreechart-1.0.17.jar` (for Version 1.0.17) to the classpath as follows:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下步骤将`jfreechart-1.0.17.jar`（针对1.0.17版本）添加到类路径中：
- en: '**For Mac OS X**: `export CLASSPATH=$CLASSPATH:/JFreeChart_path/jfreechart-1.0.17.jar`'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于Mac OS X**：`export CLASSPATH=$CLASSPATH:/JFreeChart_path/jfreechart-1.0.17.jar`'
- en: '**For Windows**: Go to system **Properties** | **Advanced system settings**
    | **Advanced** | **Environment Variables**, then edit the `CLASSPATH` variable'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于Windows系统**：转到系统**属性** | **高级系统设置** | **高级** | **环境变量**，然后编辑`CLASSPATH`变量'
- en: Add the `jfreechart-1.0.17.jar` file to your IDE environment, if needed
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有必要，将`jfreechart-1.0.17.jar`文件添加到您的IDE环境
- en: Other libraries and frameworks
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他库和框架
- en: Libraries and tools that are specific to a single chapter are introduced along
    with the topic. Scalable frameworks are presented in the last chapter along with
    the instructions to download them. Libraries related to the conditional random
    fields and support vector machines are described in their respective chapters.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 每章特有的库和工具将与主题一起介绍。可扩展的框架在最后一章中介绍，并附有下载说明。与条件随机字段和支持向量机相关的库在各自的章节中描述。
- en: Note
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Why not use the Scala algebra and numerical libraries?**'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么不使用Scala代数和数值库呢？**'
- en: Libraries such as Breeze, ScalaNLP, and Algebird are interesting Scala frameworks
    for linear algebra, numerical analysis, and machine learning. They provide even
    the most seasoned Scala programmer with a high-quality layer of abstraction. However,
    this book is designed as a tutorial that allows developers to write algorithms
    from the ground up using existing or legacy Java libraries [1:8].
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如 Breeze、ScalaNLP 和 Algebird 等库是线性代数、数值分析和机器学习的有趣 Scala 框架。它们为经验丰富的 Scala 程序员提供了高质量的抽象层。然而，本书设计为一个教程，允许开发者使用现有的或遗留的
    Java 库从头开始编写算法 [1:8]。
- en: Source code
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码
- en: The Scala programming language is used to implement and evaluate the machine
    learning techniques covered in *Scala for Machine Learning*. However, the source
    code snippets are reduced to the strict minimum essential to the understanding
    of machine learning algorithms discussed throughout the book. The formal implementation
    of these algorithms is available on the website of Packt Publishing ([http://www.packtpub.com](http://www.packtpub.com)).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用 Scala 编程语言来实现和评估《Scala for Machine Learning》中涵盖的机器学习技术。然而，源代码片段被缩减到理解书中讨论的机器学习算法所必需的最小范围。这些算法的正式实现可以在
    Packt Publishing 的网站上找到（[http://www.packtpub.com](http://www.packtpub.com)）。
- en: Tip
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Downloading the example code**'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载示例代码**'
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您在 [http://www.packtpub.com](http://www.packtpub.com) 的账户中下载您购买的所有 Packt
    书籍的示例代码文件。如果您在其他地方购买了这本书，您可以访问 [http://www.packtpub.com/support](http://www.packtpub.com/support)
    并注册，以便将文件直接通过电子邮件发送给您。
- en: Context versus view bounds
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文与视图边界
- en: 'Most Scala classes discussed in the book are parameterized with the type associated
    with the discrete/categorical value (`Int`) or continuous value (`Double`). Context
    bounds would require that any type used by the client code has `Int` or `Double`
    as upper bounds:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 书中讨论的大多数 Scala 类都是使用与离散/分类值（`Int`）或连续值（`Double`）关联的类型参数化的。上下文边界要求客户端代码中使用的任何类型都必须有
    `Int` 或 `Double` 作为上界：
- en: '[PRE6]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Such a design introduces constraints on the client to inherit from simple types
    and to deal with covariance and contravariance for container types [1:9].
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的设计对客户端施加了从简单类型继承并处理容器类型的协变和逆协变的约束 [1:9]。
- en: 'For this book, **view bounds** are used instead of context bounds because they
    only require an implicit conversion to the parameterized type to be defined:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书，**视图边界**被用于代替上下文边界，因为它们只需要定义参数化类型的隐式转换：
- en: '[PRE7]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**View bound deprecation**'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**视图边界弃用**'
- en: 'The notation for the view bound, `T <% Double`, is being deprecated in Scala
    2.11 and higher. The `class A[T <% Float]` declaration is the short notation for
    `class A[T](implicit f: T => Float)`.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '视图边界的表示法 `T <% Double` 在 Scala 2.11 及更高版本中被弃用。`class A[T <% Float]` 声明是 `class
    A[T](implicit f: T => Float)` 的简写形式。'
- en: Presentation
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 展示
- en: 'For the sake of readability of the implementation of algorithms, all nonessential
    code such as error checking, comments, exceptions, or imports are omitted. The
    following code elements are omitted in the code snippet presented in the book:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高算法实现的可读性，所有非必需代码，如错误检查、注释、异常或导入都被省略。书中展示的代码片段中省略了以下代码元素：
- en: 'Code documentation:'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码文档：
- en: '[PRE8]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Validation of class parameters and method arguments:'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类参数和方法参数的验证：
- en: '[PRE9]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Class qualifiers and scope declaration:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类限定符和作用域声明：
- en: '[PRE10]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Method qualifiers:'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法限定符：
- en: '[PRE11]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Exceptions:'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常：
- en: '[PRE12]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Logging and debugging code:'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志和调试代码：
- en: '[PRE13]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Nonessential annotation:'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非必需注解：
- en: '[PRE14]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Nonessential methods
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非必需方法
- en: The complete list of Scala code elements omitted in the code snippets in this
    book can be found in the *Code snippets format* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 本书代码片段中省略的 Scala 代码元素完整列表可以在 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")
    的 *代码片段格式* 部分找到，*基本概念*。
- en: Primitives and implicits
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始类型和隐式转换
- en: The algorithms presented in this book share the same primitive types, generic
    operators, and implicit conversions.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 本书所展示的算法共享相同的原始类型、泛型操作符和隐式转换。
- en: Primitive types
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 原始类型
- en: 'For the sake of readability of the code, the following primitive types will
    be used:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高代码的可读性，以下原始类型将被使用：
- en: '[PRE15]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The times series introduced in the *Time series in Scala* section in [Chapter
    3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"), *Data Preprocessing*,
    is implemented as `XSeries[T]` or `XVSeries[T]` of a parameterized `T` type.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](part0172.xhtml#aid-5410O2 "第3章 数据预处理")“Scala中的时间序列”部分介绍的时间序列作为参数化类型`T`的`XSeries[T]`或`XVSeries[T]`实现。
- en: Note
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Make a note of these six types; they are used throughout the book.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这六种类型；它们在本书中都有使用。
- en: Type conversions
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 类型转换
- en: 'Implicit conversion is an important feature of the Scala programming language.
    It allows developers to specify a type conversion for an entire library in a single
    place. Here are a few of the implicit type conversions that are used throughout
    the book:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式转换是Scala编程语言的一个重要特性。它允许开发者在单个位置为整个库指定类型转换。以下是本书中使用的几个隐式类型转换：
- en: '[PRE16]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Library-specific conversion**'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '**库特定转换**'
- en: The conversion between the primitive type listed here and types introduced in
    a particular library (such as, the Apache Commons Math library) are described
    in the relevant chapters.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出的原始类型与特定库（如Apache Commons Math库）中引入的类型之间的转换在相关章节中描述。
- en: Immutability
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可变性
- en: It is usually a good idea to reduce the number of states of an object. A method
    invocation transitions an object from one state to another. The larger the number
    of methods or states, the more cumbersome the testing process becomes.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，减少对象的状态数量是一个好主意。方法调用将对象从一个状态转换到另一个状态。方法或状态的数量越多，测试过程就越繁琐。
- en: 'There is no point in creating a model that is not defined (trained). Therefore,
    making the training of a model as part of the constructor of the class it implements
    makes a lot of sense. Therefore, the only public methods of a machine learning
    algorithm are as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 创建未定义（训练）的模型是没有意义的。因此，将模型的训练作为其实现的类的构造函数的一部分是非常有意义的。因此，机器学习算法的唯一公共方法如下：
- en: Classification or prediction
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类或预测
- en: Validation
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证
- en: Retrieval of model parameters (weights, latent variables, hidden states, and
    so on), if needed
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，检索模型参数（权重、潜在变量、隐藏状态等）
- en: Performance of Scala iterators
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scala迭代器的性能
- en: The evaluation of the performance of Scala high-order iterative methods is beyond
    the scope of this book. However, it is important to be aware of the trade-off
    of each method.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Scala高阶迭代方法性能的评估超出了本书的范围。然而，了解每种方法的权衡是很重要的。
- en: The `for` construct is to be avoided as a counting iterator. It is designed
    to implement the for-comprehensive monad (`map` and `flatMap`). The source code
    presented in this book uses the high-order `foreach` method instead.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`构造不应作为计数迭代器使用。它旨在实现for-comprehensive monad（`map`和`flatMap`）。本书中展示的源代码使用高阶`foreach`方法。'
- en: Let's kick the tires
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让我们试试水
- en: This final section introduces the key elements of the training and classification
    workflow. A test case using a simple logistic regression is used to illustrate
    each step of the computational workflow.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 本节最后介绍了训练和分类工作流程的关键元素。使用简单的逻辑回归作为测试案例来展示计算工作流程的每一步。
- en: An overview of computational workflows
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算工作流程概述
- en: 'In its simplest form, a computational workflow to perform runtime processing
    of a dataset is composed of the following stages:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，执行数据集运行时处理的计算工作流程由以下阶段组成：
- en: Loading the dataset from files, databases, or any streaming devices.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件、数据库或任何流式设备中加载数据集。
- en: Splitting the dataset for parallel data processing.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分割以进行并行数据处理。
- en: Preprocessing data using filtering techniques, analysis of variance, and applying
    penalty and normalization functions whenever necessary.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用过滤技术、方差分析和在必要时应用惩罚及归一化函数进行数据预处理。
- en: Applying the model—either a set of clusters or classes—to classify new data.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用模型——无论是聚类集还是类别集——以对新数据进行分类。
- en: Assessing the quality of the model.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型的品质。
- en: 'A similar sequence of tasks is used to extract a model from a training dataset:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似的任务序列从训练数据集中提取模型：
- en: Loading the dataset from files, databases, or any streaming devices.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件、数据库或任何流式设备中加载数据集。
- en: Splitting the dataset for parallel data processing.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分割以进行并行数据处理。
- en: Applying filtering techniques, analysis of variance, and penalty and normalization
    functions to the raw dataset whenever necessary.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在必要时，将过滤技术、方差分析和惩罚及归一化函数应用于原始数据集。
- en: Selecting the training, testing, and validation set from the cleansed input
    data.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从清洗后的输入数据中选择训练集、测试集和验证集。
- en: Extracting key features and establishing affinity between a similar group of
    observations using clustering techniques or supervised learning algorithms.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用聚类技术或监督学习算法提取关键特征，并在一组相似观测之间建立亲和力。
- en: Reducing the number of features to a manageable set of attributes to avoid overfitting
    the training set.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征数量减少到可管理的属性集，以避免过度拟合训练集。
- en: Validating the model and tuning the model by iterating steps 5, 6, and 7 until
    the error meets a predefined convergence criteria.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过迭代步骤5、6和7直到错误满足预定义的收敛标准来验证模型并调整模型。
- en: Storing the model in a file or database so that it can be applied to future
    observations.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型存储在文件或数据库中，以便可以应用于未来的观测。
- en: 'Data clustering and data classification can be performed independent of each
    other or as part of a workflow that uses clustering techniques at the preprocessing
    stage of the training phase of a supervised learning algorithm. Data clustering
    does not require a model to be extracted from a training set, while classification
    can be performed only if a model has been built from the training set. The following
    image gives an overview of training, classification, and validation:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 数据聚类和数据分类可以独立进行，或者作为使用聚类技术在监督学习算法训练阶段预处理阶段的工作流程的一部分进行。数据聚类不需要从训练集中提取模型，而分类只能在从训练集构建了模型后才能执行。以下图像给出了训练、分类和验证的概述：
- en: '![An overview of computational workflows](img/image01245.jpeg)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![计算工作流程概述](img/image01245.jpeg)'
- en: A generic data flow for training and running a model
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和运行模型的通用数据流
- en: The preceding diagram is an overview of a typical data mining processing pipeline.
    The first phase consists of extracting the model through clustering or training
    of a supervised learning algorithm. The model is then validated against test data
    for which the source is the same as the training set but with different observations.
    Once the model is created and validated, it can be used to classify real-time
    data or predict future behavior. Real-world workflows are more complex and require
    dynamic configuration to allow experimentation of different models. Several alternative
    classifiers can be used to perform a regression and different filtering algorithms
    are applied against input data, depending on the latent noise in the raw data.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表是典型数据挖掘处理流程的概述。第一阶段包括通过聚类或监督学习算法的训练提取模型。然后，该模型与测试数据进行验证，其来源与训练集相同，但观测不同。一旦模型创建并验证，就可以用于分类实时数据或预测未来行为。现实世界的工作流程更为复杂，需要动态配置以允许不同模型的实验。可以使用几种不同的分类器来执行回归，并根据原始数据中的潜在噪声应用不同的过滤算法。
- en: Writing a simple workflow
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写一个简单的工作流程
- en: This book relies on financial data to experiment with different learning strategies.
    The objective of the exercise is to build a model that can discriminate between
    volatile and nonvolatile trading sessions for stock or commodities. For the first
    example, we select a simplified version of the binomial logistic regression as
    our classifier as we treat stock-price-volume action as a continuous or pseudo-continuous
    process.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 本书依赖于金融数据来实验不同的学习策略。练习的目标是构建一个模型，能够区分股票或商品的波动和非波动交易时段。对于第一个例子，我们选择简化版的二项式逻辑回归作为我们的分类器，因为我们把股价-成交量行为视为连续或准连续过程。
- en: Note
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**An introduction to the logistic regression**'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归简介**'
- en: Logistic regression is explained in depth in the *Logistic regression* section
    in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization*. The model treated in this example is the simple
    binomial logistic regression classifier for two-dimension observations.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归在[第6章](part0188.xhtml#aid-5J99O2 "第6章。回归和正则化")的*逻辑回归*部分进行了深入解释，*回归和正则化*。本例中处理的是针对二维观测的简单二项式逻辑回归分类器。
- en: 'The steps for classification of trading sessions according to their volatility
    and volume is as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 根据交易时段的波动性和成交量对交易时段进行分类的步骤如下：
- en: Scoping the problem
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定问题范围
- en: Loading data
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据
- en: Preprocessing raw data
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理原始数据
- en: Discovering patterns, whenever possible
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在可能的情况下发现模式
- en: Implementing the classifier
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现分类器
- en: Evaluating the model
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Step 1 – scoping the problem
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1步 – 确定问题范围
- en: 'The objective is to create a model for stock price using its daily trading
    volume and volatility. Throughout the book, we will rely on financial data to
    evaluate and discuss the merits of different data processing and machine learning
    methods. In this example, the data is extracted from **Yahoo Finances** using
    the CSV format with the following fields:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是创建一个使用其每日交易量和波动性的股票价格模型。在整本书中，我们将依靠财务数据来评估和讨论不同数据处理和机器学习方法的优点。在这个例子中，数据使用CSV格式从**Yahoo
    Finances**中提取，以下字段：
- en: Date
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期
- en: Price at open
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开盘价
- en: Highest price in the session
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话中的最高价
- en: Lowest price in the session
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话中的最低价
- en: Price at session close
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话结束时的价格
- en: Volume
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成交量
- en: Adjust price at session close
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在会话结束时调整价格
- en: 'The `YahooFinancials` enumerator extracts the historical daily trading information
    from the Yahoo finance site:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '`YahooFinancials` 枚举器从雅虎财经网站提取历史每日交易信息：'
- en: '[PRE17]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `toDouble` method converts an array of string into a single value (line
    `1`) and `toDblArray` converts an array of string into an array of values (line
    `2`). The `YahooFinancials` enumerator is described in the *Data sources* section
    in [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts* in detail.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '`toDouble` 方法将字符串数组转换为单个值（行`1`），而`toDblArray`将字符串数组转换为值数组（行`2`）。`YahooFinancials`
    枚举器在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")的*数据来源*部分以及*基本概念*中详细描述。'
- en: Let's create a simple program that loads the content of the file, executes some
    simple preprocessing functions, and creates a simple model. We selected the CSCO
    stock price between January 1, 2012 and December 1, 2013 as our data input.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个简单的程序，该程序加载文件内容，执行一些简单的预处理函数，并创建一个简单的模型。我们选择了2012年1月1日至2013年12月1日之间的CSCO股票价格作为我们的数据输入。
- en: 'Let''s consider the two variables, *price* and *volume*, as shown in the following
    screenshot. The top graph displays the variation of the price of Cisco stock over
    time and the bottom bar chart represents the daily trading volume on Cisco stock
    over time:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下截图中的两个变量，*价格*和*成交量*。顶部图表显示了思科股票价格随时间的变化，底部柱状图表示思科股票随时间的每日交易量：
- en: '![Step 1 – scoping the problem](img/image01246.jpeg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 1 – 确定问题范围](img/image01246.jpeg)'
- en: Price-Volume action for Cisco stock 2012-2013
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 2012-2013年思科股票的价格-成交量动作
- en: Step 2 – loading data
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 2 – 加载数据
- en: 'The second step is loading the dataset from a local or remote data storage.
    Typically, large datasets are loaded from a database or distributed filesystems
    such as **Hadoop Distributed File System** (**HDFS**). The `load` method takes
    an absolute pathname, `extract`, and transforms the input data from a file into
    a time series of a `Vector[DblPair]` type:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是从本地或远程数据存储加载数据集。通常，大型数据集是从数据库或如**Hadoop分布式文件系统**（**HDFS**）这样的分布式文件系统中加载的。`load`
    方法接受绝对路径名，`extract`，并将输入数据从文件转换为`Vector[DblPair]`类型的时间序列：
- en: '[PRE18]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The data file is extracted through an invocation of the `Source.fromFile` static
    method (line `3`), and then the fields are extracted through a map before the
    header (first row in the file) is removed using `drop` (line `4`). The file has
    to be closed to avoid leaking of the file handle (line `5`).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件通过调用`Source.fromFile`静态方法（行`3`）提取，然后在移除标题（文件中的第一行）之前通过`drop`提取字段。必须关闭文件以避免文件句柄泄漏（行`5`）。
- en: Note
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Data extraction**'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据提取**'
- en: The `Source.fromFile.getLines.map` invocation pipeline method returns an iterator
    that can be traversed only once.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`Source.fromFile.getLines.map` 调用管道方法返回一个只能遍历一次的迭代器。'
- en: 'The purpose of the `extract` method is to generate a time series of two variables
    (*relative stock volatility* and *relative stock daily trading volume*):'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '`extract` 方法的目的是生成两个变量（*相对股票波动性*和*相对股票每日交易量*）的时间序列：'
- en: '[PRE19]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The only purpose of the `extract` method is to convert the raw textual data
    into a two-dimensional time series. The first step consists of selecting the three
    features to extract `LOW` (the lowest stock price in the session), `HIGH` (the
    highest price in the session), and `VOLUME` (trading volume for the session) (line
    `6`). This feature set is used to convert each line of fields into a corresponding
    set of three values (line `7`). Finally, the feature set is reduced to the following
    two variables (line `8`):'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`extract` 方法的唯一目的是将原始文本数据转换为二维时间序列。第一步包括选择要提取的三个特征 `LOW`（会话中的最低股价）、`HIGH`（会话中的最高价）和
    `VOLUME`（会话的交易量）（行 `6`）。这个特征集用于将字段行转换为相应的三个值集（行 `7`）。最后，特征集被缩减为以下两个变量（行 `8`）：'
- en: 'Relative volatility of the stock price in a session: *1.0 – LOW/HIGH*'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话中股价的相对波动：*1.0 – LOW/HIGH*
- en: 'Trading volume for the stock in the session: *VOLUME*'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话中该股票的交易量：*VOLUME*
- en: Note
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Code readability**'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码可读性**'
- en: 'A long pipeline of Scala high-order methods make the code and underlying code
    quite difficult to read. It is recommended that you break down long chains of
    method calls, such as the following:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列长的 Scala 高阶方法使得代码及其底层代码难以阅读。建议您分解长链式的方法调用，例如以下内容：
- en: '[PRE20]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can break down method calls into several steps as follows:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将方法调用分解为以下几个步骤：
- en: '[PRE21]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We strongly encourage you to consult the excellent guide *Effective Scala,*
    written by Marius Eriksen from Twitter. This is definitively a must read for any
    Scala developer [1:10].
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强烈建议您查阅由 Twitter 的 Marius Eriksen 编写的优秀指南 *Effective Scala*。这绝对是对任何 Scala
    开发者必读的[1:10]。
- en: Step 3 – preprocessing the data
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步 - 数据预处理
- en: The next step is to normalize the data in the range *[0.0, 1.0]* to be trained
    by the binomial logistic regression. It is time to introduce an immutable and
    flexible normalization class.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将数据归一化到*[0.0, 1.0]*范围，以便由二项式逻辑回归进行训练。是时候引入一个不可变且灵活的归一化类了。
- en: Immutable normalization
  id: totrans-353
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不可变归一化
- en: The logistic regression relies on the sigmoid curve or logistic function is
    described in the *Logistic function* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*.
    The logistic functions are used to segregate training data into classes. The output
    value of the logistic function ranges from 0 for *x = - INFINITY* to 1 for *x
    = + INFINITY*. Therefore, it makes sense to normalize the input data or observation
    over [0, 1].
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归依赖于 sigmoid 曲线或逻辑函数，这在[第 6 章](part0188.xhtml#aid-5J99O2 "第 6 章。回归和正则化")的*逻辑函数*部分有描述，*回归和正则化*。逻辑函数用于将训练数据分类。逻辑函数的输出值范围从
    *x = - INFINITY* 的 0 到 *x = + INFINITY* 的 1。因此，对输入数据或观测进行[0, 1]归一化是有意义的。
- en: Note
  id: totrans-355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Normalize or not normalize?**'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化还是不归一化？**'
- en: The purpose of normalizing data is to impose a single range of values for all
    the features, so the model does not favor any particular feature. Normalization
    techniques include linear normalization and Z-score. Normalization is an expensive
    operation that is not always needed.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 数据归一化的目的是为所有特征施加一个单一的范围，这样模型就不会偏袒任何特定的特征。归一化技术包括线性归一化和 Z 分数。归一化是一个昂贵的操作，并不总是需要的。
- en: The normalization is a linear transformation of the raw data that can be generalized
    to any range *[l, h]*.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化是原始数据的线性变换，可以推广到任何范围 *[l, h]*。
- en: Note
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Linear normalization**'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性归一化**'
- en: 'M2: [0, 1] Normalization of features *{x[i]}* with minimum *x[min]* and maximum
    *x[max]* values:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 'M2: [0, 1] 归一化特征 *{x[i]}* 的最小值 *x[min]* 和最大值 *x[max]*:'
- en: '![Immutable normalization](img/image01247.jpeg)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![不可变归一化](img/image01247.jpeg)'
- en: 'M3: [l, h] Normalization of features *{xi}*:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 'M3: [l, h] 归一化特征 *{xi}*:'
- en: '![Immutable normalization](img/image01248.jpeg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![不可变归一化](img/image01248.jpeg)'
- en: 'The normalization of input data in supervised learning has a specific requirement:
    the classification and prediction of new observations have to use the normalization
    parameters (*min* and *max*) extracted from the training set, so all the observations
    share the same scaling factor.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习中输入数据的归一化有特定的要求：对新观测的分类和预测必须使用从训练集中提取的归一化参数（*min* 和 *max*），因此所有观测共享相同的缩放因子。
- en: 'Let''s define the `MinMax` normalization class. The class is immutable: the
    minimum, `min`, and maximum, `max`, values are computed within the constructor.
    The class takes a time series of a parameterized `T` type and values as arguments
    (line `8`). The steps of the normalization process are defined as follows:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义`MinMax`归一化类。该类是不可变的：最小值`min`和最大值`max`在构造函数中计算。该类接受参数化类型`T`的时间序列和值作为参数（第8行）。归一化过程的步骤定义如下：
- en: Initialize the minimum values for a given time series during instantiation (line
    `9`).
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实例化时初始化给定时间序列的最小值（第9行）。
- en: Compute the normalization parameters (line `10`) and normalize the input data
    (line `11`).
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算归一化参数（第10行）并归一化输入数据（第11行）。
- en: 'Normalize any new data points reusing the normalization parameters (line `14`):'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新使用归一化参数归一化任何新的数据点（第14行）：
- en: '[PRE22]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The class constructor computes the tuple of minimum and maximum values, `minMax`,
    using a fold (line `9`). The `scaleFactors` scaling parameters are computed during
    the normalization of the time series (line `11`), which are described as follows.
    The `normalize` method initializes the scaling factor parameters (line `12`) before
    normalizing the input data (line `13`):'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 类构造函数使用折叠（第9行）计算最小值和最大值的元组`minMax`。`scaleFactors`缩放参数在时间序列归一化期间计算（第11行），具体描述如下。`normalize`方法在归一化输入数据之前初始化缩放因子参数（第12行）：
- en: '[PRE23]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Subsequent observations use the same scaling factors extracted from the input
    time series in `normalize` (line `14`):'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 后续观察使用从`normalize`中提取的相同缩放因子（第14行）：
- en: '[PRE24]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `MinMax` class normalizes single variable observations.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '`MinMax`类对单变量观测值进行归一化。'
- en: Note
  id: totrans-376
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The statistics class**'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '**统计学类**'
- en: The class that extracts the basic statistics from a `Stats` dataset, which is
    introduced in the *Profiling data* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*, inherits the `MinMax` class.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 从*数据概览*部分介绍的`Stats`数据集中提取基本统计信息的类，在[第2章](part0165.xhtml#aid-4TBCQ2 "第2章。Hello
    World!")的*Hello World!*中继承自`MinMax`类。
- en: 'The test case with the binomial logistic regression uses a multiple variable
    normalization, implemented by the `MinMaxVector` class, which takes observations
    of the `XVSeries[Double]` type as inputs:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多项式逻辑回归的测试用例通过`MinMaxVector`类实现了多变量归一化，该类将`XVSeries[Double]`类型的观测值作为输入：
- en: '[PRE25]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The constructor of the `MinMaxVector` class transposes the vector of array of
    observations in order to compute the minimum and maximum value for each dimension
    (line `15`).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '`MinMaxVector`类的构造函数将观测值的数组向量转置，以便计算每个维度的最小值和最大值（第15行）。'
- en: Step 4 – discovering patterns
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 发现模式
- en: The price action chart has a very interesting characteristic.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 价格行为图表有一个非常有趣的特性。
- en: Analyzing data
  id: totrans-384
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分析数据
- en: At a closer look, a sudden change in price and increase in volume occurs about
    every three months or so. Experienced investors will undoubtedly recognize that
    these price-volume patterns are related to the release of quarterly earnings of
    Cisco. Such a regular but unpredictable pattern can be a source of concern or
    opportunity if risk can be properly managed. The strong reaction of the stock
    price to the release of corporate earnings may scare some long-term investors
    while enticing day traders.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察，价格突然变动和交易量增加大约每三个月发生一次。经验丰富的投资者无疑会认识到这些价格-交易量模式与思科公司季度收益的发布有关。这种规律但不可预测的模式，如果风险得到适当管理，可能成为担忧或机会的来源。股票价格对公司收益发布的强烈反应可能会吓到一些长期投资者，同时吸引日交易者。
- en: 'The following graph visualizes the potential correlation between sudden price
    change (volatility) and heavy trading volume:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表展示了突然的价格变动（波动性）和大量交易量之间的潜在相关性：
- en: '![Analyzing data](img/image01249.jpeg)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![分析数据](img/image01249.jpeg)'
- en: Price-volume correlation for the Cisco stock 2012-2013
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 思科股票2012-2013年的价格-交易量相关性
- en: The next section is not required for the understanding of the test case. It
    illustrates the capabilities of JFreeChart as a simple visualization and plotting
    library.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节对于理解测试用例不是必需的。它展示了JFreeChart作为一个简单的可视化和绘图库的能力。
- en: Plotting data
  id: totrans-390
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据绘图
- en: Although charting is not the primary goal of this book, we thought that you
    will benefit from a brief introduction to JFreeChart.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然图表绘制不是本书的主要目标，但我们认为您将受益于对JFreeChart的简要介绍。
- en: Note
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Plotting classes**'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**绘图类**'
- en: This section illustrates a simple Scala interface to JFreeChart Java classes.
    Reading this is not required for the understanding of machine learning. The visualization
    of the results of a computation is beyond the scope of this book.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了JFreeChart Java类的一个简单Scala接口。阅读本节内容对于理解机器学习不是必需的。计算结果的可视化超出了本书的范围。
- en: Some of the classes used in visualization are described in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在可视化中使用的某些类在[附录A](part0229.xhtml#aid-6QCGQ2 "附录A.基本概念")中进行了描述，*基本概念*。
- en: 'The dataset (volatility and volume) is converted into internal JFreeChart data
    structures. The `ScatterPlot` class implements a simple configurable scatter plot
    with the following arguments:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集（波动性和成交量）转换为JFreeChart内部数据结构。`ScatterPlot`类实现了一个简单的可配置散点图，具有以下参数：
- en: '`config`: This includes information, labels, fonts, and so on, of the plot'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`：这包括图表的信息、标签、字体等。'
- en: '`theme`: This is the predefined theme for the plot (black, white background,
    and so on)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`theme`：这是图表的预定义主题（黑色、白色背景等）。'
- en: 'The code will be as follows:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE26]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `PlotTheme` class defines a specific theme or preconfiguration of the chart
    (line **16**). The class offers a set of `display` methods to accommodate a wide
    range of data structures and configuration (line `17`).
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '`PlotTheme`类定义了图表的特定主题或预配置（第16行）。该类提供了一套`display`方法，以适应广泛的数据结构和配置（第17行）。'
- en: Note
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Visualization**'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '**可视化**'
- en: The JFreeChart library is introduced as a robust charting tool. The code related
    to plots and charts is omitted from the book in order to keep the code snippets
    concise and dedicated to machine learning. On a few occasions, output data is
    formatted as a CSV file to be imported into a spreadsheet.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: JFreeChart库被介绍为一个健壮的图表工具。为了使代码片段简洁并专注于机器学习，本书省略了与绘图和图表相关的代码。在少数情况下，输出数据格式化为CSV文件，以便导入电子表格。
- en: 'The `ScatterPlot.display` method is used to display the normalized input data
    used in the binomial logistic regression as follows:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '`ScatterPlot.display`方法用于显示在二项式逻辑回归中使用的标准化输入数据，如下所示：'
- en: '[PRE27]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![Plotting data](img/image01250.jpeg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![绘制数据](img/image01250.jpeg)'
- en: A scatter plot of volatility and volume for the Cisco stock 2012-2013
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 2012-2013年思科股票的波动性和成交量散点图
- en: The scatter plot shows a level of correlation between session volume and session
    volatility and confirms the initial finding in the stock price and volume chart.
    We can leverage this information to classify trading sessions by their volatility
    and volume. The next step is to create a two class model by loading a training
    set, observations, and expected values, into our logistic regression algorithm.
    The classes are delimited by a **decision boundary** (also known as a hyperplane)
    drawn on the scatter plot.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图显示了时段交易量和时段波动性之间的相关性水平，并证实了股票价格和成交量图表中的初步发现。我们可以利用这些信息根据波动性和成交量对交易时段进行分类。下一步是通过将训练集、观察值和期望值加载到我们的逻辑回归算法中，创建一个双分类模型。类别由散点图上绘制的**决策边界**（也称为超平面）分隔。
- en: Visualizing labels—the normalized variation of the stock price between the opening
    and closing of the trading session is selected as the label for this classifier.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化标签——选择交易时段开盘价和收盘价之间股票价格的标准化变化作为此分类器的标签。
- en: Step 5 – implementing the classifier
  id: totrans-411
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第5步 – 实现分类器
- en: The objective of this training is to build a model that can discriminate between
    volatile and nonvolatile trading sessions. For the sake of the exercise, session
    volatility is defined as the relative difference between the session highest price
    and lower price. The total trading volume within a session constitutes the second
    parameter of the model. The relative price movement within a trading session (that
    is, *closing price/open price - 1*) is our expected values or labels.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 本次训练的目的是构建一个能够区分波动性和非波动性交易时段的模型。为了练习，将时段波动性定义为时段最高价与最低价之间的相对差异。时段内的总交易量构成模型的第二个参数。交易时段内的相对价格变动（即*收盘价/开盘价
    - 1*）是我们期望的值或标签。
- en: Logistic regression is commonly used in statistics inference.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归在统计学推断中常用。
- en: Tip
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'M4: **Logistic regression model**'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: M4：**逻辑回归模型**
- en: '![Step 5 – implementing the classifier](img/image01251.jpeg)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![第5步 - 实现分类器](img/image01251.jpeg)'
- en: The first weight *w[0]* is known as the intercept. The binomial logistic regression
    is described in the *Logistic regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*,
    in detail.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个权重 *w[0]* 被称为截距。二项式逻辑回归在 [第 6 章](part0188.xhtml#aid-5J99O2 "第 6 章。回归和正则化")
    的 *逻辑回归* 部分中详细描述，*回归和正则化*。
- en: The following implementation of the binomial logistic regression classifier
    exposes a single `classify` method to comply with our desire to reduce the complexity
    and life cycle of objects. The model `weights` parameters are computed during
    training when the `LogBinRegression` class/model is instantiated. As mentioned
    earlier, the sections of the code nonessential to the understanding of the algorithm
    are omitted.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 以下二项式逻辑回归分类器的实现公开了一个单一的 `classify` 方法，以满足我们减少复杂性和对象生命周期的方法。模型 `weights` 参数在实例化
    `LogBinRegression` 类/模型时计算。如前所述，省略了代码中与理解算法无关的部分。
- en: 'The `LogBinRegression` constructor has five arguments (line `18`):'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogBinRegression` 构造函数有五个参数（第 `18` 行）：'
- en: '`obsSet`: These are vector observations that represent volume and volatility'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`obsSet`：这些是表示体积和波动的向量观测值'
- en: '`expected`: This is a vector of expected values'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`expected`：这是一个预期值的向量'
- en: '`maxIters`: This is the maximum number of iterations allowed for the optimizer
    to extract the regression weights during training'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxIters`：这是优化器在训练期间提取回归权重允许的最大迭代次数'
- en: '`eta`: This is the learning or training rate'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta`：这是学习或训练速率'
- en: '`eps`: This is the maximum value of the error (*predicted—expected*) for which
    the model is valid'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eps`：这是模型有效的最大误差值（*预测值—预期值*）'
- en: 'The code is as follows:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE28]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `LogBinRegressionModel` model is generated through training during the
    instantiation of the `LogBinRegression` logistic regression class (line `19`):'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogBinRegressionModel` 模型是在实例化 `LogBinRegression` 逻辑回归类（第 `19` 行）时通过训练生成的：'
- en: '[PRE29]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The model is fully defined by its weights, as described in the mathematical
    formula **M3**. The `weights(0)` intercept represents the mean value of the prediction
    for observations for which variables are zero. The intercept does not have any
    specific meaning for most of the cases and it is not always computable.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 模型完全由其权重定义，如数学公式 **M3** 所述。`weights(0)` 截距表示变量为零的观测值的预测平均值。对于大多数情况，截距没有特定的含义，并且不一定可计算。
- en: Note
  id: totrans-430
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Intercept or not intercept?**'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '**是否包含截距？**'
- en: The intercept corresponds to the value of weights when the observations have
    null values. It is a common practice to estimate, whenever possible, the intercept
    for binomial linear or logistic regression independently from the slope of the
    model in the minimization of the error function. The multinomial regression models
    treat the intercept or weight *w[0]* as part of the regression model, as described
    in the *Ordinary least squares regression* section of [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 截距对应于观测值为空值时的权重值。在可能的情况下，独立于模型斜率的最小化误差函数来估计二项式线性或逻辑回归的截距是一种常见做法。多项式回归模型将截距或权重
    *w[0]* 视为回归模型的一部分，如 [第 6 章](part0188.xhtml#aid-5J99O2 "第 6 章。回归和正则化") 的 *普通最小二乘回归*
    部分所述，*回归和正则化*。
- en: 'The code will be as follows:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE30]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `classify` methods takes new observations as inputs and compute the index
    of the classes (0 or 1) the observations belong to and the actual likelihood (line
    `20`).
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '`classify` 方法接受新的观测值作为输入，并计算观测值所属的类别索引（0 或 1）以及实际的似然值（第 `20` 行）。'
- en: Selecting an optimizer
  id: totrans-436
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择优化器
- en: The goal of the training of a model using expected values is to compute the
    optimal weights that minimizes the **error** or **cost function**. We select the
    **batch gradient descent** algorithm to minimize the cumulative error between
    the predicted and expected values for all the observations. Although there are
    quite a few alternative optimizers, the gradient descent is quite robust and simple
    enough for this first chapter. The algorithm consists of updating the weights
    *w[i]* of the regression model by minimizing the cost.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预期值训练模型的目标是计算最优权重，以最小化 **误差** 或 **成本函数**。我们选择 **批量梯度下降** 算法来最小化预测值和预期值之间所有观测值的累积误差。尽管有相当多的替代优化器，但梯度下降对于本章来说足够稳健且简单。该算法通过最小化成本来更新回归模型的权重
    *w[i]*。
- en: Note
  id: totrans-438
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Cost function**'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '**代价函数**'
- en: 'M5: Cost (or *compound error = predicted – expected*):'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: M5：代价（或 *复合误差 = 预测值 - 预期值*）：
- en: '![Selecting an optimizer](img/image01252.jpeg)'
  id: totrans-441
  prefs: []
  type: TYPE_IMG
  zh: '![选择优化器](img/image01252.jpeg)'
- en: 'M6: The batch gradient descent method to update model weights *w[i]* is as
    follows:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: M6：更新模型权重 *w[i]* 的批量梯度下降方法如下：
- en: '![Selecting an optimizer](img/image01253.jpeg)'
  id: totrans-443
  prefs: []
  type: TYPE_IMG
  zh: '![选择优化器](img/image01253.jpeg)'
- en: For those interested in learning about of optimization techniques, the *Summary
    of optimization techniques* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts* presents an overview of the most
    commonly used optimizers. The batch descent gradient method is also used for the
    training of the multilayer perceptron (refer to *The training epoch* section under
    *The multilayer perceptron* section in [Chapter 9](part0207.xhtml#aid-65D4E1 "Chapter 9. Artificial
    Neural Networks"), *Artificial Neural Networks*).
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些对学习优化技术感兴趣的人来说，[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的“优化技术总结”部分，*基本概念*部分概述了最常用的优化器。批量下降梯度法也用于多层感知器的训练（参见[第9章](part0207.xhtml#aid-65D4E1
    "第9章. 人工神经网络")下的*训练周期*部分，*人工神经网络*）。
- en: 'The execution of the batch gradient descent algorithm follows these steps:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 批量梯度下降算法的执行遵循以下步骤：
- en: Initialize the weights of the regression model.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化回归模型的权重。
- en: Shuffle the order of observations and expected values.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打乱观测值和预期值的顺序。
- en: Aggregate the cost or error for the entire observation set.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合整个观测集的代价或误差。
- en: Update the model weights using the cost as the objective function.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用代价作为目标函数来更新模型权重。
- en: Repeat from step 2 until either the maximum number of iterations is reached
    or the incremental update of the cost is close to zero.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从步骤2重复，直到达到最大迭代次数或代价的增量更新接近零。
- en: The purpose of **shuffling** the order of the observations between iterations
    is to avoid the minimization of the cost reaching a local minimum.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 在迭代之间**打乱**观测顺序的目的是为了避免代价最小化达到局部最小值。
- en: Tip
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Batch and stochastic gradient descent**'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量和随机梯度下降**'
- en: The stochastic gradient descent is a variant of the gradient descent that updates
    the model weights after computing the error on each observation. Although the
    stochastic gradient descent requires a higher computation effort to process each
    observation, it converges toward the optimal value of weights fairly quickly after
    a small number of iterations. However, the stochastic gradient descent is sensitive
    to the initial value of the weights and the selection of the learning rate, which
    is usually defined by an adaptive formula.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降是梯度下降的一种变体，它在计算每个观测的误差后更新模型权重。尽管随机梯度下降需要更高的计算努力来处理每个观测，但在经过少量迭代后，它相当快地收敛到权重的最优值。然而，随机梯度下降对权重的初始值和学习率的选取非常敏感，学习率通常由自适应公式定义。
- en: Training the model
  id: totrans-455
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'The `train` method consists of iterating through the computation of the weight
    using a simple descent gradient method. The method computes `weights` and returns
    an instance of the `LogBinRegressionModel` model:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '`train` 方法通过简单的梯度下降法迭代计算权重。该方法计算 `weights` 并返回一个 `LogBinRegressionModel` 模型实例：'
- en: '[PRE31]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `train` method extracts the number of weights, `nWeights`, for the regression
    model as the *number of variables in each observation + 1* (line `21`). The method
    initializes `weights` with random values over [0, 1] (line `22`). The weights
    are computed through the tail recursive `gradientDescent` method, and the method
    returns a new model for the binomial logistic regression (line `23`).
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`train` 方法提取回归模型的权重数量 `nWeights` 作为 *每个观测变量的数量 + 1*（行 `21`）。该方法使用 [0, 1] 范围内的随机值初始化
    `weights`（行 `22`）。权重通过尾递归的 `gradientDescent` 方法计算，该方法返回二元逻辑回归的新模型（行 `23`）。'
- en: Tip
  id: totrans-459
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Unwrapping values from Try**'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '**从 Try 中解包值**'
- en: 'It is usually not recommended to invoke the `get` method to a `Try` value,
    unless it is enclosed in a `Try` statement. The best course of action is to do
    the following:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 通常不建议对 `Try` 值调用 `get` 方法，除非它被包含在 `Try` 语句中。最佳做法是执行以下操作：
- en: 1\. Catch the failure with `match{ case Success(m) => ..case Failure(e) =>}`
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 使用 `match{ case Success(m) => ..case Failure(e) =>}` 捕获失败
- en: 2\. Extract the `getOrElse( /* … */ )` result safely
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 安全地提取 `getOrElse( /* … */ )` 的结果
- en: 3\. Propagate the results as a `Try` type `map( _.m)`
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 将结果作为 `Try` 类型的 `map( _.m)` 传播
- en: 'Let''s take a look at the computation for `weights` through the minimization
    of the cost function in the `gradientDescent` method:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `gradientDescent` 方法中通过最小化成本函数来计算 `weights` 的过程：
- en: '[PRE32]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `gradientDescent` method recurses on the vector of pairs (observations and
    expected values), `obsAndLbl`, `cost`, and the model `weights` (line `24`). It
    throws an exception if the maximum number of iterations allowed for the optimization
    is reached (line `25`). It shuffles the order of the observations (line `26`)
    before computing the `errorGrad` derivatives of the cost over each weights (line
    `27`). The computation of the derivative of the cost (or *error = predicted value
    – expected value*) in formula **M5** returns a pair of cumulative cost and derivative
    values using the formula (line `28`).
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '`gradientDescent` 方法递归于包含观察和预期值的向量 `obsAndLbl`，`cost` 和模型 `weights`（第 `24`
    行）。如果达到允许的优化最大迭代次数，则抛出异常（第 `25` 行）。在计算每个权重的成本 `errorGrad` 导数之前（第 `27` 行），它会打乱观察的顺序（第
    `26` 行）。成本导数（或 *error = 预测值 - 预期值*）的计算（公式 **M5**）使用公式返回累积成本和导数值（第 `28` 行）。'
- en: Next, the method computes the overall compound cost using the formula **M4**
    (line `29`), converts it to a relative incremental `relativeError` cost that is
    compared to the `eps` convergence criteria (line `30`). The method extracts `derivatives`
    of cost over weights by transposing the matrix of errors, and then prepends the
    bias `1.0` value to match the array of weights (line `31`).
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，该方法使用公式 **M4** (第 `29` 行) 计算整体复合成本，将其转换为相对增量 `relativeError` 成本，并与 `eps`
    收敛标准（第 `30` 行）进行比较。该方法通过转置误差矩阵来提取成本关于权重的 `derivatives`，然后将偏置 `1.0` 值添加到数组中，以匹配权重数组（第
    `31` 行）。
- en: Note
  id: totrans-469
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Bias value**'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏置值**'
- en: 'The purpose of the bias value is to prepend `1.0` to the vector of observation
    so it can be directly processed (for example, zip and dot) with the weights. For
    instance, a regression model for two-dimensional observations (x, y) has three
    weights (*w[0], w[1], w[2]*). The bias value +1 is prepended to the observations
    to compute the predicted value 1.0: *w[0] + x.w[1], + y.w[2]*.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置值的目的是在向量中添加 `1.0`，以便可以直接与权重（例如，压缩和点积）进行处理。例如，对于二维观察（x，y）的回归模型（*w[0]，w[1]，w[2]*）具有三个权重。偏置值
    +1 添加到观察中，以计算预测值 1.0：*w[0] + x.w[1]，+ y.w[2]*。
- en: This technique is used in the computation of the activation function of the
    multilayer perceptron, as described in the *The multilayer perceptron* section
    in [Chapter 9](part0207.xhtml#aid-65D4E1 "Chapter 9. Artificial Neural Networks"),
    *Artificial Neural Networks*.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术在多层感知器的激活函数计算中得到了应用，如 [第 9 章](part0207.xhtml#aid-65D4E1 "第 9 章。人工神经网络")
    中 *多层感知器* 部分所述，*人工神经网络*。
- en: The formula **M6** updates the weights for the next iteration (line `32`) before
    invoking the method with new weights, cost, and iteration count (line `33`).
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 公式 **M6** 在调用带有新权重、成本和迭代计数的函数之前（第 `33` 行）更新下一次迭代的权重（第 `32` 行）。
- en: 'Let''s take a look at the shuffling of the order of observations using a random
    sequence generator. The following implementation is an alternative to the Scala
    standard library method `scala.util.Random.shuffle` for shuffling elements of
    collections. The purpose is to change the order of observations and labels between
    iterations in order to prevent the optimizer to reach a local minimum. The `shuffle`
    method permutes the order in the `labelObs` vector of observations by partitioning
    it into segments of random size and reversing the order of the other segment:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过随机序列生成器来查看观察顺序的打乱。以下实现是 Scala 标准库方法 `scala.util.Random.shuffle` 对集合元素进行打乱的替代方案。目的是在迭代之间改变观察和标签的顺序，以防止优化器达到局部最小值。`shuffle`
    方法通过将 `labelObs` 观察向量划分为随机大小的段并反转其他段的顺序来重新排列观察的 `labelObs` 向量：
- en: '[PRE33]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Once the order of the observations is updated, the vector of pair (observations,
    labels) is easily built through a map (line `34`). The actual shuffling of the
    index is performed in the following `shuffle` recursive function:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦更新了观察的顺序，通过映射（第 `34` 行）可以轻松构建（观察，标签）对的向量。实际的索引打乱是在下面的 `shuffle` 递归函数中执行的：
- en: '[PRE34]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The maximum size of partition of the `maxChunkSize` vector observations is randomly
    computed (line `35`). The method extracts the next slice (`start`, `end`) (line
    `36`). The slice is either added to the existing indices vector and returned once
    all the observations have been shuffled (line `37`) or passed to the next invocation.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxChunkSize`向量观察值的最大分区大小是随机计算的（第35行）。该方法提取下一个切片（`start`，`end`）（第36行）。该切片要么在所有观察值都打乱后添加到现有的索引向量中并返回，要么传递给下一次调用。'
- en: 'The `slice` method returns an array of indices over the range (`start`, `end`)
    either in the right order if the number of segments processed is odd, or in reverse
    order if the number of segment processed is even:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '`slice`方法返回一个索引数组，该数组覆盖范围（`start`，`end`），如果处理的段数是奇数，则按正确顺序返回，如果是偶数，则按相反顺序返回：'
- en: '[PRE35]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-481
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Iterative versus tail recursive computation**'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '**迭代与尾递归计算**'
- en: The tail recursion in Scala is a very efficient alternative to the iterative
    algorithm. Tail recursion avoids the need to create a new stack frame for each
    invocation of the method. It is applied to the implementation of many machine
    learning algorithms presented throughout the book.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: Scala中的尾递归是迭代算法的一个非常高效的替代方案。尾递归避免了为方法每次调用创建新的栈帧的需要。它应用于本书中提出的许多机器学习算法的实现。
- en: 'In order to train the model, we need to label the input data. The labeling
    process consists of associating the relative price movement during a session (price
    at *close/price at open – 1*) with one of the following two configurations:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，我们需要标记输入数据。标记过程包括将一个会话期间的相对价格变动（收盘价/开盘价 - 1）与以下两种配置之一相关联：
- en: Volatile trading sessions with high trading volume
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交易量高、波动性高的交易时段
- en: Trading sessions with low volatility and low trading volume
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交易量低、波动性低的交易时段
- en: The two classes of training observations are segregated by a decision boundary
    drawn on the scatter plot in the previous section. The labeling process is usually
    quite cumbersome and should be automated as much as possible.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个部分中绘制的散点图上的决策边界将两类训练观察值隔离开。标记过程通常相当繁琐，应尽可能自动化。
- en: Note
  id: totrans-488
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Automated labeling**'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动标记**'
- en: Although quite convenient, automated creation of training labels is not without
    risk as it may mislabel singular observations. This technique is used in this
    test for convenience, but it is not recommended unless a domain expert reviews
    the labels manually.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然非常方便，但自动创建训练标签并非没有风险，因为它可能会错误地标记单个观察值。这种技术在本次测试中出于方便而使用，但除非领域专家手动审查标签，否则不建议使用。
- en: Classifying observations
  id: totrans-491
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对观察进行分类
- en: 'Once the model is successfully created through training, it is available to
    classify new observation. The runtime classification of observations using the
    binomial logistic regression is implemented by the `classify` method:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过训练成功创建模型，它就可以用于对新观察值进行分类。通过`classify`方法实现的二项逻辑回归的观察值运行时分类如下：
- en: '[PRE36]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The method applies the logistic function to the linear inner product, `linear`,
    of the new `obs` and `weights` observations of the model (line `37`). The method
    returns the tuple (the predicted class of the observation {0, 1}, prediction value)
    where the class is defined by comparing the prediction to the boundary value `0.0`
    (line `38`).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法将逻辑函数应用于模型的新`obs`和`weights`观察值的线性内积`linear`（第37行）。该方法返回一个元组（观察的预测类别{0, 1}，预测值），其中类别是通过将预测值与边界值`0.0`（第38行）进行比较来定义的。
- en: 'The computation of the `dot` product of weights and observations uses the bias
    value as follows:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 权重和观察值的点积计算使用偏差值如下：
- en: '[PRE37]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The alternative implementation of the `dot` product of weights and observations
    consists of extracting the first `w.head` weight:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 权重和观察值的点积的替代实现是提取第一个`w.head`权重：
- en: '[PRE38]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The `dot` method is used in the `classify` method.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在`classify`方法中使用`dot`方法。
- en: Step 6 – evaluating the model
  id: totrans-500
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第6步 – 评估模型
- en: 'The first step is to define the configuration parameters for the test: the
    maximum number of `NITERS` iterations, the `EPS` convergence criteria, the `ETA`
    learning rate, the decision boundary used to label the `BOUNDARY` training observations,
    and the path to the training and test sets:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义测试的配置参数：最大迭代次数`NITERS`，收敛标准`EPS`，学习率`ETA`，用于标记`BOUNDARY`训练观察值的决策边界，以及训练集和测试集的路径：
- en: '[PRE39]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The various activities of creating and testing the model, loading, normalizing
    data, training the model, loading, and classifying test data is organized as a
    workflow using the monadic composition of the `Try` class:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和测试模型的各种活动，包括加载数据、归一化数据、训练模型、加载数据和分类测试数据，是通过使用`Try`类的单子组合作为一个工作流程组织的：
- en: '[PRE40]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: First, the daily trading volatility and volume for the `volatilityVol` stock
    price is loaded from file (line `39`). The workflow initializes the multi-dimensional
    `MinMaxVec` normalizer (line `40`) and uses it to normalize the training set (line
    `41`). The `logRegr` method instantiates the binomial `classifier` logistic regression
    (line `42`). The `testValues` test data is loaded from file (line `43`), normalized
    using `MinMaxVec` already applied to the training data (line `44`), and classified
    (line `45`).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从文件中加载`volatilityVol`股票价格的每日交易波动性和成交量（第`39`行）。工作流程初始化多维`MinMaxVec`归一化器（第`40`行），并使用它来归一化训练集（第`41`行）。`logRegr`方法实例化了二项式`classifier`逻辑回归（第`42`行）。从文件中加载`testValues`测试数据（第`43`行），使用已应用于训练数据的`MinMaxVec`进行归一化（第`44`行），并进行分类（第`45`行）。
- en: 'The `load` method extracts `data` (observations) of a `XVSeries[Double]` type
    from the file. The heavy lifting is done by the `extract` method (line `46`),
    and then the file handle is closed (line `47`) before returning the vector of
    raw observations:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '`load`方法从文件中提取`XVSeries[Double]`类型的`data`（观测值）。繁重的工作由`extract`方法（第`46`行）完成，然后在返回原始观测值向量之前关闭文件句柄（第`47`行）：'
- en: '[PRE41]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The private `logRegr` method has the following two purposes:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 私有的`logRegr`方法有两个目的：
- en: Labeling automatically the `obs` observations to generate the `expected` values
    (line `48`)
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动标记`obs`观测值以生成`expected`值（第`48`行）
- en: Initializing (instantiation and training of the model) the binomial logistic
    regression (line `49`)
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化（实例化和训练）二项式逻辑回归（第`49`行）
- en: 'The code is as follows:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE42]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The method labels observations by evaluating if they belong to any one of the
    two classes delimited by the `BOUNDARY` condition, as illustrated in the scatter
    plot in a previous section.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法通过评估观测值是否属于由`BOUNDARY`条件定义的两个类别之一来标记观测值，如图中前一个部分的散点图所示。
- en: Note
  id: totrans-514
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Validation**'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证**'
- en: The simple classification in this test case is provided for illustrating the
    runtime application of the model. It does not constitute a validation of the model
    by any stretch of imagination. The next chapter digs into validation methodologies
    (refer to the *Assessing a model* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个测试案例中提供的简单分类是为了说明模型的运行时应用。这无论如何都不能构成对模型的验证。下一章将深入研究验证方法（请参阅[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中的*评估模型*部分，*Hello World!*）
- en: 'The training run is performed with three different values of the learning rate.
    The following chart illustrates the convergence of the batch gradient descent
    in the minimization of the cost, given different values of learning rates:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 训练运行使用三个不同的学习率值进行。以下图表说明了不同学习率值下批量梯度下降在成本最小化过程中的收敛：
- en: '![Step 6 – evaluating the model](img/image01254.jpeg)'
  id: totrans-518
  prefs: []
  type: TYPE_IMG
  zh: '![第6步 – 评估模型](img/image01254.jpeg)'
- en: Impact of the learning rate on the batch gradient descent on the convergence
    of the cost (error)
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率对批量梯度下降在成本（误差）收敛中的影响
- en: As expected, the execution of the optimizer with a higher learning rate produces
    a steepest descent in the cost function.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，使用较高学习率的优化器在成本函数中产生了最陡的下降。
- en: 'The execution of the test produces the following model:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 测试执行产生了以下模型：
- en: '**iters = 495**'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: '**迭代次数 = 495**'
- en: '**weights: 0.859-3.6177923,-64.927832**'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: '**权重：0.859-3.6177923,-64.927832**'
- en: '**input (0.0088, 4.10E7) normalized (0.063,0.061) class 1 prediction 0.515**'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入（0.0088，4.10E7）归一化（0.063，0.061）类别1预测0.515**'
- en: '**input (0.0694, 3.68E8) normalized (0.517,0.641) class 0 prediction 0.001**'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入（0.0694，3.68E8）归一化（0.517，0.641）类别0预测0.001**'
- en: Note
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Learning more about regressive models**'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '**了解更多关于回归模型**'
- en: The binomial logistic regression is merely used to illustrate the concept of
    training and prediction. It is described in the *Logistic regression* section
    in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization* in detail.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 二项式逻辑回归仅用于说明训练和预测的概念。它在[第6章](part0188.xhtml#aid-5J99O2 "第6章。回归和正则化")的*逻辑回归*部分，*回归和正则化*中进行了详细描述。
- en: Summary
  id: totrans-529
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'I hope you enjoyed this introduction to machine learning. You learned how to
    leverage your skills in Scala programming to create a simple logistic regression
    program for predicting stock price/volume action. Here are the highlights of this
    introductory chapter:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这篇机器学习的介绍。你学习了如何利用Scala编程技能创建一个简单的逻辑回归程序来预测股价/量价走势。以下是本章的要点：
- en: From monadic composition and high order collection methods for parallelization
    to configurability and reusability patterns, Scala is the perfect fit to implement
    data mining and machine learning algorithms for large-scale projects.
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从单调组合和高阶集合方法用于并行化到可配置性和重用模式，Scala是实施大规模项目中的数据挖掘和机器学习算法的完美选择。
- en: There are many logical steps to create and deploy a machine learning model.
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和部署机器学习模型有许多逻辑步骤。
- en: The implementation of the binomial logistic regression classifier presented
    as part of the test case is simple enough to encourage you to learn how to write
    and apply more advanced machine learning algorithms.
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为测试用例一部分呈现的二项逻辑回归分类器的实现足够简单，足以鼓励你学习如何编写和应用更高级的机器学习算法。
- en: To the delight of Scala programming aficionados, the next chapter will dig deeper
    into building a flexible workflow by leveraging monadic data transformation and
    stackable traits.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 让Scala编程爱好者感到高兴的是，下一章将深入探讨通过利用单调数据转换和可堆叠特性来构建灵活的工作流程。
- en: Chapter 2. Hello World!
  id: totrans-535
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。你好，世界！
- en: In the first chapter, you were acquainted with some rudimentary concepts regarding
    data processing, clustering, and classification. This chapter is dedicated to
    the creation and maintenance of a flexible end-to-end workflow to train and classify
    data. The first section of the chapter introduces a data-centric (functional)
    approach to create number-crunching applications.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，你熟悉了一些关于数据处理、聚类和分类的基本概念。本章致力于创建和维护一个灵活的端到端工作流程来训练和分类数据。本章的第一节介绍了一种以数据为中心（函数式）的方法来创建数据处理应用。
- en: 'You will learn how to:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 你将学习如何：
- en: Apply the concept of monadic design to create dynamic workflows
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将单调设计概念应用于创建动态工作流程
- en: Leverage some of Scala's advanced patterns, such as the cake pattern, to build
    portable computational workflows
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Scala的一些高级模式，如蛋糕模式，来构建可移植的计算工作流程
- en: Take into account the bias-variance trade-off in selecting a model
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选择模型时考虑偏差-方差权衡
- en: Overcome overfitting in modeling
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克服建模中的过拟合问题
- en: Break down data into training, test, and validation sets
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分解为训练集、测试集和验证集
- en: Implement model validation in Scala using precision, recall, and F score
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用精确度、召回率和F分数在Scala中实现模型验证
- en: Modeling
  id: totrans-544
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模
- en: Data is the lifeline of any scientist, and the selection of data providers is
    critical in developing or evaluating any statistical inference or machine learning
    algorithm.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何科学家的生命线，选择数据提供者对于开发或评估任何统计推断或机器学习算法至关重要。
- en: A model by any other name
  id: totrans-546
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任何名称的模型
- en: We briefly introduced the concept of a **model** in the *Model categorization*
    section in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"),
    *Getting Started*.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](part0155.xhtml#aid-4JQ761 "第1章。入门")的*模型分类*部分简要介绍了**模型**的概念，*入门*。
- en: 'What constitutes a model? Wikipedia provides a reasonably good definition of
    a model as understood by scientists [2:1]:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是模型？维基百科为科学家理解的模型提供了一个相当好的定义 [2:1]：
- en: '*A scientific model seeks to represent empirical objects, phenomena, and physical
    processes in a logical and objective way.*'
  id: totrans-549
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*科学模型旨在以逻辑和客观的方式表示经验对象、现象和物理过程。*'
- en: ''
  id: totrans-550
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-551
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: …
- en: ''
  id: totrans-552
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Models that are rendered in software allow scientists to leverage computational
    power to simulate, visualize, manipulate and gain intuition about the entity,
    phenomenon or process being represented.*'
  id: totrans-553
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*在软件中呈现的模型允许科学家利用计算能力来模拟、可视化、操作并获取对所表示实体、现象或过程的直观理解。*'
- en: In statistics and the probabilistic theory, a model describes data that one
    might observe from a system to express any form of uncertainty and noise. A model
    allows us to infer rules, make predictions, and learn from data.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和概率论中，模型描述了从系统可能观察到的数据，以表达任何形式的不确定性和噪声。模型使我们能够推断规则、做出预测并从数据中学习。
- en: A model is composed of **features**, also known as **attributes** or **variables**,
    and a set of relation between those features. For instance, the model represented
    by the function *f(x, y) = x.sin(2y)* has two features, *x* and *y,* and a relation,
    *f*. Those two features are assumed to be independent. If the model is subject
    to a constraint such as *f(x, y) < 20*, then the **conditional independence**
    is no longer valid.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型由**特征**组成，也称为**属性**或**变量**，以及这些特征之间的一组关系。例如，由函数 *f(x, y) = x.sin(2y)* 表示的模型有两个特征，*x*
    和 *y*，以及一个关系，*f*。这两个特征被认为是独立的。如果模型受到如 *f(x, y) < 20* 这样的约束，那么**条件独立性**就不再有效。
- en: An astute Scala programmer would associate a model to a monoid for which the
    set is a group of observations and the operator is the function implementing the
    model.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 一个敏锐的Scala程序员会将一个模型与一个幺半群关联起来，其中集合是一组观测值，运算符是实现模型的函数。
- en: 'Models come in a variety of shapes and forms:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 模型有多种形状和形式：
- en: '**Parametric**: This consists of functions and equations (for example, *y =
    sin(2t + w)*)'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数化**：这包括函数和方程（例如，*y = sin(2t + w)*）'
- en: '**Differential**: This consists of ordinary and partial differential equations
    (for example, *dy = 2x.dx*)'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微分**：这包括常微分方程和偏微分方程（例如，*dy = 2x.dx*）'
- en: '**Probabilistic**: This consists of probability distributions (for example,
    *p(x|c) = exp (k.logx – x)/x!*)'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率论**：这包括概率分布（例如，*p(x|c) = exp (k.logx – x)/x!*)'
- en: '**Graphical**: This consists of graphs that abstract out the conditional independence
    between variables (for example, *p(x,y|c) = p(x|c).p(y|c)*)'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形表示**：这包括抽象变量之间条件独立性的图（例如，*p(x,y|c) = p(x|c).p(y|c)*）'
- en: '**Directed graphs**: This consists of temporal and spatial relationships (for
    example, a scheduler)'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有向图**：这包括时间和空间关系（例如，一个调度器）'
- en: '**Numerical method**: This consists of computational methods such as finite
    difference, finite elements, or Newton-Raphson'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数值方法**：这包括有限差分、有限元或牛顿-拉夫森等计算方法'
- en: '**Chemistry**: This consists of formula and components (for example, *H[2]O,
    Fe + C[12] = FeC[13]*, and so on)'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**化学**：这包括公式和成分（例如，*H[2]O, Fe + C[12] = FeC[13]*，等等）'
- en: '**Taxonomy**: This consists of a semantic definition and relationship of concepts
    (for example, *APG/Eudicots/Rosids/Huaceae/Malvales*)'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类学**：这包括概念的含义和关系（例如，*APG/Eudicots/Rosids/Huaceae/Malvales*）'
- en: '**Grammar and lexicon**: This consists of a syntactic representation of documents
    (for example, the Scala programming language)'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语法和词汇**：这包括文档的句法表示（例如，Scala编程语言）'
- en: '**Inference logic**: This consists of rules (for example, *IF (stock vol >
    1.5 * average) AND rsi > 80 THEN …*)'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理逻辑**：这包括规则（例如，*IF (stock vol > 1.5 * average) AND rsi > 80 THEN …*）'
- en: Model versus design
  id: totrans-568
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型与设计
- en: 'The confusion between a model and design is quite common in computer science,
    the reason being that these terms have different meanings for different people
    depending on the subject. The following metaphors should help with your understanding
    of these two concepts:'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学中，模型和设计的混淆相当常见，原因在于这些术语对不同的人来说有不同的含义，这取决于主题。以下隐喻应该有助于您理解这两个概念：
- en: '**Modeling**: This describes something you know. A model makes an assumption,
    which becomes an assertion if proven correct (for example, the US population,
    *p*, increases by 1.2 percent a year, *dp/dt = 1.012*).'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建模**：这描述了您所知道的东西。一个模型做出假设，如果得到证实，则成为断言（例如，美国人口，*p*，每年增加1.2%，*dp/dt = 1.012*）。'
- en: '**Designing**: This manipulates the representation of things you don''t know.
    Designing can be regarded as the exploration phase of modeling (for example, what
    are the features that contribute to the growth of the US population? Birth rate?
    Immigration? Economic conditions? Social policies?).'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计**：这操作未知事物的表示。设计可以被视为建模的探索阶段（例如，哪些特征有助于美国人口的增长？出生率？移民？经济条件？社会政策？）。'
- en: Selecting features
  id: totrans-572
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择特征
- en: The selection of a model's features is the process of discovering and documenting
    the minimum set of variables required to build the model. Scientists assume that
    data contains many redundant or irrelevant features. Redundant features do not
    provide information already given by the selected features, and irrelevant features
    provide no useful information.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 选择模型特征的过程是发现和记录构建模型所需的最小变量集。科学家们假设数据包含许多冗余或不相关的特征。冗余特征不提供已由所选特征提供的信息，而不相关的特征不提供任何有用的信息。
- en: 'A **features selection** consists of two consecutive steps:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征选择**包括两个连续的步骤：'
- en: Searching for new feature subsets.
  id: totrans-575
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻找新的特征子集。
- en: Evaluating these feature subsets using a scoring mechanism.
  id: totrans-576
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用评分机制评估这些特征子集。
- en: The process of evaluating each possible subset of features to find the one that
    maximizes the objective function or minimizes the error rate is computationally
    intractable for large datasets. A model with *n* features requires *2^n-1* evaluations.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型数据集，评估每个可能的特征子集以找到最大化目标函数或最小化错误率的进程在计算上是不可行的。具有*n*个特征的模型需要*2^n-1*次评估。
- en: Extracting features
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取特征
- en: An **observation** is a set of indirect measurements of hidden, also known as
    latent, variables, which may be noisy or contain a high degree of correlation
    and redundancies. Using raw observations in a classification task would very likely
    produce inaccurate results. Using all features in each observation also incurs
    a high computation cost.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '**观测**是一组对隐藏的、也称为潜在变量的间接测量，这些变量可能是有噪声的或包含高度的相关性和冗余。在分类任务中使用原始观测可能会导致不准确的结果。在每个观测中使用所有特征也会产生很高的计算成本。'
- en: The purpose of **features extraction** is to reduce the number of variables
    or dimensions of the model by eliminating redundant or irrelevant features. The
    features are extracted by transforming the original set of observations into a
    smaller set at the risk of losing some vital information embedded in the original
    set.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征提取**的目的是通过消除冗余或不相关的特征来减少模型中的变量或维度数量。特征提取是通过将原始观测集转换为更小的集合来进行的，这可能会丢失原始集合中嵌入的一些重要信息。'
- en: Defining a methodology
  id: totrans-581
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义一个方法
- en: A data scientist has many options in selecting and implementing a classification
    or clustering algorithm.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在选择和实现分类或聚类算法时有很多选择。
- en: 'Firstly, a mathematical or statistical model is to be selected to extract knowledge
    from the raw input data or the output of a data upstream transformation. The selection
    of the model is constrained by the following parameters:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要选择一个数学或统计模型来从原始输入数据或数据上游转换的输出中提取知识。模型的选择受到以下参数的限制：
- en: Business requirements such as accuracy of results or computation time
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业需求，例如结果准确性或计算时间
- en: Availability of training data, algorithms, and libraries
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据、算法和库的可用性
- en: Access to a domain or subject matter expert, if needed
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，访问领域或主题专家
- en: 'Secondly, the engineer has to select a computational and deployment framework
    suitable for the amount of data to be processed. The computational context is
    to be defined by the following parameters:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，工程师必须选择一个适合处理的数据量的计算和部署框架。计算环境将由以下参数定义：
- en: Available resources such as machines, CPU, memory, or I/O bandwidth
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用资源，例如机器、CPU、内存或I/O带宽
- en: An implementation strategy such as iterative versus recursive computation or
    caching
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种实现策略，例如迭代计算或缓存
- en: Requirements for the responsiveness of the overall process such as duration
    of computation or display of intermediate results
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对整体过程响应性的要求，例如计算持续时间或显示中间结果
- en: Thirdly, a domain expert has to tag or label the observations in order to generate
    an accurate classifier.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，领域专家必须标记或标注观测，以便生成准确的分类器。
- en: Finally, the model has to be validated against a reliable test dataset.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模型必须与可靠的测试数据集进行验证。
- en: 'The following diagram illustrates the selection process to create a workflow:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了创建工作流程的选择过程：
- en: '![Defining a methodology](img/image01255.jpeg)'
  id: totrans-594
  prefs: []
  type: TYPE_IMG
  zh: '![定义一个方法](img/image01255.jpeg)'
- en: Statistical and computation modeling for machine learning applications
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习应用中的统计和计算建模
- en: Note
  id: totrans-596
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Domain expertise, data science, and software engineering**'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '**领域专业知识、数据科学和软件工程**'
- en: A domain or subject matter expert is a person with authoritative or credited
    expertise in a particular area or topic. A chemist is an expert in the domain
    of chemistry and possibly related fields.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 领域或主题专家是在特定领域或主题上具有权威或认可的专业知识的人。化学家是化学领域的专家，可能是相关领域。
- en: A data scientist solves problems related to data in a variety of fields, such
    as biological sciences, health care, marketing, or finances. Data and text mining,
    signal processing, statistical analysis, and modeling using machine learning algorithms
    are some of the activities performed by a data scientist.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在生物科学、医疗保健、营销或金融等众多领域解决与数据相关的问题。数据挖掘、信号处理、统计分析以及使用机器学习算法进行建模是数据科学家执行的一些活动。
- en: A software developer performs all the tasks related to the creation of software
    applications, including analysis, design, coding, testing, and deployment.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发者执行与创建软件应用程序相关的所有任务，包括分析、设计、编码、测试和部署。
- en: The parameters of a data transformation may need to be reconfigured according
    to the output of the upstream data transformation. Scala's higher-order functions
    are particularly suitable for implementing configurable data transformations.
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换的参数可能需要根据上游数据转换的输出重新配置。Scala 的高阶函数特别适合实现可配置的数据转换。
- en: Monadic data transformation
  id: totrans-602
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单子数据转换
- en: The first step is to define a trait and method that describe the transformation
    of data by the computation units of a workflow. The data transformation is the
    foundation of any workflow for processing and classifying a dataset, training
    and validating a model, and displaying results.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义一个特性和方法，描述工作流程的计算单元对数据的转换。数据转换是任何处理和分类数据集、训练和验证模型以及显示结果的工作流程的基础。
- en: 'There are two symbolic models used for defining a data processing or data transformation:'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 定义数据处理或数据转换时使用了两种符号模型：
- en: '**Explicit model**: The developer creates a model explicitly from a set of
    configuration parameters. Most of deterministic algorithms and unsupervised learning
    techniques use an explicit model.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式模型**：开发者从一组配置参数显式创建模型。大多数确定性算法和无监督学习技术使用显式模型。'
- en: '**Implicit model**: The developer provides a training set that is a set of
    labeled observations (observations with an expected outcome). A classifier extracts
    a model through the training set. Supervised learning techniques rely on models
    implicitly generated from labeled data.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐式模型**：开发者提供一组标记观察（具有预期结果的观察）的训练集。分类器通过训练集提取模型。监督学习技术依赖于从标记数据隐式生成的模型。'
- en: Error handling
  id: totrans-607
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误处理
- en: 'The simplest form of data transformation is **morphism** between the two `U`
    and `V` types. The data transformation enforces a *contract* for validating an
    input and returning either a value or an error. From now on, we use the following
    convention:'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换的最简单形式是两种类型`U`和`V`之间的**同态**。数据转换强制执行一个*契约*，用于验证输入并返回值或错误。从现在开始，我们使用以下约定：
- en: '**Input value**: The validation is implemented through a partial function of
    the `PartialFunction` type that is returned by the data transformation. A `MatchErr`
    error is thrown in case the input value does not meet the required condition (contract).'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入值**：验证通过返回数据转换的`PartialFunction`类型部分函数实现。如果输入值不符合所需条件（契约），则抛出`MatchErr`错误。'
- en: '**Output value**: The type of a return value is `Try[V]` for which an exception
    is returned in case of an error.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出值**：返回值的类型为`Try[V]`，在发生错误时返回异常。'
- en: Note
  id: totrans-611
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Reusability of partial functions**'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '**部分函数的可重用性**'
- en: 'Reusability is another benefit of partial functions, which is illustrated in
    the following code snippet:'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 可重用性是部分函数的另一个好处，以下代码片段展示了这一点：
- en: '[PRE43]'
  id: totrans-614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Partial functions enable developers to implement methods that address the most
    common (primary) use cases for which input values have been tested. All other
    nontrivial use cases (or input values) generate a `MatchErr` exception. At a later
    stage in the development cycle, the developer can implement the code to handle
    the less common use cases.
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 部分函数允许开发者实现针对最常见（主要）用例的方法，这些用例的输入值已经过测试。所有其他非平凡用例（或输入值）都会生成`MatchErr`异常。在开发周期的后期，开发者可以实施代码来处理较少见的用例。
- en: Note
  id: totrans-616
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Runtime validation of a partial function**'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '**部分函数的运行时验证**'
- en: 'It is a good practice to validate if a partial function is defined for a specific
    value of the argument:'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 验证一个部分函数是否为特定参数值定义是一个好的实践：
- en: '[PRE44]'
  id: totrans-619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This preemptive approach allows the developer to select an alternative method
    or a full function. It is an efficient alternative to catch a `MathErr` exception.
    The validation of a partial function is omitted throughout the book for the sake
    of clarity.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 这种先发制人的方法允许开发者选择一个替代方法或完整功能。这是捕获`MathErr`异常的有效替代方案。为了清晰起见，本书中省略了对部分函数的验证。
- en: 'Therefore, the signature of a data transformation is defined as follows:'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据转换的签名被定义为如下：
- en: '[PRE45]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note
  id: totrans-623
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**F# language references**'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: '**F#语言参考**'
- en: The `|>` notation used as the signature of the transform is borrowed from the
    F# language [2:2].
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 作为转换签名的`|>`符号是从F#语言[2:2]借用的。
- en: Explicit models
  id: totrans-626
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显式模型
- en: 'The objective is to define a symbolic representation of the transformation
    of different types of data without exposing the internal state of the algorithm
    implementing the data transformation. The transformation on a dataset is performed
    using a model or configuration that is fully defined by the user, which is illustrated
    in the following diagram:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是定义不同类型数据的符号表示，而不暴露实现数据转换的算法的内部状态。数据集上的转换是通过用户完全定义的模型或配置来执行的，如下面的图示所示：
- en: '![Explicit models](img/image01256.jpeg)'
  id: totrans-628
  prefs: []
  type: TYPE_IMG
  zh: '![显式模型](img/image01256.jpeg)'
- en: Visualization of explicit models
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 显式模型的可视化
- en: 'The transformation of an explicit configuration or model, `config`, is defined
    as an `ETransform` abstract class parameterized by the `T` type of the model:'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 显式配置或模型`config`的转换被定义为`ETransform`抽象类的一个参数化类型`T`：
- en: '[PRE46]'
  id: totrans-631
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The input `U` type and output `V` type have to be defined in the subclasses
    of `ETransform`. The `|>` transform operator returns a partial function that can
    be reused for different input values.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 输入`U`类型和输出`V`类型必须在`ETransform`的子类中定义。`|>`转换运算符返回一个部分函数，可以用于不同的输入值。
- en: 'The creation of a class that implements a specific transformation using an
    explicit configuration is quite simple: all you need is the definition of an input/output
    `U`/`V` type and an implementation of the `|>` transformation method.'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个实现特定转换的显式配置的类相当简单：你所需要的就是定义一个输入/输出`U`/`V`类型以及实现`|>`转换方法。
- en: 'Let''s consider the extraction of data from a financial source, `DataSource`,
    that takes a list of functions that convert some text fields, `Fields`, into a
    `Double` value as the input and produce a list of observations of the `XSeries[Double]`
    type. The extraction parameters are defined in the `DataSourceConfig` class:'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑从金融数据源`DataSource`中提取数据，该数据源接受一个将某些文本字段`Fields`转换为`Double`值的函数列表作为输入，并产生一个`XSeries[Double]`类型的观察列表。提取参数在`DataSourceConfig`类中定义：
- en: '[PRE47]'
  id: totrans-635
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The `DataSourceConfig` configuration is explicitly provided as an argument of
    the constructor for `DataSource` (line `1`). The constructor implements the basic
    type and data transformation associated with an explicit model (line `2`). The
    class defines the `U` type of input values (line `3`), `V` type of output values
    (line `4`), and `|>` transformation method that returns a partial function (line
    `5`).
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataSourceConfig`配置作为`DataSource`构造函数的参数显式提供（行`1`）。构造函数实现了与显式模型相关的基本类型和数据转换（行`2`）。该类定义了输入值的`U`类型（行`3`），输出值的`V`类型（行`4`），以及返回部分函数的`|>`转换方法（行`5`）。'
- en: Note
  id: totrans-637
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The DataSource class**'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: '**`DataSource`类**'
- en: The *Data extraction* section of the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts* describes the `DataSource` class
    functionality. The `DataSource` class is used throughout the book.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: '[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*数据提取*部分，*基本概念*描述了`DataSource`类的功能。本书中使用了`DataSource`类。'
- en: 'Data transformations using an explicit model or configuration constitute a
    category with monadic operations. The monad associated with the `ETransform` class
    subclasses the definition of the higher kind, `_Monad`:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 使用显式模型或配置进行数据转换构成一个具有单调运算的类别。与`ETransform`类子类关联的单子继承自高阶单子的定义`_Monad`：
- en: '[PRE48]'
  id: totrans-641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The singleton `eTransformMonad` implements the following basic monadic operators
    introduced in the *Monads* section under *Abstraction* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*:'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 单例`eTransformMonad`实现了在[第1章](part0155.xhtml#aid-4JQ761 "第1章. 入门")中*抽象*部分的*Monads*节下引入的以下基本单调运算符，*入门*：
- en: The `unit` method is used to instantiate `ETransform` (line `6`)
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unit`方法用于实例化`ETransform`（行`6`）'
- en: The `map` is used to transform an `ETransform` object by morphing its elements
    (line `7`)
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`map`通过变形其元素（第`7`行）来转换一个`ETransform`对象。
- en: The `flatMap` is used to transform an `ETransform` object by instantiating its
    elements (line `8`)
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`flatMap`通过实例化其元素（第`8`行）来转换一个`ETransform`对象。
- en: 'For practical purposes, an implicit class is created to convert an `ETransform`
    object to its associated monad, allowing transparent access to the `unit`, `map`,
    and `flatMap` methods:'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实际应用，创建了一个隐式类，将`ETransform`对象转换为相关的单子，允许透明访问`unit`、`map`和`flatMap`方法：
- en: '[PRE49]'
  id: totrans-647
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Implicit models
  id: totrans-648
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐式模型
- en: 'Supervised learning models are extracted from a training set. Transformations,
    such as classification or regression use the implicit models to process the input
    data, as illustrated in the following diagram:'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习模型是从训练集中提取的。如分类或回归等转换使用隐式模型来处理输入数据，如下面的图所示：
- en: '![Implicit models](img/image01257.jpeg)'
  id: totrans-650
  prefs: []
  type: TYPE_IMG
  zh: '![隐式模型](img/image01257.jpeg)'
- en: Visualization of implicit models
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式模型的可视化
- en: 'The transformation for a model implicitly extracted from the training data
    is defined as an abstract `ITransform` class parameterized by the `T` type of
    observations, `xt`:'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练数据隐式提取的模型的转换定义为由观察类型`T`、`xt`参数化的抽象`ITransform`类：
- en: '[PRE50]'
  id: totrans-653
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The type of the data collection is `Vector`, which is an immutable and effective
    container. An `ITransform` type is created by defining the `T` type of the observation,
    the `V` output of the data transformation, and the `|>` method that implements
    the transformation, usually a classification or regression. Let'' s consider the
    support vector machine algorithm, `SVM`, to illustrate the implementation of a
    data transformation using an implicit model:'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集合的类型是`Vector`，它是一个不可变且有效的容器。通过定义观察的`T`类型、数据转换的`V`输出以及实现转换的`|>`方法（通常是一个分类或回归）来创建`ITransform`类型。让我们以支持向量机算法`SVM`为例，说明使用隐式模型实现数据转换的实现方式：
- en: '[PRE51]'
  id: totrans-655
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The support vector machine is a discriminative supervised learning algorithm
    described in [Chapter 8](part0200.xhtml#aid-5UNGG2 "Chapter 8. Kernel Models and
    Support Vector Machines"), *Kernel Models and Support Vector Machines*. A support
    vector machine, `SVM`, is instantiated with a configuration and training set:
    the `xt` observations and `expected` data (line `9`). Contrary to the explicit
    model, the `config` configuration does not define the model used in the data transformation;
    the model is implicitly generated from the training set of the `xt` input data
    and `expected` values. An `SVM` instance is created as an `ITransform` (line `10`)
    by specifying the `V` output type (line `11`) and overriding the `|>` transformation
    method (line `12`).'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机是一种在[第8章](part0200.xhtml#aid-5UNGG2 "第8章. 核模型与支持向量机")《核模型与支持向量机》中描述的判别式监督学习算法。支持向量机（`SVM`）通过配置和训练集实例化：`xt`观察数据和`expected`数据（第`9`行）。与显式模型相反，`config`配置不定义用于数据转换的模型；模型是从`xt`输入数据的训练集和`expected`值中隐式生成的。通过指定`V`输出类型（第`11`行）并覆盖`|>`转换方法（第`12`行），创建了一个`ITransform`实例。
- en: The `|>` classification method produces a partial function that takes an `x`
    observation as an input and returns the prediction value of a `Double` type.
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`分类方法产生一个部分函数，它接受一个`x`观察值作为输入，并返回一个`Double`类型的预测值。'
- en: 'Similar to the explicit transformation, we define the monadic operation for
    the `ITransform` by overriding the `unit` (line `13`), `map` (line `14`), and
    `flatMap` (line `15`) methods:'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 与显式转换类似，我们通过覆盖`unit`（第`13`行）、`map`（第`14`行）和`flatMap`（第`15`行）方法来定义`ITransform`的单子操作：
- en: '[PRE52]'
  id: totrans-659
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Finally, let''s create an implicit class to automatically convert an `ITransform`
    object into its associated monad so that it can access the `unit`, `map`, and
    `flatMap` monad methods transparently:'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们创建一个隐式类，自动将`ITransform`对象转换为相关的单子，以便它可以透明地访问`unit`、`map`和`flatMap`单子方法：
- en: '[PRE53]'
  id: totrans-661
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The `filter` method is strictly not an operator of the monad (line `16`). However,
    it is commonly included to constrain (or guard) a sequence of transformation (for
    example, for comprehension closure). As stated in the *Presentation* section under
    *Source code* in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"),
    *Getting Started*, code related to exceptions, error checking, and validation
    of arguments is omitted.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter` 方法严格来说不是单子的运算符（行 `16`）。然而，它通常被包含以约束（或保护）一系列变换（例如，用于理解闭包）。如 [第 1 章](part0155.xhtml#aid-4JQ761
    "第 1 章。入门") 的 *源代码* 部分的 *演示* 部分所述，*入门*，与异常、错误检查和参数验证相关的代码被省略。'
- en: Note
  id: totrans-663
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Immutable transformations**'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '**不可变变换**'
- en: 'The model for a data transformation (or a processing unit or classifier) class
    should be immutable. Any modification will alter the integrity of the model or
    parameters used to process data. In order to ensure that the same model is used
    in processing the input data for the entire lifetime of a transformation, we do
    the following:'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 数据变换（或处理单元或分类器）类的模型应该是不可变的。任何修改都将改变模型或用于处理数据的参数的完整性。为了确保在整个变换的生命周期中始终使用相同的模型来处理输入数据，我们执行以下操作：
- en: A model for an `ETransform` is defined as an argument of its constructor.
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ETransform` 的模型定义为构造函数的参数。'
- en: The constructor of an `ITransform` generates the model from a given training
    set. The model has to be rebuilt from the training set (not altered), if it provides
    an incorrect outcome or prediction.
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ITransform` 的构造函数从给定的训练集中生成模型。如果模型提供不正确的结果或预测，则必须从训练集中重新构建模型（而不是修改）。'
- en: Models are created by the constructor of classifiers or data transformation
    classes to ensure their immutability. The design of an immutable transformation
    is described in the *Design template for immutable classifiers* section under
    *Scala programming* of the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 模型由分类器或数据变换类的构造函数创建，以确保其不可变性。不可变变换的设计在 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录
    A。基本概念") 的 *Scala 编程* 部分的 *不可变分类器设计模板* 部分中描述，*基本概念*。
- en: A workflow computational model
  id: totrans-669
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作流计算模型
- en: Monads are very useful for manipulating and chaining data transformations using
    implicit configurations or explicit models. However, they are restricted to a
    single morphism `T => U` type. More complex and flexible workflows require weaving
    transformations of different types using a generic factory pattern.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 单子对于使用隐式配置或显式模型操作和链式数据变换非常有用。然而，它们被限制为单个形态 `T => U` 类型。更复杂和灵活的工作流程需要使用通用工厂模式编织不同类型变换。
- en: Traditional factory patterns rely on a combination of composition and inheritance
    and do not provide developers with the same level of flexibility as stackable
    traits.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的工厂模式依赖于组合和继承的组合，并且不向开发者提供与可堆叠特质相同级别的灵活性。
- en: In this section, we introduce you to the concept of modeling using mixins and
    a variant of the cake pattern to provide a workflow with three degrees of configurability.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您介绍使用混入和蛋糕模式变体进行建模的概念，以提供一个具有三个配置级别的流程。
- en: Supporting mathematical abstractions
  id: totrans-673
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持数学抽象
- en: 'Stackable traits enable developers to follow a strict mathematical formalism
    while implementing a model in Scala. Scientists use a universally accepted template
    to solve a mathematical problem:'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 可堆叠特质使开发者能够在 Scala 中实现模型时遵循严格的数学形式主义。科学家使用一个普遍接受的模板来解决数学问题：
- en: Declare the variables relevant to the problem.
  id: totrans-675
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明与问题相关的变量。
- en: Define a model (equations, algorithms, formulas, and so on) as the solution
    to the problem.
  id: totrans-676
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个模型（方程、算法、公式等）作为问题的解决方案。
- en: Instantiate the variables and execute the model to solve the problem.
  id: totrans-677
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化变量并执行模型以解决问题。
- en: Let's consider the example of the concept of kernel functions (described in
    the *Kernel functions* section in [Chapter 8](part0200.xhtml#aid-5UNGG2 "Chapter 8. Kernel
    Models and Support Vector Machines"), *Kernel Models and Support Vector Machines*),
    a model that consists of a composition of two mathematical functions and its potential
    implementation in Scala.
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑核函数的概念示例（在第 8 章的 *核函数* 部分中描述，[第 8 章](part0200.xhtml#aid-5UNGG2 "第 8 章。核模型和支持向量机")，*核模型和支持向量机*），这是一个由两个数学函数的组合及其在
    Scala 中的潜在实现的模型。
- en: Step 1 – variable declaration
  id: totrans-679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 1 步 – 变量声明
- en: The implementation consists of wrapping (scope) the two functions into traits
    and defining these functions as abstract values.
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 实现包括将两个函数包装（作用域）到特质中，并将这些函数定义为抽象值。
- en: 'The mathematical formalism is as follows:'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 数学正式性如下：
- en: '![Step 1 – variable declaration](img/image01258.jpeg)'
  id: totrans-682
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 1 – 变量声明](img/image01258.jpeg)'
- en: 'The Scala implementation is as follows:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 实现如下：
- en: '[PRE54]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Step 2 – model definition
  id: totrans-685
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 2 – 模型定义
- en: 'The model is defined as the composition of the two functions. The `G` and `F`
    stack of traits describe the type of compatible functions that can be composed
    using the self-referenced `self: G with F` constraint.'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: '模型定义为两个函数的组合。`G`和`F`特质栈描述了可以使用自引用的`self: G with F`约束组合的兼容函数类型。'
- en: The formalism will be *h = f o g*.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 正式性将是 *h = f o g*。
- en: 'The Scala implementation is as follows:'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 实现如下：
- en: '[PRE55]'
  id: totrans-689
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Step 3 – instantiation
  id: totrans-690
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3 – 实例化
- en: The model is executed once the `f` and `g` variables are instantiated.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在`f`和`g`变量实例化后执行。
- en: 'The formalism will be as follows:'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 正式性如下：
- en: '![Step 3 – instantiation](img/image01259.jpeg)'
  id: totrans-693
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 3 – 实例化](img/image01259.jpeg)'
- en: 'The Scala implementation is as follows:'
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 实现如下：
- en: '[PRE56]'
  id: totrans-695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Note
  id: totrans-696
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Lazy value triggers**'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: '**懒值触发器**'
- en: In the preceding example, the value of *h(v) = g(f(v))* can be automatically
    computed as soon as *g* and *f* are initialized, by declaring *h* a lazy value.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，*h(v) = g(f(v))* 的值可以在 *g* 和 *f* 初始化后自动计算，通过将 *h* 声明为懒值。
- en: Clearly, Scala preserves the formalism of mathematical models, making it easier
    for scientists and developers to migrate their existing projects written in scientific-oriented
    languages, such as R.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，Scala 保留了数学模型的正式性，这使得科学家和开发者更容易将用科学导向语言编写的现有项目迁移到 Scala。
- en: Note
  id: totrans-700
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Emulation of R**'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: '**R 的模拟**'
- en: Most data scientists use the R language to create models and apply learning
    strategies. They may consider Scala as an alternative to R in some cases, as Scala
    preserves the mathematical formalism used in models implemented in R.
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学家使用 R 语言创建模型并应用学习策略。在某些情况下，他们可能会将 Scala 视为 R 的替代品，因为 Scala 保留了在 R 中实现的模型所使用的数学正式性。
- en: Let's extend the concept preservation of mathematical formalism to the dynamic
    creation of workflows using traits. The design pattern described in the next section
    is sometimes referred to as the **Cake pattern**.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将数学正式性的概念扩展到使用特质动态创建工作流程。下一节中描述的设计模式有时被称为 **Cake 模式**。
- en: Composing mixins to build a workflow
  id: totrans-704
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过组合 mixins 构建工作流程
- en: This section presents the key constructs behind the Cake pattern. A workflow
    composed of configurable data transformations requires a dynamic modularization
    (substitution) of the different stages of the workflow.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了 Cake 模式背后的关键构造。由可配置数据转换组成的流程需要动态模块化（替换）工作流程的不同阶段。
- en: Note
  id: totrans-706
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Traits and mixins**'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '**特质和 mixins**'
- en: Mixins are traits that are stacked against a class. The composition of mixins
    and the Cake pattern described in this section are important for defining the
    sequences of data transformations. However, the topic is not directly related
    to machine learning and so you can skip this section.
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: Mixins 是堆叠在类上的特质。本节中描述的 mixin 组合和 Cake 模式对于定义数据转换的序列很重要，但这个主题与机器学习没有直接关系，因此您可以跳过这一节。
- en: The Cake pattern is an advanced class composition pattern that uses mixin traits
    to meet the demands of a configurable computation workflow. It is also known as
    stackable modification traits [2:4].
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: Cake 模式是一种高级类组合模式，它使用 mixin 特质来满足可配置计算工作流程的需求。它也被称为可堆叠修改特质 [2:4]。
- en: This is not an in-depth analysis of the **stackable trait injection** and **self-reference**
    in Scala. There are few interesting articles on dependencies injection that are
    worth a look [2:5].
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是对 Scala 中的 **可堆叠特质注入** 和 **自引用** 的深入分析。有一些关于依赖注入的有趣文章值得一看 [2:5]。
- en: 'Java relies on packages tightly coupled with the directory structure and prefixed
    to modularize the code base. Scala provides developers with a flexible and reusable
    approach to create and organize modules: traits. Traits can be nested, mixed with
    classes, stacked, and inherited.'
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: Java 依赖于与目录结构紧密耦合的包，并使用前缀来模块化代码库。Scala 为开发者提供了一种灵活且可重用的方法来创建和组织模块：特质。特质可以嵌套、与类混合、堆叠和继承。
- en: Understanding the problem
  id: totrans-712
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解问题
- en: 'Dependency injection is a fancy name for a reverse look-up and binding to dependencies.
    Let''s consider a simple application that requires data preprocessing, classification,
    and validation. A simple implementation using traits looks like this:'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖注入是一个用于反向查找和绑定依赖关系的花哨名称。让我们考虑一个需要数据预处理、分类和验证的简单应用程序。使用特质的简单实现如下：
- en: '[PRE57]'
  id: totrans-714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'If, at a later stage, you need to use an unsupervised clustering algorithm
    instead of a classifier, then the application has to be rewired:'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在后续阶段需要使用无监督聚类算法而不是分类器，那么应用程序必须重新布线：
- en: '[PRE58]'
  id: totrans-716
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This approach results in code duplication and lack of flexibility. Moreover,
    the `filter` class member needs to be redefined for each new class in the composition
    of the application. The problem arises when there is a dependency between traits
    used in the composition. Let's consider the case for which the *filter* depends
    on the *validation* methodology.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法会导致代码重复和缺乏灵活性。此外，`filter` 类成员需要为应用程序组合中的每个新类重新定义。当组合中使用的特性之间存在依赖关系时，问题就出现了。让我们考虑这样一个案例，其中
    `filter` 依赖于 `validation` 方法。
- en: Note
  id: totrans-718
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Mixins linearization** [2:6]'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '**混合函数的线性化** [2:6]'
- en: 'The linearization or invocation of methods between mixins follows a right-to-left
    and base-to-subtype pattern:'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 混合函数之间的线性化或方法调用遵循从右到左和基类到子类的模式：
- en: Trait *B* extends *A*
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特性 *B* 扩展 *A*
- en: Trait *C* extends *A*
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特性 *C* 扩展 *A*
- en: Class *M* extends *N* with *C* with *B*
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类 *M* 扩展 *N*、*C* 和 *B*
- en: The Scala compiler implements the linearization as *A => B => C => N*.
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 编译器将线性化实现为 *A => B => C => N*。
- en: 'Although you can define `filter` as an abstract value, it still has to be redefined
    each time a new validation type is introduced. The solution is to use the `self`
    type in the definition of the newly composed `PreProcessingWithValidation` trait:'
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以将 `filter` 定义为一个抽象值，但它仍然需要在引入新的验证类型时重新定义。解决方案是在新组成的 `PreProcessingWithValidation`
    特质的定义中使用 `self` 类型：
- en: '[PRE59]'
  id: totrans-726
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The application is built by stacking the `PreProcessingWithValidation` mixin
    against the `Classification` class:'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序是通过将 `PreProcessingWithValidation` 混合函数堆叠到 `Classification` 类上来构建的：
- en: '[PRE60]'
  id: totrans-728
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-729
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Overriding def with val**'
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: '**用 val 覆盖 def**'
- en: 'It is advantageous to override the declaration of a method with a declaration
    of a value with the same signature. Contrary to a value that is assigned once
    for all during instantiation, a method may return a different value for each invocation.
    A **def** is a **proc** that can be redefined as a **def**, **val**, or **lazy
    val**. Therefore, you should not override a value declaration with a method with
    the same signature:'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 用具有相同签名的值声明覆盖方法声明是有利的。与在实例化期间一次性分配给所有值的值不同，方法可以为每次调用返回不同的值。一个 **def** 是一个可以重新定义为
    **def**、**val** 或 **lazy val** 的 **proc**。因此，你不应该用具有相同签名的值声明覆盖方法：
- en: '[PRE61]'
  id: totrans-732
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Let's adapt and generalize this pattern to construct a boilerplate template
    in order to create dynamic computational workflows.
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调整并推广这个模式，构建一个样板模板，以便创建动态计算工作流程。
- en: Defining modules
  id: totrans-734
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义模块
- en: The first step is to generate different modules to encapsulate different types
    of data transformation.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是生成不同的模块来封装不同类型的数据转换。
- en: Note
  id: totrans-736
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Use case for describing the cake pattern**'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述蛋糕模式的用例**'
- en: It is difficult to build an example of a real-world workflow using classes and
    algorithms introduced later in the book. The following simple example is realistic
    enough to illustrate the different components of the Cake pattern.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 使用书中后面介绍过的类和算法构建一个真实世界工作流程的示例很困难。以下简单的示例足以说明蛋糕模式的不同组件：
- en: 'Let''s define a sequence of the three parameterized modules that each define
    a specific data transformation using the explicit configuration of the `Etransform`
    type:'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个由三个参数化模块组成的序列，每个模块都使用 `Etransform` 类型的显式配置来定义特定的数据转换：
- en: '`Sampling`: This is used to extract a sample from raw data'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`采样`：这用于从原始数据中提取样本'
- en: '`Normalization`: This is used to normalize the sampled data over [0, 1]'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`归一化`：这用于将样本数据归一化到 [0, 1] 范围内'
- en: '`Aggregation`: This is used to aggregate or reduce the data'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`聚合`：这用于聚合或减少数据'
- en: 'The code will be as follows:'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE62]'
  id: totrans-744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The modules contain a single abstract value. One characteristic of the Cake
    pattern is to enforce strict modularity by initializing the abstract values with
    the type encapsulated in the module. One of the objectives in building the framework
    is allowing developers to create data transformation (inherited from `ETransform`)
    independently from any workflow.
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 模块包含一个抽象值。蛋糕模式的一个特点是通过对模块中封装的类型初始化抽象值来强制执行严格的模块化。构建框架的一个目标是在不依赖任何工作流程的情况下允许开发者独立创建数据转换（从`ETransform`继承）。
- en: Note
  id: totrans-746
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Scala traits and Java packages**'
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scala特性和Java包**'
- en: There is a major difference between Scala and Java in terms of modularity. Java
    packages constrain developers into following a strict syntax that requires, for
    instance, the source file to have the same name as the class it contains. Scala
    modules based on stackable traits are far more flexible.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 在模块化方面，Scala和Java之间存在重大差异。Java包将开发者约束在遵循严格的语法中，例如，源文件必须与包含的类同名。基于可堆叠特质的Scala模块要灵活得多。
- en: Instantiating the workflow
  id: totrans-749
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实例化工作流程
- en: 'The next step is to *write* the different modules into a workflow. This is
    achieved by using the `self` reference to the stack of the three traits defined
    in the previous section:'
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将不同的模块写入工作流程。这是通过使用前一个部分中定义的三个特质的`self`引用到栈中实现的：
- en: '[PRE63]'
  id: totrans-751
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'A picture is worth a thousand words; the following UML class diagram illustrates
    the workflow factory (or Cake) design pattern:'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 一图胜千言；以下UML类图说明了工作流程工厂（或蛋糕）设计模式：
- en: '![Instantiating the workflow](img/image01260.jpeg)'
  id: totrans-753
  prefs: []
  type: TYPE_IMG
  zh: '![实例化工作流程](img/image01260.jpeg)'
- en: The UML class diagram of the workflow factory
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程工厂的UML类图
- en: 'Finally, the workflow is instantiated by dynamically initializing the `sampler`,
    `normalizer`, and `aggregator` abstract values of the transformation as long as
    the signature (input and output types) matches the parameterized types defined
    in each module (line `1`):'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过动态初始化转换的`sampler`、`normalizer`和`aggregator`抽象值，只要签名（输入和输出类型）与每个模块中定义的参数化类型匹配（行`1`）来实例化工作流程：
- en: '[PRE64]'
  id: totrans-756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Let's implement the data transformation function for each of the three modules/traits
    by assigning a transformation to the abstract values.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过为抽象值分配转换来实现每个三个模块/特性的数据转换函数。
- en: 'The first transformation, `sampler`, samples a `f` function with frequency
    as *1/samples* over the interval [0, 1]. The second transformation, `normalizer`,
    normalizes the data over the range [0, 1] using the `Stats` class introduced in
    the next chapter. The last transformation, `aggregator`, extracts the index of
    the large sample (value 1.0):'
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个转换，`sampler`，在区间[0, 1]上以频率*1/samples*采样`f`函数。第二个转换，`normalizer`，使用下一章中引入的`Stats`类在范围[0,
    1]内归一化数据。最后一个转换，`aggregator`，提取大样本的索引（值1.0）：
- en: '[PRE65]'
  id: totrans-759
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The `sampler` transformation uses a single model or configuration parameter,
    `sample`, (line `2`). The `U` type of an input is defined as `Double => Double`
    (line `3`) and the `V` type of an output is defined as a vector of floating point
    values, `DblVector` (line `4`). In this particular case, the transformation consists
    of applying the input `f` function to a vector of increasing normalized values
    (line `5`).
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: '`sampler`转换使用单个模型或配置参数，`sample`（行`2`）。输入的`U`类型定义为`Double => Double`（行`3`），输出的`V`类型定义为浮点值向量，`DblVector`（行`4`）。在这种情况下，转换包括将输入的`f`函数应用于递增归一化值的向量（行`5`）。'
- en: 'The `normalizer` and `aggregator` transforms follow the same design pattern
    as `sampler`:'
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: '`normalizer`和`aggregator`转换遵循与`sampler`相同的模式：'
- en: '[PRE66]'
  id: totrans-762
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The instantiation of the transformation function follows the template described
    in the *Explicit models* section in this chapter.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: 转换函数的实例化遵循本章中“显式模型”部分中描述的模板。
- en: 'The workflow is now ready to process any function as an input:'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程现在可以处理任何函数作为输入：
- en: '[PRE67]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The workflow is executed by providing the input `g` function to the first `sampler`
    mixin (line `6`).
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程通过向第一个`sampler`混合提供输入`g`函数来执行（行`6`）。
- en: Scala's strong type checking catches any inconsistent data types at compilation
    time. It reduces the development cycle because runtime errors are more difficult
    to track down.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: Scala的强类型检查在编译时捕捉任何不一致的数据类型。它减少了开发周期，因为运行时错误更难追踪。
- en: Note
  id: totrans-768
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Mixins composition for ITransform**'
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: '**ITransform的混合组成**'
- en: We arbitrary selected a data transformation using an explicit `ETransform` configuration
    to illustrate the concept of mixins composition. The same pattern applies to the
    implicit `ITransform` data transformation.
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: 我们任意选择了一个使用显式 `ETransform` 配置的数据转换来展示混入（mixins）组合的概念。相同的模式也适用于隐式 `ITransform`
    数据转换。
- en: Modularization
  id: totrans-771
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模块化
- en: 'The last step is the modularization of the workflow. For complex scientific
    computations, you need to be able to do the following:'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是工作流程的模块化。对于复杂的科学计算，你需要能够做到以下几步：
- en: Select the appropriate *workflow* as a sequence of modules or tasks according
    to the objective of the execution (regression, classification, clustering, and
    so on).
  id: totrans-773
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据执行目标（回归、分类、聚类等）选择适当的 *工作流程* 作为模块或任务的序列。
- en: Select the appropriate *algorithm* to fulfill a task according to the data (noisy
    data, an incomplete training set, and so on).
  id: totrans-774
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据数据（噪声数据、不完整的训练集等）选择完成任务的适当 *算法*。
- en: Select the appropriate *implementation* of the algorithm according to the environment
    (distributed with a high-latency network, single host, and so on).![Modularization](img/image01261.jpeg)
  id: totrans-775
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据环境（具有高延迟网络的分布式、单个主机等）选择算法的适当 *实现*。![模块化](img/image01261.jpeg)
- en: An Illustration of the dynamic creation of a workflow from modules/traits
  id: totrans-776
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从模块/特性动态创建工作流程的示例
- en: 'Let''s consider a simple preprocessing task defined in the `PreprocessingModule`
    module. The module (or task) is declared as a trait to hide its internal workings
    from other modules. The preprocessing task is executed by a preprocessor of a
    `Preprocessor` type. We arbitrary list two algorithms: the exponential moving
    average of the `ExpMovingAverage` type and the discrete Fourier transform low
    pass filter of the `DFTFilter` type as a potential preprocessor:'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个在 `PreprocessingModule` 模块中定义的简单预处理任务。该模块（或任务）被声明为一个特性，以隐藏其内部工作原理对其他模块的可见性。预处理任务由
    `Preprocessor` 类型的预处理程序执行。我们任意列出两个算法：`ExpMovingAverage` 类型的指数移动平均和 `DFTFilter`
    类型的离散傅里叶变换低通滤波器作为潜在的预处理程序：
- en: '[PRE68]'
  id: totrans-778
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The generic preprocessor trait, `Preprocessor`, declares a single `execute`
    method whose purpose is to filter an `x` input vector of an element of a `T` type
    for noise (line `7`). The instance of the preprocessor is declared as an abstract
    class to be instantiated as one of the filtering algorithms (line `8`).
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 通用预处理特性 `Preprocessor` 声明了一个单一的 `execute` 方法，其目的是过滤 `x` 输入向量中 `T` 类型的元素以去除噪声（第
    `7` 行）。预处理器的实例被声明为一个抽象类，以便作为过滤算法之一进行实例化（第 `8` 行）。
- en: The first filtering algorithm of an `ExpMovingAverage` type implements the `Preprocessor`
    trait and overrides the `execute` method (line `9`). The class declares the algorithm
    but delegates its implementation to a class with an identical `org.scalaml.filtering.ExpMovingAverage`
    signature (line `10`). The partial function returned from the `|>` method is instantiated
    as a `pfn` value, so it can be applied multiple times (line `11`). The same design
    pattern is used for the discrete Fourier transform filter (line `12`).
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExpMovingAverage` 类型的第一个过滤算法实现了 `Preprocessor` 特性并覆盖了 `execute` 方法（第 `9` 行）。该类声明了算法，但其实现委托给具有相同
    `org.scalaml.filtering.ExpMovingAverage` 签名的类（第 `10` 行）。从 `|>` 方法返回的偏函数被实例化为 `pfn`
    值，因此它可以被多次应用（第 `11` 行）。相同的设计模式也用于离散傅里叶变换滤波器（第 `12` 行）。'
- en: The filtering algorithm (`ExpMovingAverage` or `DFTFir`) is selected according
    to the profile or characteristic of the input data. Its implementation in the
    `org.scalaml.filtering` package depends on the environment (a single host, cluster,
    Apache spark, and so on).
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输入数据的配置或特性选择过滤算法（`ExpMovingAverage` 或 `DFTFir`）。其在 `org.scalaml.filtering`
    包中的实现取决于环境（单个主机、集群、Apache spark 等）。
- en: Note
  id: totrans-782
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Filtering algorithms**'
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: '**过滤算法**'
- en: The filtering algorithms used to illustrate the concept of modularization in
    the context of the Cake pattern are described in detail in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*.
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Cake 模式背景下，用于展示模块化概念的过滤算法在 [第 3 章](part0172.xhtml#aid-5410O2 "第 3 章。数据预处理")
    *数据预处理* 中详细描述。
- en: Profiling data
  id: totrans-785
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置文件数据
- en: The selection of a preprocessing, clustering, or classification algorithm depends
    highly on the quality and profile of the input data (observations and expected
    values whenever available). The *Step 3 – preprocessing the data* section under
    *Let's kick the tires* in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting
    Started"), *Getting Started*, introduced the `MinMax` class for normalizing a
    dataset using the minimum and maximum values.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理、聚类或分类算法的选择高度依赖于输入数据（观察值和预期值，如果可用）的质量和特征。在[第1章](part0155.xhtml#aid-4JQ761
    "第1章。入门")中，“让我们试试轮胎”下的“第3步 - 预处理数据”部分介绍了`MinMax`类，用于使用最小值和最大值归一化数据集。
- en: Immutable statistics
  id: totrans-787
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可变统计
- en: The mean and standard deviation are the most commonly used statistics.
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 均值和标准差是最常用的统计量。
- en: Note
  id: totrans-789
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Mean and variance**'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值和方差**'
- en: 'Arithmetic mean is defined as:'
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 算术平均数定义为：
- en: '![Immutable statistics](img/image01262.jpeg)'
  id: totrans-792
  prefs: []
  type: TYPE_IMG
  zh: '![不可变统计](img/image01262.jpeg)'
- en: 'Variance is defined as:'
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: 方差定义为：
- en: '![Immutable statistics](img/image01263.jpeg)'
  id: totrans-794
  prefs: []
  type: TYPE_IMG
  zh: '![不可变统计](img/image01263.jpeg)'
- en: 'Variance adjusted for a sampling bias is defined as:'
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到抽样偏差的方差调整定义为：
- en: '![Immutable statistics](img/image01264.jpeg)'
  id: totrans-796
  prefs: []
  type: TYPE_IMG
  zh: '![不可变统计](img/image01264.jpeg)'
- en: 'Let''s extend the `MinMax` class with some basic statistics capabilities using
    `Stats`:'
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`Stats`扩展`MinMax`类以获得一些基本的统计功能：
- en: '[PRE69]'
  id: totrans-798
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The `Stats` class implements **immutable statistics**. Its constructor computes
    the sum of `values` and sum of square values, `sums` (line `1`). The statistics
    such as `mean` and `variance` are computed once when needed by declaring these
    values as lazy (line `2`). The `Stats` class inherits the normalization functions
    of `MinMax`.
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stats`类实现了**不可变统计**。其构造函数计算`values`的总和以及平方值的总和`sums`（行`1`）。如`mean`和`variance`之类的统计量在需要时通过将这些值声明为懒加载（行`2`）来一次性计算。`Stats`类继承了`MinMax`的归一化函数。'
- en: Z-Score and Gauss
  id: totrans-800
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Z分数与高斯
- en: The Gaussian distribution of the input data is implemented by the `gauss` method
    of the `Stats` class.
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据的高斯分布是通过`Stats`类的`gauss`方法实现的。
- en: Note
  id: totrans-802
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The Gaussian distribution**'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯分布**'
- en: 'M1: Gaussian for a mean μ and a standard deviation σ transformation is defined
    as:'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: M1：对于均值μ和标准差σ的变换，高斯定义为：
- en: '![Z-Score and Gauss](img/image01265.jpeg)'
  id: totrans-805
  prefs: []
  type: TYPE_IMG
  zh: '![Z分数与高斯](img/image01265.jpeg)'
- en: 'The code is as follows:'
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE70]'
  id: totrans-807
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The computation of the normal distribution is computed as a partially applied
    function. The Z-score is computed as a normalization of the raw data taking into
    account the standard deviation.
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布的计算作为一个部分应用函数。Z分数是通过考虑标准差对原始数据进行归一化计算得出的。
- en: Note
  id: totrans-809
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Z-score normalization**'
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: '**Z分数归一化**'
- en: 'M2: Z-score for a mean μ and a standard deviation σ is defined as:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: M2：对于均值μ和标准差σ的Z分数定义为：
- en: '![Z-Score and Gauss](img/image01266.jpeg)'
  id: totrans-812
  prefs: []
  type: TYPE_IMG
  zh: '![Z分数与高斯](img/image01266.jpeg)'
- en: 'The computation of the Z-score is implemented by the `zScore` method of `Stats`:'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: Z分数的计算是通过`Stats`类的`zScore`方法实现的：
- en: '[PRE71]'
  id: totrans-814
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The following graph illustrates the relative behavior of the `zScore` normalization
    and normal transformation:'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了`zScore`归一化和正态变换的相对行为：
- en: '![Z-Score and Gauss](img/image01267.jpeg)'
  id: totrans-816
  prefs: []
  type: TYPE_IMG
  zh: '![Z分数与高斯](img/image01267.jpeg)'
- en: A comparative analysis of linear, Gaussian, and Z-score normalization
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 线性、高斯和Z分数归一化的比较分析
- en: Assessing a model
  id: totrans-818
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: Evaluating a model is an essential part of the workflow. There is no point in
    creating the most sophisticated model if you do not have the tools to assess its
    quality. The validation process consists of defining some quantitative reliability
    criteria, setting a strategy such as a **K-fold cross-validation** scheme, and
    selecting the appropriate labeled data.
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型是工作流程的一个基本部分。如果你没有评估其质量的工具，创建最复杂的模型也没有意义。验证过程包括定义一些定量可靠性标准，设置策略，如**K折交叉验证**方案，并选择适当的有标签数据。
- en: Validation
  id: totrans-820
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证
- en: The purpose of this section is to create a reusable Scala class to validate
    models. For starters, the validation process relies on a set of metrics to quantify
    the fitness of a model generated through training.
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目的在于创建一个可重用的Scala类来验证模型。首先，验证过程依赖于一组指标来量化通过训练生成的模型的适用性。
- en: Key quality metrics
  id: totrans-822
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键质量指标
- en: 'Let''s consider a simple classification model with two classes defined as positive
    (with respect to negative) represented with Black (with respect to White) color
    in the following diagram. Data scientists use the following terminologies:'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个简单的具有两个类别的分类模型，正类（相对于负类）用黑色（相对于白色）在以下图中表示。数据科学家使用以下术语：
- en: '**True positives** (**TP**): These are observations that are correctly labeled
    as those that belong to the positive class (white dots on a dark background)'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**（**TP**）：这些是被正确标记为属于正类的观察值（在深色背景上的白色点）'
- en: '**True negatives** (**TN**): These are observations that are correctly labeled
    as those that belong to the negative class (black dots on a light background)'
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**（**TN**）：这些是被正确标记为属于负类的观察值（浅色背景上的黑色点）'
- en: '**False positives** (**FP**): These are observations incorrectly labeled as
    those that belong to the positive class (white dots on a dark background)'
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（**FP**）：这些是不正确标记为属于正类的观察值（深色背景上的白色点）'
- en: '**False negatives** (**FN**): These are observations incorrectly labeled as
    those that belong to the negative class (dark dots on a light background)![Key
    quality metrics](img/image01268.jpeg)'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（**FN**）：这些是不正确标记为属于负类的观察值（浅色背景上的深色点）![关键质量指标](img/image01268.jpeg)'
- en: Categorization of validation results
  id: totrans-828
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证结果分类
- en: 'This simplistic representation can be extended to classification problems that
    involve more than two classes. For instance, false positives are defined as observations
    incorrectly labeled that belong to any class other than the correct one. These
    four factors are used for evaluating accuracy, precision, recall, and F and G
    measures, as follows:'
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: 这种简单的表示可以扩展到涉及两个以上类别的分类问题。例如，假阳性被定义为不正确标记为属于任何其他类别的观察值。这四个因素用于评估准确度、精确度、召回率和
    F 及 G 度量，如下所示：
- en: '**Accuracy**: This is the percentage of observations correctly classified and
    is represented as *ac*.'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确度**：这是正确分类的观察值的百分比，用 *ac* 表示。'
- en: '**Precision**: This is the percentage of observations correctly classified
    as positive in the group that the classifier has declared positive. It is represented
    as *p*.'
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**：这是在分类器声明为正的组中正确分类为正的观察值的百分比。用 *p* 表示。'
- en: '**Recall**: This is the percentage of observations labeled as positive that
    are correctly classified and is represented as *r*.'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回忆率**：这是被标记为正的观察值中正确分类的比例，用 *r* 表示。'
- en: '**F[1]-measure or F[1]****-score**: This measure strikes a balance between
    precision and recall. It is computed as the harmonic mean of the precision and
    recall with values ranging between 0 (worst score) and 1 (best score). It is represented
    as *F[1]*.'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F[1]度量或F[1]分数**：这个度量在精确度和召回率之间取得平衡。它是精确度和召回率的调和平均数，分数范围在 0（最差分数）到 1（最佳分数）之间。用
    *F[1]* 表示。'
- en: '**F[n] score**: This is the generic F scoring method with an arbitrary *n*
    degree. It is represented as *F[n]*.'
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F[n]分数**：这是具有任意 *n* 次方的通用 F 分数方法。用 *F[n]* 表示。'
- en: '**G measure**: This is similar to the F-measure but is computed as the geometric
    mean of precision *p* and recall *r*. It is represented as *G*.'
  id: totrans-835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**G 度量**：这与 F 度量类似，但它是精确度 *p* 和召回率 *r* 的几何平均数。用 *G* 表示。'
- en: Note
  id: totrans-836
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Validation metrics**'
  id: totrans-837
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证指标**'
- en: 'M3:Accuracy *ac*, precision *p*, recall *r*, *F[1]*, *F[n]*, and *G* scores
    are defined as follows:'
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: M3：准确度 *ac*、精确度 *p*、召回率 *r*、*F[1]*、*F[n]* 和 *G* 分数定义如下：
- en: '![Key quality metrics](img/image01269.jpeg)'
  id: totrans-839
  prefs: []
  type: TYPE_IMG
  zh: '![关键质量指标](img/image01269.jpeg)'
- en: 'The computation of the precision, recall, and F[1] score depends on the number
    of classes used in the classifier. We will consider the following implementations:'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度、召回率和 F[1] 分数的计算取决于分类器中使用的类别数量。我们将考虑以下实现：
- en: F-score validation for binomial (two classes) classification (that is, a positive
    and negative outcome)
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二项式（两个类别）分类的 F 分数验证（即正负结果）
- en: F-score validation for multinomial (more than two classes) classification
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式（多于两个类别）分类的 F 分数验证
- en: F-score for binomial classification
  id: totrans-843
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二项式分类的 F 分数
- en: The binomial F validation computes the precision, recall, and F scores for the
    positive class.
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: 二项式 F 验证计算正类的精确度、召回率和 F 分数。
- en: 'Let''s implement the F-score or F-measure as a specialized validation of the
    following:'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现 F 分数或 F 度量作为以下特殊验证：
- en: '[PRE72]'
  id: totrans-846
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The `BinFValidation` class encapsulates the computation of the *F[n]* score
    as well as precision and recall by counting the occurrences of *TP*, *TN*, *FP*,
    and *FN* values. It implements the **M3** formula. In the tradition of Scala programming,
    the class is immutable; it computes the counters for *TP*, *TN*, *FP*, and *FN*
    when the class is instantiated. The class takes the following three parameters:'
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: '`BinFValidation`类封装了*F[n]*分数以及精确度和召回率的计算，通过计数*TP*、*TN*、*FP*和*FN*值来实现。它实现了**M3**公式。在Scala编程的传统中，该类是不可变的；它在类实例化时计算*TP*、*TN*、*FP*和*FN*的计数器。该类接受以下三个参数：'
- en: The `expected` values with the `0` value for a negative outcome and `1` for
    a positive outcome
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于负结果为`0`值和正结果为`1`值的`expected`值
- en: The set of observations, `xt`, is used for validating the model
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观测值集`xt`用于验证模型
- en: The predictive `predict` function classifies observations (line `1`)
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的`predict`函数对观测值进行分类（行`1`）
- en: 'The code will be as follows:'
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE73]'
  id: totrans-852
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The constructor counts the number of occurrences for each of the four outcomes
    (*TP*, *TN*, *FP*, and *FN*) (line `2`). The `precision`, `recall`, and `f1` values
    are defined as lazy values so they are computed only once, when they are accessed
    directly or the `score` method is invoked (line `4`). The F[1] measure is the
    most commonly used scoring value for validating classifiers. Therefore, it is
    the default score (line `3`). The `classify` private method extracts the qualifier
    from the expected and predicted values (line `5`).
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数计算每个四个结果（*TP*、*TN*、*FP*和*FN*）的出现次数（行`2`）。`precision`、`recall`和`f1`值被定义为懒值，因此它们仅在直接访问或调用`score`方法时计算（行`4`）。F[1]度量是验证分类器最常用的评分值，因此它是默认评分（行`3`）。`classify`私有方法从预期值和预测值中提取限定符（行`5`）。
- en: The `BinFValidation` class is independent of the type of classifier, training,
    labeling process, and type of observations.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: '`BinFValidation`类与分类器类型、训练、标记过程和观测类型无关。'
- en: 'Contrary to Java, which defines an enumerator as a class of types, Scala requires
    enumerators to be singletons. Enumerators extend the `scala.Enumeration` abstract
    class:'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: 与Java不同，Java将枚举定义为类型类，Scala要求枚举必须是单例。枚举扩展了`scala.Enumeration`抽象类：
- en: '[PRE74]'
  id: totrans-856
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The F-score formula with higher cardinality (F[n]) with *n > 1* favors precision
    over recall, which is shown in the following graph:'
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 具有更高基数（F[n]）的F分数公式（n > 1）优先考虑精确度而不是召回率，这在以下图表中显示：
- en: '![F-score for binomial classification](img/image01270.jpeg)'
  id: totrans-858
  prefs: []
  type: TYPE_IMG
  zh: '![二项式分类的F分数](img/image01270.jpeg)'
- en: A comparative analysis of the impact of precision on F1, F2, and F3 score for
    a given recall
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: 对给定召回率下精确度对F1、F2和F3分数影响的比较分析
- en: Note
  id: totrans-860
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Multiclass scoring**'
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: '**多类评分**'
- en: Our implementation of the binomial validation computes the precision, recall,
    and F[1] score for the positive class only. The generic multinomial validation
    class presented in the next section computes these quality metrics for both positive
    and negative classes.
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的二项式验证计算仅对正类进行精确度、召回率和F[1]分数。下一节中介绍的通用多项式验证类计算正类和负类的这些质量指标。
- en: F-score for multinomial classification
  id: totrans-863
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多项式分类的F分数
- en: 'The validation metric is defined by the **M3** formula. The idea is quite simple:
    the precision and recall values are computed for all the classes and then they
    are averaged to produce a single precision and recall value for the entire model.
    The precision and recall for the entire model leverage the counts of *TP*, *FP*,
    *FN*, and *TN* introduced in the previous section.'
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: 验证指标由**M3**公式定义。其思想非常简单：计算所有类别的精确度和召回率值，然后取平均值以产生整个模型的单个精确度和召回率值。整个模型的精确度和召回率利用了上一节中引入的*TP*、*FP*、*FN*和*TN*的计数。
- en: 'There are two commonly used set of formulas to compute the precision and recall
    for a model:'
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: 有两组常用的公式用于计算模型的精确度和召回率：
- en: '**Macro**: This method computes the precision and recall for each class, sums
    and then averages them up.'
  id: totrans-866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宏**：此方法计算每个类的精确度和召回率，然后求和并取平均值。'
- en: '**Micro**: This method sums the numerator and denominator of the precision
    and recall formulas for all the classes before computing the precision and recall.'
  id: totrans-867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微**：此方法在计算精确度和召回率之前，对所有类别的精确度和召回率的分子和分母进行求和。'
- en: We will use the macro formulas from now on.
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将使用宏公式。
- en: Note
  id: totrans-869
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Macro formulas for multinomial precision and recall**'
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: '**多项式精确度和召回率的宏公式**'
- en: 'M4: The macro version of the precision *p* and recall *r* for a model of the
    *c* classes is computed as follows:'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: M4：对于*c*个类别的模型，精确率*p*和召回率*r*的宏版本计算如下：
- en: '![F-score for multinomial classification](img/image01271.jpeg)'
  id: totrans-872
  prefs: []
  type: TYPE_IMG
  zh: '![多项式分类的F分数](img/image01271.jpeg)'
- en: 'The computation of the precision and recall factor for a classifier with more
    than two classes requires the extraction and manipulation of the **confusion matrix**.
    We use the following convention: *expected values are defined as columns and predicted
    values are defined as rows*.'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有两个以上类别的分类器，计算精确率和召回率因子需要提取和操作**混淆矩阵**。我们使用以下约定：*预期值定义为列，预测值定义为行*。
- en: '![F-score for multinomial classification](img/image01272.jpeg)'
  id: totrans-874
  prefs: []
  type: TYPE_IMG
  zh: '![多项式分类的F分数](img/image01272.jpeg)'
- en: A confusion matrix for six class classification
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: 六类分类的混淆矩阵
- en: 'The `MultiFValidation` multinomial validation class takes the following four
    parameters:'
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: '`MultiFValidation`多项式验证类接受以下四个参数：'
- en: The `expected` class index with the `0` value for a negative outcome and `1`
    for a positive outcome
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`expected`类别索引，对于负结果值为`0`，对于正结果值为`1`'
- en: The set of observations, `xt`, is used for validating the model
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用观测集`xt`来验证模型
- en: The number of `classes` in the model
  id: totrans-879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型中的`classes`数量
- en: The `predict` predictive function classifies observations (line `7`)
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict`预测函数对观测值进行分类（第7行）'
- en: 'The code will be as follows:'
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE75]'
  id: totrans-882
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The core element of the multiclass validation is the confusion matrix, `confusionMatrix`
    (line `8`). Its elements at indices *(i, j) = (index of expected class for an
    observation, index of the predicted class for the same observation)* are computed
    using the expected and predictive outcome for each class (line `9`).
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: 多类验证的核心元素是混淆矩阵，`confusionMatrix`（第8行）。其元素在索引*(i, j) = (观测值的预期类别索引，相同观测值的预测类别索引)*处计算，使用每个类别的预期和预测结果（第9行）。
- en: As stated in the introduction of the section, we use the macro definition of
    the precision and recall (line `10`). The count of a true positive, `tp`, for
    each class corresponds to the diagonal element of the confusion matrix (line `11`).
    The count of the `fn` false negatives for a class is computed as the sum of the
    counts for all the predicted classes (column values), given an expected class
    except the true positive class (line `12`). The count of the `fp` false positives
    for a class is computed as the sum of the counts for all the expected classes
    (row values), given a predicted class except the true positive class (line `13`).
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节引言所述，我们使用宏定义的精确率和召回率（第10行）。每个类别的真阳性`tp`计数对应于混淆矩阵的对角元素（第11行）。一个类别的假阴性`fn`计数是所有预测类别计数之和（列值），给定一个预期类别（除了真阳性类别）（第12行）。一个类别的假阳性`fp`计数是所有预期类别计数之和（行值），给定一个预测类别（除了真阳性类别）（第13行）。
- en: The formula for the computation of the F[1] score is the same as the formula
    used in the binomial validation.
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: 计算F[1]分数的公式与二项式验证中使用的公式相同。
- en: Cross-validation
  id: totrans-886
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: It is quite common that the labeled dataset (observations plus the expected
    outcome) available to the scientists is not very large. The solution is to break
    the original labeled dataset into *K* groups of data.
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: 对于科学家可用的标记数据集（观测值加上预期结果），通常不是很大。解决方案是将原始标记数据集分成*K*组数据。
- en: One-fold cross validation
  id: totrans-888
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单折交叉验证
- en: 'The one-fold cross validation is the simplest scheme used for extracting a
    training set and validation set from a labeled dataset, as described in the following
    diagram:'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: 单折交叉验证是从标记数据集中提取训练集和验证集所使用的最简单方案，如下图中所述：
- en: '![One-fold cross validation](img/image01273.jpeg)'
  id: totrans-890
  prefs: []
  type: TYPE_IMG
  zh: '![单折交叉验证](img/image01273.jpeg)'
- en: An illustration of the generation of a one-fold validation set
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: 单折验证集生成的示意图
- en: 'The one-fold cross validation methodology consists of the following three steps:'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 单折交叉验证方法包括以下三个步骤：
- en: Select the ratio of the size of the training set over the size of the validation
    set.
  id: totrans-893
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择训练集大小与验证集大小的比例。
- en: Randomly select the labeled observations for the validation phase.
  id: totrans-894
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机选择用于验证阶段的标记观测值。
- en: Create the training set as the remaining labeled observations.
  id: totrans-895
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将剩余的标记观测值创建为训练集。
- en: 'The one-fold cross validation is implemented by the `OneFoldXValidation` class.
    It takes the following three arguments: an `xt` vector of observations, the `expected`
    vector of expected classes, and `ratio` of the size of the training set over the
    size of the validation set (line `14`):'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 单折交叉验证是通过`OneFoldXValidation`类实现的。它接受以下三个参数：观测值的`xt`向量，预期类别的`expected`向量，以及训练集大小与验证集大小的`ratio`（第`14`行）：
- en: '[PRE76]'
  id: totrans-897
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The constructor of the `OneFoldXValidation` class generates the segregated
    training and validation sets from the set of observations and expected classes
    (line `15`):'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: '`OneFoldXValidation`类的构造函数从观测值和预期类别的集合中生成分离的训练集和验证集（第`15`行）：'
- en: '[PRE77]'
  id: totrans-899
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: The initialization of the `OneFoldXValidation` class creates a `labeledData`
    vector of labeled observations by zipping the observations and the expected outcome
    (line `16`). The training `ratio` value is used to compute the respective size
    of the training set (line `17`) and validation set (line `18`).
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '`OneFoldXValidation`类的初始化通过将观测值和预期结果进行压缩来创建标记观测值的`labeledData`向量（第`16`行）。训练`ratio`值用于计算训练集（第`17`行）和验证集（第`18`行）的相应大小。'
- en: In order to create training and validations sets randomly, we zip the labeled
    dataset with a random generator (line `19`), and then reorder the labeled dataset
    by sorting the random values (line `20`). Finally, the method returns the pair
    of training set and validation set (line `21`).
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 为了随机创建训练集和验证集，我们将标记的数据集与随机生成器进行压缩（第`19`行），然后通过排序随机值对标记的数据集进行重新排序（第`20`行）。最后，该方法返回训练集和验证集的成对（第`21`行）。
- en: K-fold cross validation
  id: totrans-902
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K折交叉验证
- en: The data scientist creates *K* training-validation datasets by selecting one
    of the groups as a validation set and then combining all the remaining groups
    into a training set, as illustrated in the following diagram. The process is known
    as the **K-fold cross validation** [2:7].
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家通过选择一个组作为验证集，然后将所有剩余的组合并成一个训练集来创建*K*个训练-验证数据集，如图所示。这个过程被称为**K折交叉验证** [2:7]。
- en: '![K-fold cross validation](img/image01274.jpeg)'
  id: totrans-904
  prefs: []
  type: TYPE_IMG
  zh: '![K折交叉验证](img/image01274.jpeg)'
- en: An illustration of the generation of a K-fold cross validation set
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了K折交叉验证集的生成
- en: The third segment is used as validation data and all other dataset segments
    except S3 are combined into a single training set. This process is applied to
    each segment of the original labeled dataset.
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 第三部分用作验证数据，除了S3之外的所有数据集部分合并成一个单独的训练集。这个过程应用于原始标记数据集的每个部分。
- en: Bias-variance decomposition
  id: totrans-907
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差-方差分解
- en: The challenge is to create a model that fits both the training set and subsequent
    observations to be classified during the validation phase.
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战在于创建一个模型，该模型既能拟合训练集，也能在验证阶段正确分类后续的观测值。
- en: If the model tightly fits the observations selected for training, there is a
    high probability that new observations may not be correctly classified. This is
    usually the case when the model is complex. This model is characterized as having
    a low bias with a high variance. Such a scenario can be attributed to the fact
    that the scientist is overly confident that the observations she/he selected for
    training are representative of the real world.
  id: totrans-909
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型紧密地拟合了用于训练的观测值，那么新观测值可能无法被正确分类。这通常发生在模型复杂的情况下。这种模型的特点是具有低偏差和高方差。这种场景可以归因于科学家过度自信地认为她/他选择的用于训练的观测值代表了现实世界。
- en: The probability of a new observation being classified as belonging to a positive
    class increases as the selected model fits loosely the training set. In this case,
    the model is characterized as having a high bias with a low variance.
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: 当选定的模型对训练集的拟合较为宽松时，新观测值被分类为正类别的概率会增加。在这种情况下，该模型的特点是具有高偏差和低方差。
- en: 'The mathematical definition for the **bias**, **variance**, and **mean square
    error** (MSE) of the distribution are defined by the following formulas:'
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: 分布的**偏差**、**方差**和**均方误差**（MSE）的数学定义由以下公式给出：
- en: Note
  id: totrans-912
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M5: Variance and bias for a true model, θ, is defined as:'
  id: totrans-913
  prefs: []
  type: TYPE_NORMAL
  zh: 'M5: 对于真实模型θ，其方差和偏差定义为：'
- en: '![Bias-variance decomposition](img/image01275.jpeg)'
  id: totrans-914
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01275.jpeg)'
- en: 'M6: Mean square error is defined as:'
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: 'M6: 均方误差定义为：'
- en: '![Bias-variance decomposition](img/image01276.jpeg)'
  id: totrans-916
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01276.jpeg)'
- en: 'Let''s illustrate the concept of bias, variance, and mean square error with
    an example. At this stage, you have not been introduced to most of the machines
    learning techniques. Therefore, we create a simulator to illustrate the relation
    between the bias and variance of a classifier. The components of the simulation
    are as follows:'
  id: totrans-917
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来说明偏差、方差和均方误差的概念。在这个阶段，你还没有接触到大多数机器学习技术。因此，我们创建了一个模拟器来展示分类器的偏差和方差之间的关系。模拟的组成部分如下：
- en: A training set, `training`
  id: totrans-918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集，`training`
- en: 'A simulated `target` model of the `target: Double => Double` type extracted
    from the training set'
  id: totrans-919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '从训练集中提取的`target: Double => Double`类型的模拟`target`模型'
- en: A set of possible `models` to evaluate
  id: totrans-920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组可能的`models`用于评估
- en: A model that exactly matches the training data overfits the target model. Models
    that approximate the target model will most likely underfit. The models in this
    example are defined by single variable functions.
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: 完全匹配训练数据的模型会过拟合目标模型。近似目标模型的模型很可能会欠拟合。本例中的模型由单变量函数定义。
- en: 'These models are evaluated against a validation dataset. The `BiasVariance`
    class takes the target model, `target`, and the size of the `nValues` validation
    test as parameters (line `22`). It merely implements the formula to compute the
    bias and variance for each model:'
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型与验证数据集进行比较。`BiasVariance`类接受目标模型`target`和验证测试的`nValues`大小作为参数（行`22`）。它仅实现了计算每个模型的偏差和方差的公式：
- en: '[PRE78]'
  id: totrans-923
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The `fit` method computes the variance and bias for each of the `models` model
    compared to the `target` model (line `23`). It computes the mean, variance, and
    bias in the `accumulate` method (line `24`):'
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit`方法计算每个`models`模型相对于`target`模型的方差和偏差（行`23`）。它在`accumulate`方法中计算均值、方差和偏差（行`24`）：'
- en: '[PRE79]'
  id: totrans-925
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The training data is generated by the single variable function with the *r[1]*
    and *r[2]* noise components:'
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据由具有噪声成分*r[1]*和*r[2]*的单变量函数生成：
- en: '![Bias-variance decomposition](img/image01277.jpeg)'
  id: totrans-927
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01277.jpeg)'
- en: 'The `accumulate` method returns a tuple (variance, bias) for each model, *f*
    (line `25`). The model candidates are defined by the following family of single
    variable for values *n = 1, 2, and 4*:'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: '`accumulate`方法为每个模型返回一个元组（方差，偏差）*f*（行`25`）。模型候选者由以下单变量函数族定义，对于值*n = 1, 2, 和
    4*：'
- en: '![Bias-variance decomposition](img/image01278.jpeg)'
  id: totrans-929
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01278.jpeg)'
- en: 'The `target` model (line `26`) and `models` (line `27`) belong to the same
    family of single variable functions:'
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: '`target`模型（行`26`）和`models`（行`27`）属于同一类单变量函数：'
- en: '[PRE80]'
  id: totrans-931
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The **JFreeChart** library is used to display the training dataset and the
    models:'
  id: totrans-932
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**JFreeChart**库显示训练数据集和模型：
- en: '![Bias-variance decomposition](img/image01279.jpeg)'
  id: totrans-933
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01279.jpeg)'
- en: Fitting models to dataset
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型拟合到数据集
- en: 'The model that replicates the training data overfits. The models that smooth
    the model with lower amplitude for the sine component of the `template` function
    underfit. The **variance-bias trade-off** for the different models and training
    data is illustrated in the following scatter chart:'
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: 复制训练数据的模型会过拟合。对`template`函数的正弦分量使用较低振幅进行平滑的模型会欠拟合。不同模型和训练数据的**偏差-方差权衡**在以下散点图中展示：
- en: '![Bias-variance decomposition](img/image01280.jpeg)'
  id: totrans-936
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01280.jpeg)'
- en: Scatter plot for the bias-variance trade-off for four models, one duplicating
    the training set
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: 四个模型的偏差-方差权衡的散点图，其中一个复制了训练集
- en: 'The variance of each of the smoothing or approximating models is lower than
    the variance of the training set. As expected the target model, *0.2.x.(1+sin(x/10))*,
    has no bias and no variance. The training set has a very high variance because
    it overfits any target model. The last chart compares the mean square error between
    each of the models, training set, and the target model:'
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 每个平滑或近似模型的方差都低于训练集的方差。正如预期的那样，目标模型*0.2.x.(1+sin(x/10))*没有偏差和方差。训练集具有非常高的方差，因为它对任何目标模型都过拟合。最后一张图表比较了每个模型、训练集和目标模型之间的均方误差：
- en: '![Bias-variance decomposition](img/image01281.jpeg)'
  id: totrans-939
  prefs: []
  type: TYPE_IMG
  zh: '![偏差-方差分解](img/image01281.jpeg)'
- en: Comparative mean squares error for four models
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: 四个模型的比较均方误差
- en: Note
  id: totrans-941
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Evaluating bias and variance**'
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估偏差和方差**'
- en: The section uses a fictitious target model and training set to illustrate the
    concept of the bias and variance of models. The bias and variance of machine learning
    models are actually estimated using validation data.
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: 该节使用一个虚构的目标模型和训练集来说明模型的偏差和方差的概念。机器学习模型的偏差和方差实际上是通过验证数据来估计的。
- en: Overfitting
  id: totrans-944
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过度拟合
- en: You can apply the methodology presented in the example to any classification
    and regression model. The list of models with low variance includes constant functions
    and models independent of the training set. High degree polynomials, complex functions,
    and deep neural networks have high variance. Linear regression applied to linear
    data has a low bias, while linear regression applied to nonlinear data has a higher
    bias [2:8].
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将示例中提出的方法应用于任何分类和回归模型。具有低方差模型的列表包括常数函数和与训练集无关的模型。高次多项式、复杂函数和深度神经网络具有高方差。应用于线性数据的线性回归具有低偏差，而应用于非线性数据的线性回归具有更高的偏差
    [2:8]。
- en: 'Overfitting affects all aspects of the modeling process negatively, for example:'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: 过度拟合对建模过程的各个方面都有负面影响，例如：
- en: It renders debugging difficult
  id: totrans-947
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使得调试变得困难
- en: It makes the model too dependent of minor fluctuations (long tail) and noisy
    data
  id: totrans-948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使模型过于依赖微小的波动（长尾）和噪声数据
- en: It may discover irrelevant relationships between observed and latent features
  id: totrans-949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可能会发现观测特征和潜在特征之间不相关的关系
- en: It leads to poor predictive performance
  id: totrans-950
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它导致预测性能不佳
- en: 'However, there are well-proven solutions to reduce overfitting [2:9]:'
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些经过充分验证的解决方案可以减少过度拟合 [2:9]：
- en: Increasing the size of the training set whenever possible
  id: totrans-952
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可能的情况下增加训练集的大小
- en: Reducing noise in labeled observations using smoothing and filtering techniques
  id: totrans-953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用平滑和过滤技术减少标记观察中的噪声
- en: Decreasing the number of features using techniques such as principal components
    analysis, as discussed in the *Principal components analysis* section in [Chapter
    4](part0178.xhtml#aid-59O442 "Chapter 4. Unsupervised Learning"), *Unsupervised
    Learning*
  id: totrans-954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用主成分分析等技术减少特征数量，如第4章[主成分分析](https://wiki.example.org/part0178#aid-59O442 "第4章.
    无监督学习")中所述，*无监督学习*
- en: Modeling observable and latent noisy data using Kalman or auto regressive models,
    as discussed in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"),
    *Data Preprocessing*
  id: totrans-955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卡尔曼或自回归模型对可观测和潜在噪声数据进行建模，如第3章[数据预处理](https://wiki.example.org/part0172#aid-5410O2
    "第3章. 数据预处理")中所述，*数据预处理*
- en: Reducing inductive bias in a training set by applying cross-validation
  id: totrans-956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过应用交叉验证减少训练集中的归纳偏差
- en: Penalizing extreme values for some of the model's features using regularization
    techniques, as discussed in the *Regularization* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*
  id: totrans-957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则化技术惩罚模型的一些特征中的极端值，如第6章[正则化](https://wiki.example.org/part0188#aid-5J99O2
    "第6章. 回归和正则化")中所述，*回归和正则化*
- en: Summary
  id: totrans-958
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we established the framework for the different data processing
    units that will be introduced in this book. There is a very good reason why the
    topics of model validation and overfitting are explored early in this book. There
    is no point in building models and selecting algorithms if we do not have a methodology
    to evaluate their relative merits.
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为本书中将要介绍的不同数据处理单元建立了框架。在本书中早期探讨模型验证和过度拟合的话题有很好的理由。如果我们没有一种方法来评估它们的相对优点，那么构建模型和选择算法就没有意义。
- en: 'In this chapter, you were introduced to the following:'
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你被介绍了以下内容：
- en: The concept of monadic transformation for implicit and explicit models
  id: totrans-961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐式和显式模型的单子变换概念
- en: The versatility and cleanness of the Cake pattern and mixins composition in
    Scala as an effective scaffolding tool for data processing
  id: totrans-962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scala中Cake模式及其mixins组合的灵活性和简洁性，作为数据处理的有效脚手架工具
- en: A robust methodology to validate machine learning models
  id: totrans-963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种稳健的方法来验证机器学习模型
- en: The challenge in fitting models to both training and real-world data
  id: totrans-964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据和现实世界数据中的挑战
- en: The next chapter will address the problem of overfitting by identifying outliers
    and reducing noise in data.
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将通过识别异常值和减少数据中的噪声来解决这个问题，即过度拟合。
- en: Chapter 3. Data Preprocessing
  id: totrans-966
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章 数据预处理
- en: Real-world data is usually noisy and inconsistent with missing observations.
    No classification, regression, or clustering model can extract relevant information
    from raw data.
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: 实际数据通常是有噪声的，并且与缺失观察不一致。没有任何分类、回归或聚类模型可以从原始数据中提取相关信息。
- en: 'Data preprocessing consists of cleaning, filtering, transforming, and normalizing
    raw observations using statistics in order to correlate features or groups of
    features, identify trends and models, and filter out noise. The purpose of cleansing
    raw data is as follows:'
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理包括使用统计方法对原始观察数据进行清理、过滤、转换和归一化，以便关联特征或特征组，识别趋势和模型，并过滤掉噪声。清理原始数据的目的如下：
- en: To extract some basic knowledge from raw datasets
  id: totrans-969
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据集中提取一些基本知识
- en: To evaluate the quality of data and generate clean datasets for unsupervised
    or supervised learning
  id: totrans-970
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估数据质量并生成用于无监督或监督学习的干净数据集
- en: You should not underestimate the power of traditional statistical analysis methods
    to infer and classify information from textual or unstructured data.
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: 你不应低估传统统计分析方法从文本或非结构化数据中推断和分类信息的能力。
- en: 'In this chapter, you will learn how to:'
  id: totrans-972
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何：
- en: Apply commonly used moving average techniques to detect long-term trends in
    a time series
  id: totrans-973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将常用的移动平均技术应用于时间序列以检测长期趋势
- en: Identify market and sector cycles using discrete Fourier series
  id: totrans-974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用离散傅里叶级数识别市场和行业周期
- en: Leverage the discrete Kalman filter to extract the state of a linear dynamic
    system from incomplete and noisy observations
  id: totrans-975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用离散卡尔曼滤波器从不完全和有噪声的观察中提取线性动态系统的状态
- en: Time series in Scala
  id: totrans-976
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala中的时间序列
- en: The overwhelming majority of examples used to illustrate the different machine
    algorithms in this book deal with time series or sequential, time-ordered set
    of observations.
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: 本书用于说明不同机器算法的大多数示例都涉及时间序列或按时间顺序排列的观察数据集。
- en: Types and operations
  id: totrans-978
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类型和方法
- en: The *Primitives types* section under *Source code* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*, introduced the types for a time
    series of a single `XSeries[T]` variable and multiple `XVSeries[T]` variables.
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](part0155.xhtml#aid-4JQ761 "第1章。入门")中“源代码”部分的“原始类型”部分介绍了单个`XSeries[T]`变量和多个`XVSeries[T]`变量时间序列的类型。
- en: 'A time series of observations is a vector (a `Vector` type) of observation
    elements of the following types:'
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: 观察的时间序列是以下类型的观察元素向量（一个`Vector`类型）：
- en: A `T` type in the case of a single variable/feature observation
  id: totrans-981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于单个变量/特征观察，使用`T`类型。
- en: An `Array[T]` type for observations with more than one variable/feature
  id: totrans-982
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于具有多个变量/特征的观察，使用`Array[T]`类型
- en: A time series of labels or expected values is a single variable vector for which
    elements may have a primitive `Int` type for classification and `Double` for regression.
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: 标签或预期值的时间序列是一个单一变量向量，其元素可以是用于分类的原始`Int`类型和用于回归的`Double`类型。
- en: 'A time series of labeled observations is a pair of a vector of observations
    and a vector of labels:'
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: 标记观察的时间序列是一对观察向量与标签向量：
- en: '![Types and operations](img/image01282.jpeg)'
  id: totrans-985
  prefs: []
  type: TYPE_IMG
  zh: '![类型和操作](img/image01282.jpeg)'
- en: Visualization of the single features and multi-feature observations
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: 单个特征和多特征观察的可视化
- en: The two generic `XSeries` and `XVSeries` types for the time series will be used
    as the two primary classes for the input data, from now on.
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在起，将使用两个通用的`XSeries`和`XVSeries`类型作为输入数据的主要类，用于时间序列。
- en: Note
  id: totrans-988
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Structure of labeled observations**'
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: '**标记观察的结构**'
- en: Throughout the book, labeled observations are defined either as a pair of vector
    of observations and a vector of labels/expected values or as a vector of a pair
    of {observation, label/expected value}.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，标记观察被定义为观察向量和标签/预期值向量的对，或者是一对{观察，标签/预期值}的向量。
- en: 'The `Stats` class introduced in the *Profiling data* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*, implements some basic statistics and
    normalization for single variable observations. Let''s create an `XTSeries` singleton
    to compute the statistics and normalize multidimensional observations:'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](part0165.xhtml#aid-4TBCQ2 "第2章。Hello World！")中“数据概要”部分介绍的`Stats`类，实现了对单个变量观察的一些基本统计和归一化。让我们创建一个`XTSeries`单例来计算统计信息和归一化多维观察：
- en: '[PRE81]'
  id: totrans-992
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The first method of the `XTSeries` singleton generates a vector of a pair of
    elements by zipping the last *size – n* elements of a time series with its first
    *size – n* elements (line `1`). The `statistics` (line `2`) and `normalize` (line
    `3`) methods operate on both the single and multivariable observations. These
    three methods are subsets of functionalities implemented in `XTSeries`.
  id: totrans-993
  prefs: []
  type: TYPE_NORMAL
  zh: '`XTSeries`单例的第一个方法通过将时间序列的最后`size – n`个元素与它的第一个`size – n`个元素进行连接来生成一对元素的向量（行`1`）。`statistics`（行`2`）和`normalize`（行`3`）方法作用于单变量和多变量观测。这三个方法是`XTSeries`中实现的功能的子集。'
- en: 'Create a time series of the `XVSeries[T]` type by zipping the two `x` and `y`
    vectors and converting the pair into an array:'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将两个`x`和`y`向量进行连接并转换成数组来创建一个`XVSeries[T]`类型的时间序列：
- en: '[PRE82]'
  id: totrans-995
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Split a single or multidimensional time series, `xv`, into a two-time series
    at index, *n*:'
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: 将单维或多维时间序列`xv`在索引*n*处分割成两个时间序列：
- en: '[PRE83]'
  id: totrans-997
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Apply a `zScore` transform to a single dimension time series:'
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: 对单维时间序列应用`zScore`转换：
- en: '[PRE84]'
  id: totrans-999
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Apply a `zScore` transform to a multidimension time series:'
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 对多维时间序列应用`zScore`转换：
- en: '[PRE85]'
  id: totrans-1001
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Transform a single dimension time series `x` into a new time series whose elements
    are *x(n) – x(n-1)*:'
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 将单维时间序列`x`转换成一个新的时间序列，其元素为*x(n) – x(n-1)*：
- en: '[PRE86]'
  id: totrans-1003
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Transform a single dimension time series `x` into a new time series which elements
    if *(x(n) – x(n-1) > 0.0) 1 else 0*:'
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 将单维时间序列`x`转换成一个新的时间序列，其元素为*(x(n) – x(n-1) > 0.0) 1 else 0*：
- en: '[PRE87]'
  id: totrans-1005
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Compute the sum of the squared error between the two `x` and `z` arrays:'
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: 计算两个`x`和`z`数组之间平方误差的和：
- en: '[PRE88]'
  id: totrans-1007
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Compute the mean squared error between the two `x` and `z` arrays:'
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: 计算两个`x`和`z`数组之间的均方误差：
- en: '[PRE89]'
  id: totrans-1009
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Compute the mean squared error between the two `x` and `z` vectors:'
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: 计算两个`x`和`z`向量之间的均方误差：
- en: '[PRE90]'
  id: totrans-1011
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Compute the statistics for each feature of a multidimensional time series:'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: 计算多维时间序列每个特征的统计数据：
- en: '[PRE91]'
  id: totrans-1013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Apply a `f` function to a zipped pair of multidimensional vectors of the `XVSeries`
    type:'
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 对`XVSeries`类型的两个多维向量对应用`f`函数：
- en: '[PRE92]'
  id: totrans-1015
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: The magnet pattern
  id: totrans-1016
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 磁场模式
- en: 'Some operations on the time series that are implemented as the `XTSeries` methods
    may have a large variety of input and output types. Scala and Java support method
    overloading that has the following limitations:'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 实现为`XTSeries`方法的某些时间序列操作可能有多种输入和输出类型。Scala和Java支持方法重载，但有以下限制：
- en: It does not prevent the type collision caused by the erasure type in the JVM
  id: totrans-1018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不能防止由JVM中的擦除类型引起的类型冲突
- en: It does not allow lifting to a single, generic function
  id: totrans-1019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不允许提升到单个通用函数
- en: It does not completely reduce code redundancy
  id: totrans-1020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不能完全减少代码冗余
- en: The transpose operator
  id: totrans-1021
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转置算子
- en: 'Let''s consider the transpose operator for any kind of multidimensional time
    series. The transpose operator can be objectified as the `Transpose` trait:'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑任何类型的多维时间序列的转置算子。转置算子可以对象化为`Transpose`特质：
- en: '[PRE93]'
  id: totrans-1023
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'The trait has an abstract `Result` type (line `4`) and an abstract `apply()`constructor
    (line `5`) that allows us to create a generic `transpose` method with any kind
    of combination of input and output types. The conversion type for the input and
    output types of the `transpose` method is defined as `implicit`:'
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: 特质有一个抽象的`Result`类型（行`4`）和一个抽象的`apply()`构造函数（行`5`），这允许我们创建一个具有任何输入和输出类型组合的通用`transpose`方法。`transpose`方法的输入和输出类型的转换类型定义为`implicit`：
- en: '[PRE94]'
  id: totrans-1025
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: The first `xvSeries2Matrix` implicit transposes a time series of the `XVSeries[T]`
    type into a matrix with elements of the `T` type (line `6`). The `list2Matrix`
    implicit transposes a time series of the `List[Array[T]]` type into a matrix with
    elements of the `T` type (line `7`).
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个`xvSeries2Matrix`隐式地将`XVSeries[T]`类型的时间序列转换为元素类型为`T`的矩阵（行`6`）。`list2Matrix`隐式地将`List[Array[T]]`类型的时间序列转换为元素类型为`T`的矩阵（行`7`）。
- en: 'The generic `transpose` method is written as follows:'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 通用`transpose`方法编写如下：
- en: '[PRE95]'
  id: totrans-1028
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: The differential operator
  id: totrans-1029
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微分算子
- en: 'The second candidate for the magnet pattern is the computation of the differential
    in a time series. The purpose is to generate the time series *{x[t+1] – x[t]}*
    from a time series *{x[t]}*:'
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: 磁场模式的第二个候选是计算时间序列的微分。目的是从一个时间序列`{x[t]}`生成时间序列`{x[t+1] – x[t]}`：
- en: '[PRE96]'
  id: totrans-1031
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'The `Difference` trait allows us to compute the differential of a time series
    with arbitrary element types. For instance, the differential of a one-dimensional
    vector of the `Double` type is defined by the following implicit conversion:'
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: '`Difference`特性允许我们计算任意元素类型的时间序列的差分。例如，`Double`类型一维向量的差分由以下隐式转换定义：'
- en: '[PRE97]'
  id: totrans-1033
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The `apply()`constructor takes one argument: the user-defined `f` function
    that computes the difference between two consecutive elements of the time series
    (line `8`). The generic difference method is as follows:'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply()`构造函数接受一个参数：用户定义的`f`函数，该函数计算时间序列中连续两个元素的差（第`8`行）。通用的差分方法如下：'
- en: '[PRE98]'
  id: totrans-1035
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Here are some of the predefined differential operators of a time series for
    which the output of the operator has the `Double` (line `9`), `Int` (line `10`),
    and `Boolean` (line `11`) types:'
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些时间序列预定义的差分算子，其输出类型为`Double`（第`9`行），`Int`（第`10`行）和`Boolean`（第`11`行）：
- en: '[PRE99]'
  id: totrans-1037
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'The differential operator is used to implement the `labeledData` method to
    generate labeled data from observations with two features and a target (labels)
    dataset:'
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: 差分算子用于实现`labeledData`方法，从具有两个特征和目标（标签）数据集的观测值生成标签数据：
- en: '[PRE100]'
  id: totrans-1039
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: The structure of the labeled data is the pair of observations and the differential
    of target values.
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: 标签数据的结构是观测值和目标值差分的配对。
- en: Lazy views
  id: totrans-1041
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 懒惰视图
- en: A view in Scala is a proxy collection that represents a collection but implements
    the data transformation or higher-order method lazily. The elements of a view
    are defined as lazy values, which are instantiated on demand.
  id: totrans-1042
  prefs: []
  type: TYPE_NORMAL
  zh: Scala中的视图是一个代理集合，它代表一个集合，但以懒加载的方式实现数据转换或高阶方法。视图的元素被定义为懒值，它们在需要时才被实例化。
- en: One important advantage of views over a **strict** (or fully allocated) collection
    is the reduced memory consumption.
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: 视图相较于一个**严格**（或完全分配）的集合的一个重要优点是减少了内存消耗。
- en: 'Let''s take a look at the `aggregator` data transformation introduced in the
    *Instantiating the workflow* section under *A workflow computational model* in
    [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*.
    There is no need to allocate the entire set of `x.size` of elements: the higher-order
    `find` method may exit after only a few elements have been read (line `12`):'
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在[第2章](part0165.xhtml#aid-4TBCQ2 "第2章。Hello World!")中“工作流计算模型”下的“实例化工作流”部分引入的`aggregator`数据转换，*Hello
    World!*。不需要分配整个`x.size`的元素集合：高阶`find`方法可能只读取了几个元素后就会退出（第`12`行）：
- en: '[PRE101]'
  id: totrans-1045
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: Note
  id: totrans-1046
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Views, iterators, and streams**'
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: '**视图、迭代器和流**'
- en: 'Views, iterators, and streams share the same objective of constructing elements
    on demand. There are, however, some major differences:'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 视图、迭代器和流具有相同的构建按需元素的目标。然而，它们之间有一些主要区别：
- en: Iterators do not persist elements of the collection (read once)
  id: totrans-1049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代器不会持久化集合的元素（只读一次）
- en: Streams allow operations to be performed on the collection with an undefined
    size
  id: totrans-1050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流允许对具有未定义大小的集合执行操作
- en: Moving averages
  id: totrans-1051
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动平均
- en: Moving averages provide data analysts and scientists with a basic predictive
    model. Despite its simplicity, the moving average method is widely used in a variety
    of fields, such as marketing survey, consumer behavior, or sport statistics. Traders
    use the moving average method to identify different levels of support and resistance
    for the price of a given security.
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: 移动平均为数据分析师和科学家提供了一个基本的预测模型。尽管其简单，移动平均法在各个领域都得到了广泛应用，如市场调查、消费者行为或体育统计。交易者使用移动平均法来识别给定证券价格的不同支撑和阻力水平。
- en: Note
  id: totrans-1053
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**An average reducing function**'
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均减少函数**'
- en: 'Let''s consider the time series *x[t] = x(t)* and function *f(x[t-p-1],…, x[t])*
    that reduces the last *p* observations into a value or average. The estimation
    of the observation at *t* is defined by the following formula:'
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑时间序列*x[t] = x(t)*和函数*f(x[t-p-1],…, x[t])*，它将最后*p*个观测值减少到一个值或平均值。在*t*处的观测值估计由以下公式定义：
- en: '![Moving averages](img/image01283.jpeg)'
  id: totrans-1056
  prefs: []
  type: TYPE_IMG
  zh: '![移动平均](img/image01283.jpeg)'
- en: Here, *f* is an average reducing function from the previous *p* data points.
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*f*是来自之前*p*个数据点的平均减少函数。
- en: The simple moving average
  id: totrans-1058
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单移动平均
- en: The simple moving average is the simplest form of the moving averages algorithms
    [3:1]. The simple moving average of period *p* estimates the value at time *t*
    by computing the average value of the previous *p* observations using the following
    formula.
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: 简单移动平均是移动平均算法的最简单形式 [3:1]。周期为 *p* 的简单移动平均通过以下公式估计时间 *t* 的值：
- en: Note
  id: totrans-1060
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The simple moving average**'
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单移动平均**'
- en: 'M1: The simple moving average of a time series *{x[t]}* with a period *p* is
    computed as the average of the last *p* observations:'
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: M1：时间序列 *{x[t]}* 的周期为 *p* 的简单移动平均是通过计算最后 *p* 个观测值的平均值来得到的：
- en: '![The simple moving average](img/image01284.jpeg)'
  id: totrans-1063
  prefs: []
  type: TYPE_IMG
  zh: '![简单移动平均](img/image01284.jpeg)'
- en: 'M2: The computation is implemented iteratively using the following formula:'
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: M2：计算通过以下公式迭代实现：
- en: '![The simple moving average](img/image01285.jpeg)'
  id: totrans-1065
  prefs: []
  type: TYPE_IMG
  zh: '![简单移动平均](img/image01285.jpeg)'
- en: Here, ![The simple moving average](img/image01286.jpeg) is the estimate or simple
    moving average value at time *t*.
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![简单移动平均](img/image01286.jpeg) 是时间 *t* 的估计值或简单移动平均值。
- en: 'Let''s build a class hierarchy of moving average algorithms, with the parameterized
    `MovingAverage` trait as its root:'
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个移动平均算法的类层次结构，其中参数化的 `MovingAverage` 特性作为其根：
- en: '[PRE102]'
  id: totrans-1068
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'We use the generic `XSeries[T]` type and the data transform with the `ETransform`
    explicit configuration, introduced in the *Explicit models* section under *Monadic
    data transformation* in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*, to implement the simple moving average, `SimpleMovingAverage`:'
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用通用的 `XSeries[T]` 类型以及 `ETransform` 显式配置的数据转换，该配置在 [第2章](part0165.xhtml#aid-4TBCQ2
    "第2章. Hello World!") 下 *Monadic 数据转换* 的 *显式模型* 部分中介绍，用于实现简单移动平均，`SimpleMovingAverage`：
- en: '[PRE103]'
  id: totrans-1070
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: The class is parameterized for the `T` type of elements of the input time series;
    *we cannot make any assumption regarding the type of input data*. The type of
    the elements of the output time series is `Double`. The implicit instantiation
    of the `Numeric[T]` class is required by the `sum` and `/` arithmetic operators
    (line `1`). The simple moving average implements `ETransform` by defining the
    abstract `U` types for the input (line `2`) and `V` for the output ( line `3`)
    as a time series, `DblVector`.
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: 该类针对输入时间序列的 `T` 类型元素进行参数化；*我们无法对输入数据的类型做出任何假设*。输出时间序列的元素类型为 `Double`。`sum` 和
    `/` 算术运算符需要 `Numeric[T]` 类的隐式实例化（行 `1`）。简单移动平均通过定义输入的抽象 `U` 类型（行 `2`）和输出为 `V`
    的类型（行 `3`）作为时间序列 `DblVector` 来实现 `ETransform`。
- en: 'The implementation has a few interesting elements. First, the set of observations
    is duplicated and the index in the resulting clone instance is shifted by `p`
    observations before being zipped with the original to the array of a pair of `slider`
    values (line `4`):'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: 实现有几个有趣的元素。首先，观测值集被复制，并在与原始数据合并到包含一对 `slider` 值的数组之前，将索引在结果克隆实例中移动 `p` 个观测值（行
    `4`）：
- en: '![The simple moving average](img/image01287.jpeg)'
  id: totrans-1073
  prefs: []
  type: TYPE_IMG
  zh: '![简单移动平均](img/image01287.jpeg)'
- en: The sliding algorithm to compute moving averages
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 计算移动平均的滑动算法
- en: The average value is initialized with the mean value of the first `period` data
    points (line `5`). The first `period` values of the trends are initialized to
    zero (line `6`). The method concatenates the initial null values and the computed
    average values to implement the **M2** formula (line `7`).
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值初始化为第一个 `period` 数据点的平均值（行 `5`）。趋势的第一个 `period` 值初始化为零（行 `6`）。该方法通过连接初始空值和计算出的平均值来实现
    **M2** 公式（行 `7`）。
- en: The weighted moving average
  id: totrans-1076
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加权移动平均
- en: The weighted moving average method is an extension of the simple moving average
    by computing the weighted average of the last *p* observations [3:2]. The weights
    *α[j]* are assigned to each of the last *p* data points *x[j]* and are normalized
    by the sum of the weights.
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: 加权移动平均方法是通过计算最后 *p* 个观测值的加权平均值来扩展简单移动平均的 [3:2]。权重 *α[j]* 被分配给最后 *p* 个数据点 *x[j]*，并通过权重的总和进行归一化。
- en: Note
  id: totrans-1078
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The weighted moving average**'
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权移动平均**'
- en: 'M3: The weighted moving average of a series *{x[t]}* with a period *p* and
    a normalized weights distribution *{α[j]}* is given by the following formula:'
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: M3：具有周期 *p* 和归一化权重分布 *{α[j]}* 的序列 *{x[t]}* 的加权移动平均由以下公式给出：
- en: '![The weighted moving average](img/image01288.jpeg)'
  id: totrans-1081
  prefs: []
  type: TYPE_IMG
  zh: '![加权移动平均](img/image01288.jpeg)'
- en: Here, *x[t]* is the estimate or simple moving average value at time *t*.
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x[t]* 是时间 *t* 的估计值或简单移动平均值。
- en: 'The implementation of the `WeightedMovingAverage` class requires the computation
    of the last *p* (`weights.size`) data points. There is no simple iterative formula
    to compute the weighted moving average at time *t + 1* using the moving average
    at time *t*:'
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: '`WeightedMovingAverage` 类的实现需要计算最后 *p* (`weights.size`) 个数据点。没有简单的迭代公式可以用来在时间
    *t + 1* 时使用时间 *t* 时刻的移动平均来计算加权移动平均：'
- en: '[PRE104]'
  id: totrans-1084
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: The computation of the weighted moving average is a bit more involved than the
    simple moving average. Therefore, we specify the generation of the byte code that
    is dedicated to the `Double` type using the specialized annotation. The weighted
    moving average inherits the `SimpleMovingAverage` class, and therefore, implements
    the `ETransform` explicit transformation for a configuration of weights, with
    input observations of the `XSeries[T]` type and output observations of the `DblVector`
    type. The implementation of **M3** formula generates a smoothed time series by
    slicing (line `9`) the input time series and then computing the inner product
    of weights and the slice of the time series (line `10`).
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 加权移动平均的计算比简单移动平均复杂一些。因此，我们使用专门的注解指定为 `Double` 类型生成专用字节码。加权移动平均继承自 `SimpleMovingAverage`
    类，因此，实现了配置权重时的 `ETransform` 显式转换，输入观测类型为 `XSeries[T]`，输出观测类型为 `DblVector`。**M3**
    公式的实现通过切片（第 `9` 行）输入时间序列并计算权重与时间序列切片的内积（第 `10` 行）来生成平滑的时间序列。
- en: As with the simple moving average, the output is the concatenation of the initial
    `weights.size` null values, `zeros`, and the `smoothed` data (line `11`).
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: 与简单移动平均一样，输出是初始 `weights.size` 个空值、`zeros` 和 `smoothed` 数据（第 `11` 行）的连接。
- en: The exponential moving average
  id: totrans-1087
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指数移动平均
- en: The exponential moving average is widely used in financial analysis and marketing
    surveys because it favors the latest values. The older the value, the less impact
    it has on the moving average value at time *t* [3:3].
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 指数移动平均在金融分析和市场调查中被广泛使用，因为它倾向于最新的值。值越老，对时间 *t* 时刻的移动平均值的冲击就越小 [3:3]。
- en: Note
  id: totrans-1089
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The exponential moving average**'
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: '**指数移动平均**'
- en: 'M4: The exponential moving average of a series *{x[t]}* and smoothing factor
    *α* is computed by the following iterative formula:'
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: M4：计算序列 *{x[t]}* 的指数移动平均和平滑因子 *α* 的迭代公式如下：
- en: '![The exponential moving average](img/image01289.jpeg)'
  id: totrans-1092
  prefs: []
  type: TYPE_IMG
  zh: '![指数移动平均](img/image01289.jpeg)'
- en: Here, ![The exponential moving average](img/image01290.jpeg) is the value of
    the exponential average at *t*.
  id: totrans-1093
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![指数移动平均](img/image01290.jpeg) 是在 *t* 时刻的指数平均值。
- en: 'The implementation of the `ExpMovingAverage` class is rather simple. The constructor
    has a single `α` argument (the decay rate) (line `12`):'
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExpMovingAverage` 类的实现相当简单。构造函数有一个单一的 `α` 参数（衰减率）（第 `12` 行）：'
- en: '[PRE105]'
  id: totrans-1095
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: The exponential moving average implements the `ETransform` (line `13`) by defining
    the abstract `U` types for the input (line `14`) as a time series named `XSeries[T]`
    and `V` for the output (line `15`) as a time series named `DblVector`. The `|>`
    method applies the **M4** formula to all the observations of the time series within
    a `map` (line `16`).
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: 指数移动平均通过定义输入（第 `14` 行）的抽象 `U` 类型为时间序列 `XSeries[T]` 和输出（第 `15` 行）的 `V` 类型为时间序列
    `DblVector` 来实现 `ETransform`（第 `13` 行）。`|>` 方法在 `map`（第 `16` 行）中对时间序列的所有观测值应用
    **M4** 公式。
- en: 'The version of the constructor that uses the `p` period to compute *alpha =
    1/(p+1)* as an argument is implemented using the Scala `apply` method:'
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `p` 期来计算 *alpha = 1/(p+1)* 的构造函数版本是通过 Scala 的 `apply` 方法实现的：
- en: '[PRE106]'
  id: totrans-1098
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Let''s compare the results generated from these three moving averages methods
    with the original price. We use a data source, `DataSource`, to load and extract
    values from the historical daily closing stock price of Bank of America (BAC),
    which is available at the Yahoo Financials pages. The `DataSink` class is responsible
    for formatting and saving the results into a CSV file for further analysis. The
    `DataSource` and `DataSink` classes are described in detail in the *Data extraction*
    section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*:'
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较从这三种移动平均方法生成的结果与原始价格。我们使用一个数据源，`DataSource`，从美国银行（BAC）的历史每日收盘价中加载和提取值，这些数据可在雅虎财经页面找到。`DataSink`
    类负责格式化和将结果保存到 CSV 文件中，以供进一步分析。`DataSource` 和 `DataSink` 类在 [附录 A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念") 的 *数据提取* 部分中详细描述，*基本概念*：
- en: '[PRE107]'
  id: totrans-1100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Note
  id: totrans-1101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**isDefinedAt**'
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: '**isDefinedAt**'
- en: Each of the partial function is validated by a call to `isDefinedAt`. From now
    on, the validation of a partial function will be omitted throughout the book for
    the sake of clarity.
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: 每个部分函数通过调用`isDefinedAt`进行验证。从现在起，为了清晰起见，本书中将省略部分函数的验证。
- en: The coefficients for the weighted moving average are generated (line `17`) and
    normalized (line `18`). The trading data regarding the ticker symbol, BAC, is
    extracted from the Yahoo Finances CSV file (line `19`), `YahooFinancials`, using
    the `adjClose` extractor (line `20`). The next step is to initialize the `pfnSMvAve`,
    `pfnWMvAve`, and `pfnEMvAve` partial functions related to each of the moving average
    (line `21`). The invocation of the partial functions with `price` as an argument
    generates the three smoothed time series (line `22`).
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: 加权移动平均的系数是在（行`17`）生成的，并在（行`18`）进行归一化。关于股票代码BAC的交易数据是从Yahoo Finances CSV文件（行`19`），`YahooFinancials`，使用`adjClose`提取器（行`20`）提取的。下一步是初始化与每个移动平均相关的`pfnSMvAve`、`pfnWMvAve`和`pfnEMvAve`部分函数（行`21`）。以`price`作为参数调用部分函数生成三个平滑的时间序列（行`22`）。
- en: Finally, a `DataSink` instance formats and dumps the results into a file (line
    `23`).
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`DataSink`实例格式化并将结果输出到文件（行`23`）。
- en: Note
  id: totrans-1106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Implicit postfixOps
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式后缀操作
- en: The instantiation of the `filter |>` partial function requires that the post
    fix operation, `postfixOps`, be made visible by importing `scala.language.postfixOps`.
  id: totrans-1108
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化`filter |>`部分函数需要通过导入`scala.language.postfixOps`使后缀操作`postfixOps`可见。
- en: 'The weighted moving average method relies on a symmetric distribution of normalized
    weights computed by a function passed as an argument of the generic `tabulate`
    method. Note that the original price time series is displayed if one of the specific
    moving averages cannot be computed. The following graph is an example of a symmetric
    filter for weighted moving averages:'
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: 加权移动平均方法依赖于通过将函数作为参数传递给通用`tabulate`方法计算出的归一化权重的对称分布。请注意，如果无法计算特定的移动平均之一，则显示原始的价格时间序列。以下图形是加权移动平均的对称滤波器示例：
- en: '![The exponential moving average](img/image01291.jpeg)'
  id: totrans-1110
  prefs: []
  type: TYPE_IMG
  zh: '![指数移动平均](img/image01291.jpeg)'
- en: An example of a symmetric filter for weighted moving averages
  id: totrans-1111
  prefs: []
  type: TYPE_NORMAL
  zh: 加权移动平均的对称滤波器示例
- en: 'The three moving average techniques are applied to the price of the stock of
    Bank of America stock (BAC) over 200 trading days. Both the simple and weighted
    moving averages use a period of 11 trading days. The exponential moving average
    method uses a scaling factor of *2/(11+1) = 0.1667*:'
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: 三种移动平均技术应用于美国银行（BAC）股票在200个交易日内的价格。简单移动平均和加权移动平均都使用11个交易日的周期。指数移动平均方法使用缩放因子*2/(11+1)
    = 0.1667*：
- en: '![The exponential moving average](img/image01292.jpeg)'
  id: totrans-1113
  prefs: []
  type: TYPE_IMG
  zh: '![指数移动平均](img/image01292.jpeg)'
- en: 11-day moving averages of the historical stock price of Bank of America
  id: totrans-1114
  prefs: []
  type: TYPE_NORMAL
  zh: 美国银行历史股票价格11天的移动平均
- en: 'The three techniques filter the noise out of the original historical price
    time series. The exponential moving average reacts to a sudden price fluctuation
    despite the fact that the smoothing factor is low. If you increase the period
    to 51 trading days (which is equivalent to two calendar months), the simple and
    weighted moving averages produce a time series smoother than the exponential moving
    average with *alpha = 2/(p+1) = 0.038*:'
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种技术从原始的历史价格时间序列中滤除了噪声。尽管平滑因子较低，指数移动平均对突然的价格波动反应敏感。如果您将周期增加到51个交易日（相当于两个日历月），简单移动平均和加权移动平均产生的时间序列比具有*alpha
    = 2/(p+1) = 0.038*的指数移动平均更平滑：
- en: '![The exponential moving average](img/image01293.jpeg)'
  id: totrans-1116
  prefs: []
  type: TYPE_IMG
  zh: '![指数移动平均](img/image01293.jpeg)'
- en: 51-day moving averages of the historical stock price of Bank of America
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: 美国银行历史股票价格51天的移动平均
- en: 'You are invited to experiment further with different smooth factors and weight
    distributions. You will be able to confirm the following basic rule: as the period
    of the moving average increases, noise with decreasing frequencies is eliminated.
    In other words, the window of allowed frequencies is shrinking. The moving average
    acts as a **low-pass filter** that preserves only lower frequencies.'
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎您进一步实验不同的平滑因子和权重分布。您将能够确认以下基本规则：随着移动平均周期的增加，频率逐渐降低的噪声被消除。换句话说，允许的频率窗口正在缩小。移动平均充当一个**低通滤波器**，仅保留低频。
- en: Fine-tuning the period of a smoothing factor is time consuming. Spectral analysis,
    or more specifically, Fourier analysis transforms a time series into a sequence
    of frequencies, which provide the statistician with a more powerful frequency
    analysis tool.
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 微调平滑因子的周期是耗时的。频谱分析，或更具体地说，傅里叶分析将时间序列转换为一个频率序列，为统计学家提供了一个更强大的频谱分析工具。
- en: Note
  id: totrans-1120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The moving average on a multidimensional time series**'
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: '**多维时间序列上的移动平均**'
- en: 'The moving average techniques are presented for a single feature or variable
    time series, for the sake of simplicity. Moving averages on multidimensional time
    series are computed by executing a single variable moving average for each feature
    using the `transform` method of `XTSeries`, which is introduced in the first section.
    For example, the simple moving average applied to a multidimensional time series,
    `xt`. The smoothed values are computed as follows:'
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，移动平均技术被用于单个特征或变量时间序列。多维时间序列上的移动平均是通过使用`XTSeries`的`transform`方法对每个特征执行单个变量的移动平均来计算的，这在第一节中已介绍。例如，应用于多维时间序列`xt`的简单移动平均，其平滑值计算如下：
- en: '[PRE108]'
  id: totrans-1123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Fourier analysis
  id: totrans-1124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 傅里叶分析
- en: The purpose of **spectral density estimation** is to measure the amplitude of
    a signal or a time series according to its frequency [3:4]. The objective is to
    estimate the spectral density by detecting periodicities in the dataset. A scientist
    can better understand a signal or time series by analyzing its harmonics.
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: '**谱密度估计**的目的是根据其频率测量信号或时间序列的幅度 [3:4]。目标是通过对数据集中的周期性进行检测来估计谱密度。通过分析其谐波，科学家可以更好地理解信号或时间序列。'
- en: Note
  id: totrans-1126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The spectral theory**'
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
  zh: '**谱理论**'
- en: Spectral analysis for a time series should not be confused with the spectral
    theory, a subset of linear algebra that studies eigenfunctions on **Hilbert**
    and **Banach** spaces. In fact, harmonic analysis and Fourier analysis are regarded
    as subsets of the spectral theory.
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列的频谱分析不应与谱理论混淆，谱理论是线性代数的一个子集，研究希尔伯特和巴拿赫空间上的特征函数。事实上，调和分析和傅里叶分析被视为谱理论的一部分。
- en: Let's explore the concept behind the discrete Fourier series as well as its
    benefits as applied to financial markets. The **Fourier analysis** approximates
    any generic function as the sum of trigonometric functions, sine and cosine.
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨离散傅里叶级数的概念以及其在金融市场中的应用优势。**傅里叶分析**将任何通用函数近似为三角函数（正弦和余弦函数）的和。
- en: Note
  id: totrans-1130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Complex Fourier transform**'
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: '**复数傅里叶变换**'
- en: This section focuses on the discrete Fourier series for real values. The generic
    Fourier transform applies to complex values [3:5].
  id: totrans-1132
  prefs: []
  type: TYPE_NORMAL
  zh: 本节重点介绍实值离散傅里叶级数。通用的傅里叶变换适用于复数值 [3:5]。
- en: The decomposition in a basic trigonometric function process is known as the
    **Fourier transform** [3:6].
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本三角函数分解过程中，分解称为 **傅里叶变换** [3:6]。
- en: Discrete Fourier transform
  id: totrans-1134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离散傅里叶变换
- en: A time series *{x[k]}* can be represented as a discrete real-time domain function
    *f, x = f(t)*. In the 18^(th) century, Jean Baptiste Joseph Fourier demonstrated
    that any continuous periodic function *f* can be represented as a linear combination
    of sine and cosine functions. The **discrete Fourier transform** (**DFT**) is
    a linear transformation that converts a time series into a list of coefficients
    of a finite combination of complex or real trigonometric functions, ordered by
    their frequencies.
  id: totrans-1135
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列 *{x[k]}* 可以表示为一个离散的实时域函数 *f, x = f(t)*。在18世纪，让-巴蒂斯特-约瑟夫·傅里叶证明了任何连续周期函数
    *f* 都可以表示为正弦和余弦函数的线性组合。**离散傅里叶变换**（**DFT**）是一种线性变换，它将时间序列转换为一个有限组合的复数或实数三角函数的系数列表，按其频率排序。
- en: The frequency *ω* of each trigonometric function defines one of the harmonics
    of the signal. The space that represents the signal amplitude versus frequency
    of the signal is known as the **frequency domain**. The generic DFT transforms
    a time series into a sequence of frequencies defined as complex numbers *a + j.φ
    (j² = -1)*, where *a* is the amplitude of the frequency and *φ* is the phase.
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: 每个三角函数的频率 *ω* 定义了信号的谐波之一。表示信号幅度与频率关系的空间被称为 **频域**。通用的快速傅里叶变换（DFT）将时间序列转换为一个由复数
    *a + j.φ (j² = -1)* 定义的频率序列，其中 *a* 是频率的幅度，*φ* 是相位。
- en: This section is dedicated to the real DFT that converts a time series into an
    ordered sequence of frequencies with real values.
  id: totrans-1137
  prefs: []
  type: TYPE_NORMAL
  zh: 本节专门介绍将时间序列转换为具有实数值的有序频率序列的实数DFT。
- en: Note
  id: totrans-1138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Real discrete Fourier transform**'
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: '**实数离散傅里叶变换**'
- en: 'M5: A periodic function *f* can be represented as an infinite combination of
    sine and cosine functions:'
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
  zh: M5：周期函数 *f* 可以表示为正弦和余弦函数的无限组合：
- en: '![Discrete Fourier transform](img/image01294.jpeg)'
  id: totrans-1141
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01294.jpeg)'
- en: 'M6: The Fourier cosine transform of a function *f* is defined as:'
  id: totrans-1142
  prefs: []
  type: TYPE_NORMAL
  zh: M6：函数 *f* 的傅里叶余弦变换定义为：
- en: '![Discrete Fourier transform](img/image01295.jpeg)'
  id: totrans-1143
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01295.jpeg)'
- en: 'M7: The discrete real cosine series of a function *f(-x) = f(x)* is defined
    as:'
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: M7：函数 *f(-x) = f(x)* 的离散实数余弦级数定义为：
- en: '![Discrete Fourier transform](img/image01296.jpeg)'
  id: totrans-1145
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01296.jpeg)'
- en: 'M8: The Fourier sine transform of a function is defined as:'
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: M8：函数的傅里叶正弦变换定义为：
- en: '![Discrete Fourier transform](img/image01297.jpeg)'
  id: totrans-1147
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01297.jpeg)'
- en: 'M9: The discrete real sine series of a function *f(-x) = f(x)* is defined as:'
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: M9：函数 *f(-x) = f(x)* 的离散实数正弦级数定义为：
- en: '![Discrete Fourier transform](img/image01298.jpeg)'
  id: totrans-1149
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01298.jpeg)'
- en: The computation of the Fourier trigonometric series is time consuming with an
    asymptotic time complexity of *O(n²)*. Scientists and mathematicians have been
    working to make the computation as effective as possible. The most common numerical
    algorithm used to compute the Fourier series is the **Fast Fourier Transform**
    (**FFT**) created by J.W. Cooley and J. Tukey [3:7].
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: 傅里叶三角级数的计算耗时，其渐近时间复杂度为 *O(n²)*。科学家和数学家一直在努力使计算尽可能有效。用于计算傅里叶级数最常用的数值算法是由 J.W.
    库利和 J. 图基创建的 **快速傅里叶变换**（**FFT**）[3:7]。
- en: The algorithm called Radix-2 version recursively breaks down the Fourier transform
    for a time series of *N* data points into any combination of *N[1]* and *N[2]*
    sized segments such as *N = N[1] N[2]*. Ultimately, the discrete Fourier transform
    is applied to the deeper-nested segments.
  id: totrans-1151
  prefs: []
  type: TYPE_NORMAL
  zh: Radix-2 版本的算法递归地将时间序列的傅里叶变换分解为任何组合的 *N[1]* 和 *N[2]* 大小的段，例如 *N = N[1] N[2]*。最终，离散傅里叶变换应用于更深层次的段。
- en: Tip
  id: totrans-1152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**The Cooley-Tukey algorithm**'
  id: totrans-1153
  prefs: []
  type: TYPE_NORMAL
  zh: '**库利-图基算法**'
- en: I encourage you to implement the Radix-2 Cooley-Tukey algorithm in Scala using
    a tail recursion.
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你使用 Scala 的尾递归实现 Radix-2 库利-图基算法。
- en: 'The Radix-2 implementation requires that the number of data points is *N=2^n*
    for even functions (sine) and *N=2^n+1* for cosine. There are two approaches to
    meet this constraint:'
  id: totrans-1155
  prefs: []
  type: TYPE_NORMAL
  zh: Radix-2 实现要求数据点的数量为 *N=2^n*，对于偶函数（正弦函数）和 *N=2^n+1*，对于余弦函数。有两种方法来满足这个约束：
- en: Reduce the actual number of points to the next lower radix, *2^n* *< N*
  id: totrans-1156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将实际点数减少到下一个较低的基数，*2^n* *< N*
- en: Extend the original time series by padding it with 0 to the next higher radix,
    *N < 2^n**+1*
  id: totrans-1157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过用 0 填充到下一个更高的基数，扩展原始时间序列，*N < 2^n**+1*
- en: Padding the time series is the preferred option because it does not affect the
    original set of observations.
  id: totrans-1158
  prefs: []
  type: TYPE_NORMAL
  zh: 填充时间序列是首选选项，因为它不会影响原始的观测集。
- en: 'Let''s define a `DTransform` trait for any variant of the discrete Fourier
    transform. The first step is to wrap the default configuration parameters used
    in the Apache Commons Math library into a `Config` singleton:'
  id: totrans-1159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为任何离散傅里叶变换的变体定义一个 `DTransform` 特性。第一步是将 Apache Commons Math 库中使用的默认配置参数封装到一个
    `Config` 单例中：
- en: '[PRE109]'
  id: totrans-1160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The main purpose of the `DTransform` trait is to pad the `vec` time series
    with zero values:'
  id: totrans-1161
  prefs: []
  type: TYPE_NORMAL
  zh: '`DTransform` 特性的主要目的是用零值填充 `vec` 时间序列：'
- en: '[PRE110]'
  id: totrans-1162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: The `pad` method computes the optimal size of the frequency vector as *2^N*
    by invoking the `padSize` method (line `1`). It then concatenates the padding
    with the original time series or vector of observations (line `2`). The `padSize`
    method adjusts the size of the data depending on whether the time series has initially
    an even or odd number of observations (line `3`). It relies on bit operations
    to find the next radix, *N* (line `4`).
  id: totrans-1163
  prefs: []
  type: TYPE_NORMAL
  zh: '`pad` 方法通过调用 `padSize` 方法（行 `1`）计算频率向量的最佳大小为 *2^N*。然后，它将填充与原始时间序列或观测向量连接（行
    `2`）。`padSize` 方法根据时间序列最初是否有偶数个观测值调整数据的大小（行 `3`）。它依赖于位操作来找到下一个基数，*N*（行 `4`）。'
- en: Note
  id: totrans-1164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The while loop**'
  id: totrans-1165
  prefs: []
  type: TYPE_NORMAL
  zh: '**while 循环**'
- en: Scala developers prefer Scala higher-order methods for collections to implement
    the iterative computation. However, nothing prevents you from using the traditional
    `while` or `do {…} while` loop if either readability or performance is an issue.
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 开发者更喜欢使用 Scala 高阶方法来对集合进行迭代计算。然而，如果可读性或性能是一个问题，你仍然可以使用传统的 `while` 或 `do
    {…} while` 循环。
- en: 'The fast implementation of the padding method, `pad`, consists of detecting
    the number of *N* observations as a power of 2 (the next highest radix). The method
    evaluates if *N* and *(N-1)* are zero after it shifts the number of bits in the
    value, *N*. The code illustrates the effective use of implicit conversion to make
    the code readable in the `pad` method:'
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: 填充方法 `pad` 的快速实现包括检测 *N* 个观测值作为 2 的幂（下一个最高的基数）。该方法在将值 *N* 中的位数移动后评估 *N* 和 *(N-1)*
    是否为零。代码展示了在 `pad` 方法中有效使用隐式转换以使代码可读的示例：
- en: '[PRE111]'
  id: totrans-1168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'The next step is to write the `DFT` class for the real sine and cosine discrete
    transforms by subclassing `DTransform`. The class relies on the padding mechanism
    implemented in `DTransform` whenever necessary:'
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编写 `DFT` 类，用于实正弦和余弦离散变换，通过继承 `DTransform` 实现。该类在必要时依赖于 `DTransform` 中实现的填充机制：
- en: '[PRE112]'
  id: totrans-1170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'We treat the discrete Fourier transform as a transformation on the time series
    using an explicit `ETransform` configuration (line `5`). The `U` data type of
    the input and the `V` type of the output have to be defined (line `6`). The `|>`
    transformation function delegates the computation to the `fwrd` method (line `7`):'
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将离散傅里叶变换视为使用显式 `ETransform` 配置对时间序列进行变换（行 `5`）。输入的 `U` 数据类型和输出的 `V` 类型必须定义（行
    `6`）。`|>` 变换函数将计算委托给 `fwrd` 方法（行 `7`）：
- en: '[PRE113]'
  id: totrans-1172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: The `fwrd` method selects the discrete Fourier sine series if the first value
    of the time series is 0.0, otherwise it selects the discrete cosine series. This
    implementation automates the selection of the appropriate series by evaluating
    `xt.head` (line `8`). The transformation invokes the `FastSineTransformer` (line
    `9`) and `FastCosineTransformer` (line `10`) classes of the Apache Commons Math
    library [3:8] introduced in the first chapter.
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果时间序列的第一个值是 0.0，则 `fwrd` 方法选择离散傅里叶正弦级数；否则，它选择离散余弦级数。此实现通过评估 `xt.head`（行 `8`）来自动选择适当的序列。变换调用
    Apache Commons Math 库中的 `FastSineTransformer`（行 `9`）和 `FastCosineTransformer`（行
    `10`）类，这些类在第一章中介绍 [3:8]。
- en: This example uses the standard formulation of the cosine and sine transformations,
    defined by the `COSINE` argument. The orthogonal normalization that normalizes
    the frequency by a factor of *1/sqrt(2(N-1))*, where *N* is the size of the time
    series, generates a cleaner frequency spectrum for a higher computation cost.
  id: totrans-1174
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例使用由 `COSINE` 参数定义的余弦和正弦变换的标准公式。通过将频率通过一个因子 *1/sqrt(2(N-1))* 进行归一化，其中 *N*
    是时间序列的大小，生成一个更干净的频率谱，但计算成本更高。
- en: Note
  id: totrans-1175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The @specialized annotation**'
  id: totrans-1176
  prefs: []
  type: TYPE_NORMAL
  zh: '**@specialized 注解**'
- en: The `@specialized(Double)` annotation is used to instruct the Scala compiler
    to generate a specialized and more efficient version of the class for the `Double`
    type. The drawback of the specialization is the duplication of byte code as the
    specialized version coexists with the parameterized classes [3:9].
  id: totrans-1177
  prefs: []
  type: TYPE_NORMAL
  zh: '`@specialized(Double)` 注解用于指示 Scala 编译器为 `Double` 类型生成一个专门且更高效的类版本。专化的缺点是字节码的重复，因为专门版本与参数化类共存
    [3:9]。'
- en: 'In order to illustrate the different concepts behind DFTs, let''s consider
    the case of a time series generated by a `h` sequence of sinusoidal functions:'
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 DFT 背后的不同概念，让我们考虑由正弦函数的 `h` 序列生成的时间序列的情况：
- en: '[PRE114]'
  id: totrans-1179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'As the signal is synthetically created, we can select the size of the time
    series to avoid padding. The first value in the time series is not null, so the
    number of observations is *2^n+1*. The data generated by the *h* function is plotted
    as follows:'
  id: totrans-1180
  prefs: []
  type: TYPE_NORMAL
  zh: 由于信号是合成的，我们可以选择时间序列的大小以避免填充。时间序列的第一个值不为空，因此观测值的数量是 *2^n+1*。由 `h` 函数生成的数据如下所示：
- en: '![Discrete Fourier transform](img/image01299.jpeg)'
  id: totrans-1181
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01299.jpeg)'
- en: An example of sinusoidal time series
  id: totrans-1182
  prefs: []
  type: TYPE_NORMAL
  zh: 正弦时间序列的示例
- en: 'Let''s extract the frequencies'' spectrum for the time series generated by
    the `h` function. The data points are created by tabulating the `h` function.
    The frequencies spectrum is computed with a simple invocation of the explicit
    `|>` data transformation of the `DFT` class:'
  id: totrans-1183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提取由 `h` 函数生成的时间序列的频率谱。数据点是通过表格化 `h` 函数创建的。频率谱是通过简单调用 `DFT` 类的显式 `|>` 数据变换来计算的：
- en: '[PRE115]'
  id: totrans-1184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'The execution of the data simulator follows these steps:'
  id: totrans-1185
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模拟器的执行遵循以下步骤：
- en: Generate a raw data with the 3-harmonic `h` function (line `12`).
  id: totrans-1186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 3 阶谐波的 `h` 函数生成原始数据（行 `12`）。
- en: Instantiate the partial function generated by the transformation (line `11`).
  id: totrans-1187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化由变换生成的部分函数（行 `11`）。
- en: Store the resulting frequencies in a data sink (filesystem) (line `13`).
  id: totrans-1188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果频率存储在数据接收器（文件系统）中（行 `13`）。
- en: Note
  id: totrans-1189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Data sinks and spreadsheets**'
  id: totrans-1190
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据接收器和电子表格**'
- en: In this particular case, the results of the discrete Fourier transform are dumped
    into a CSV file so that it can be loaded into a spreadsheet. Some spreadsheets
    support a set of filtering techniques that can be used to validate the result
    of the example. A simpler alternative would be to use JFreeChart.
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的情况下，离散傅里叶变换的结果被输出到一个CSV文件中，以便它可以被加载到电子表格中。一些电子表格支持一组过滤技术，可以用来验证示例的结果。一个更简单的替代方案是使用JFreeChart。
- en: 'The spectrum of frequencies of the time series, plotted for the first 32 points,
    clearly shows three frequencies at *k = 2*, *5*, and *15*. This result is expected
    because the original signal is composed of three sinusoidal functions. The amplitude
    of these frequencies are 1024/1, 1024/2, and 1024/6, respectively. The following
    plot represents the first 32 harmonics for the time series:'
  id: totrans-1192
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列的频率谱，对于前32个点进行绘图，清楚地显示了在 *k = 2*、*5* 和 *15* 处的三个频率。这个结果是预期的，因为原始信号由三个正弦函数组成。这些频率的幅度分别是
    1024/1、1024/2 和 1024/6。以下图表表示时间序列的前32个谐波：
- en: '![Discrete Fourier transform](img/image01300.jpeg)'
  id: totrans-1193
  prefs: []
  type: TYPE_IMG
  zh: '![离散傅里叶变换](img/image01300.jpeg)'
- en: The frequency spectrum for a three-frequency sinusoidal
  id: totrans-1194
  prefs: []
  type: TYPE_NORMAL
  zh: 三频率正弦波的频谱
- en: The next step is to use the frequencies spectrum to create a low-pass filter
    using DFT. There are many algorithms available to implement a low or pass band
    filter in the time domain, from autoregressive models to the Butterworth algorithm.
    However, the discrete Fourier transform is still a very popular technique to smooth
    signals and identify trends.
  id: totrans-1195
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用频率谱通过DFT创建一个低通滤波器。在时域中实现低通或带通滤波器的算法有很多，从自回归模型到巴特沃斯算法。然而，离散傅里叶变换仍然是一种非常流行的技术，用于平滑信号和识别趋势。
- en: Note
  id: totrans-1196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Big Data**'
  id: totrans-1197
  prefs: []
  type: TYPE_NORMAL
  zh: '**大数据**'
- en: A DFT for a large time series can be very computation intensive. One option
    is to treat the time series as a continuous signal and sample it using the **Nyquist**
    frequency. The Nyquist frequency is half of the sampling rate of a continuous
    signal.
  id: totrans-1198
  prefs: []
  type: TYPE_NORMAL
  zh: 对大型时间序列进行DFT可能非常计算密集。一个选项是将时间序列视为连续信号，并使用 **奈奎斯特** 频率对其进行采样。奈奎斯特频率是连续信号采样率的一半。
- en: DFT-based filtering
  id: totrans-1199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于DFT的过滤
- en: 'The purpose of this section is to introduce, describe, and implement a noise
    filtering mechanism that leverages the discrete Fourier transform. The idea is
    quite simple: the forward and inverse Fourier series are used sequentially to
    convert the raw data from the time domain to the frequency domain and back. The
    only input you need to supply is a function *g* that modifies the sequence of
    frequencies. This operation is known as the convolution of the filter *g* and
    the frequencies'' spectrum.'
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目的在于介绍、描述和实现一个利用离散傅里叶变换的噪声过滤机制。这个想法相当简单：正向和逆向傅里叶级数依次使用，将原始数据从时域转换为频域再转换回时域。您唯一需要提供的是函数
    *g*，该函数修改频率序列。这种操作称为滤波器 *g* 与频率谱的卷积。
- en: 'A convolution is similar to an inner product of two time series in the frequencies
    domain. Mathematically, the convolution is defined as follows:'
  id: totrans-1201
  prefs: []
  type: TYPE_NORMAL
  zh: 在频域中，卷积类似于两个时间序列的内积。数学上，卷积定义为以下内容：
- en: Note
  id: totrans-1202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Convolution**'
  id: totrans-1203
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积**'
- en: 'M10: The convolution of two functions *f* and *g* is defined as:'
  id: totrans-1204
  prefs: []
  type: TYPE_NORMAL
  zh: M10：两个函数 *f* 和 *g* 的卷积定义为：
- en: '![DFT-based filtering](img/image01301.jpeg)'
  id: totrans-1205
  prefs: []
  type: TYPE_IMG
  zh: '![基于DFT的过滤](img/image01301.jpeg)'
- en: 'M11: The convolution *F* of a time series *x = (x[i]}* with a frequency spectrum
    *ω^x* and a filter *f* in frequency domain *ω^f* is defined as:'
  id: totrans-1206
  prefs: []
  type: TYPE_NORMAL
  zh: M11：时间序列 *x = (x[i]}* 与频率谱 *ω^x* 和频域中的滤波器 *f* 的卷积 *F* 定义为：
- en: '![DFT-based filtering](img/image01302.jpeg)'
  id: totrans-1207
  prefs: []
  type: TYPE_IMG
  zh: '![基于DFT的过滤](img/image01302.jpeg)'
- en: 'Let''s apply the convolution to our filtering problem. The filtering algorithm
    using the discrete Fourier transform consists of five steps:'
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将卷积应用于我们的过滤问题。使用离散傅里叶变换的过滤算法包括五个步骤：
- en: Pad the time series to enable the discrete sine or cosine transform.
  id: totrans-1209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充时间序列以启用离散正弦或余弦变换。
- en: Generate the ordered sequence of frequencies using the forward transform *F*.
  id: totrans-1210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用正向变换 *F* 生成频率的有序序列。
- en: Select the filter function *G* in the frequency domain and a cutoff frequency.
  id: totrans-1211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在频域中选择滤波函数 *G* 和截止频率。
- en: Convolute the sequence of frequency with the filter function *G*.
  id: totrans-1212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将频率序列与滤波函数 *G* 进行卷积。
- en: Generate the filtered signal in the time domain by applying the inverse DFT
    transform to the convoluted frequencies.![DFT-based filtering](img/image01303.jpeg)
  id: totrans-1213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过对卷积频率应用逆 DFT 变换，在时域中生成滤波后的信号。![基于 DFT 的滤波](img/image01303.jpeg)
- en: A diagram of the discrete Fourier filter
  id: totrans-1214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 离散傅里叶滤波器的示意图
- en: 'The most commonly used low-pass filter functions are known as the `sinc` and
    `sinc2` functions, which are defined as a rectangular function and triangular
    function, respectively. These functions are partially applied functions that are
    derived from a generic `convol` method. The simplest `sinc` function returns `1`
    for frequencies below a cutoff frequency, `fC`, and `0` if the frequency is higher:'
  id: totrans-1215
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的低通滤波函数被称为 `sinc` 和 `sinc2` 函数，分别定义为矩形函数和三角形函数。这些函数是从通用 `convol` 方法派生出的部分应用函数。最简单的
    `sinc` 函数在截止频率 `fC` 以下返回 `1`，如果频率更高则返回 `0`：
- en: '[PRE116]'
  id: totrans-1216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: Note
  id: totrans-1217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Partially applied functions versus partial functions**'
  id: totrans-1218
  prefs: []
  type: TYPE_NORMAL
  zh: '**部分应用函数与部分函数**'
- en: Partial functions and partially applied functions are not actually related.
  id: totrans-1219
  prefs: []
  type: TYPE_NORMAL
  zh: 部分函数和部分应用函数实际上并不相关。
- en: 'A partial function *f''* is a function that is applied to a subset *X''* of
    the input space *X*. It does not execute all possible input values:'
  id: totrans-1220
  prefs: []
  type: TYPE_NORMAL
  zh: 部分函数 *f'* 是应用于输入空间 *X* 的子集 *X'* 的函数。它不会执行所有可能的输入值：
- en: '![DFT-based filtering](img/image01304.jpeg)'
  id: totrans-1221
  prefs: []
  type: TYPE_IMG
  zh: '![基于 DFT 的滤波](img/image01304.jpeg)'
- en: 'A partially applied function *f"* is a function value for which the user supplies
    the value for one or more arguments. The projection reduces the dimension of the
    input space *(X, Z)*:'
  id: totrans-1222
  prefs: []
  type: TYPE_NORMAL
  zh: 部分应用函数 *f"* 是用户为其中一个或多个参数提供值的函数值。投影减少了输入空间的维度 *(X, Z)*：
- en: '![DFT-based filtering](img/image01305.jpeg)'
  id: totrans-1223
  prefs: []
  type: TYPE_IMG
  zh: '![基于 DFT 的滤波](img/image01305.jpeg)'
- en: 'The `DFTFilter` class inherits from the `DFT` class in order to reuse the `fwrd`
    forward transform function. The `g` frequency domain function is an attribute
    of the filter. The `g` function takes the `fC` frequency cutoff value as the second
    argument (line `14`). The two `sinc` and `sinc2` filters defined in the previous
    section are examples of filtering functions:'
  id: totrans-1224
  prefs: []
  type: TYPE_NORMAL
  zh: '`DFTFilter` 类从 `DFT` 类继承，以便重用 `fwrd` 正向变换函数。`g` 频率域函数是滤波器的一个属性。`g` 函数将 `fC`
    频率截止值作为第二个参数（第 `14` 行）。上一节中定义的两个 `sinc` 和 `sinc2` 滤波器是滤波函数的例子：'
- en: '[PRE117]'
  id: totrans-1225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'The filtering process follows three steps:'
  id: totrans-1226
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波过程分为三个步骤：
- en: Computation of the `fwrd` discrete Fourier forward transformation (sine or cosine)
    (line `15`).
  id: totrans-1227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 `fwrd` 离散傅里叶正向变换（正弦或余弦）（第 `15` 行）。
- en: Apply the filter function (formula **M11**) through a Scala `map` method (line
    `16`).
  id: totrans-1228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 Scala 的 `map` 方法（第 `16` 行）应用滤波函数（公式 **M11**）。
- en: Apply the inverse transform to the frequencies (line `17`).
  id: totrans-1229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对频率应用逆变换（第 `17` 行）。
- en: 'Let''s evaluate the impact of the cutoff values on the filtered data. The implementation
    of the test program consists of loading the data from the file (line `19`) and
    then invoking the `DFTFilter` of the `pfnDFTfilter` partial function (line `19`):'
  id: totrans-1230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们评估截止值对滤波数据的影响。测试程序的实现包括从文件中加载数据（第 `19` 行），然后调用 `pfnDFTfilter` 部分函数的 `DFTFilter`（第
    `19` 行）：
- en: '[PRE118]'
  id: totrans-1231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Filtering out the noise is accomplished by selecting the cutoff value between
    any of the three harmonics with the respective frequencies of 2, 5, and 15\. The
    original and the two filtered time series are plotted on the following graph:'
  id: totrans-1232
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择介于三个谐波之间的截止值来过滤噪声，这三个谐波的频率分别为 2、5 和 15。原始数据和两个滤波后的时间序列将在以下图表中展示：
- en: '![DFT-based filtering](img/image01306.jpeg)'
  id: totrans-1233
  prefs: []
  type: TYPE_IMG
  zh: '![基于 DFT 的滤波](img/image01306.jpeg)'
- en: Plotting of the discrete Fourier filter-based smoothing
  id: totrans-1234
  prefs: []
  type: TYPE_NORMAL
  zh: 基于离散傅里叶滤波器的平滑绘图
- en: As you would expect, the low-pass filter with a cutoff value of 12 eliminates
    the noise with the highest frequencies. The filter with the cutoff value 4 cancels
    out the second harmonic (low-frequency noise), leaving out only the main trend
    cycle.
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期，截止值为 12 的低通滤波器消除了最高频率的噪声。截止值为 4 的滤波器消除了第二个谐波（低频噪声），只留下了主要趋势周期。
- en: Detection of market cycles
  id: totrans-1236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 市场周期的检测
- en: Using the discrete Fourier transform to generate the frequencies spectrum of
    a periodical time series is easy. However, what about real-world signals such
    as the time series that represent the historical price of a stock?
  id: totrans-1237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用离散傅里叶变换生成周期性时间序列的频率谱是容易的。然而，对于现实世界中的信号，例如代表股票历史价格的时序，该怎么办呢？
- en: 'The purpose of the next exercise is to detect, if any, the long term cycle(s)
    of the overall stock market by applying the discrete Fourier transform to the
    quote of the S&P 500 index between January 1, 2009 and December 31, 2013, as illustrated
    in the following graph:'
  id: totrans-1238
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个练习的目的是通过将2009年1月1日至2013年12月31日标准普尔500指数的报价应用离散傅里叶变换，检测整体股市是否存在长期周期（s），如图所示：
- en: '![Detection of market cycles](img/image01307.jpeg)'
  id: totrans-1239
  prefs: []
  type: TYPE_IMG
  zh: '![市场周期检测](img/image01307.jpeg)'
- en: Historical S&P 500 index prices
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
  zh: 历史标准普尔500指数价格
- en: 'The first step is to apply the DFT to extract a frequencies spectrum for the
    S&P 500 historical prices, as shown in the following graph, with the first 32
    harmonics:'
  id: totrans-1241
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是应用DFT以提取标准普尔500历史价格的频率谱，如图所示，包括前32个谐波：
- en: '![Detection of market cycles](img/image01308.jpeg)'
  id: totrans-1242
  prefs: []
  type: TYPE_IMG
  zh: '![市场周期检测](img/image01308.jpeg)'
- en: Frequencies spectrum for the historical S&P index
  id: totrans-1243
  prefs: []
  type: TYPE_NORMAL
  zh: 历史标准普尔指数的频率谱
- en: 'The frequency domain chart highlights some interesting characteristics regarding
    the S&P 500 historical prices:'
  id: totrans-1244
  prefs: []
  type: TYPE_NORMAL
  zh: 频率域图突出了关于标准普尔500历史价格的一些有趣特征：
- en: Both positive and negative amplitudes are present, as you would expect in a
    time series with complex values. The cosine series contributes to the positive
    amplitudes while the sine series affects both positive and negative amplitudes,
    *(cos(x+π) = sin(x))*.
  id: totrans-1245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正负振幅都存在，正如你在具有复数值的时间序列中预期的那样。余弦级数对正振幅有贡献，而正弦级数影响正负振幅，*(cos(x+π) = sin(x))*。
- en: The decay of the amplitude along the frequencies is steep enough to warrant
    further analysis beyond the first harmonic, which represents the main trend of
    the historical stock price. The next step is to apply a band-pass filter technique
    to the S&P 500 historical data in order to identify short-term trends with lower
    periodicity.
  id: totrans-1246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沿频率的振幅衰减足够陡峭，足以保证对第一谐波（代表历史股价的主要趋势）之外进行进一步分析。下一步是对标准普尔500历史数据进行带通滤波器技术处理，以识别具有较低周期的短期趋势。
- en: 'A low-pass filter is limited to reduce or cancel out the noise in the raw data.
    In this case, a band-pass filter using a range or window of frequencies is appropriate
    to isolate the frequency or the group of frequencies that characterize a specific
    cycle. The `sinc` function, which was introduced in the previous section to implement
    a low-pass filter, is modified to enforce the band-pass filter within a window,
    *[w[1], w[2]]*, as follows:'
  id: totrans-1247
  prefs: []
  type: TYPE_NORMAL
  zh: 限带通滤波器用于减少或消除原始数据中的噪声。在这种情况下，使用频率范围或窗口的带通滤波器是合适的，以隔离表征特定周期的频率或频率组。在上一节中引入的`sinc`函数，用于实现低通滤波器，被修改为在窗口*[w[1],
    w[2]]*内强制执行带通滤波器，如下所示：
- en: '[PRE119]'
  id: totrans-1248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Let''s define a DFT-based band-pass filter with a window of width 4, *w=(i,
    i+4)*, with *i* ranging between 2 and 20\. Applying the window *[4, 8]* isolates
    the impact of the second harmonic on the price. As we eliminate the main upward
    trend with frequencies less than 4, all the filtered data varies within a short
    range relative to the main trend. The following graph shows the output of this
    filter:'
  id: totrans-1249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个基于DFT的带通滤波器，窗口宽度为4，*w=(i, i+4)*，其中*i*的范围在2到20之间。应用窗口*[4, 8]*可以隔离第二个谐波对价格的影响。随着我们消除小于4的频率的主上升趋势，所有过滤后的数据相对于主趋势都在一个相对较短的范围内变化。以下图形显示了该滤波器的输出：
- en: '![Detection of market cycles](img/image01309.jpeg)'
  id: totrans-1250
  prefs: []
  type: TYPE_IMG
  zh: '![市场周期检测](img/image01309.jpeg)'
- en: The output of a band-pass DFT filter range 4-8 on the historical S&P index
  id: totrans-1251
  prefs: []
  type: TYPE_NORMAL
  zh: 历史标准普尔指数上的带通DFT滤波器输出范围4-8
- en: 'In this case, we filter the S&P 500 index around the third group of harmonics
    with frequencies ranging from 18 to 22; the signal is converted into a familiar
    sinusoidal function, as shown here:'
  id: totrans-1252
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用第三组谐波（频率范围从18到22）对标准普尔500指数进行滤波；信号被转换成熟悉的正弦函数，如图所示：
- en: '![Detection of market cycles](img/image01310.jpeg)'
  id: totrans-1253
  prefs: []
  type: TYPE_IMG
  zh: '![市场周期检测](img/image01310.jpeg)'
- en: The output of a band-pass DFT filter range 18-22 on the historical S&P index
  id: totrans-1254
  prefs: []
  type: TYPE_NORMAL
  zh: 历史标准普尔指数的带通DFT滤波器输出范围18-22
- en: There is a possible rational explanation for the shape of the S&P 500 data filtered
    by a band-pass filter with a frequency of 20, as illustrated in the previous graph.
    The S&P 500 historical data plot shows that the frequency of the fluctuation in
    the middle of the uptrend (trading sessions 620 to 770) increases significantly.
  id: totrans-1255
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过频率为20的带通滤波器过滤的标准普尔500数据，存在一个可能的合理解释，如图所示。标准普尔500历史数据图显示，上升趋势（交易时段620至770）中间的波动频率显著增加。
- en: 'This phenomenon can be explained by the fact that the S&P 500 index reaches
    a resistance level around the trading session 545 when the existing uptrend breaks.
    A tug of war starts between the bulls, betting the market nudges higher, and the
    bears, who are expecting a correction. The back and forth between the traders
    ends when the S&P 500 index breaks through its resistance and resumes a strong
    uptrend characterized by a high amplitude low frequency, as shown in the following
    graph:'
  id: totrans-1256
  prefs: []
  type: TYPE_NORMAL
  zh: 这种现象可以通过以下事实来解释：当现有的上升趋势被打破时，标准普尔500指数在交易时段545左右达到阻力位。多头和空头之间开始了一场拉锯战，多头押注市场会小幅上涨，而空头则预期会有修正。当标准普尔500指数突破阻力位并恢复到具有高振幅低频率的强劲上升趋势时，交易者的拉锯战结束，如下面的图表所示：
- en: '![Detection of market cycles](img/image01311.jpeg)'
  id: totrans-1257
  prefs: []
  type: TYPE_IMG
  zh: '![市场周期检测](img/image01311.jpeg)'
- en: An illustration of support and resistance levels for the historical S&P 500
    index prices
  id: totrans-1258
  prefs: []
  type: TYPE_NORMAL
  zh: 历史标准普尔500指数价格支撑和阻力水平的示意图
- en: One of the limitations of using the discrete Fourier-based filters to clean
    up data is that it requires the data scientist to extract the frequencies spectrum
    and modify the filter on a regular basis, as he or she is never sure that the
    most recent batch of data does not introduce noise with a different frequency.
    The Kalman filter addresses this limitation.
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于离散傅立叶的滤波器清理数据的一个局限性是，它要求数据科学家定期提取频率谱并修改滤波器，因为他或她永远无法确定最新的数据批次不会引入不同频率的噪声。卡尔曼滤波器解决了这一局限性。
- en: The discrete Kalman filter
  id: totrans-1260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离散卡尔曼滤波器
- en: The Kalman filter is a mathematical model that provides an accurate and recursive
    computation approach to estimate the previous states and predict the future states
    of a process for which some variables may be unknown. R.E. Kalman introduced it
    in the early 60s to model dynamics systems and predict a trajectory in aerospace
    [3:10]. Today, the Kalman filter is used to discover a relationship between two
    observed variables that may or may not be associated with other hidden variables.
    In this respect, the Kalman filter shares some similarities with the Hidden Markov
    models, as described in the *The hidden Markov model* section in [Chapter 7](part0193.xhtml#aid-5O1SI1
    "Chapter 7. Sequential Data Models"), *Sequential Data Models* [3:11].
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器是一个数学模型，它提供了一种准确且递归的计算方法来估计过程的先前状态并预测未来状态，其中某些变量可能未知。R.E. 卡尔曼在20世纪60年代初引入它来模拟动态系统并在航空航天领域预测轨迹[3:10]。今天，卡尔曼滤波器用于发现两个可能或可能不与其他隐藏变量相关联的观测变量之间的关系。在这方面，卡尔曼滤波器与第7章中描述的*隐藏马尔可夫模型*部分中所述的*顺序数据模型*有一些相似之处[3:11]。
- en: 'The Kalman filter is used as:'
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器被用作：
- en: A predictor of the next data point from the current observation
  id: totrans-1263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从当前观测值预测下一个数据点
- en: A filter that weeds out noise by processing the last two observations
  id: totrans-1264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过处理最后两个观测值来消除噪声的滤波器
- en: A smoothing model that identifies trends from a history of observations
  id: totrans-1265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从观测历史中识别趋势的平滑模型
- en: Note
  id: totrans-1266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Smoothing versus filtering**'
  id: totrans-1267
  prefs: []
  type: TYPE_NORMAL
  zh: '**平滑与滤波**'
- en: Smoothing is an operation that removes high-frequency fluctuations from a time
    series or signal. Filtering consists of selecting a range of frequencies to process
    the data. In this regard, smoothing is somewhat similar to low-pass filtering.
    The only difference is that a low-pass filter is usually implemented through linear
    methods.
  id: totrans-1268
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑是一种从时间序列或信号中去除高频波动的操作。滤波包括选择一系列频率来处理数据。在这方面，平滑与低通滤波有些相似。唯一的区别是低通滤波通常通过线性方法实现。
- en: 'Conceptually, the Kalman filter estimates the state of a system from noisy
    observations. The Kalman filter has two characteristics:'
  id: totrans-1269
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，卡尔曼滤波器通过噪声观测估计系统的状态。卡尔曼滤波器有两个特点：
- en: '**Recursive**: A new state is predicted and corrected using the input of a
    previous state'
  id: totrans-1270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**递归**：使用先前状态输入预测并校正新状态'
- en: '**Optimal**: This is an optimal estimator because it minimizes the mean square
    error of the estimated parameters (against actual values)'
  id: totrans-1271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最优**：这是一个最优估计器，因为它最小化了估计参数的均方误差（与实际值相比）'
- en: The Kalman filter is one of the stochastic models that are used in adaptive
    control [3:12].
  id: totrans-1272
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器是自适应控制中使用的随机模型之一[3:12]。
- en: Note
  id: totrans-1273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Kalman and nonlinear systems**'
  id: totrans-1274
  prefs: []
  type: TYPE_NORMAL
  zh: '**卡尔曼与非线性系统**'
- en: The Kalman filter estimates the internal state of a linear dynamic system. However,
    it can be extended to a nonlinear state space model using linear or quadratic
    approximation functions. These filters are known as, you guessed it, **Extended
    Kalman Filters** (**EKF**), the theory of which is beyond the scope of this book.
  id: totrans-1275
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器估计线性动态系统的内部状态。然而，它可以通过使用线性或二次近似函数扩展到非线性状态空间模型。这些滤波器被称为，你可能已经猜到了，**扩展卡尔曼滤波器**（**EKF**），其理论超出了本书的范围。
- en: The following section is dedicated to discrete Kalman filters for linear systems,
    as applied to financial engineering. A continuous signal can be converted to a
    time series using the Nyquist frequency.
  id: totrans-1276
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节专门介绍用于金融工程的线性系统的离散卡尔曼滤波器。连续信号可以使用奈奎斯特频率转换为时间序列。
- en: The state space estimation
  id: totrans-1277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 状态空间估计
- en: 'The Kalman filter model consists of two core elements of a dynamic system:
    a process that generates data and a measurement that collects data. These elements
    are referred to as the state space model. Mathematically speaking, the state space
    model consists of two equations:'
  id: totrans-1278
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器模型由动态系统的两个核心元素组成：生成数据的过程和收集数据的测量。这些元素被称为状态空间模型。从数学上讲，状态空间模型由两个方程组成：
- en: '**The transition equation**: This describes the dynamics of the system, including
    the unobserved variables'
  id: totrans-1279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换方程**：这描述了系统的动力学，包括未观察到的变量'
- en: '**The measurement equation**: This describes the relationship between the observed
    and unobserved variables'
  id: totrans-1280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测量方程**：这描述了观察到的和未观察到的变量之间的关系'
- en: The transition equation
  id: totrans-1281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换方程
- en: 'Let''s consider a system with a linear state *x[t]* of *n* variables and a
    control input vector *u[t]*. The prediction of the state at time *t* is computed
    by a linear stochastic equation (**M12**):'
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个具有线性状态 *x[t]* 的 *n* 个变量的系统和控制输入向量 *u[t]*。在时间 *t* 的状态预测是通过一个线性随机方程（**M12**）计算的：
- en: '![The transition equation](img/image01312.jpeg)'
  id: totrans-1283
  prefs: []
  type: TYPE_IMG
  zh: '![转换方程](img/image01312.jpeg)'
- en: '*A^t* is the square matrix of dimension *n* that represents the transition
    from a state *x[t-1]* at *t-1* to a state *x[t]* at *t*. The matrix is intrinsic
    to the dynamic system under consideration.'
  id: totrans-1284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A^t* 是一个 *n* 维度的方阵，它表示从时间 *t-1* 的状态 *x[t-1]* 到时间 *t* 的状态 *x[t]* 的转换。这个矩阵是考虑的动态系统固有的。'
- en: '*B[t]* is a *n by n* matrix that describes the control input model (an external
    action on the system or model). It is applied to the control vector, *u[t]*.'
  id: totrans-1285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B[t]* 是一个 *n by n* 矩阵，它描述了控制输入模型（对系统或模型的外部作用）。它应用于控制向量，*u[t]*。'
- en: '*w[t]* represents the noise generated by the system, or from a probabilistic
    point of view, it represents the uncertainty on the model. It is known as the
    process white noise.'
  id: totrans-1286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w[t]* 代表系统产生的噪声，或者从概率的角度来看，它代表模型的不确定性。它被称为过程白噪声。'
- en: The control input vector represents the external input (or control) to the state
    of the system. Most systems, including our financial example later in this chapter,
    have no external input to the state of the model.
  id: totrans-1287
  prefs: []
  type: TYPE_NORMAL
  zh: 控制输入向量表示系统状态的外部输入（或控制）。大多数系统，包括本章后面的金融示例，都没有外部输入到模型状态。
- en: Note
  id: totrans-1288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**A white and Gaussian noise**'
  id: totrans-1289
  prefs: []
  type: TYPE_NORMAL
  zh: '**白噪声和高斯噪声**'
- en: A white noise is a Gaussian noise, following a normal distribution with zero
    mean.
  id: totrans-1290
  prefs: []
  type: TYPE_NORMAL
  zh: 白噪声是高斯噪声，遵循均值为零的正态分布。
- en: The measurement equation
  id: totrans-1291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量方程
- en: 'The measurement of *m* values *z[t]* of the state of the system is defined
    by the following equation (M13):'
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: 系统状态的 *m* 个值 *z[t]* 的测量由以下方程定义（M13）：
- en: '![The measurement equation](img/image01313.jpeg)'
  id: totrans-1293
  prefs: []
  type: TYPE_IMG
  zh: '![测量方程](img/image01313.jpeg)'
- en: '*H[t]* is a *m by n* matrix that models the dependency of the measurement to
    the state of the system.'
  id: totrans-1294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H[t]* 是一个 *m by n* 矩阵，它模拟了测量与系统状态之间的依赖关系。'
- en: '*v[t]* is the white noise introduced by the measuring devices. Similarly to
    the process noise, *v* follows a Gaussian distribution with zero mean and a variance
    *R*, known as the **measurement noise covariance**.'
  id: totrans-1295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*v[t]* 是测量设备引入的白噪声。与过程噪声类似，*v* 遵循均值为零、方差为 *R* 的高斯分布，称为**测量噪声协方差**。'
- en: Note
  id: totrans-1296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The time dependency model**'
  id: totrans-1297
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间依赖性模型**'
- en: We cannot assume that the parameters of the generalized discrete Kalman filter,
    such as the state transition *A[t]*, control input *B[t]*, and observation matrices
    (or measurement dependency) *H[t]* are independent of time. However, these parameters
    are constant in most practical applications.
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能假设广义离散卡尔曼滤波器的参数，如状态转换 *A[t]*、控制输入 *B[t]* 和观测矩阵（或测量依赖性）*H[t]* 与时间无关。然而，在大多数实际应用中，这些参数是恒定的。
- en: The recursive algorithm
  id: totrans-1299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 递归算法
- en: 'The set of equations for the discrete Kalman filter is implemented as a recursive
    computation with two distinct steps:'
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: 离散卡尔曼滤波器的方程组被实现为具有两个不同步骤的递归计算：
- en: The algorithm uses the transition equations to estimate the next observation
  id: totrans-1301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法使用转换方程来估计下一个观测值
- en: The estimation is created with the actual measurement for this observation
  id: totrans-1302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估计是通过此观测的实际测量值创建的
- en: 'The recursion is visualized in the following diagram:'
  id: totrans-1303
  prefs: []
  type: TYPE_NORMAL
  zh: 递归在以下图中得到可视化：
- en: '![The recursive algorithm](img/image01314.jpeg)'
  id: totrans-1304
  prefs: []
  type: TYPE_IMG
  zh: '![递归算法](img/image01314.jpeg)'
- en: An overview diagram of the recursive Kalman algorithm
  id: totrans-1305
  prefs: []
  type: TYPE_NORMAL
  zh: 递归卡尔曼算法的概述图
- en: 'Let''s illustrate the prediction and correction phases in the context of filtering
    financial data, in a manner similar to the moving average and Fourier transform.
    The objective is to extract the trend and the transitory component of the yield
    of the 10-year Treasury bond. The Kalman filter is particularly suitable for the
    analysis of interest rates for two reasons:'
  id: totrans-1306
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在过滤金融数据的情况下，以类似于移动平均和傅里叶变换的方式说明预测和校正阶段。目标是提取10年期国债收益的趋势和暂时性成分。卡尔曼滤波器特别适合分析利率，原因有两个：
- en: Yields are the results of multiple factors, some of which are not directly observable.
  id: totrans-1307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收益是多个因素的结果，其中一些因素是不可直接观察的。
- en: Yields are influenced by the policy of the Federal Reserve that can be easily
    modeled by the control matrix.
  id: totrans-1308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收益受美联储政策的影响，该政策可以通过控制矩阵轻松建模。
- en: The 10-year Treasury bond has a higher trading volume than bonds with longer
    maturity, making trends in interest rates a bit more reliable [3:13].
  id: totrans-1309
  prefs: []
  type: TYPE_NORMAL
  zh: 10年期国债的交易量高于期限更长的债券，这使得利率的趋势更加可靠 [3:13]。
- en: 'Applying the Kalman filter to clean raw data requires you to define a model
    that encompasses both observed and non-observed states. In the case of the trend
    analysis, we can safely create our model with a two-variable state: the current
    yield *x[t]* and the previous yield *x[t-1]*.'
  id: totrans-1310
  prefs: []
  type: TYPE_NORMAL
  zh: 将卡尔曼滤波器应用于清洗原始数据需要您定义一个包含观测和非观测状态的模型。在趋势分析的情况下，我们可以安全地创建我们的模型，具有两个变量状态：当前收益
    *x[t]* 和前一个收益 *x[t-1]*。
- en: Note
  id: totrans-1311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The state of dynamic systems**'
  id: totrans-1312
  prefs: []
  type: TYPE_NORMAL
  zh: '**动态系统的状态**'
- en: The term "state" refers to the state of the dynamic system under consideration
    and not the state of the execution of the algorithm.
  id: totrans-1313
  prefs: []
  type: TYPE_NORMAL
  zh: “状态”一词指的是所考虑的动态系统的状态，而不是算法执行的状态。
- en: 'This implementation of the Kalman filter uses the Apache Commons Math library.
    Therefore, we need to specify the implicit conversion from our primitives, introduced
    in the *Primitives and implicits* section in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*, to the `RealMatrix`, `RealVector`,
    `Array2DRowRealMatrix`, and `ArrayRealVector` Apache Commons Math types:'
  id: totrans-1314
  prefs: []
  type: TYPE_NORMAL
  zh: 此卡尔曼滤波器的实现使用了Apache Commons Math库。因此，我们需要指定从我们在第1章的“原始和隐式”部分中引入的原始类型到 `RealMatrix`、`RealVector`、`Array2DRowRealMatrix`
    和 `ArrayRealVector` Apache Commons Math类型的隐式转换：
- en: '[PRE120]'
  id: totrans-1315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: The client code has to import the implicit conversion functions within its scope.
  id: totrans-1316
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端代码必须在其作用域内导入隐式转换函数。
- en: 'The Kalman model assumes that the process and measurement noise follows a Gaussian
    distribution, also known as a white noise. For the sake of maintainability, the
    generation of the white noise is encapsulated in the `QRNoise` class with the
    following arguments (line `1`):'
  id: totrans-1317
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼模型假设过程噪声和测量噪声遵循高斯分布，也称为白噪声。为了便于维护，白噪声的生成被封装在具有以下参数的 `QRNoise` 类中（行 `1`）：
- en: '`qr`: This is the tuple of scale factors for the process noise matrix *Q* and
    the measurement noise *R*'
  id: totrans-1318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qr`：这是过程噪声矩阵 *Q* 和测量噪声 *R* 的尺度因子元组的表示'
- en: '`profile`: This is the noise profile with the normal distribution as default'
  id: totrans-1319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`profile`：这是默认为正态分布的噪声配置文件'
- en: 'The two `noiseQ` and `noiseR` methods generate an array of two independent
    white noise elements (line `2`):'
  id: totrans-1320
  prefs: []
  type: TYPE_NORMAL
  zh: 两个 `noiseQ` 和 `noiseR` 方法生成两个独立的白噪声元素数组（行 `2`）：
- en: '[PRE121]'
  id: totrans-1321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: Note
  id: totrans-1322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Experimenting with a noise profile**'
  id: totrans-1323
  prefs: []
  type: TYPE_NORMAL
  zh: '**尝试不同的噪声分布**'
- en: Although the discrete Kalman filter assumes that the noise profile follows a
    normal distribution, the `QRNoise` class allows the user to experiment with different
    noise profiles.
  id: totrans-1324
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然离散卡尔曼滤波假设噪声分布遵循正态分布，但`QRNoise`类允许用户尝试不同的噪声分布。
- en: 'The easiest approach to manage the matrices and vectors used in the recursion
    is to define them as arguments of a `kalmanConfig` configuration class. The arguments
    of the configuration follow the naming convention defined in the mathematical
    formulas: `A` is the state transition matrix, `B` is the control matrix, `H` is
    the matrix of observations that define the dependencies between the measurement
    and system state, and `P` is the covariance error matrix:'
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: 管理递归中使用的矩阵和向量的最简单方法是将它们定义为`kalmanConfig`配置类的参数。配置的参数遵循数学公式中定义的命名约定：`A`是状态转换矩阵，`B`是控制矩阵，`H`是定义测量与系统状态之间依赖关系的观测矩阵，`P`是协方差误差矩阵：
- en: '[PRE122]'
  id: totrans-1326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'Let''s implement the Kalman filter as a `DKalman` transformation of the `ETransform`
    type on a time series with a predefined `KalmanConfig` configuration:'
  id: totrans-1327
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在具有预定义`KalmanConfig`配置的时间序列上实现卡尔曼滤波作为`ETransform`类型的`DKalman`转换：
- en: '[PRE123]'
  id: totrans-1328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: As with any explicit data transformation, we need to specify the `U` and `V`
    types (lines `3` and `4`), which are identical. The Kalman filter does not alter
    the structure of the data, it alters only the values. We define an internal state
    for the `KRState` Kalman computation by creating a tuple of two `KalmanFilter`
    and `RealVector` (line `5`) Apache Commons Math types.
  id: totrans-1329
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何明确的数据转换一样，我们需要指定`U`和`V`的类型（第`3`和`4`行），它们是相同的。卡尔曼滤波不改变数据的结构，它只改变值。我们通过创建一个包含两个`KalmanFilter`和`RealVector`（第`5`行）Apache
    Commons Math类型的元组来定义`KRState`卡尔曼计算的内部状态。
- en: The key elements of the filter are now in place and it's time to implement the
    prediction-correction cycle portion of the Kalman algorithm.
  id: totrans-1330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在滤波器的关键元素已经就位，是时候实现卡尔曼算法的预测-校正循环部分了。
- en: Prediction
  id: totrans-1331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测
- en: 'The prediction phase consists of estimating the *x* state (yield of the Treasury
    bond) using the transition equation. We assume that the Federal Reserve has no
    material effect on the interest rates, making the *B* control input matrix null.
    The transition equation can be easily resolved using simple operations on matrices:'
  id: totrans-1332
  prefs: []
  type: TYPE_NORMAL
  zh: 预测阶段包括使用转换方程估计*x*状态（国库券的收益）。我们假设美联储对利率没有实质性影响，使得控制输入矩阵*B*为空。转换方程可以通过对矩阵进行简单运算轻松解决：
- en: '![Prediction](img/image01315.jpeg)'
  id: totrans-1333
  prefs: []
  type: TYPE_IMG
  zh: '![预测](img/image01315.jpeg)'
- en: Visualization of the transition equation of the Kalman filter
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波转换方程的可视化
- en: The purpose of this exercise is to evaluate the impact of the different parameters
    of the transition matrix *A* in terms of smoothing.
  id: totrans-1335
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目的是评估转换矩阵*A*的不同参数对平滑度的影响。
- en: Note
  id: totrans-1336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The control input matrix B**'
  id: totrans-1337
  prefs: []
  type: TYPE_NORMAL
  zh: '**控制输入矩阵B**'
- en: In this example, the control matrix *B* is null because there is no known, deterministic
    external action on the yield of the 10-year Treasury bond. However, the yield
    can be affected by unknown parameters that we represent as hidden variables. For
    example, the matrix *B* can be used to model the decision of the Federal Reserve
    regarding asset purchases and federal fund rates.
  id: totrans-1338
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，控制矩阵*B*为空，因为没有已知的外部行动对10年期国库券收益产生影响。然而，收益可能受到我们表示为隐藏变量的未知参数的影响。例如，矩阵*B*可以用来模拟美联储关于资产购买和联邦基金利率的决定。
- en: The mathematics behind the Kalman filter presented as a reference to the implementation
    in Scala, use the same notation for matrices and vectors. It is absolutely not
    a prerequisite to understand the Kalman filter and its implementation in the next
    section. If you have a natural inclination toward linear algebra, the following
    describe the two equations for the prediction step.
  id: totrans-1339
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波背后的数学作为Scala实现参考，使用相同的矩阵和向量符号。这绝对不是理解卡尔曼滤波及其在下一节中的实现的前提条件。如果你对线性代数有自然的倾向，以下描述了预测步骤的两个方程。
- en: Note
  id: totrans-1340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The prediction step**'
  id: totrans-1341
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测步骤**'
- en: 'M14: The prediction of the state at time *t* is computed by extrapolating the
    state estimate:'
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: M14：在时间*t*的状态预测是通过外推状态估计来计算的：
- en: '![Prediction](img/image01316.jpeg)'
  id: totrans-1343
  prefs: []
  type: TYPE_IMG
  zh: '![预测](img/image01316.jpeg)'
- en: '*A* is the square matrix of dimension *n* that represents the transition from
    state *x* at *t-1* to state *x* at time *t*'
  id: totrans-1344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A*是维度为*n*的平方矩阵，代表从时间*t-1*的状态*x*到时间*t*的状态*x*的转换'
- en: '*x''[t]* is the predicted state of the system based on the current state and
    the model *A*'
  id: totrans-1345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x''[t]* 是基于当前状态和模型 *A* 预测的系统状态'
- en: '*B* is the vector of *n* dimension that describes the input to the state'
  id: totrans-1346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B* 是一个描述状态输入的 *n* 维向量'
- en: 'M15: The mean square error matrix, *P*, which is to be minimized, is updated
    using the following formula:'
  id: totrans-1347
  prefs: []
  type: TYPE_NORMAL
  zh: M15：要最小化的均方误差矩阵 *P*，使用以下公式更新：
- en: '![Prediction](img/image01317.jpeg)'
  id: totrans-1348
  prefs: []
  type: TYPE_IMG
  zh: '![预测](img/image01317.jpeg)'
- en: '*A^T* is the transpose of the state transition matrix'
  id: totrans-1349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A^T* 是状态转换矩阵的转置'
- en: '*Q* is the process white noise described as a Gaussian distribution with a
    zero mean and a variance *Q*, known as the noise covariance'
  id: totrans-1350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Q* 是过程白噪声，描述为零均值和方差 *Q* 的高斯分布，称为噪声协方差'
- en: The state transition matrix is implemented using the matrix and vector classes
    included in the Apache Commons Math library. The types of matrices and vectors
    are automatically converted into the `RealMatrix` and `RealVector` classes.
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: 状态转换矩阵使用 Apache Commons Math 库中包含的矩阵和向量类实现。矩阵和向量的类型自动转换为 `RealMatrix` 和 `RealVector`
    类。
- en: 'The implementation of the equation **M14** is as follows:'
  id: totrans-1352
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 **M14** 的实现如下：
- en: '[PRE124]'
  id: totrans-1353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: The new state is predicted (or estimated), and then used as an input to the
    correction step.
  id: totrans-1354
  prefs: []
  type: TYPE_NORMAL
  zh: 新状态被预测（或估计），然后用作校正步骤的输入。
- en: Correction
  id: totrans-1355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 校正
- en: 'The second step of the recursive Kalman algorithm is the correction of the
    estimated yield of the 10-year Treasury bond with the actual yield. In this example,
    the white noise of the measurement is negligible. The measurement equation is
    simple because the state is represented by the current and previous yield and
    their measurement, *z*:'
  id: totrans-1356
  prefs: []
  type: TYPE_NORMAL
  zh: 递归卡尔曼算法的第二步是校正10年期国债收益的实际收益。在这个例子中，测量白噪声可以忽略不计。测量方程很简单，因为状态由当前和前一个收益及其测量值 *z*
    表示：
- en: '![Correction](img/image01318.jpeg)'
  id: totrans-1357
  prefs: []
  type: TYPE_IMG
  zh: '![更正](img/image01318.jpeg)'
- en: Visualization of the measurement equation of the Kalman filter
  id: totrans-1358
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器测量方程的可视化
- en: The sequence of mathematical equations of the correction phase consists of updating
    the estimation of the state *x* using the actual values *z* and computing the
    Kalman gain, *K*.
  id: totrans-1359
  prefs: []
  type: TYPE_NORMAL
  zh: 校正阶段的数学方程序列包括使用实际值 *z* 更新状态 *x* 的估计，并计算卡尔曼增益 *K*。
- en: Note
  id: totrans-1360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The correction step**'
  id: totrans-1361
  prefs: []
  type: TYPE_NORMAL
  zh: '**校正步骤**'
- en: 'M16: The state of the system *x* is estimated from the actual measurement *z*
    using the following formula:'
  id: totrans-1362
  prefs: []
  type: TYPE_NORMAL
  zh: M16：系统状态 *x* 使用以下公式从实际测量 *z* 中估计：
- en: '![Correction](img/image01319.jpeg)'
  id: totrans-1363
  prefs: []
  type: TYPE_IMG
  zh: '![更正](img/image01319.jpeg)'
- en: '*r[t]* is the residual between the predicted measurement and the actual measured
    values'
  id: totrans-1364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*r[t]* 是预测测量值和实际测量值之间的残差'
- en: '*K[t]* is the Kalman gain for the correction factor'
  id: totrans-1365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*K[t]* 是校正因子的卡尔曼增益'
- en: 'M17: The Kalman gain is computed as:'
  id: totrans-1366
  prefs: []
  type: TYPE_NORMAL
  zh: M17：卡尔曼增益的计算如下：
- en: '![Correction](img/image01320.jpeg)'
  id: totrans-1367
  prefs: []
  type: TYPE_IMG
  zh: '![更正](img/image01320.jpeg)'
- en: Here, *H^T* is the matrix transpose of *H* and *P[t]'* is the estimate of the
    error covariance.
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*H^T* 是 *H* 的矩阵转置，*P[t]'* 是误差协方差的估计。
- en: Kalman smoothing
  id: totrans-1369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卡尔曼平滑
- en: 'It is time to put our knowledge of the transition and measurement equations
    to test. The Apache Commons Math library defines the two `DefaultProcessModel`
    and `DefaultMeasurementModel` classes to encapsulate the components of the matrices
    and vectors. The historical values for the yield of the 10-year Treasury bond
    are loaded through the `DataSource` method and mapped to the smoothed series that
    is the output of the filter:'
  id: totrans-1370
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候检验我们对状态和测量方程的知识了。Apache Commons Math 库定义了两个 `DefaultProcessModel` 和 `DefaultMeasurementModel`
    类来封装矩阵和向量的组件。10 年期国债收益的历史值通过 `DataSource` 方法加载，并映射到滤波器的输出平滑序列：
- en: '[PRE125]'
  id: totrans-1371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: The data transformation for the Kalman filter initializes the process and measurement
    model for each data point in the private `initialize` (line `6`) method, updates
    the state using the transition and correction equations iteratively in the `newState`
    method (line `7`), and returns the filtered series of pair values (line `8`).
  id: totrans-1372
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器的数据转换在私有 `initialize` 方法（行 `6`）中初始化每个数据点的过程和测量模型，在 `newState` 方法（行 `7`）中迭代地使用转换和校正方程更新状态，并返回成对的值滤波序列（行
    `8`）。
- en: Note
  id: totrans-1373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Exception handling**'
  id: totrans-1374
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常处理**'
- en: 'The code to catch and process exceptions thrown by the Apache Commons Math
    library is omitted as the standard practice in the book. As far as the execution
    of the Kalman filter is concerned, the following exceptions have to be handled:'
  id: totrans-1375
  prefs: []
  type: TYPE_NORMAL
  zh: 书中省略了捕获和处理由Apache Commons Math库抛出的异常的代码，这是标准做法。就卡尔曼滤波的执行而言，必须处理以下异常：
- en: '`NonSquareMatrixException`'
  id: totrans-1376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NonSquareMatrixException`'
- en: '`DimensionMismatchException`'
  id: totrans-1377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DimensionMismatchException`'
- en: '`MatrixDimensionMismatchException`'
  id: totrans-1378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MatrixDimensionMismatchException`'
- en: 'The `initialize` method encapsulates the initialization of the `pModel` process
    model (line `9`) and the `mModel` measurement (observations dependencies) model
    (line `10`), as defined in the Apache Commons Math library:'
  id: totrans-1379
  prefs: []
  type: TYPE_NORMAL
  zh: '`initialize`方法封装了`pModel`过程模型（第9行）和`mModel`测量（观测）模型（第10行）的初始化，这些模型在Apache Commons
    Math库中定义：'
- en: '[PRE126]'
  id: totrans-1380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'The exceptions thrown by the Apache Commons Math API are caught and processed
    through the `Try` monad. The iterative prediction and correction of the smoothed
    yields of 10-year Treasury bond is implemented by the `newState` method. The method
    iterates through the following steps:'
  id: totrans-1381
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Commons Math API抛出的异常被捕获并通过`Try`单子进行处理。通过`newState`方法实现10年期国债平滑收益的迭代预测和校正。该方法通过以下步骤迭代：
- en: Estimate the new values of the state by invoking the Apache Commons Math `KalmanFilter.predict`
    method that implements the **M14** formula (line `11`).
  id: totrans-1382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用实现**M14**公式（第11行）的Apache Commons Math `KalmanFilter.predict`方法来估计新的状态值。
- en: Apply the **M12** formula to the new state *x* at time *t* (line `12`).
  id: totrans-1383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**M12**公式应用于时间t的新状态*x*（第12行）。
- en: Compute the measured value *z* at time *t* using the **M13** formula (line `13`).
  id: totrans-1384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**M13**公式（第13行）计算时间t的测量值*z*。
- en: Invoke the Apache Commons Math `KalmanFilter.correct` method to implement the
    **M16** formula (line `14`).
  id: totrans-1385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用Apache Commons Math的`KalmanFilter.correct`方法来实现**M16**公式（第14行）。
- en: Return the estimated value of the state *x* by invoking the Apache Commons Math
    `KalmanFilter.getStateEstimation` method (line `15`).
  id: totrans-1386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用Apache Commons Math的`KalmanFilter.getStateEstimation`方法（第15行）返回状态*x*的估计值。
- en: 'The code will be as follows:'
  id: totrans-1387
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE127]'
  id: totrans-1388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: Note
  id: totrans-1389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The exit condition**'
  id: totrans-1390
  prefs: []
  type: TYPE_NORMAL
  zh: '**退出条件**'
- en: In the code snippet for the `newState` method, the iteration for specific data
    points exits when the maximum number of iterations is reached. A more elaborate
    implementation consists of either evaluating the matrix *P* at each iteration
    or estimation converged within a predefined range.
  id: totrans-1391
  prefs: []
  type: TYPE_NORMAL
  zh: 在`newState`方法的代码片段中，当达到最大迭代次数时，特定数据点的迭代会退出。更详细实现包括在每个迭代中评估矩阵*P*或估计收敛到预定义范围内。
- en: Fixed lag smoothing
  id: totrans-1392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 固定滞后平滑
- en: So far, we have studied the Kalman filtering algorithm. We need to adapt it
    to the smoothing of a time series. The **fixed lag smoothing** technique consists
    of backward correcting previous data points, taking into account the latest actual
    value.
  id: totrans-1393
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了卡尔曼滤波算法。我们需要将其适应于时间序列的平滑处理。**固定滞后平滑**技术包括向后纠正先前数据点，并考虑最新的实际值。
- en: A N-lag smoother defines the input as a vector *X = {x[t-N-1], x[t-N-2], …,
    x[t]}* for which the value *x[t-N-j]* is corrected taking into account the current
    value of *x[t]*.
  id: totrans-1394
  prefs: []
  type: TYPE_NORMAL
  zh: N滞后平滑器定义输入为向量*X = {x[t-N-1], x[t-N-2], …, x[t]}*，其中*x[t-N-j]*的值在考虑*x[t]*的当前值时被纠正。
- en: The strategy is quite similar to the hidden Markov model forward and backward
    passes (refer to the *Evaluation – CF-1* section under *The hidden Markov model*
    in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"),
    *Sequential Data Models*).
  id: totrans-1395
  prefs: []
  type: TYPE_NORMAL
  zh: 该策略与隐藏马尔可夫模型的前向和后向传递相当相似（参见[第7章](part0193.xhtml#aid-5O1SI1 "第7章。顺序数据模型")下*隐藏马尔可夫模型*中的*评估
    – CF-1*部分，*顺序数据模型*）。
- en: Note
  id: totrans-1396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Complex strategies for lag smoothing**'
  id: totrans-1397
  prefs: []
  type: TYPE_NORMAL
  zh: '**滞后平滑的复杂策略**'
- en: There are numerous formulas or methodologies to implement an accurate fixed
    lag smoothing strategy and correct the predicted observations. Such strategies
    are beyond the scope of this book.
  id: totrans-1398
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多公式或方法可以实现精确的固定滞后平滑策略并纠正预测观测值。这些策略超出了本书的范围。
- en: Experimentation
  id: totrans-1399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实验
- en: The objective is to smoothen the yield of the 10-year Treasury bond using a
    **two-step lag smoothing** algorithm.
  id: totrans-1400
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是使用**两步滞后平滑**算法来平滑10年期国债的收益。
- en: Note
  id: totrans-1401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The two-step lag smoothing**'
  id: totrans-1402
  prefs: []
  type: TYPE_NORMAL
  zh: '**两步滞后平滑**'
- en: 'M18: The two-step lag smoothing algorithm for state *St* using a single smoothing
    factor *α* is defined as:'
  id: totrans-1403
  prefs: []
  type: TYPE_NORMAL
  zh: M18：使用单个平滑因子*α*对状态*St*定义的两步滞后平滑算法如下：
- en: '![Experimentation](img/image01321.jpeg)'
  id: totrans-1404
  prefs: []
  type: TYPE_IMG
  zh: '![实验](img/image01321.jpeg)'
- en: The state equation updates the values of the state *[x[t], x[t-1]]* using the
    previous state *[x[t-1], x[t-2]]*, where *x[t]* represents the yield of the 10-year
    Treasury bond at time *t*. This is accomplished by shifting the values of the
    original time series *{x[0] … x[n-1]}* by 1 using the drop method, *X[1]* *={x[1],
    …, x[n-1]}*, creating a copy of the original time series without the last element
    *X[2]={x[0], …, x[n-2]}*, and zipping *X[1]* and *X[2]*. This process is implemented
    by the `zipWithShift` method, which is introduced in the first section of the
    chapter.
  id: totrans-1405
  prefs: []
  type: TYPE_NORMAL
  zh: 状态方程使用先前的状态*[x[t], x[t-1]]*更新状态值，其中*x[t]*代表时间*t*的10年期国债收益率。这是通过使用drop方法将原始时间序列*{x[0]
    … x[n-1]}*的值向右移动1来实现的，*X[1]* *={x[1], …, x[n-1]}*，创建一个不包含最后一个元素的原始时间序列的副本*X[2]={x[0],
    …, x[n-2]}*，然后将*X[1]*和*X[2]*进行zip操作。这个过程是通过`zipWithShift`方法实现的，该方法在第1节中介绍。
- en: 'The resulting sequence of a state vector *S[k] = [x[k], x[k-1]]^T* is processed
    by the Kalman algorithm, as shown in the following code:'
  id: totrans-1406
  prefs: []
  type: TYPE_NORMAL
  zh: 状态向量序列*S[k] = [x[k], x[k-1]]^T*由卡尔曼算法处理，如下面的代码所示：
- en: '[PRE128]'
  id: totrans-1407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: Note
  id: totrans-1408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**An implicit noise instance**'
  id: totrans-1409
  prefs: []
  type: TYPE_NORMAL
  zh: '**隐式噪声实例**'
- en: 'The noise for the process and measurement is defined as an implicit argument
    to the `DKalman` Kalman filter for the following two reasons:'
  id: totrans-1410
  prefs: []
  type: TYPE_NORMAL
  zh: 对于过程和测量的噪声被定义为`DKalman`卡尔曼滤波的隐式参数，以下两个原因：
- en: The profile of the noise is specific to the process or system under evaluation
    and its measurement; it is independent of the `A`, `B`, and `H` Kalman configuration
    parameters. Therefore, it cannot be a member of the `KalmanConfig` class.
  id: totrans-1411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 噪声的轮廓特定于评估的过程或系统及其测量；它与`A`、`B`和`H`卡尔曼配置参数无关。因此，它不能是`KalmanConfig`类的一个成员。
- en: The same noise characteristics should be shared with other alternative filtering
    techniques, if needed.
  id: totrans-1412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，应与其他替代滤波技术共享相同的噪声特性。
- en: The white noise for the process and measurement is initialized implicitly with
    the `qrNoise` value (line `16`). The code initializes the matrices `H` of the
    measurement dependencies on the state (line `17`) and `P0` that contains the initial
    covariance errors (line `18`). The input data is extracted from a CSV file that
    contains the daily Yahoo financial data (line `19`). Finally, the method executes
    the `twoStepLagSmoother` two-step lag smoothing algorithm with two different `ALPHA1`
    and `ALPHA2` alpha parameter values (line `20`).
  id: totrans-1413
  prefs: []
  type: TYPE_NORMAL
  zh: 过程和测量的白噪声被隐式地初始化为`qrNoise`值（第16行）。代码初始化了测量对状态的依赖矩阵`H`（第17行）和包含初始协方差错误的`P0`（第18行）。输入数据是从包含每日Yahoo金融数据的CSV文件中提取的（第19行）。最后，该方法使用两个不同的`ALPHA1`和`ALPHA2`
    alpha参数值执行`twoStepLagSmoother`两步滞后平滑算法（第20行）。
- en: 'Let''s take a look at the `twoStepLagSmoother` method:'
  id: totrans-1414
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`twoStepLagSmoother`方法：
- en: '[PRE129]'
  id: totrans-1415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'The `twoStepLagSmoother` method takes two arguments:'
  id: totrans-1416
  prefs: []
  type: TYPE_NORMAL
  zh: '`twoStepLagSmoother`方法接受两个参数：'
- en: A `zSeries` single variable time series
  id: totrans-1417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`zSeries`单变量时间序列
- en: A `alpha` state transition parameter
  id: totrans-1418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`alpha`状态转换参数
- en: It initializes the state transition matrix `A` using the `alpha` exponential
    moving average decay parameter (line `21`). It creates the two-step lag time series,
    `xt`, using the `zipWithShift` method (line `22`). It extracts the `pfnKalman`
    partial function (line `23`), processes, and finally, displays the two-step lag
    time series (line `24`).
  id: totrans-1419
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用`alpha`指数移动平均衰减参数（第21行）初始化状态转换矩阵`A`。它使用`zipWithShift`方法（第22行）创建了两个步骤的滞后时间序列`xt`。它提取了`pfnKalman`部分函数（第23行），进行处理，最后显示两个步骤的滞后时间序列（第24行）。
- en: Note
  id: totrans-1420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Modeling state transition and noise**'
  id: totrans-1421
  prefs: []
  type: TYPE_NORMAL
  zh: '**建模状态转换和噪声**'
- en: The state transition and the noise related to the process have to be selected
    carefully. The resolution of the state equations relies on the **Cholesky** (QR)
    decomposition, which requires a nonnegative definite matrix. The implementation
    in the Apache Commons Math library throws a `NonPositiveDefiniteMatrixException`
    exception if the principle is violated.
  id: totrans-1422
  prefs: []
  type: TYPE_NORMAL
  zh: 状态转换和与过程相关的噪声必须仔细选择。状态方程的分辨率依赖于**Cholesky**（QR）分解，它需要一个非负定矩阵。如果违反了这一原则，Apache
    Commons Math库的实现将抛出`NonPositiveDefiniteMatrixException`异常。
- en: 'The smoothed yield is plotted along the raw data as follows:'
  id: totrans-1423
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑后的收益率如下绘制在原始数据上：
- en: '![Experimentation](img/image01322.jpeg)'
  id: totrans-1424
  prefs: []
  type: TYPE_IMG
  zh: '![实验](img/image01322.jpeg)'
- en: The output of the Kalman filter for the 10-year Treasury-Bond historical prices
  id: totrans-1425
  prefs: []
  type: TYPE_NORMAL
  zh: 对于10年期国债历史价格的卡尔曼滤波输出
- en: 'The Kalman filter is able to smooth the historical yield of the 10-year Treasury
    bond while preserving the spikes and lower frequency noise. Let''s analyze the
    data for a shorter period during which the noise is the strongest, between the
    190^(th) and the 275^(th) trading days:'
  id: totrans-1426
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器能够平滑10年期国债的历史收益率，同时保留尖峰和低频噪声。让我们分析一个较短的时间段内的数据，在这个时间段内噪声最强，即在第190天和第275天的交易日之间：
- en: '![Experimentation](img/image01323.jpeg)'
  id: totrans-1427
  prefs: []
  type: TYPE_IMG
  zh: '![实验](img/image01323.jpeg)'
- en: The output of the Kalman filter for the 10-year Treasury bond prices 0.8-.02
  id: totrans-1428
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器对10年期国债价格的输出为0.8-.02
- en: 'The high frequency noise has been significantly reduced without cancelling
    the actual spikes. The distribution (0.8, 0.2) takes into consideration the previous
    state and favors the predicted value. Contrarily, a run with a state transition
    matrix *A* [0.2, 0.8, 0.0, 1.0] that favors the latest measurement will preserve
    the noise, as seen in the following graph:'
  id: totrans-1429
  prefs: []
  type: TYPE_NORMAL
  zh: 在不取消实际尖峰的情况下，高频噪声已显著降低。分布（0.8，0.2）考虑了先前状态并倾向于预测值。相反，一个使用状态转移矩阵 *A* [0.2，0.8，0.0，1.0]
    且倾向于最新测量的运行将保留噪声，如下图中所示：
- en: '![Experimentation](img/image01324.jpeg)'
  id: totrans-1430
  prefs: []
  type: TYPE_IMG
  zh: '![实验](img/image01324.jpeg)'
- en: The output of the Kalman filter for the 10-year Treasury bond price 0.2-0.8
  id: totrans-1431
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器对10年期国债价格的输出为0.2-0.8
- en: Benefits and drawbacks
  id: totrans-1432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优点和缺点
- en: The Kalman filter is a very useful and powerful tool used to help you understand
    the distribution of the noise between the process and observation. Contrary to
    the low or band-pass filters based on the discrete Fourier transform, the Kalman
    filter does not require the computation of the frequencies spectrum or assume
    the range of frequencies of the noise.
  id: totrans-1433
  prefs: []
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器是一个非常有用且强大的工具，用于帮助您理解过程和观测之间的噪声分布。与基于离散傅里叶变换的低通或带通滤波器不同，卡尔曼滤波器不需要计算频率谱或假设噪声的频率范围。
- en: 'However, the linear discrete Kalman filter has its limitations, which are as
    follows:'
  id: totrans-1434
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，线性离散卡尔曼滤波器有其局限性，如下所述：
- en: The noise generated by both the process and the measurement has to be Gaussian.
    Processes with non-Gaussian noise can be modeled with techniques such as a Gaussian
    sum filter or adaptive Gaussian mixture [3:14].
  id: totrans-1435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由过程和测量产生的噪声必须是高斯分布的。具有非高斯噪声的过程可以使用高斯和滤波器或自适应高斯混合[3:14]等技术进行建模。
- en: It requires that the underlying process is linear. However, researchers have
    been able to formulate extensions to the Kalman filter, known as the **extended
    Kalman filter** (**EKF**), to filter signals from nonlinear dynamic systems, at
    the cost of significant computational complexity.
  id: totrans-1436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它要求底层过程是线性的。然而，研究人员已经能够制定卡尔曼滤波器的扩展，称为**扩展卡尔曼滤波器**（**EKF**），以从非线性动态系统中过滤信号，但这会带来显著的计算复杂性。
- en: Note
  id: totrans-1437
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The continuous-time Kalman filter**'
  id: totrans-1438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**连续时间卡尔曼滤波器**'
- en: The Kalman filter is not restricted to dynamic systems with discrete states
    *x*. The case of continuous state-time is handled by modifying the state transition
    equation, so the estimated state is computed as the derivative *dx/dt*.
  id: totrans-1439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卡尔曼滤波器不仅限于具有离散状态 *x* 的动态系统。对于连续状态-时间的情况，通过修改状态转移方程来处理，因此估计的状态是计算为导数 *dx/dt*。
- en: Alternative preprocessing techniques
  id: totrans-1440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同的预处理技术
- en: 'For the sake of space and your time, this chapter introduced and applied three
    filtering and smoothing classes of algorithms. Moving averages, Fourier series,
    and the Kalman filter are far from being the only techniques used in cleaning
    raw data. The alternative techniques can be classified into the following categories:'
  id: totrans-1441
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省空间和您的宝贵时间，本章介绍了并应用了三种滤波和光滑算法类别。移动平均、傅里叶级数和卡尔曼滤波器远非清理原始数据所使用的唯一技术。其他技术可以归类为以下类别：
- en: Autoregressive models that encompass **Autoregressive Moving Average** (**ARMA**),
    **Autoregressive Integrated Moving Average** (**ARIMA**), **generalized autoregressive**
    **conditional heteroskedasticity** (**GARCH**), and Box-Jenkins that relies on
    some form of autocorrelation function.
  id: totrans-1442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自回归模型包括**自回归移动平均**（**ARMA**）、**自回归积分移动平均**（**ARIMA**）、**广义自回归条件异方差**（**GARCH**）以及依赖于某种自相关函数的Box-Jenkins。
- en: '**Curve-fitting** algorithms that include the polynomial and geometric fit
    with the ordinary least squares method, nonlinear least squares using the **Levenberg-Marquardt**
    optimizer, and probability distribution fitting.'
  id: totrans-1443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**曲线拟合**算法包括多项式和几何拟合使用普通最小二乘法，非线性最小二乘使用**Levenberg-Marquardt**优化器，以及概率分布拟合。'
- en: Nonlinear dynamic systems with a Gaussian noise such as a **particle filter**.
  id: totrans-1444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有高斯噪声的非线性动态系统，例如**粒子滤波器**。
- en: Hidden Markov models, as described in the *The hidden Markov model* section
    in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"),
    *Sequential Data Models*.
  id: totrans-1445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如[第7章](part0193.xhtml#aid-5O1SI1 "第7章. 序列数据模型")的*隐藏马尔可夫模型*部分所述的**隐藏马尔可夫模型**，*序列数据模型*。
- en: Summary
  id: totrans-1446
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This completes the overview of the most commonly used data filtering and smoothing
    techniques. There are other types of data preprocessing algorithms such as normalization,
    analysis, and reduction of variance; the identification of missing values is also
    essential to avoid the **garbage-in garbage-out** conundrum that plagues so many
    projects that use machine learning for regression or classification.
  id: totrans-1447
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了对最常用数据过滤和平滑技术的概述。还有其他类型的数据预处理算法，如标准化、分析和方差减少；识别缺失值对于避免许多使用机器学习进行回归或分类的项目所面临的**垃圾输入垃圾输出**难题也是至关重要的。
- en: Scala can be effectively used to make the code understandable and avoid cluttering
    methods with unnecessary arguments.
  id: totrans-1448
  prefs: []
  type: TYPE_NORMAL
  zh: Scala可以有效地用于使代码易于理解，并避免在方法中使用不必要的参数。
- en: 'The three techniques presented in this chapter, from the simplest moving averages
    and Fourier transform to the more elaborate Kalman filter, go a long way in setting
    up data for the concepts introduced in the next chapter: unsupervised learning
    and more specifically, clustering.'
  id: totrans-1449
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中介绍的三种技术，从最简单的移动平均和傅里叶变换到更复杂的卡尔曼滤波，对于为下一章介绍的概念设置数据大有裨益：无监督学习和更具体地说，聚类。
- en: Chapter 4. Unsupervised Learning
  id: totrans-1450
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 无监督学习
- en: Labeling a set of observations for classification or regression can be a daunting
    task, especially in the case of a large feature set. In some cases, labeled observations
    are either unavailable or not possible to create. In an attempt to extract some
    hidden associations or structures from observations, the data scientist relies
    on unsupervised learning techniques to detect patterns or similarity in data.
  id: totrans-1451
  prefs: []
  type: TYPE_NORMAL
  zh: 为分类或回归标记一组观测值可能是一项艰巨的任务，尤其是在特征集很大的情况下。在某些情况下，标记的观测值可能不可用或无法创建。为了尝试从观测值中提取一些隐藏的关联或结构，数据科学家依赖于无监督学习技术来检测数据中的模式或相似性。
- en: The goal of unsupervised learning is to discover patterns of regularities and
    irregularities in a set of observations. These techniques are also applied in
    reducing the solution or feature space.
  id: totrans-1452
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的目标是发现一组观测值中的规律性和不规则性模式。这些技术也应用于减少解或特征空间。
- en: 'There are numerous unsupervised algorithms; some are more appropriate to handle
    dependent features while others generate affinity groups in the case of hidden
    features [4:1]. In this chapter, you will learn three of the most common unsupervised
    learning algorithms:'
  id: totrans-1453
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多无监督算法；一些更适合处理相关特征，而另一些则在隐藏特征的情况下生成亲和组[4:1]。在本章中，你将学习三种最常见的无监督学习算法：
- en: '**K-means**: This used for clustering observed features'
  id: totrans-1454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K-means**：这是用于聚类观测特征'
- en: '**Expectation-maximization** (**EM**): This is used for clustering observed
    and latent features'
  id: totrans-1455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**期望最大化**（**EM**）：这是用于聚类观测和潜在特征'
- en: '**Principal Components Analysis** (**PCA**): This is used to reduce the dimension
    of the model'
  id: totrans-1456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）：这是用来降低模型维度'
- en: Any of these algorithms can be applied to technical analysis or fundamental
    analysis. Fundamental analysis of financial ratios and technical analysis of price
    movements is discussed in the *Technical analysis* section under *Finances 101*
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*. The K-means algorithm is fully implemented in Scala while expectation-maximization
    and Principal Components Analysis leverage the Apache Commons Math library.
  id: totrans-1457
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法中的任何一个都可以应用于技术分析或基本面分析。在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")的*Finances
    101*下的*技术分析*部分讨论了财务比率的**基本面分析**和价格走势的**技术分析**。K-means算法在Scala中完全实现，而期望最大化（expectation-maximization）和主成分分析（Principal
    Components Analysis）则利用了Apache Commons Math库。
- en: The chapter concludes with a brief overview of dimension reduction techniques
    for non-linear models.
  id: totrans-1458
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以非线性模型降维技术的简要概述结束。
- en: Clustering
  id: totrans-1459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: Problems involving a large number of features for large datasets become quickly
    intractable, and it is quite difficult to evaluate the independence between features.
    Any computation that requires some level of optimization and, at a minimum, the
    computation of first order derivatives requires a significant amount of computing
    power to manipulate high-dimension matrices. As with many engineering fields,
    a divide-and-conquer approach to classifying very large datasets is quite effective.
    The objective is to reduce very large sets of observations into a small group
    of observations that share some common attributes.
  id: totrans-1460
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型数据集，涉及大量特征的问题很快就会变得难以处理，并且很难评估特征之间的独立性。任何需要一定程度的优化和至少计算一阶导数的计算都需要大量的计算能力来操作高维矩阵。与许多工程领域一样，将非常大的数据集分类的分割和征服方法非常有效。目标是把非常大的观测集减少到一小组具有一些共同属性的观测。
- en: '![Clustering](img/image01325.jpeg)'
  id: totrans-1461
  prefs: []
  type: TYPE_IMG
  zh: '![聚类](img/image01325.jpeg)'
- en: Visualization of data clustering
  id: totrans-1462
  prefs: []
  type: TYPE_NORMAL
  zh: 数据聚类的可视化
- en: This approach is known as vector quantization. Vector quantization is a method
    that divides a set of observations into groups of similar size. The main benefit
    of vector quantization is that the analysis using a representative of each group
    is far simpler than an analysis of the entire dataset [4:2].
  id: totrans-1463
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法被称为向量量化。向量量化是一种将一组观测分为相似大小组的方法。向量量化的主要好处是，使用每个组的代表进行的分析远比分析整个数据集简单得多 [4:2]。
- en: '**Clustering**, also known as **cluster analysis**, is a form of vector quantization
    that relies on a concept of distance or similarity to generate groups known as
    clusters.'
  id: totrans-1464
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**，也称为**聚类分析**，是一种基于距离或相似性的概念来生成称为聚类的组的向量量化形式。'
- en: Note
  id: totrans-1465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Learning vector quantization (LVQ)**'
  id: totrans-1466
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习向量量化（LVQ**）'
- en: Vector quantization should not be confused with **learning vector quantization**;
    learning vector quantization is a special case of artificial neural networks that
    relies on a winner-take-all learning strategy to compress signals, images, or
    videos.
  id: totrans-1467
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化不应与**学习向量量化**混淆；学习向量量化是人工神经网络的一个特殊情况，它依赖于赢家通吃的学习策略来压缩信号、图像或视频。
- en: 'This chapter introduces two of the most commonly applied clustering algorithms:'
  id: totrans-1468
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了两种最常用的聚类算法：
- en: '**K-means**: This is used for quantitative types and minimizes the total error
    (known as the reconstruction error) given the number of clusters and the distance
    formula.'
  id: totrans-1469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K-means**：这是用于定量类型，给定聚类数量和距离公式，最小化总误差（称为重建误差）。'
- en: '**Expectation-maximization** (**EM**): This is a two-step probabilistic approach
    that maximizes the likelihood estimates of a set of parameters. EM is particularly
    suitable for handling missing data.'
  id: totrans-1470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**期望最大化**（**EM**）：这是一种两步概率方法，最大化一组参数的似然估计。EM 特别适合处理缺失数据。'
- en: K-means clustering
  id: totrans-1471
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K-means 聚类
- en: K-means is a popular clustering algorithm that can be implemented either iteratively
    or recursively. The representative of each cluster is computed as the center of
    the cluster, known as the **centroid**. The similarity between observations within
    a single cluster relies on the concept of distance (or similarity) between observations.
  id: totrans-1472
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 是一种流行的聚类算法，它可以迭代或递归地实现。每个聚类的代表是计算为该聚类的中心，称为**质心**。单个聚类内观测之间的相似性依赖于观测之间的距离（或相似性）概念。
- en: Measuring similarity
  id: totrans-1473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量相似性
- en: 'There are many ways to measure the similarity between observations. The most
    appropriate measure has to be intuitive and avoid computational complexity. This
    section reviews three similarity measures:'
  id: totrans-1474
  prefs: []
  type: TYPE_NORMAL
  zh: 测量观测之间的相似性的方法有很多。最合适的度量必须直观且避免计算复杂性。本节回顾了三种相似性度量：
- en: The Manhattan distance
  id: totrans-1475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿距离
- en: The Euclidean distance
  id: totrans-1476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: The normalized inner or dot product
  id: totrans-1477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归一化内积或点积
- en: 'The Manhattan distance is defined by the absolute distance between two variables
    or vectors, *{x[i]}* and *{y[i]}*, of the same size (M1):'
  id: totrans-1478
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿距离定义为两个相同大小的变量或向量（*{x[i]}* 和 *{y[i]}*）之间的绝对距离（M1）：
- en: '![Measuring similarity](img/image01326.jpeg)'
  id: totrans-1479
  prefs: []
  type: TYPE_IMG
  zh: '![测量相似性](img/image01326.jpeg)'
- en: 'The implementation is generic enough to compute the distance between two vectors
    of elements of different types as long as an implicit conversion between each
    of these types to the `Double` values is already defined, as follows:'
  id: totrans-1480
  prefs: []
  type: TYPE_NORMAL
  zh: 实现足够通用，可以计算不同类型元素的两个向量的距离，只要已经定义了这些类型之间的隐式转换为 `Double` 值，如下所示：
- en: '[PRE130]'
  id: totrans-1481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'The ubiquitous Euclidean distance between two vectors, *{x[i]}* and *{y[i]}*,
    of the same size is defined by the following formula (M2):'
  id: totrans-1482
  prefs: []
  type: TYPE_NORMAL
  zh: 同大小两个向量，*{x[i]}* 和 *{y[i]}*，之间的普遍欧几里得距离由以下公式定义（M2）：
- en: '![Measuring similarity](img/image01327.jpeg)'
  id: totrans-1483
  prefs: []
  type: TYPE_IMG
  zh: '![测量相似度](img/image01327.jpeg)'
- en: 'The code will be as follows:'
  id: totrans-1484
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将如下所示：
- en: '[PRE131]'
  id: totrans-1485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'The normalized inner product or cosine distance between two vectors, *{x[i]}*
    and *{y[i]}*, is defined by the following formula (M3):'
  id: totrans-1486
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量，*{x[i]}* 和 *{y[i]}*，之间的归一化内积或余弦距离由以下公式定义（M3）：
- en: '![Measuring similarity](img/image01328.jpeg)'
  id: totrans-1487
  prefs: []
  type: TYPE_IMG
  zh: '![测量相似度](img/image01328.jpeg)'
- en: 'In this implementation, the computation of the dot product and the norms for
    each dataset is done simultaneously using the tuple within the `fold` method:'
  id: totrans-1488
  prefs: []
  type: TYPE_NORMAL
  zh: 在此实现中，使用`fold`方法中的元组同时计算每个数据集的点积和范数：
- en: '[PRE132]'
  id: totrans-1489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Note
  id: totrans-1490
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Performance of zip and zipped**'
  id: totrans-1491
  prefs: []
  type: TYPE_NORMAL
  zh: '**zip和zipped的性能**'
- en: 'The scalar product of two vectors is one of the most common operations. It
    is tempting to implement the dot product using the generic `zip` method:'
  id: totrans-1492
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的标量积是最常见的操作之一。使用通用的`zip`方法实现点积很有诱惑力：
- en: '[PRE133]'
  id: totrans-1493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'A functional alternative is to use the `Tuple2.zipped` method:'
  id: totrans-1494
  prefs: []
  type: TYPE_NORMAL
  zh: 一种功能替代方法是使用`Tuple2.zipped`方法：
- en: '[PRE134]'
  id: totrans-1495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: If readability is not a primary issue, you can always implement the `dot` method
    with a `while` loop, which prevents you from using the ubiquitous `while` loop.
  id: totrans-1496
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可读性不是主要问题，你总是可以使用`while`循环实现`dot`方法，这可以防止你使用普遍的`while`循环。
- en: Defining the algorithm
  id: totrans-1497
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义算法
- en: The main advantage of the K-means algorithm (and the reason for its popularity)
    is its simplicity [4:3].
  id: totrans-1498
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法的主要优势（以及其受欢迎的原因）是其简单性[4:3]。
- en: Note
  id: totrans-1499
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**K-means objective**'
  id: totrans-1500
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means目标**'
- en: 'M4: Let''s consider K clusters, *{C[k]}*, with means or centroids, *{m[k]}*.
    The K-means algorithm is indeed an optimization problem whose objective is to
    minimize the reconstruction or total error defined as the total sum of the distance:'
  id: totrans-1501
  prefs: []
  type: TYPE_NORMAL
  zh: M4：让我们考虑K个簇，*{C[k]}*，具有均值或质心，*{m[k]}*。K-means算法实际上是一个优化问题，其目标是使重建或总误差最小化，定义为距离的总和：
- en: '![Defining the algorithm](img/image01329.jpeg)'
  id: totrans-1502
  prefs: []
  type: TYPE_IMG
  zh: '![定义算法](img/image01329.jpeg)'
- en: 'The four steps of the K-means algorithm are as follows:'
  id: totrans-1503
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法的四个步骤如下：
- en: Cluster configuration (initializing the centroids or means *m[k]* of the K clusters).
  id: totrans-1504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 簇配置（初始化K个簇的质心或均值 *m[k]*）。
- en: Cluster assignment (assigning observations to the nearest cluster given the
    centroids *m[k]*).
  id: totrans-1505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 簇分配（根据质心 *m[k]* 将观测值分配给最近的簇）。
- en: 'Error minimization (computing the total reconstruction error):'
  id: totrans-1506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误最小化（计算总重建误差）：
- en: Compute centroids *m[k]* that minimize the total reconstruction error for the
    current assignment.
  id: totrans-1507
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算质心 *m[k]* 以最小化当前分配的总重建误差。
- en: Reassign the observations given the new centroids *m[k]*.
  id: totrans-1508
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据新的质心 *m[k]* 重新分配观测值。
- en: Repeat the computation of the total reconstruction error until no observations
    are reassigned.
  id: totrans-1509
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复计算总重建误差，直到没有观测值被重新分配。
- en: Classification of a new observation by assigning the observation to the closest
    cluster.
  id: totrans-1510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将观测值分配给最近的簇来对新观测值进行分类。
- en: We need to define the components of the K-means in Scala before implementing
    the algorithm.
  id: totrans-1511
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现算法之前，我们需要在Scala中定义K-means的组件。
- en: Step 1 – cluster configuration
  id: totrans-1512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤1 – 簇配置
- en: 'Let''s create the two main components of the K-means algorithms: clusters of
    observations and the implementation of the K-means algorithm.'
  id: totrans-1513
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建K-means算法的两个主要组件：观测值的簇和K-means算法的实现。
- en: Defining clusters
  id: totrans-1514
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 定义簇
- en: 'The first step is to define a cluster. A cluster is defined by the following
    parameters:'
  id: totrans-1515
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义一个簇。簇由以下参数定义：
- en: The centroid (`center`) (line `1`)
  id: totrans-1516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质心（`center`）（行`1`）
- en: The indices of the observations that belong to this cluster (`members`) (line
    `2`)
  id: totrans-1517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属于此簇的观测值的索引（成员）（行`2`）
- en: 'The code will be as follows:'
  id: totrans-1518
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将如下所示：
- en: '[PRE135]'
  id: totrans-1519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'The cluster is responsible for managing its members (data points) at any point
    of the iterative computation of the K-means algorithm. It is assumed that a cluster
    will never contain the same data points twice. The two key methods in the `Cluster`
    class are as follows:'
  id: totrans-1520
  prefs: []
  type: TYPE_NORMAL
  zh: 簇负责在任何迭代计算K-means算法的点中管理其成员（数据点）。假设簇永远不会包含相同的数据点两次。`Cluster`类中的两个关键方法如下：
- en: '`moveCenter`: This recomputes the centroid of a cluster'
  id: totrans-1521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`moveCenter`：这重新计算簇的质心'
- en: '`stdDev`: This computes the standard deviation of the distance between all
    the observation members and the centroid'
  id: totrans-1522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stdDev`：这计算所有观测成员与质心之间的距离的标准差'
- en: 'The constructor of the `Cluster` class is implemented by the `apply` method
    in the companion object. For convenience, refer to the *Class constructor template*
    section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*:'
  id: totrans-1523
  prefs: []
  type: TYPE_NORMAL
  zh: '`Cluster` 类的构造函数是通过伴随对象的 `apply` 方法实现的。为了方便，请参考 [附录 A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念") 中的 *类构造函数模板* 部分，*基本概念*：'
- en: '[PRE136]'
  id: totrans-1524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Let''s take a look at the `moveCenter` method. It creates a new cluster with
    the existing members and a new centroid. The computation of the values of the
    centroid requires the transposition of the matrix of observations by features
    into a matrix of feature by observations (line `3`). The new centroid is computed
    by normalizing the sum of each feature across all the observations by the number
    of data points (line `4`):'
  id: totrans-1525
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `moveCenter` 方法。它通过现有成员和新的中心点创建一个新的聚类。计算中心点值需要将观测矩阵按特征转置为按观测特征矩阵（第 `3`
    行）。新的中心点通过将所有观测中每个特征的求和除以数据点的数量进行归一化计算（第 `4` 行）：
- en: '[PRE137]'
  id: totrans-1526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'The `stdDev` method computes the standard deviation of all the observations
    contained in the cluster relative to its center. The `distance` value between
    each member and the centroid is extracted through a map invocation (line `5`).
    It is then loaded into a statistics instance to compute the standard deviation
    (line `6`). The function to compute the distance between the center and an observation
    is an argument of the method. The default distance is `euclidean`:'
  id: totrans-1527
  prefs: []
  type: TYPE_NORMAL
  zh: '`stdDev` 方法计算相对于其中心的聚类中所有观测的标准差。通过映射调用提取每个成员与中心点之间的 `distance` 值（第 `5` 行）。然后将其加载到统计实例中以计算标准差（第
    `6` 行）。计算中心点与观测之间距离的函数是方法的一个参数。默认距离是 `euclidean`：'
- en: '[PRE138]'
  id: totrans-1528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: Note
  id: totrans-1529
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Cluster selection**'
  id: totrans-1530
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类选择**'
- en: There are different ways to select the most appropriate cluster when reassigning
    an observation (updating its membership). In this implementation, we will select
    the cluster with the larger spread or lowest density. An alternative is to select
    the cluster with the largest membership.
  id: totrans-1531
  prefs: []
  type: TYPE_NORMAL
  zh: 在重新分配观测（更新其成员资格）时，选择最合适的聚类有不同的方法。在本实现中，我们将选择具有较大分散度或最低密度的聚类。另一种选择是选择具有最大成员资格的聚类。
- en: Initializing clusters
  id: totrans-1532
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 初始化聚类
- en: The initialization of the cluster centroids is important to ensure fast convergence
    of the K-means algorithm. Solutions range from the simple random generation of
    centroids to the application of genetic algorithms to evaluate the fitness of
    centroid candidates. We selected an efficient and fast initialization algorithm
    developed by M. Agha and W. Ashour [4:4].
  id: totrans-1533
  prefs: []
  type: TYPE_NORMAL
  zh: 确保K-means算法快速收敛，聚类中心的初始化非常重要。解决方案范围从简单的随机生成中心点到应用遗传算法来评估中心点候选者的适应性。我们选择了一个由M.
    Agha和W. Ashour开发的既高效又快速的初始化算法 [4:4]。
- en: 'The steps of the initialization are as follows:'
  id: totrans-1534
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化步骤如下：
- en: Compute the standard deviation of the set of observations.
  id: totrans-1535
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算观测集的标准差。
- en: Compute the index of the feature *{x[k,0], x[k,1] … x[k,n]}* with the maximum
    standard deviation.
  id: totrans-1536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算具有最大标准差的特征索引 *{x[k,0], x[k,1] … x[k,n]}*。
- en: Rank the observations by their increasing value of standard deviation for the
    dimension *k*.
  id: totrans-1537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照维度 *k* 的标准差递增值对观测进行排序。
- en: Divide the ranked observations set equally into *K* sets *{S[m]}*.
  id: totrans-1538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将排序后的观测集平均分成 *K* 个集合 *{S[m]}*。
- en: Find the median value's *size(S[m])/2*.
  id: totrans-1539
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到中值大小的 *size(S[m])/2*。
- en: Use the resulting observations as initial centroids.
  id: totrans-1540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用得到的观测作为初始中心点。
- en: 'Let''s deconstruct the implementation of the Agha-Ashour algorithm in the `initialize`
    method:'
  id: totrans-1541
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解 `initialize` 方法中 Agha-Ashour 算法的实现：
- en: '[PRE139]'
  id: totrans-1542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: The `statistics` method on time series of the `XVSeries` type is defined in
    the *Time series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing* (line `7`). The dimension (or feature) with
    the `maxSDevVar` maximum variance or standard deviation is computed using the
    `maxBy` method on a `Stats` instance (line `8`). Then, the observations are ranked
    by the increasing value of the `rankedObs` standard deviation (line `9`).
  id: totrans-1543
  prefs: []
  type: TYPE_NORMAL
  zh: '`XVSeries` 类型的时间序列的 `statistics` 方法在 [第 3 章](part0172.xhtml#aid-5410O2 "第 3
    章. 数据预处理") 的 *时间序列在Scala中* 部分定义，*数据预处理*（第 `7` 行）。使用 `maxBy` 方法在 `Stats` 实例上计算具有
    `maxSDevVar` 最大方差或标准差的特征维度（或特征）（第 `8` 行）。然后，根据 `rankedObs` 标准差的递增值对观测进行排序（第 `9`
    行）。'
- en: 'The ordered sequence of observations is then broken into the `xt.size/_config.K`
    segments (line `10`) and the indices of the centroids are selected as the midpoint
    (or median) observations of those segments using the `isContained` filtering condition
    (line `11`):'
  id: totrans-1544
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将有序的观测值序列分割成`xt.size/_config.K`个段（第10行），并使用`isContained`过滤条件（第11行）选择这些段的索引作为中点（或中位数）观测值：
- en: '[PRE140]'
  id: totrans-1545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: Finally, the list of clusters is generated using an `aggregate` call on the
    set of centroids (line `12`).
  id: totrans-1546
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过在质心集合上调用`aggregate`来生成簇列表（第12行）。
- en: Step 2 – cluster assignment
  id: totrans-1547
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步 – 簇分配
- en: 'The second step in the K-means algorithm is the assignment of the observations
    to the clusters for which the centroids have been initialized in step 1\. This
    feat is accomplished by the private `assignToClusters` method:'
  id: totrans-1548
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法的第二步是在第1步初始化质心后的簇中分配观测值。这一壮举是通过私有的`assignToClusters`方法完成的：
- en: '[PRE141]'
  id: totrans-1549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: The core of the assignment of observations to each cluster is the filter on
    the time series (line `13`). The filter computes the index of the closest cluster
    and checks whether the observation is to be reassigned (line `14`). The observation
    at the `n` index is added to the nearest cluster, `clusters(nearestCluster)` (line
    `15`). The current membership of the observations is then updated (line `16`).
  id: totrans-1550
  prefs: []
  type: TYPE_NORMAL
  zh: 观测值分配到每个簇的核心是对时间序列的过滤（第13行）。过滤计算最近簇的索引，并检查观测值是否需要重新分配（第14行）。在`n`索引处的观测值被添加到最近的簇`clusters(nearestCluster)`（第15行）。然后更新观测值的当前成员资格（第16行）。
- en: 'The cluster closest to an observation data is computed by the private `getNearestCluster`
    method as follows:'
  id: totrans-1551
  prefs: []
  type: TYPE_NORMAL
  zh: 通过私有的`getNearestCluster`方法计算与观测值数据最近的簇，如下所示：
- en: '[PRE142]'
  id: totrans-1552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: A fold is used to extract the cluster that is closest to the `x` observation
    from the list of clusters using the distance metric defined in the K-means constructor
    (line `17`).
  id: totrans-1553
  prefs: []
  type: TYPE_NORMAL
  zh: 使用K-means构造函数中定义的距离度量（第17行），通过折叠提取与`x`观测值最近的簇列表中的簇。
- en: As with other data processing units, the extraction of K-means clusters is encapsulated
    in a data transformation so that clustering can be integrated into a workflow
    using the composition of mixins described in the *Composing mixins to build a
    workflow* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"),
    *Hello World!*
  id: totrans-1554
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他数据处理单元一样，K-means簇的提取封装在数据转换中，以便可以将聚类集成到工作流程中，使用[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中*组合mixins以构建工作流程*部分描述的mixins组合。
- en: Note
  id: totrans-1555
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**K-means algorithm exit condition**'
  id: totrans-1556
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means算法退出条件**'
- en: In some rare instances, the algorithm may reassign the same few observations
    between clusters, preventing its convergence toward a solution in a reasonable
    time. Therefore, it is recommended that you add a maximum number of iterations
    as an exit condition. If K-means does not converge with the maximum number of
    iterations, then the cluster centroids need to be reinitialized and the iterative
    (or recursive) execution needs to be restarted.
  id: totrans-1557
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些罕见的情况下，算法可能会在簇之间重新分配相同的一些观测值，这会阻止其在合理的时间内收敛到解决方案。因此，建议您添加一个最大迭代次数作为退出条件。如果K-means在最大迭代次数后没有收敛，那么需要重新初始化簇质心，并重新启动迭代（或递归）执行。
- en: 'The `|>` transformation requires that the computation of the standard deviation
    of the distance of the observations related to the centroid, `c`, is computed
    in the `stdDev` method:'
  id: totrans-1558
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`转换要求在`stdDev`方法中计算与质心`c`相关的观测值距离的标准差：'
- en: '[PRE143]'
  id: totrans-1559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: Note
  id: totrans-1560
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Centroid versus mean**'
  id: totrans-1561
  prefs: []
  type: TYPE_NORMAL
  zh: '**质心与均值**'
- en: 'The terms centroid and mean refer to the same entity: the center of a cluster.
    This chapter uses these two terms interchangeably.'
  id: totrans-1562
  prefs: []
  type: TYPE_NORMAL
  zh: 中心点和均值指的是同一实体：簇的中心。本章使用这两个术语互换。
- en: Step 3 – reconstruction/error minimization
  id: totrans-1563
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步 – 重建/误差最小化
- en: 'The clusters are initialized with predefined set of observations as their members.
    The algorithm updates the membership of each cluster by minimizing the total reconstruction
    error. There are two effective strategies to execute the K-means algorithm:'
  id: totrans-1564
  prefs: []
  type: TYPE_NORMAL
  zh: 簇的成员初始化为预定义的观测值集合。算法通过最小化总重建误差来更新每个簇的成员资格。执行K-means算法有两种有效策略：
- en: Tail recursive execution
  id: totrans-1565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾递归执行
- en: Iterative execution
  id: totrans-1566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代执行
- en: Creating K-means components
  id: totrans-1567
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建K-means组件
- en: 'Let''s declare the K-means algorithm class, `KMeans`, with its public methods.
    `KMeans` implements an `ITransform` data transformation using an implicit model
    extracted from a training set and is described in the *Monadic data transformation*
    section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello
    World!* (line `18`). The configuration of the `KMeansConfig` type consists of
    the tuple (`K`, `maxIters`) with `K` being the number of clusters and `maxIters`
    being the maximum number of iterations allowed for the convergence of the algorithm:'
  id: totrans-1568
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们声明K-means算法类，`KMeans`，并定义其公共方法。`KMeans`通过从训练集中提取的隐式模型实现一个`ITransform`数据转换，并在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")的*单态数据转换*部分进行描述，*Hello World!*（行`18`）。`KMeansConfig`类型的配置由元组（`K`，`maxIters`）组成，其中`K`是簇的数量，`maxIters`是算法收敛允许的最大迭代次数：
- en: '[PRE144]'
  id: totrans-1569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'The `KMeans` class takes the following three arguments:'
  id: totrans-1570
  prefs: []
  type: TYPE_NORMAL
  zh: '`KMeans`类接受以下三个参数：'
- en: '`config`: This is the configuration used for the execution of the algorithm'
  id: totrans-1571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`：这是用于算法执行的配置'
- en: '`distance`: This is the function used to compute the distance between any observation
    and a cluster centroid'
  id: totrans-1572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distance`：这是用于计算任何观测值与簇质心之间距离的函数'
- en: '`xt`: This is the training set'
  id: totrans-1573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xt`：这是训练集'
- en: 'The implicit conversion of the `T` type to a `Double` is implemented as a view
    bound. The instantiation of the `KMeans` class initializes a `V` type of output
    from K-means as `Cluster[T]` (line `20`). The `num` instance of the `Numeric`
    class has to be passed implicitly as a class parameter because it is required
    by the `sortWith` invocation in `initialize`, the `maxBy` method, and the `Cluster.moveCenter`
    method (line `19`). The `Manifest` is required to preserve the erasure type for
    `Array[T]` in the JVM:'
  id: totrans-1574
  prefs: []
  type: TYPE_NORMAL
  zh: '`T`类型到`Double`的隐式转换实现为一个视图边界。`KMeans`类的实例化初始化了一个从K-means输出的`V`类型，作为`Cluster[T]`（行`20`）。`Numeric`类的`num`实例必须作为类参数隐式传递，因为它在`initialize`中的`sortWith`调用、`maxBy`方法和`Cluster.moveCenter`方法（行`19`）中是必需的。`Manifest`用于在JVM中保留`Array[T]`的擦除类型：'
- en: '[PRE145]'
  id: totrans-1575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: The `KMeansModel` model is defined as the list of clusters extracted through
    training.
  id: totrans-1576
  prefs: []
  type: TYPE_NORMAL
  zh: '`KMeansModel`模型定义为通过训练提取的簇列表。'
- en: Tail recursive implementation
  id: totrans-1577
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 尾递归实现
- en: 'The transformation or clustering function is implemented by the `train` training
    method that creates a partial function with `XVSeries[T]` as the input and `KMeansModel[T]`
    as the output:'
  id: totrans-1578
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`train`训练方法实现转换或聚类函数，该方法创建一个以`XVSeries[T]`作为输入和`KMeansModel[T]`作为输出的部分函数：
- en: '[PRE146]'
  id: totrans-1579
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: 'The K-means training algorithm is implemented through the following three steps:'
  id: totrans-1580
  prefs: []
  type: TYPE_NORMAL
  zh: K-means训练算法通过以下三个步骤实现：
- en: Initialize the cluster's centroid using the `initialize` method (line `21`).
  id: totrans-1581
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`initialize`方法初始化簇的质心（行`21`）。
- en: Assign observations to each cluster using the `assignToClusters` method (line
    `22`).
  id: totrans-1582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`assignToClusters`方法（行`22`）将观测值分配给每个簇。
- en: Recompute the total error reconstruction using the `update` recursive method
    (line `23`).
  id: totrans-1583
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`update`递归方法（行`23`）重新计算总误差重建。
- en: 'The computation of the total error reconstruction is implemented as a tail
    recursive method, `update`, as follows:'
  id: totrans-1584
  prefs: []
  type: TYPE_NORMAL
  zh: 总误差重建的计算实现为一个尾递归方法，`update`，如下所示：
- en: '[PRE147]'
  id: totrans-1585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: 'The recursion takes the following three arguments (line `24`):'
  id: totrans-1586
  prefs: []
  type: TYPE_NORMAL
  zh: 递归接受以下三个参数（行`24`）：
- en: The current list of `clusters` that is updated during the recursion
  id: totrans-1587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在递归过程中更新的当前`clusters`列表
- en: The `xt` input time series
  id: totrans-1588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xt`输入时间序列'
- en: The indices of membership to the clusters, `members`
  id: totrans-1589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 簇的成员索引，`members`
- en: A new list of clusters, `newClusters`, is computed by either recalculating each
    centroid if the cluster is not empty (line `25`) or evaluating the standard deviation
    of the distance of each observation relative to each centroid (line `26`). The
    execution exits when either the maximum number of the `maxIters` recursive calls
    is reached or when no more observations are reassigned to a different cluster
    (line `27`). Otherwise, the method invokes itself with an updated list of clusters
    (line `28`).
  id: totrans-1590
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重新计算每个簇不为空时的每个质心（行`25`）或评估每个观测值相对于每个质心的距离的标准差（行`26`）来计算新的簇列表，`newClusters`。当达到`maxIters`的最大递归调用次数或没有更多的观测值被重新分配到不同的簇时（行`27`），执行退出。否则，方法使用更新的簇列表调用自身（行`28`）。
- en: Iterative implementation
  id: totrans-1591
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 迭代实现
- en: 'The implementation of an iterative execution is presented for an informational
    purpose. It follows the same sequence of calls as with the recursive implementation.
    The new clusters are computed (line `29`) and the execution exits when either
    the maximum number of allowed iterations is reached (line `30`) or when no more
    observations are reassigned to a different cluster (line `31`):'
  id: totrans-1592
  prefs: []
  type: TYPE_NORMAL
  zh: 为了信息目的，展示了迭代执行的实现。它遵循与递归实现相同的调用序列。新的聚类被计算（第`29`行），当达到允许的最大迭代次数（第`30`行）或没有更多的观测值被重新分配到不同的聚类（第`31`行）时，执行退出：
- en: '[PRE148]'
  id: totrans-1593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'The density of the clusters is computed in the `KMeans` class as follows:'
  id: totrans-1594
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类密度在`KMeans`类中按以下方式计算：
- en: '[PRE149]'
  id: totrans-1595
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: Step 4 – classification
  id: totrans-1596
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 分类
- en: 'The objective of the classification is to assign an observation to a cluster
    with the closest centroid:'
  id: totrans-1597
  prefs: []
  type: TYPE_NORMAL
  zh: 分类目标是把一个观测值分配到与最近质心最接近的聚类：
- en: '[PRE150]'
  id: totrans-1598
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: The most appropriate cluster is computed by selecting the `c` cluster whose
    `center` is the closest to the `x` observation using the `minBy` higher order
    method.
  id: totrans-1599
  prefs: []
  type: TYPE_NORMAL
  zh: 最合适的聚类是通过选择`c`聚类，其`中心`与`x`观测值最接近的聚类来计算的，使用`minBy`高阶方法。
- en: The curse of dimensionality
  id: totrans-1600
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维度诅咒
- en: 'A model with a significant number of features (high dimensions) requires a
    larger number of observations in order to extract relevant and reliable clusters.
    K-means clustering with very small datasets (< 50) produces models with high bias
    and a limited number of clusters, which are affected by the order of observations
    [4:5]. I have been using the following simple empirical rule of thumb for a training
    set of size *n*, expected *K* clusters, and *N* features: *n < K.N*.'
  id: totrans-1601
  prefs: []
  type: TYPE_NORMAL
  zh: 具有大量特征（高维度）的模型需要更多的观测值来提取相关和可靠的聚类。具有非常小数据集（< 50）的K-means聚类会产生具有高偏差和有限聚类数量的模型，这些聚类受到观测值顺序的影响[4:5]。我一直在使用以下简单的经验法则来为大小为*n*的训练集、预期的*K*个聚类和*N*个特征：*n
    < K.N*。
- en: Note
  id: totrans-1602
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Dimensionality and the size of the training set
  id: totrans-1603
  prefs: []
  type: TYPE_NORMAL
  zh: 维度和训练集的大小
- en: The issue of sizing the training set given the dimensionality of a model is
    not specific to unsupervised learning algorithms. All supervised learning techniques
    face the same challenge to set up a viable training plan.
  id: totrans-1604
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定模型维度的情况下确定训练集大小的问题并不仅限于无监督学习算法。所有监督学习技术都面临着设置可行的训练计划的相同挑战。
- en: Whichever empirical rule you follow, such a restriction is particularly an issue
    for analyzing stocks using historical quotes. Let's consider our examples of using
    technical analysis to categorize stocks according to their price behavior over
    a period of 1 year (or approximately 250 trading days). The dimension of the problem
    is 250 (250 daily closing prices). The number of stocks (observations) would have
    exceeded several hundred!
  id: totrans-1605
  prefs: []
  type: TYPE_NORMAL
  zh: 无论遵循哪种经验规则，这种限制对于使用历史报价分析股票尤其成问题。让我们考虑我们的例子，使用技术分析根据股票在1年（或大约250个交易日）内的价格行为对股票进行分类。问题维度是250（250个日收盘价）。股票数量（观测值）将超过数百个！
- en: '![The curse of dimensionality](img/image01330.jpeg)'
  id: totrans-1606
  prefs: []
  type: TYPE_IMG
  zh: '![维度诅咒](img/image01330.jpeg)'
- en: Price model for K-means clustering
  id: totrans-1607
  prefs: []
  type: TYPE_NORMAL
  zh: K-means聚类的价格模型
- en: 'There are options to get around this limitation and shrink the numbers of observations,
    which are as follows:'
  id: totrans-1608
  prefs: []
  type: TYPE_NORMAL
  zh: 有选项可以绕过这种限制并减少观测数的数量，如下所示：
- en: Sampling the trading data without losing a significant amount of information
    from the raw data, assuming that the distribution of observations follows a known
    probability density function.
  id: totrans-1609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不丢失原始数据中大量信息的情况下采样交易数据，假设观测值的分布遵循已知的概率密度函数。
- en: Smoothing the data to remove the noise as seen in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*, assuming that the noise
    is Gaussian. In our test, a smoothing technique will remove the price outliers
    for each stock and therefore reduce the number of features (trading session).
    This approach differs from the first (sampling) technique because it does not
    require an assumption that the dataset follows a known density function. On the
    other hand, the reduction of features will be less significant.
  id: totrans-1610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行平滑以去除[第3章](part0172.xhtml#aid-5410O2 "第3章。数据预处理")中看到的噪声，假设噪声是高斯分布的。在我们的测试中，平滑技术将去除每只股票的价格异常值，从而减少特征数（交易会话）。这种方法与第一种（采样）技术不同，因为它不需要假设数据集遵循已知的密度函数。另一方面，特征的减少将不那么显著。
- en: These approaches are workaround solutions at best, used for the sake of this
    tutorial. You need to consider the quality of your data before applying these
    techniques to the actual commercial applications. The principal component analysis
    introduced in the last paragraph of this chapter is one of the most reliable dimension
    reduction techniques.
  id: totrans-1611
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法充其量是权宜之计，仅用于本教程。在将这些技术应用于实际商业应用之前，您需要考虑数据的质量。本章最后一段介绍的原理成分分析是最可靠的降维技术之一。
- en: Setting up the evaluation
  id: totrans-1612
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置评估
- en: 'The objective is to extract clusters from a set of stock price actions during
    a period of time between January 1 and Dec 31, 2013 as features. For this test,
    127 stocks are randomly selected from the S&P 500 list. The following chart visualizes
    the behavior of the normalized price of a subset of these 127 stocks:'
  id: totrans-1613
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是从2013年1月1日至12月31日之间的某个时间段内的一组股票价格行为中提取簇作为特征。为此测试，从标准普尔500指数中随机选择了127只股票。以下图表可视化了一组这些127只股票中正常化价格的行为：
- en: '![Setting up the evaluation](img/image01331.jpeg)'
  id: totrans-1614
  prefs: []
  type: TYPE_IMG
  zh: '![设置评估](img/image01331.jpeg)'
- en: Price action of a basket of stocks used in K-means clustering
  id: totrans-1615
  prefs: []
  type: TYPE_NORMAL
  zh: 用于K-means聚类的股票篮子的价格行为
- en: The key is to select the appropriate features prior to clustering and the time
    window to operate on. It would make sense to consider the entire historical price
    over the 252 trading days as a feature. However, the number of observations (stocks)
    is too limited to use the entire price range. The observations are the stock closing
    prices for each trading session between the 80^(th) and 130^(th) trading days.
    The adjusted daily closing prices are normalized using their respective minimum
    and maximum values.
  id: totrans-1616
  prefs: []
  type: TYPE_NORMAL
  zh: 关键是在聚类之前选择合适的特征以及操作的时间窗口。考虑252个交易日的整个历史价格作为特征是有意义的。然而，观测值（股票）的数量太少，无法使用整个价格范围。观测值是第80^(th)和第130^(th)个交易日之间的每个交易日的股票收盘价。调整后的每日收盘价使用它们各自的最小值和最大值进行归一化。
- en: 'First, let''s create a simple method to compute the density of the clusters:'
  id: totrans-1617
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个简单的方法来计算簇的密度：
- en: '[PRE151]'
  id: totrans-1618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: 'The `density` method invokes `KMeans.density` described in step 3\. Let''s
    load the data from CSV files using the `DataSource` class, as described in the
    *Data extraction* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*:'
  id: totrans-1619
  prefs: []
  type: TYPE_NORMAL
  zh: '`density`方法调用了第3步中描述的`KMeans.density`。让我们使用`DataSource`类从CSV文件加载数据，如附录A中*数据提取*部分所述[附录A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念")，*基本概念*：'
- en: '[PRE152]'
  id: totrans-1620
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: As mentioned earlier, the cluster analysis applies to the closing price in the
    range between the 80^(th) and 130^(th) trading days (line `33`). The `extractor`
    function retrieves the adjusted closing price for a stock from `YahooFinancials`
    (line `34`). The list of stock tickers (or symbols) are extracted as a list of
    CSV filenames located in `path` (line `35`). For instance, the ticker symbol for
    General Electric Corp. is GE and the trading data is located in `GE.csv`.
  id: totrans-1621
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，聚类分析应用于第80^(th)和第130^(th)个交易日之间的收盘价范围（第`33`行）。`extractor`函数从`YahooFinancials`中检索股票的调整后收盘价（第`34`行）。股票的标记（或符号）列表被提取为位于`path`中的CSV文件名列表（第`35`行）。例如，通用电气公司的标记符号是GE，交易数据位于`GE.csv`。
- en: 'The execution extracts 50 daily prices using `DataSource` and then filters
    out the incorrectly formatted data using `filter` (line `36`):'
  id: totrans-1622
  prefs: []
  type: TYPE_NORMAL
  zh: 执行提取了50个每日价格，然后使用`filter`（第`36`行）过滤掉格式不正确的数据：
- en: '[PRE153]'
  id: totrans-1623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'The historical stock prices for the trading session between the 80^(th) and
    130^(th) days are generated by the `getPricesRange` closure (line `37`):'
  id: totrans-1624
  prefs: []
  type: TYPE_NORMAL
  zh: 第80^(th)和第130^(th)天之间的交易日的历史股票价格由`getPricesRange`闭包生成（第`37`行）：
- en: '[PRE154]'
  id: totrans-1625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: It computes the density of the clusters by invoking the `density` method for
    each `ks` value of the number of clusters (line `38`).
  id: totrans-1626
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过调用每个簇数`ks`值的`density`方法来计算簇的密度（第`38`行）。
- en: The `pfnKmeans` partial classification function is created for a 5-cluster,
    `KMeans` (line `39`), and then used to classify one of the observations (line
    `40`).
  id: totrans-1627
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了一个用于5簇的`pfnKmeans`部分分类函数，它是基于`KMeans`（第`39`行），然后用于对其中一个观测值进行分类（第`40`行）。
- en: Evaluating the results
  id: totrans-1628
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果
- en: 'The first test run is executed with *K=3* clusters. The mean (or centroid)
    vector for each cluster is plotted as follows:'
  id: totrans-1629
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次测试运行使用*K=3*簇。每个簇的均值（或质心）向量如下绘制：
- en: '![Evaluating the results](img/image01332.jpeg)'
  id: totrans-1630
  prefs: []
  type: TYPE_IMG
  zh: '![评估结果](img/image01332.jpeg)'
- en: A chart of means of clusters using K-means K=3
  id: totrans-1631
  prefs: []
  type: TYPE_NORMAL
  zh: 使用K-means K=3的簇均值图表
- en: 'The means vectors of the three clusters are quite distinctive. The top and
    bottom means **1** and **2** in the chart have the respective standard deviation
    of 0.34 and 0.27 and share a very similar pattern. The difference between the
    elements of the **1** and **2** cluster mean vectors is almost constant: 0.37\.
    The cluster with a mean vector **3** represents the group of stocks that behave
    like the stocks in cluster **2** at the beginning of the time period and behave
    like the stocks in cluster **1** toward the end of the time period.'
  id: totrans-1632
  prefs: []
  type: TYPE_NORMAL
  zh: 三个聚类的均值向量非常独特。图表中顶部和底部的均值 **1** 和 **2** 分别具有 0.34 和 0.27 的标准差，并且具有非常相似的图案。**1**
    和 **2** 聚类均值向量之间的元素差异几乎恒定：0.37。具有均值向量 **3** 的聚类代表在时间周期开始时像聚类 **2** 中的股票，而在时间周期结束时像聚类
    **1** 中的股票的股票群体。
- en: 'This behavior can be easily explained by the fact that the time window or trading
    period, the 80^(th) to 130^(th) trading day, correspond to the shift in the monetary
    policy of the federal reserve in regard to the quantitative easing program. Here
    is the partial list of stocks for each of the clusters whose centroid values are
    displayed on the chart:'
  id: totrans-1633
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为可以通过以下事实轻松解释：时间窗口或交易期，第 80 天至第 130 天的交易日，对应于联邦储备关于量化宽松计划的货币政策转变。以下是每个聚类（其质心值在图表上显示）的股票部分列表：
- en: '| **Cluster 1** | AET, AHS, BBBY, BRCM, C, CB, CL, CLX, COH, CVX, CYH, DE,
    … |'
  id: totrans-1634
  prefs: []
  type: TYPE_TB
  zh: '| **聚类 1** | AET, AHS, BBBY, BRCM, C, CB, CL, CLX, COH, CVX, CYH, DE, … |'
- en: '| **Cluster 2** | AA, AAPL, ADBE, ADSK, AFAM, AMZN, AU, BHI, BTU, CAT, CCL,
    … |'
  id: totrans-1635
  prefs: []
  type: TYPE_TB
  zh: '| **聚类 2** | AA, AAPL, ADBE, ADSK, AFAM, AMZN, AU, BHI, BTU, CAT, CCL, … |'
- en: '| **Cluster 3** | ADM, ADP, AXP, BA, BBT, BEN, BK, BSX, CA, CBS, CCE, CELG,
    CHK, … |'
  id: totrans-1636
  prefs: []
  type: TYPE_TB
  zh: '| **聚类 3** | ADM, ADP, AXP, BA, BBT, BEN, BK, BSX, CA, CBS, CCE, CELG, CHK,
    … |'
- en: Let's evaluate the impact of the number of clusters *K* on the characteristics
    of each cluster.
  id: totrans-1637
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们评估聚类数量 *K* 对每个聚类特征的影响。
- en: Tuning the number of clusters
  id: totrans-1638
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调整聚类数量
- en: We repeat the previous test on the 127 stocks and the same time window with
    the number of clusters varying from 2 to 15.
  id: totrans-1639
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复之前的测试，在 127 只股票和相同的时间窗口上，聚类数量从 2 到 15 变化。
- en: 'The mean (or centroid) vector for each cluster for *K = 2* is plotted as follows:'
  id: totrans-1640
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *K = 2* 的每个聚类的均值（或质心）向量如下所示：
- en: '![Tuning the number of clusters](img/image01333.jpeg)'
  id: totrans-1641
  prefs: []
  type: TYPE_IMG
  zh: '![调整聚类数量](img/image01333.jpeg)'
- en: A chart of means of clusters using K-means K=2
  id: totrans-1642
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 K-means K=2 的聚类均值图表
- en: The chart of the results of the K-means algorithms with 2 clusters shows that
    the mean vector for the cluster labeled **2** is similar to the mean vector labeled
    **3** on the chart with *K = 5* clusters. However, the cluster with the mean vector
    **1** reflects somewhat the aggregation or summation of the mean vectors for the
    clusters **1**and **3** in the chart *K = 5*. The aggregation effect explains
    why the standard deviation for the cluster **1** (0.55) is twice as much as the
    standard deviation for the cluster **2** (0.28).
  id: totrans-1643
  prefs: []
  type: TYPE_NORMAL
  zh: 2 个聚类的 K-means 算法结果图表显示，标记为 **2** 的聚类均值向量与 *K = 5* 图表中标记为 **3** 的均值向量相似。然而，具有均值向量
    **1** 的聚类在一定程度上反映了图表 *K = 5* 中聚类 **1** 和 **3** 均值向量的聚合或求和。聚合效应解释了为什么聚类 **1**（0.55）的标准差是聚类
    **2**（0.28）标准差的两倍。
- en: 'The mean (or centroid) vector for each cluster for *K = 5* is plotted as follows:'
  id: totrans-1644
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *K = 5* 的每个聚类的均值（或质心）向量如下所示：
- en: '![Tuning the number of clusters](img/image01334.jpeg)'
  id: totrans-1645
  prefs: []
  type: TYPE_IMG
  zh: '![调整聚类数量](img/image01334.jpeg)'
- en: A chart of means of clusters using K-means K=5
  id: totrans-1646
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 K-means K=5 的聚类均值图表
- en: In this chart, we can assess that the clusters **1** (with the highest mean),
    **2** (with the lowest mean), and **3** are very similar to the clusters with
    the same labels in the chart for *K = 3*. The cluster with the mean vector **4**
    contains stocks whose behaviors are quite similar to those in cluster **3**, but
    in the opposite direction. In other words, the stocks in cluster **3** and **4**
    reacted in opposite ways following the announcement of the change in the monetary
    policy.
  id: totrans-1647
  prefs: []
  type: TYPE_NORMAL
  zh: 在此图表中，我们可以评估聚类 **1**（具有最高的均值）、**2**（具有最低的均值）和 **3** 与 *K = 3* 图表中具有相同标签的聚类非常相似。具有均值向量
    **4** 的聚类包含行为与聚类 **3** 非常相似的股票，但方向相反。换句话说，聚类 **3** 和 **4** 的股票在货币政策变化公告后反应相反。
- en: 'In the tests with high values of *K*, the distinction between the different
    clusters becomes murky, as shown in the following chart for *K = 10*:'
  id: totrans-1648
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *K* 值较高的测试中，不同聚类之间的区别变得模糊，如下图中 *K = 10* 所示：
- en: '![Tuning the number of clusters](img/image01335.jpeg)'
  id: totrans-1649
  prefs: []
  type: TYPE_IMG
  zh: '![调整聚类数量](img/image01335.jpeg)'
- en: A chart of means of clusters using K-means K=10
  id: totrans-1650
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 K-means K=10 的簇均值的图表
- en: The means for clusters **1**, **2**, and **3** seen in the first chart for the
    case *K = 2* are still visible. It is fair to assume that these are very likely
    the most reliable clusters. These clusters happened to have a low standard deviation
    or high density.
  id: totrans-1651
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个图表中，对于 *K = 2* 的情况，可以看到簇 **1**、**2** 和 **3** 的均值。有理由假设这些可能是最可靠的簇。这些簇恰好具有低标准差或高密度。
- en: 'Let''s define the density of a cluster, *C[j]*, with a centroid, *c[j]*, as
    the inverse of the Euclidean distance between all the members of each cluster
    and its mean (or centroid) (M6):'
  id: totrans-1652
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义具有质心 *c[j]* 的簇的密度，*C[j]*，为每个簇的所有成员与其均值（或质心）之间的欧几里得距离的倒数（M6）：
- en: '![Tuning the number of clusters](img/image01336.jpeg)'
  id: totrans-1653
  prefs: []
  type: TYPE_IMG
  zh: '![调整簇的数量](img/image01336.jpeg)'
- en: 'The density of the cluster is plotted against the number of clusters with *K
    = 1* to *K = 13*:'
  id: totrans-1654
  prefs: []
  type: TYPE_NORMAL
  zh: 簇的密度与簇的数量（从 *K = 1* 到 *K = 13*）的关系图被绘制出来：
- en: '![Tuning the number of clusters](img/image01337.jpeg)'
  id: totrans-1655
  prefs: []
  type: TYPE_IMG
  zh: '![调整簇的数量](img/image01337.jpeg)'
- en: A bar chart of the average cluster density for K = 1 to 13
  id: totrans-1656
  prefs: []
  type: TYPE_NORMAL
  zh: K = 1 到 13 的平均簇密度的条形图
- en: 'As expected, the average density of each cluster increases as *K* increases.
    From this experiment, we can draw the simple conclusion that the density of each
    cluster does not significantly increase in the test runs for *K = 5* and beyond.
    You may observe that the density does not always increase as the number of clusters
    increases (*K = 6* and *K = 11*). The anomaly can be explained by the following
    three factors:'
  id: totrans-1657
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，随着 *K* 的增加，每个簇的平均密度增加。从这个实验中，我们可以得出一个简单的结论：在 *K = 5* 及以上的测试运行中，每个簇的密度并没有显著增加。你可能观察到，随着簇数量的增加，密度并不总是增加（*K
    = 6* 和 *K = 11*）。这种异常可以通过以下三个因素来解释：
- en: The original data is noisy
  id: totrans-1658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据有噪声
- en: The model is somewhat dependent on the initialization of the centroids
  id: totrans-1659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在一定程度上依赖于质心的初始化
- en: The exit condition is too loose
  id: totrans-1660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 退出条件过于宽松
- en: Validation
  id: totrans-1661
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证
- en: There are several methodologies to validate the output of a K-means algorithm
    from purity to mutual information [4:6]. One effective way to validate the output
    of a clustering algorithm is to label each cluster and run those clusters through
    a new batch of labeled observations. For example, if during one of these tests,
    you find that one of the clusters, *CC*, contains most of the commodity-related
    stocks, then you can select another commodity-related stock, *SC*, which is not
    part of the first batch, and run the entire clustering algorithm again. If *SC*
    is a subset of *CC*, then K-means has performed as expected. If this is the case,
    you should run a new set of stocks, some of which are commodity-related, and measure
    the number of true positives, true negatives, false positives, and false negatives.
    The values for the precision, recall, and F[1] score introduced in the *Assessing
    a model* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"),
    *Hello World!*, confirms whether the tuning parameters and labels you selected
    for your cluster are indeed correct.
  id: totrans-1662
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以验证 K-means 算法的输出，从纯度到互信息 [4:6]。验证聚类算法输出的一个有效方法是为每个簇标记，并将这些簇通过一批新的标记观测值运行。例如，如果在这些测试之一中，你发现其中一个簇，*CC*，包含大部分与商品相关的股票，那么你可以选择另一个与商品相关的股票，*SC*，它不是第一批的一部分，并再次运行整个聚类算法。如果
    *SC* 是 *CC* 的子集，那么 K-means 已经按预期执行。如果是这种情况，你应该运行一个新的股票集，其中一些与商品相关，并测量真正阳性、真正阴性、假阳性、假阴性的数量。在
    [第 2 章](part0165.xhtml#aid-4TBCQ2 "第 2 章。Hello World!") 中 *评估模型* 部分引入的精确度、召回率和
    F[1] 分数的值，*Hello World!* 确认你为簇选择的调整参数和标签是否确实正确。
- en: Note
  id: totrans-1663
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**F1 validation for K-means**'
  id: totrans-1664
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means 的 F1 验证**'
- en: The quality of the clusters, as measured by the F[1] score, depends on the rule,
    policy, or formula used to label observations (that is, label a cluster with the
    industry with the highest relative percentage of stocks in the cluster). This
    process is quite subjective. The only sure way to validate a methodology is to
    evaluate several labeling schemes and select the one that generate the highest
    F[1] score.
  id: totrans-1665
  prefs: []
  type: TYPE_NORMAL
  zh: 簇的质量，通过 F[1] 分数来衡量，取决于用于标记观测值（即，将簇标记为包含簇中股票相对百分比最高的行业）的规则、策略或公式。这个过程相当主观。验证一个方法的唯一可靠方式是评估几个标记方案，并选择产生最高
    F[1] 分数的方案。
- en: An alternative to measure the homogeneity of the distribution of observations
    across the clusters is to compute the statistical entropy. A low entropy value
    indicates that the clusters have a low level of impurity. Entropy can be used
    to find the optimal number of clusters *K*.
  id: totrans-1666
  prefs: []
  type: TYPE_NORMAL
  zh: 一种测量观测值分布在不同簇之间同质性的替代方法是计算统计熵。低熵值表明簇的杂质水平较低。熵可以用来找到最佳簇数 *K*。
- en: 'We reviewed some of the tuning parameters that affect the quality of the results
    of the K-means clustering, which are as follows:'
  id: totrans-1667
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回顾了一些影响K-means聚类结果质量的调整参数，如下所示：
- en: Initial selection of a centroid
  id: totrans-1668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始选择质心
- en: Number of *K* clusters
  id: totrans-1669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*K* 簇的数量'
- en: In some cases, the similarity criterion (that is, the Euclidean distance or
    cosine distance) can have an impact on the *cleanness* or density of the clusters.
  id: totrans-1670
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，相似性标准（即欧几里得距离或余弦距离）可能会影响聚类簇的**纯净度**或密度。
- en: The final and important consideration is the computational complexity of the
    K-means algorithm. The previous sections of the chapter described some of the
    performance issues with K-means and possible remedies.
  id: totrans-1671
  prefs: []
  type: TYPE_NORMAL
  zh: 最后和重要的考虑因素是K-means算法的计算复杂性。本章的前几节描述了K-means的一些性能问题及其可能的补救措施。
- en: Despite its many benefits, the K-means algorithm does not handle missing data
    or unobserved features very well. Features that depend on each other indirectly
    may in fact depend on a common hidden (also known as latent) feature. The expectation-maximization
    algorithm described in the next section addresses some of these limitations.
  id: totrans-1672
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管K-means算法有许多优点，但它并不擅长处理缺失数据或未观测到的特征。实际上，相互依赖的特征可能依赖于一个共同的隐藏（也称为潜在）特征。下一节中描述的期望最大化算法解决了这些局限性之一。
- en: The expectation-maximization algorithm
  id: totrans-1673
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 期望最大化算法
- en: The expectation-maximization algorithm was originally introduced to estimate
    the maximum likelihood in the case of incomplete data [4:7]. It is an iterative
    method to compute the model features that maximize the likely estimate for observed
    values, taking into account unobserved values.
  id: totrans-1674
  prefs: []
  type: TYPE_NORMAL
  zh: 期望最大化算法最初被引入来估计不完整数据情况下的最大似然[4:7]。它是一种迭代方法，用于计算最大化观测值可能估计的模型特征，同时考虑未观测值。
- en: 'The iterative algorithm consists of computing the following:'
  id: totrans-1675
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代算法包括计算以下内容：
- en: The expectation, *E*, of the maximum likelihood for the observed data by inferring
    the latent values (E-step)
  id: totrans-1676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过推断潜在值来估计观测数据的最大似然期望 *E*（E步）
- en: The model features that maximize the expectation *E* (M-step)
  id: totrans-1677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型特征最大化期望 *E*（M步）
- en: The expectation-maximization algorithm is applied to solve clustering problems
    by assuming that each latent variable follows a normal or Gaussian distribution.
    This is similar to the K-means algorithm for which the distance of each data point
    to the center of each cluster follows a Gaussian distribution [4:8]. Therefore,
    a set of latent variables is a mixture of Gaussian distributions.
  id: totrans-1678
  prefs: []
  type: TYPE_NORMAL
  zh: 期望最大化算法通过假设每个潜在变量遵循正态或高斯分布来解决聚类问题。这与K-means算法类似，其中每个数据点到每个簇中心的距离遵循高斯分布[4:8]。因此，一组潜在变量是高斯分布的混合。
- en: Gaussian mixture models
  id: totrans-1679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高斯混合模型
- en: 'Latent variables, *Z[i]*, can be visualized as the behavior (or symptoms) of
    a model (observed) *X* for which *Z* are the root causes of the behavior:'
  id: totrans-1680
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在变量，*Z[i]*，可以被视为模型（观测）*X*的行为（或症状），其中 *Z* 是行为的原因：
- en: '![Gaussian mixture models](img/image01338.jpeg)'
  id: totrans-1681
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合模型](img/image01338.jpeg)'
- en: Visualization of observed and latent features
  id: totrans-1682
  prefs: []
  type: TYPE_NORMAL
  zh: 观测和潜在特征的可视化
- en: 'The latent values, *Z*, follow a Gaussian distribution. For the statisticians
    among us, the mathematics of a mixture model is described here:'
  id: totrans-1683
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在值，*Z*，遵循高斯分布。对于我们中的统计学家，混合模型的数学描述如下：
- en: Note
  id: totrans-1684
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Maximization of the log likelihood**'
  id: totrans-1685
  prefs: []
  type: TYPE_NORMAL
  zh: '**最大化对数似然**'
- en: 'M7: If *x = {x[i]}* is a set of observed features associated with latent features
    *z = {z[i]}*, the probability for the feature *x[i]*, of the observation *x*,
    given a model parameter *θ*, is defined as:'
  id: totrans-1686
  prefs: []
  type: TYPE_NORMAL
  zh: M7：如果 *x = {x[i]}* 是与潜在特征 *z = {z[i]}* 相关的观测特征集，则给定模型参数 *θ*，观测 *x* 中特征 *x[i]*
    的概率定义为：
- en: '![Gaussian mixture models](img/image01339.jpeg)'
  id: totrans-1687
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合模型](img/image01339.jpeg)'
- en: 'M8: The objective is to maximize the likelihood, *L(θ)*, as shown here:'
  id: totrans-1688
  prefs: []
  type: TYPE_NORMAL
  zh: M8：目标是最大化似然，*L(θ)*，如下所示：
- en: '![Gaussian mixture models](img/image01340.jpeg)'
  id: totrans-1689
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合模型](img/image01340.jpeg)'
- en: Overview of EM
  id: totrans-1690
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: EM概述
- en: 'As far as the implementation is concerned, the expectation-maximization algorithm
    can be broken down into three stages:'
  id: totrans-1691
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现方面，期望最大化算法可以分为三个阶段：
- en: The computation of the log likelihood for the model features given some latent
    variables (initial step).
  id: totrans-1692
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定一些潜在变量（初始步骤）的情况下，计算模型特征的日志似然。
- en: The computation of the expectation of the log likelihood at iteration *t* (E
    step).
  id: totrans-1693
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在迭代 *t* 时计算对数似然期望（E步）。
- en: The maximization of the expectation at iteration *t* (M step).
  id: totrans-1694
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在迭代 *t* 时最大化期望（M步）。
- en: Note
  id: totrans-1695
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The E step**'
  id: totrans-1696
  prefs: []
  type: TYPE_NORMAL
  zh: '**E步**'
- en: 'M9: The expectation, *Q*, of the complete data log likelihood for the model
    parameters, *θ[n]*, at iteration, *n*, is computed using the posterior distribution
    of latent variable, *z*, *p(z|x, θ)*, and the joint probability of the observation
    and the latent variable:'
  id: totrans-1697
  prefs: []
  type: TYPE_NORMAL
  zh: 'M9: 模型参数 *θ[n]* 在迭代 *n* 时，完整数据日志似然期望值 *Q* 的计算使用潜在变量 *z* 的后验分布 *p(z|x, θ)* 和观测值与潜在变量的联合概率：'
- en: '![Overview of EM](img/image01341.jpeg)'
  id: totrans-1698
  prefs: []
  type: TYPE_IMG
  zh: '![EM概述](img/image01341.jpeg)'
- en: '**The M-step**'
  id: totrans-1699
  prefs: []
  type: TYPE_NORMAL
  zh: '**M步**'
- en: 'M10: The expectation function *Q* is maximized for the model features *θ* to
    compute the model parameters *θ[n+1]* for the next iteration:'
  id: totrans-1700
  prefs: []
  type: TYPE_NORMAL
  zh: 'M10: 为了计算下一次迭代的模型参数 *θ[n+1]*，期望函数 *Q* 对模型特征 *θ* 进行最大化：'
- en: '![Overview of EM](img/image01342.jpeg)'
  id: totrans-1701
  prefs: []
  type: TYPE_IMG
  zh: '![EM概述](img/image01342.jpeg)'
- en: A formal, detailed, but short mathematical formulation of the EM algorithm can
    be found in S. Borman's tutorial [4:9].
  id: totrans-1702
  prefs: []
  type: TYPE_NORMAL
  zh: S. Borman 的教程 [4:9] 中可以找到 EM 算法的正式、详细但简短的数学公式。
- en: Implementation
  id: totrans-1703
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: Let's implement the three steps (initial step, E step, and M step) in Scala.
    The internal calculations of the EM algorithm are a bit complex and overwhelming.
    You may not benefit much from the details of a specific implementation such as
    computation of the eigenvalues of the covariance matrix of the expectation of
    the log likelihood. This implementation hides some complexities using the Apache
    Commons Math library package [4:10].
  id: totrans-1704
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 Scala 中实现三个步骤（初始步骤、E 步和 M 步）。EM 算法的内部计算相当复杂且令人困惑。您可能不会从特定实现的细节中获得太多好处，例如计算期望对数似然的协方差矩阵的特征值。此实现使用
    Apache Commons Math 库包隐藏了一些复杂性 [4:10]。
- en: Note
  id: totrans-1705
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The inner workings of EM**'
  id: totrans-1706
  prefs: []
  type: TYPE_NORMAL
  zh: '**EM算法的内部工作原理**'
- en: You may want to download the source code for the implementation of the EM algorithm
    in the Apache Commons Math library, if you need to understand the condition for
    which an exception is thrown.
  id: totrans-1707
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要了解抛出异常的条件，可以下载 Apache Commons Math 库中 EM 算法实现的源代码。
- en: 'The expectation-maximization algorithm of the `MultivariateEM` type is implemented
    as a data transformation of an `ITransform` type, as described in the *Monadic
    data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*. The two arguments of the constructors are the number
    of `K` clusters (or gauss distribution) and the `xt` training set (line `1`).
    The constructor initializes the `V` type of the output as `EMCluster` (line `2`):'
  id: totrans-1708
  prefs: []
  type: TYPE_NORMAL
  zh: '`MultivariateEM` 类型的期望最大化算法实现为一个 `ITransform` 类型的数据转换，如 [第 2 章](part0165.xhtml#aid-4TBCQ2
    "第 2 章. Hello World!") 中 *Monadic 数据转换* 部分所述，*Hello World!*。构造函数的两个参数是 `K` 个聚类（或高斯分布）的数量和
    `xt` 训练集（第 `1` 行）。构造函数将输出 `V` 类型的初始化为 `EMCluster`（第 `2` 行）：'
- en: '[PRE155]'
  id: totrans-1709
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: The multivariate expectation-maximization class has a model that consists of
    a list of EM clusters of the `EMCluster` type. The `Monitor` trait is used to
    collect the profiling information during training (refer to the *Monitor* section
    under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*).
  id: totrans-1710
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量期望最大化类有一个由 `EMCluster` 类型的 EM 聚类列表组成的模型。`Monitor` 特性用于在训练过程中收集配置文件信息（请参阅
    [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念") 中 *Utility 类* 下的 *Monitor* 部分，*基本概念*）。
- en: 'The information about an EM cluster, `EMCluster`, is defined by `key`, the
    centroid or `means` value, and `density` of the cluster that is the standard deviation
    of the distance of all the data points to the mean (line `4`):'
  id: totrans-1711
  prefs: []
  type: TYPE_NORMAL
  zh: EM 聚类 `EMCluster` 的信息由 `key`（质心或 `means` 值）和聚类的 `density`（密度）定义，即所有数据点到均值的距离的标准差（第
    `4` 行）：
- en: '[PRE156]'
  id: totrans-1712
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: 'The implementation of the EM algorithm in the `train` method uses the Apache
    Commons Math `MultivariateNormalMixture` for the Gaussian mixture model and `MultivariateNormalMixtureExpectationMaximization`
    for the EM algorithm:'
  id: totrans-1713
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `train` 方法中实现 EM 算法时，使用 Apache Commons Math 的 `MultivariateNormalMixture`
    用于高斯混合模型和 `MultivariateNormalMixtureExpectationMaximization` 用于 EM 算法：
- en: '[PRE157]'
  id: totrans-1714
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: Let's take a look at the main `train` method of the `MultivariateEM` wrapper
    class. The first step is to convert the time series into a primitive matrix of
    `Double` with observations/historical quotes as rows and the stock symbols as
    columns.
  id: totrans-1715
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`MultivariateEM`包装类的主要`train`方法。第一步是将时间序列转换为以观测/历史报价为行、股票符号为列的原始`Double`矩阵。
- en: The `xt` time series of the `XVSeries[T]` type is converted to a `DblMatrix`
    through an induced implicit conversion (line `5`).
  id: totrans-1716
  prefs: []
  type: TYPE_NORMAL
  zh: '`XVSeries[T]`类型的`xt`时间序列通过诱导的隐式转换（行`5`）转换为`DblMatrix`。'
- en: The initial mixture of Gaussian distributions can be provided by the user or
    can be extracted from the `estimate` datasets (line `6`). The `getFittedModel`
    triggers the M-step (line `7`).
  id: totrans-1717
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯分布的初始混合可以通过用户提供或从`estimate`数据集中提取（行`6`）。调用`getFittedModel`触发M步骤（行`7`）。
- en: Note
  id: totrans-1718
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Conversion from Java and Scala collections**'
  id: totrans-1719
  prefs: []
  type: TYPE_NORMAL
  zh: '**Java和Scala集合的转换**'
- en: Java primitives need to be converted to Scala types using the `import scala.collection.JavaConversions`
    package. For example, `java.util.List` is converted to `scala.collection.immutable.List`
    by invoking the `asScalaIterator` method of the `WrapAsScala` class, one of the
    base traits of `JavaConversions`.
  id: totrans-1720
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`import scala.collection.JavaConversions`包将Java原语转换为Scala类型。例如，通过调用`WrapAsScala`类的`asScalaIterator`方法，将`java.util.List`转换为`scala.collection.immutable.List`，这是`JavaConversions`的基本特质之一。
- en: The Apache Commons Math `getComponents` method returns a `java.util.List` that
    is converted to `scala.collection.immutable.List` by invoking the `toList` method
    (line `8`). Finally, the data transform returns a list of cluster information
    of the `EMCluster` type (line `9`).
  id: totrans-1721
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Commons Math的`getComponents`方法返回一个`java.util.List`，通过调用`toList`方法（行`8`）将其转换为`scala.collection.immutable.List`。最后，数据转换返回一个`EMCluster`类型的聚类信息列表（行`9`）。
- en: Note
  id: totrans-1722
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Third-party library exceptions**'
  id: totrans-1723
  prefs: []
  type: TYPE_NORMAL
  zh: '**第三方库异常**'
- en: 'Scala does not enforce the declaration of exceptions as part of the signature
    of a method. Therefore, there is no guarantee that all types of exceptions will
    be caught locally. This problem occurs when exceptions are thrown from a third-party
    library in two scenarios:'
  id: totrans-1724
  prefs: []
  type: TYPE_NORMAL
  zh: Scala不强制在方法签名中声明异常。因此，不能保证会捕获所有类型的异常。当第三方库在两种情况下抛出异常时，会出现这个问题：
- en: The documentation of the API does not list all the types of exceptions
  id: totrans-1725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API文档没有列出所有异常类型
- en: The library is updated and a new type of exception is added to a method
  id: totrans-1726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库已更新，并在一个方法中添加了新的异常类型
- en: 'One easy workaround is to leverage the Scala exception-handling mechanism:'
  id: totrans-1727
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的解决方案是利用Scala的异常处理机制：
- en: '[PRE158]'
  id: totrans-1728
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: Classification
  id: totrans-1729
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: 'The classification of a new observation or data points is implemented by the
    `|>` method:'
  id: totrans-1730
  prefs: []
  type: TYPE_NORMAL
  zh: 新观测或数据点的分类是通过`|>`方法实现的：
- en: '[PRE159]'
  id: totrans-1731
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: The `|>` method is similar to the `KMeans.|>` classifier.
  id: totrans-1732
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`方法类似于`KMeans.|>`分类器。'
- en: Testing
  id: totrans-1733
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试
- en: Let's apply the `MultivariateEM` class to the clustering of the same 127 stocks
    used in evaluating the K-means algorithm.
  id: totrans-1734
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将`MultivariateEM`类应用于评估K-means算法时使用的相同127只股票的聚类。
- en: As discussed in the *The curse of dimensionality* section, the number of stocks
    (127) to analyze restricts the number of observations to be used by the EM algorithm.
    A simple option is to filter out some of the noise of the stock's prices and apply
    a simple sampling method. The maximum sampling rate is restricted by the frequencies
    in the spectrum of noises of different types in the historical price of every
    stock.
  id: totrans-1735
  prefs: []
  type: TYPE_NORMAL
  zh: 如在*维度诅咒*部分所述，要分析的股票数量（127）限制了EM算法可用的观察数量。一个简单的选项是过滤掉股票价格的一些噪声，并应用简单的采样方法。最大采样率受历史价格中不同类型噪声频谱的限制。
- en: Note
  id: totrans-1736
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Filtering and sampling**'
  id: totrans-1737
  prefs: []
  type: TYPE_NORMAL
  zh: '**过滤和采样**'
- en: The preprocessing of the data using a combination of a simple moving average
    and fixed interval sampling prior to clustering is very rudimentary in this example.
    For instance, we cannot assume that the historical price of all the stocks share
    the same noise characteristics. The noise pattern in the quotation of momentum
    and heavily traded stocks is certainly different from blue-chip securities with
    a strong ownership, and these stocks are held by large mutual funds.
  id: totrans-1738
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚类之前，使用简单移动平均和固定间隔采样对数据进行预处理，在这个例子中非常基础。例如，我们不能假设所有股票的历史价格具有相同的噪声特征。动量股票和交易活跃的股票的报价噪声模式肯定与具有强大所有权的蓝筹股不同，而这些股票由大型共同基金持有。
- en: The sampling rate should take into account the spectrum of frequency of the
    noise. It should be set as at least twice the frequency of the noise with the
    lowest frequency.
  id: totrans-1739
  prefs: []
  type: TYPE_NORMAL
  zh: 采样率应考虑噪声频率的范围。它应设置为至少是最低频率噪声频率的两倍。
- en: 'The object of the test is to evaluate the impact of the sampling rate, `samplingRate`,
    and the number of `K` clusters used in the EM algorithm:'
  id: totrans-1740
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的目标是评估采样率`samplingRate`和EM算法中使用的`K`簇数量的影响：
- en: '[PRE160]'
  id: totrans-1741
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: The first step is to create a simple moving average with a predefined period
    (line `10`), as described in the *The simple moving average* section in [Chapter
    3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"), *Data Preprocessing*.
    The test code instantiates the `pfnSmAve` partial function that implements the
    moving average computation (line `11`). The symbols of the stocks under consideration
    are extracted from the name of the files in the path directory. The historical
    data is contained in the CSV file whose name is `path/STOCK_NAME.csv` (line `12`).
  id: totrans-1742
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建一个具有预定义周期的简单移动平均，如[第3章](part0172.xhtml#aid-5410O2 "第3章。数据预处理")中“简单移动平均”部分所述，在[数据预处理]中描述。测试代码实例化了实现移动平均计算的`pfnSmAve`部分函数（第11行）。考虑的股票的符号是从路径目录中文件的名称中提取的。历史数据包含在名为`path/STOCK_NAME.csv`的CSV文件中（第12行）。
- en: 'The execution of the moving average (line `13`) generates a set of smoothed
    values that is sampled given a sampling rate, `samplingRate` (line `14`). Finally,
    the expectation-maximization algorithm is instantiated to cluster the sampled
    data in the `em` method (line `15`):'
  id: totrans-1743
  prefs: []
  type: TYPE_NORMAL
  zh: 移动平均（第13行）的执行生成了一组平滑值，该值根据采样率`samplingRate`（第14行）进行采样。最后，在`em`方法中实例化期望最大化算法以聚类采样数据（第15行）：
- en: '[PRE161]'
  id: totrans-1744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: The `em` method instantiates the EM algorithm for a specific number `K` of clusters
    (line `16`). The content of the model is displayed by invoking `MultivariateEM.toString`.
    The results are aggregated, then displayed in a textual format on the standard
    output (line `17`).
  id: totrans-1745
  prefs: []
  type: TYPE_NORMAL
  zh: '`em`方法实例化了具有特定簇数`K`的EM算法（第16行）。通过调用`MultivariateEM.toString`显示模型的内容。结果被汇总，然后在标准输出上以文本格式显示（第17行）。'
- en: 'The first test is to execute the EM algorithm with *K = 3* clusters and a sampling
    period of 10 on data smoothed by a simple moving average with period of 8\. The
    sampling of historical prices of the 127 stocks between January 1, 2013 and December
    31, 2013 with a frequency of 0.1 hertz produces 24 data points. The following
    chart displays the mean of each of the three clusters:'
  id: totrans-1746
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次测试是执行具有3个簇和10个采样周期的EM算法，数据是通过8个周期的简单移动平均平滑的。2013年1月1日至2013年12月31日之间127只股票的历史价格以0.1赫兹的频率采样，产生24个数据点。以下图表显示了每个簇的平均值：
- en: '![Testing](img/image01343.jpeg)'
  id: totrans-1747
  prefs: []
  type: TYPE_IMG
  zh: '![Testing](img/image01343.jpeg)'
- en: A chart of the normalized means per cluster using EM K=3
  id: totrans-1748
  prefs: []
  type: TYPE_NORMAL
  zh: 使用EM K=3的每个簇标准化均值图表
- en: 'The mean vectors of clusters **2** and **3** have similar patterns, which may
    suggest that a set of three clusters is accurate enough to provide a first insight
    into the similarity within groups of stocks. The following is a chart of the normalized
    standard deviation per cluster using EM with *K = 3*:'
  id: totrans-1749
  prefs: []
  type: TYPE_NORMAL
  zh: 簇2和簇3的均值向量具有相似的图案，这可能表明一组三个簇足以提供对股票群体内部相似性的初步了解。以下是一个使用EM方法且K=3时每个簇标准化标准差的图表：
- en: '![Testing](img/image01344.jpeg)'
  id: totrans-1750
  prefs: []
  type: TYPE_IMG
  zh: '![Testing](img/image01344.jpeg)'
- en: A chart of the normalized standard deviation per cluster using EM K=3
  id: totrans-1751
  prefs: []
  type: TYPE_NORMAL
  zh: 使用EM K=3的每个簇标准化标准差图表
- en: The distribution of the standard deviation along with the mean vector of each
    cluster can be explained by the fact that the price of stocks from a couple of
    industries went down in synergy, while others went up as a semi-homogenous group
    following the announcement from the Federal Reserve that the monthly quantity
    of bonds purchased as part of the quantitative easing program would be reduced
    in the near future.
  id: totrans-1752
  prefs: []
  type: TYPE_NORMAL
  zh: 每个簇的标准差分布以及均值向量可以由以下事实解释：几个行业的股票价格协同下降，而其他股票则作为一个半同质群体随着美联储宣布，作为量化宽松计划的一部分，未来几个月购买的债券数量将减少而上涨。
- en: Note
  id: totrans-1753
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Relation to K-means**'
  id: totrans-1754
  prefs: []
  type: TYPE_NORMAL
  zh: '**与K-means的关系**'
- en: You may wonder what is the relation between EM and K-means, as both the techniques
    address the same problem. The K-means algorithm assigns each observation uniquely
    to one and only one cluster. The EM algorithm assigns an observation based on
    posterior probability. K-means is a special case of the EM for Gaussian mixtures
    [4:11].
  id: totrans-1755
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道EM和K-means之间有什么关系，因为这两种技术都解决了相同的问题。K-means算法将每个观测值唯一地分配给一个且仅一个簇。EM算法根据后验概率分配观测值。K-means是EM在高斯混合模型中的特例[4:11]。
- en: The online EM algorithm
  id: totrans-1756
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在线EM算法
- en: Online learning is a powerful strategy for training a clustering model when
    dealing with very large datasets. This strategy has regained interest from scientists
    lately. The description of the online EM algorithm is beyond the scope of this
    tutorial. However, you may need to know that there are several algorithms for
    online EM available if you ever have to deal with large datasets, such as batch
    EM, stepwise EM, incremental EM, and Monte Carlo EM [4:12].
  id: totrans-1757
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理非常大的数据集时，在线学习是训练聚类模型的一个强大策略。最近，这种方法又引起了科学家的兴趣。在线EM算法的描述超出了本教程的范围。然而，如果你必须处理大型数据集，你可能需要知道有几个在线EM算法可供选择，例如批量EM、逐步EM、增量EM和蒙特卡洛EM
    [4:12]。
- en: Dimension reduction
  id: totrans-1758
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减维
- en: Without prior knowledge of the problem domain, data scientists include all possible
    features in their first attempt to create a classification, prediction, or regression
    model. After all, making assumptions is a poor and dangerous approach to reduce
    the search space. It is not uncommon for a model to use hundreds of features,
    adding complexity and significant computation costs to build and validate the
    model.
  id: totrans-1759
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有对问题领域有先验知识的情况下，数据科学家会在他们的第一次尝试中包括所有可能的特征来创建分类、预测或回归模型。毕竟，做出假设是减少搜索空间的一个糟糕且危险的方法。一个模型使用数百个特征并不罕见，这增加了构建和验证模型的复杂性和显著的计算成本。
- en: Noise filtering techniques reduce the sensitivity of the model to features that
    are associated with sporadic behavior. However, these noise-related features are
    not known prior to the training phase, and therefore, cannot be completely discarded.
    As a consequence, training of the model becomes a very cumbersome and time-consuming
    task.
  id: totrans-1760
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声过滤技术降低了模型对与偶发行为相关的特征的敏感性。然而，这些与噪声相关的特征在训练阶段之前是未知的，因此不能完全丢弃。因此，模型的训练变得非常繁琐且耗时。
- en: Overfitting is another hurdle that can arise from a large feature set. A training
    set of limited size does not allow you to create an accurate model with a large
    number of features.
  id: totrans-1761
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是另一个可能由大量特征集引起的障碍。有限大小的训练集不允许你使用大量特征创建一个准确的模型。
- en: Dimension reduction techniques alleviate these problems by detecting features
    that have little influence on the overall model behavior.
  id: totrans-1762
  prefs: []
  type: TYPE_NORMAL
  zh: 减维技术通过检测对整体模型行为影响较小的特征来缓解这些问题。
- en: 'There are three approaches to reduce the number of features in a model:'
  id: totrans-1763
  prefs: []
  type: TYPE_NORMAL
  zh: 降低模型中特征数量的三种方法：
- en: Statistical analysis solutions such as ANOVA for smaller feature sets
  id: totrans-1764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于较小的特征集，可以使用如方差分析等统计分析解决方案
- en: Regularization and shrinking techniques, which are introduced in the *Regularization*
    section in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization*
  id: totrans-1765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第6章](part0188.xhtml#aid-5J99O2 "第6章。回归和正则化")的“正则化”部分中介绍的正规化和收缩技术，*回归和正则化*
- en: Algorithms that maximize the variance of the dataset by transforming the covariance
    matrix
  id: totrans-1766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过变换协方差矩阵来最大化数据集方差的算法
- en: 'The next section introduces one of the most commonly used algorithms of the
    third category: principal component analysis.'
  id: totrans-1767
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节介绍了第三类中最常用的算法之一：主成分分析。
- en: Principal components analysis
  id: totrans-1768
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主成分分析
- en: 'The purpose of principal components analysis is to transform the original set
    of features into a new set of ordered features by decreasing the order of variance.
    The original observations are transformed into a set of variables with a lower
    degree of correlation. Let''s consider a model with two features, *{x, y}*, and
    a set of observations, *{x[i], y[i]}*, plotted on the following chart:'
  id: totrans-1769
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析的目的是通过降低方差顺序将原始特征集转换成一个新的有序特征集。原始观测值被转换成一组相关性较低的新变量。让我们考虑一个具有两个特征*{x, y}*和一组观测值*{x[i],
    y[i]}*的模型，这些观测值在以下图表中绘制：
- en: '![Principal components analysis](img/image01345.jpeg)'
  id: totrans-1770
  prefs: []
  type: TYPE_IMG
  zh: '![主成分分析](img/image01345.jpeg)'
- en: Visualization of principal components analysis for a two-dimensional model
  id: totrans-1771
  prefs: []
  type: TYPE_NORMAL
  zh: 二维模型的主成分分析可视化
- en: The *x* and *y* features are converted into two *X* and *Y* variables (that
    is rotation) to appropriately match the distribution of observations. The variable
    with the highest variance is known as the first principal component. The variable
    with the n^(th) highest variance is known as the n^(th) principal component.
  id: totrans-1772
  prefs: []
  type: TYPE_NORMAL
  zh: 将 *x* 和 *y* 特征转换为两个 *X* 和 *Y* 变量（即旋转），以适当地匹配观察值的分布。具有最高方差的变量称为第一个主成分。具有第 n 个最高方差的变量称为第
    n 个主成分。
- en: Algorithm
  id: totrans-1773
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法
- en: I highly recommend that you read the tutorial from Lindsay Smith [4:13] that
    describes the PCA algorithm in a very concrete and simple way using a two-dimensional
    model.
  id: totrans-1774
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈推荐您阅读 Lindsay Smith 的教程[4:13]，该教程以非常具体和简单的方式使用二维模型描述了 PCA 算法。
- en: Note
  id: totrans-1775
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**PCA and covariance matrix**'
  id: totrans-1776
  prefs: []
  type: TYPE_NORMAL
  zh: '**PCA 和协方差矩阵**'
- en: 'M11: The covariance of two *X* and *Y* features with the observations set *{x[i],
    y[i]}* and their respective mean values is defined as:'
  id: totrans-1777
  prefs: []
  type: TYPE_NORMAL
  zh: M11：两个 *X* 和 *Y* 特征与观察集 *{x[i]，y[i]}* 及其各自平均值之间的协方差定义为：
- en: '![Algorithm](img/image01346.jpeg)'
  id: totrans-1778
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01346.jpeg)'
- en: Here, ![Algorithm](img/image01347.jpeg) and ![Algorithm](img/image01348.jpeg)
    are the respective mean values for the observations, *x* and *y*.
  id: totrans-1779
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![算法](img/image01347.jpeg) 和 ![算法](img/image01348.jpeg) 分别是观察值 *x* 和 *y*
    的各自平均值。
- en: 'M12: The covariance is computed from the Z-score of each observation:'
  id: totrans-1780
  prefs: []
  type: TYPE_NORMAL
  zh: M12：协方差是从每个观察值的 Z 分数计算的：
- en: '![Algorithm](img/image01349.jpeg)'
  id: totrans-1781
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01349.jpeg)'
- en: 'M13: For a model with *n* features, *x[i]*, the covariance matrix is defined
    as:'
  id: totrans-1782
  prefs: []
  type: TYPE_NORMAL
  zh: M13：对于具有 *n* 个特征的模型，*x[i]*，协方差矩阵定义为：
- en: '![Algorithm](img/image01350.jpeg)'
  id: totrans-1783
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01350.jpeg)'
- en: 'M14: The transformation of *x* to *X* consists of computing the eigenvalues
    of the covariance matrix:'
  id: totrans-1784
  prefs: []
  type: TYPE_NORMAL
  zh: M14：将 *x* 转换为 *X* 的转换包括计算协方差矩阵的特征值：
- en: '![Algorithm](img/image01351.jpeg)'
  id: totrans-1785
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01351.jpeg)'
- en: 'M15: The eigenvalues are ranked by their decreasing order of variance. Finally,
    the *m* top eigenvalues for which the cumulative of variance exceeds a predefined
    threshold (percentage of the trace of the matrix) are the principal components:'
  id: totrans-1786
  prefs: []
  type: TYPE_NORMAL
  zh: M15：特征值按其方差递减的顺序排序。最后，累积方差超过预定义阈值（矩阵迹的百分比）的前 *m* 个特征值是主成分：
- en: '![Algorithm](img/image01352.jpeg)'
  id: totrans-1787
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01352.jpeg)'
- en: 'The algorithm is implemented in five steps:'
  id: totrans-1788
  prefs: []
  type: TYPE_NORMAL
  zh: 算法分为五个步骤：
- en: Compute the Z-score for the observations by standardizing the mean and standard
    deviation.
  id: totrans-1789
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过标准化均值和标准差计算观察值的 Z 分数。
- en: Compute the covariance matrix *Σ* for the original set of observations.
  id: totrans-1790
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算原始观察集的协方差矩阵 *Σ*。
- en: Compute the new covariance matrix *Σ'* for the observations with the transformed
    features by extracting the eigenvalues and eigenvectors.
  id: totrans-1791
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提取特征值和特征向量，为具有转换特征的观察值计算新的协方差矩阵 *Σ'*。
- en: Convert the matrix to rank eigenvalues by decreasing the order of variance.
    The ordered eigenvalues are the principal components.
  id: totrans-1792
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过降低方差顺序将矩阵转换为秩特征值。有序的特征值是主成分。
- en: Select the principal components for which the total sum of variance exceeds
    a threshold by a percentage of the trace of the new covariance matrix.
  id: totrans-1793
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将新协方差矩阵迹的百分比作为阈值，选择总方差超过阈值的特征值。
- en: 'The extraction of principal components by diagonalization of the covariance
    matrix *Σ* is visualized in the following diagram. The shades of grey used to
    represent the covariance value varies from white (lowest value) to black (highest
    value):'
  id: totrans-1794
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对协方差矩阵 *Σ* 进行对角化提取主成分的过程在以下图中进行了可视化。用于表示协方差值的灰色阴影从白色（最低值）到黑色（最高值）变化：
- en: '![Algorithm](img/image01353.jpeg)'
  id: totrans-1795
  prefs: []
  type: TYPE_IMG
  zh: '![算法](img/image01353.jpeg)'
- en: Visualization of the extraction of eigenvalues in PCA
  id: totrans-1796
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 中提取特征值的可视化
- en: The eigenvalues (variance of *X*) are ranked by the decreasing order of their
    values. The PCA algorithm succeeds when the cumulative value of the last eigenvalues
    (the right-bottom section of the diagonal matrix) becomes insignificant.
  id: totrans-1797
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值（*X* 的方差）按其值递减的顺序排序。当最后一个特征值的累积值（对角矩阵的右下角部分）变得不显著时，PCA 算法成功。
- en: Implementation
  id: totrans-1798
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: The principal components analysis can be easily implemented using the Apache
    Commons Math library methods that compute the eigenvalues and eigenvectors. The
    `PCA` class is defined as a data transformation of the `ITransform` type, as described
    in the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*
  id: totrans-1799
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用Apache Commons Math库中计算特征值和特征向量的方法轻松实现主成分分析。`PCA`类定义为`ITransform`类型的数据转换，如第2章中*单调数据转换*部分所述，[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World！")，*Hello World！*
- en: 'The `PCA` class has a single argument: the `xt` training set (line `1`). The
    output type has a `Double` for the projection of an observation along with the
    eigenvectors (line `2`). The constructor defines the z-score `norm` function (line
    `3`):'
  id: totrans-1800
  prefs: []
  type: TYPE_NORMAL
  zh: '`PCA`类有一个单一参数：`xt`训练集（第1行）。输出类型为`Double`，用于投影观测值和特征向量（第2行）。构造函数定义了Z分数`norm`函数（第3行）：'
- en: '[PRE162]'
  id: totrans-1801
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: The model for the PCA algorithm is defined by the `PCAModel` case class (line
    `4`).
  id: totrans-1802
  prefs: []
  type: TYPE_NORMAL
  zh: PCA算法的模型由`PCAModel`案例类定义（第4行）。
- en: Note
  id: totrans-1803
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Triggering an implicit conversion**'
  id: totrans-1804
  prefs: []
  type: TYPE_NORMAL
  zh: '**触发隐式转换**'
- en: 'Implicit conversions can be invoked through an assignment to fully declared
    variables. For example, the conversion from `XVSeries[T]` to `XVseries[Double]`
    is invoked by the declaring the type of the target variable: `val z: XVSeries[Double]
    = xv` (line `4`).'
  id: totrans-1805
  prefs: []
  type: TYPE_NORMAL
  zh: '可以通过向完全声明的变量赋值来调用隐式转换。例如，通过声明目标变量的类型来调用从`XVSeries[T]`到`XVseries[Double]`的转换：`val
    z: XVSeries[Double] = xv`（第4行）。'
- en: 'The model for the PCA algorithm, `PCAModel`, consists of the covariance matrix,
    `covariance` defined in the formula **M11,** and array of eigenvalues computed
    in the formula **M16**:'
  id: totrans-1806
  prefs: []
  type: TYPE_NORMAL
  zh: PCA算法的模型`PCAModel`由公式**M11**中定义的协方差矩阵`covariance`和公式**M16**中计算的特征值数组组成：
- en: '[PRE163]'
  id: totrans-1807
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: 'The `|>` transformative method implements the computation of the principal
    components (that is, the eigenvector and eigenvalues):'
  id: totrans-1808
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`转换方法实现了主成分的计算（即特征向量和特征值）：'
- en: '[PRE164]'
  id: totrans-1809
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: The normalization function `zScores` the Z-score transformation (formula **M12**)
    (line `5`). Next, the method computes the `covariance` matrix from the normalized
    data (line `6`). The eigenvectors, `eigenVectors`, are computed (line `7`) and
    then retrieved using the `getV` method in the Apache Commons Math `EigenDecomposition`
    class (line `8`). The method computes the diagonal, transformed covariance matrix
    from the eigenvector (line `9`). Finally, the data transformation returns an instance
    of the PCA model (line `10`).
  id: totrans-1810
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化函数`zScores`执行Z分数转换（公式**M12**）（第5行）。接下来，该方法从标准化数据中计算协方差矩阵（第6行）。计算了特征向量`eigenVectors`（第7行），然后使用Apache
    Commons Math `EigenDecomposition`类的`getV`方法检索（第8行）。该方法从特征向量计算对角线转换后的协方差矩阵（第9行）。最后，数据转换返回PCA模型的一个实例（第10行）。
- en: 'The `|>` predictive method consists of projecting an observation onto the principal
    components:'
  id: totrans-1811
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`预测方法包括将观测值投影到主成分上：'
- en: '[PRE165]'
  id: totrans-1812
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: The `inner` method of the `XTSeries` object computes the dot product of the
    values `x` and the `eigenvalues` model.
  id: totrans-1813
  prefs: []
  type: TYPE_NORMAL
  zh: '`XTSeries`对象的`inner`方法计算值`x`和特征值模型的点积。'
- en: Test case
  id: totrans-1814
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试用例
- en: 'Let''s apply the PCA algorithm to extract a subset of the features that represents
    some of the financial metrics ratios of 34 S&P 500 companies. The metrics under
    consideration are as follows:'
  id: totrans-1815
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将PCA算法应用于提取代表34家标准普尔500公司部分财务指标比率的特征子集。考虑的指标如下：
- en: Trailing Price-to-Earnings ratio (PE)
  id: totrans-1816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪市盈率（PE）
- en: Price-to-Sale ratio (PS)
  id: totrans-1817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 市销率（PS）
- en: Price-to-Book ratio (PB)
  id: totrans-1818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 市净率（PB）
- en: Return on Equity (ROE)
  id: totrans-1819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 净资产收益率（ROE）
- en: Operation Margin (OM)
  id: totrans-1820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运营利润率（OM）
- en: The financial metrics are described in the *Terminology* section under *Finances
    101* in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*.
  id: totrans-1821
  prefs: []
  type: TYPE_NORMAL
  zh: 财务指标在[附录A](part0229.xhtml#aid-6QCGQ2 "附录A。基本概念")中*金融101*的*术语*部分进行描述，*基本概念*。
- en: 'The input data is specified with the following format as a tuple (a ticker
    symbol and an array of five financial ratios, PE, PS, PB, ROE, and OM):'
  id: totrans-1822
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据以以下格式指定为一个元组（一个股票代码和一个包含五个财务比率（市盈率PE、市销率PS、市净率PB、净资产收益率ROE和运营利润率OM）的数组）：
- en: '[PRE166]'
  id: totrans-1823
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: 'The client code that executes the PCA algorithm is defined simply as follows:'
  id: totrans-1824
  prefs: []
  type: TYPE_NORMAL
  zh: 执行PCA算法的客户端代码定义如下：
- en: '[PRE167]'
  id: totrans-1825
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: The PCA is instantiated with the `input` data (line `11`) and then displayed
    in a textual format (line `12`).
  id: totrans-1826
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`input`数据实例化PCA，然后以文本格式显示（第12行）。
- en: Evaluation
  id: totrans-1827
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估
- en: 'The first test on the 34 financial ratios uses a model that has five dimensions.
    As expected, the algorithm produces a list of five ordered eigenvalues:'
  id: totrans-1828
  prefs: []
  type: TYPE_NORMAL
  zh: 对34个财务比率的第一项测试使用了一个具有五个维度的模型。正如预期的那样，算法产生了一个五个有序的特征值列表：
- en: '*2.5321, 1.0350, 0.7438, 0.5218, 0.3284*'
  id: totrans-1829
  prefs: []
  type: TYPE_NORMAL
  zh: '*2.5321, 1.0350, 0.7438, 0.5218, 0.3284*'
- en: 'Let''s plot the relative value of the eigenvalues (that is, relative importance
    of each feature) on the following bar chart:'
  id: totrans-1830
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下面的柱状图中绘制特征值的相对值（即每个特征的相对重要性）：
- en: '![Evaluation](img/image01354.jpeg)'
  id: totrans-1831
  prefs: []
  type: TYPE_IMG
  zh: '![评估](img/image01354.jpeg)'
- en: Distribution of eigenvalues in PCA for 5 dimensions
  id: totrans-1832
  prefs: []
  type: TYPE_NORMAL
  zh: PCA中5维度的特征值分布
- en: 'The chart shows that three out of five features account for 85 percent of the
    total variance (trace of the transformed covariance matrix). I invite you to experiment
    with different combinations of these features. The selection of a subset of the
    existing features is as simple as applying Scala''s `take` or `drop` methods:'
  id: totrans-1833
  prefs: []
  type: TYPE_NORMAL
  zh: 图显示，五个特征中有三个特征占到了总方差的85%（变换后协方差矩阵的迹）。我邀请你尝试这些特征的不同组合。选择现有特征子集的操作就像应用Scala的`take`或`drop`方法一样简单：
- en: '[PRE168]'
  id: totrans-1834
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'Let''s plot the cumulative eigenvalues for the three different model configurations:'
  id: totrans-1835
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制三个不同模型配置的累积特征值：
- en: '**Five features**: PE, PS, PB, ROE, and OM'
  id: totrans-1836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**五个特征**：PE、PS、PB、ROE和OM'
- en: '**Four features**: PE, PS, PB, and ROE'
  id: totrans-1837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**四个特征**：PE、PS、PB和ROE'
- en: '**Three features**: PE, PS, and PB'
  id: totrans-1838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三个特征**：PE、PS和PB'
- en: 'The graph will be as follows:'
  id: totrans-1839
  prefs: []
  type: TYPE_NORMAL
  zh: 图将如下所示：
- en: '![Evaluation](img/image01355.jpeg)'
  id: totrans-1840
  prefs: []
  type: TYPE_IMG
  zh: '![评估](img/image01355.jpeg)'
- en: Distribution of eigenvalues in PCA for 3, 4, and 5 features
  id: totrans-1841
  prefs: []
  type: TYPE_NORMAL
  zh: PCA中3、4和5个特征的特征值分布
- en: 'The chart displays the cumulative value of eigenvalues that are the variance
    of the transformed features, *X[i]*. If we apply a threshold of 90 percent to
    the cumulative variance, then the number of principal components for each test
    model is as follows:'
  id: totrans-1842
  prefs: []
  type: TYPE_NORMAL
  zh: 图显示了变换后特征的方差的特征值的累积值。如果我们对累积方差应用90%的阈值，那么每个测试模型的特征值数量如下：
- en: '**{PE, PS, PB}**: 2'
  id: totrans-1843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{PE, PS, PB}**: 2'
- en: '**{PE, PS, PB, ROE}**:3'
  id: totrans-1844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{PE, PS, PB, ROE}**: 3'
- en: '**{PE, PS, PB, ROE, OM}**: 3'
  id: totrans-1845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**{PE, PS, PB, ROE, OM}**: 3'
- en: In conclusion, the PCA algorithm reduced the dimension of the model by 33 percent
    for the three-feature model, 25 percent for the four-feature model, and 40 percent
    for the five-feature model for a threshold of 90 percent.
  id: totrans-1846
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，PCA算法将三特征模型降低了33%，四特征模型降低了25%，五特征模型降低了40%，阈值为90%。
- en: Note
  id: totrans-1847
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Cross-validation of PCA**'
  id: totrans-1848
  prefs: []
  type: TYPE_NORMAL
  zh: '**PCA交叉验证**'
- en: Like any other unsupervised learning technique, the resulting principal components
    have to be validated through a one or K-fold cross-validation methodology using
    a regression estimator such as **Partial Least Square Regression** (PLSR) or the
    **Predicted Residual Error Sum of Squares** (**PRESS**). For those who are not
    afraid of statistics, I recommend that you read *Fast Cross-validation in Robust
    PCA* by *S. Engelen and M. Hubert* [4:14]. You need to be aware of the fact that
    the implementation of these regression estimators is not simple. The validation
    of the PCA is beyond the scope of this book.
  id: totrans-1849
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何其他无监督学习技术一样，得到的特征值必须通过使用回归估计量（如**偏最小二乘回归**（PLSR）或**预测残差误差平方和**（PRESS））进行一或K折交叉验证的方法来验证。对于那些不怕统计的人来说，我建议你阅读S.
    Engelen和M. Hubert的*《快速鲁棒PCA交叉验证》* [4:14]。你需要意识到这些回归估计量的实现并不简单。PCA的验证超出了本书的范围。
- en: Principal components analysis is a special case of the more general factor analysis.
    The latter class of algorithm does not require the transformation of the covariance
    matrix to be orthogonal.
  id: totrans-1850
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析是更一般性因子分析的一个特例。后者类别的算法不需要将协方差矩阵转换成正交矩阵。
- en: Non-linear models
  id: totrans-1851
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非线性模型
- en: 'The principal components analysis technique requires the model to be linear.
    Although the study of such algorithms is beyond the scope of this book, it''s
    worth mentioning two approaches that extend PCA for non-linear models:'
  id: totrans-1852
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析技术要求模型是线性的。尽管这类算法的研究超出了本书的范围，但值得提及两种扩展PCA以用于非线性模型的方法：
- en: Kernel PCA
  id: totrans-1853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核PCA
- en: Manifold learning
  id: totrans-1854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流形学习
- en: Kernel PCA
  id: totrans-1855
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核PCA
- en: PCA extracts a set of orthogonal linear projections of an array of correlated
    values, *X = {x[i]}*. The kernel PCA algorithm consists of extracting a similar
    set of orthogonal projection of the inner product matrix, *X^TX*. Nonlinearity
    is supported by applying a kernel function to the inner product. Kernel functions
    are described in the *Kernel functions* section in [Chapter 8](part0200.xhtml#aid-5UNGG2
    "Chapter 8. Kernel Models and Support Vector Machines"), *Kernel Models and Support
    Vector Machines*. The kernel PCA is an attempt to extract a low dimension feature
    set (or manifold) from the original observation space. The linear PCA is the projection
    on the tangent space of the manifold.
  id: totrans-1856
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）从一组相关值数组中提取一组正交线性投影，*X = {x[i]}*。核PCA算法包括从内积矩阵*X^TX*中提取相似的正交投影集。通过应用核函数到内积，支持非线性。核函数在[第8章](part0200.xhtml#aid-5UNGG2
    "第8章. 核模型和支持向量机")的*核函数*部分中描述，*核模型和支持向量机*。核PCA是尝试从原始观测空间中提取一个低维特征集（或流形）。线性PCA是流形切空间上的投影。
- en: Manifolds
  id: totrans-1857
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流形
- en: The concept of a manifold is borrowed from differential geometry. **Manifolds**
    generalize the notions of curves in a two-dimension space or surfaces in a three
    dimension space to a higher dimension. Nonlinear models are associated with Riemann
    manifolds whose metric is the inner product, *X^TX*, on a tangent space. The manifold
    represents a low dimension feature space embedded into the original observation
    space. The idea is to project the principal components from the linear tangent
    space to a manifold using a exponential map. This feat is accomplished using a
    variety of techniques from Local Linear Embedding and density preserving maps
    to Laplacian Eigenmaps [4:15].
  id: totrans-1858
  prefs: []
  type: TYPE_NORMAL
  zh: 流形的概念借鉴自微分几何。**流形**将二维空间中的曲线或三维空间中的曲面推广到更高维度。非线性模型与度量是切空间上的内积*X^TX*的黎曼流形相关联。流形代表一个低维特征空间，它嵌入到原始观测空间中。想法是使用指数映射将线性切空间的主成分投影到流形上。这一壮举是通过使用从局部线性嵌入和密度保持映射到拉普拉斯特征映射等众多技术实现的
    [4:15]。
- en: The vector of observations cannot be directly used on a manifold because metrics
    such as norms or inner products depend on the location of the manifold the vector
    is applied to. Computation on manifolds relies on tensors such as contravariant
    and covariant vectors. Tensors algebra is supported by covariant and contravariant
    functors, which is introduced in the *Abstraction* section in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*.
  id: totrans-1859
  prefs: []
  type: TYPE_NORMAL
  zh: 观测向量不能直接用于流形上，因为诸如范数或内积等度量依赖于向量应用到的流形的定位。在流形上的计算依赖于诸如逆变和协变向量之类的张量。张量代数由协变和逆变函子支持，这在[第1章](part0155.xhtml#aid-4JQ761
    "第1章. 入门")的*抽象*部分中介绍，*入门*。
- en: Techniques that use differentiable manifolds are known as spectral dimensionality
    reduction.
  id: totrans-1860
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可微流形的技巧被称为谱降维。
- en: Note
  id: totrans-1861
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Alternative dimension reduction techniques**'
  id: totrans-1862
  prefs: []
  type: TYPE_NORMAL
  zh: '**替代降维技术**'
- en: 'Here are some more alternative techniques, listed as references: factor analysis,
    principal factor analysis, maximum likelihood factor analysis, independent component
    analysis, Random projection, nonlinear ICA, Kohonen''s self-organizing maps, neural
    networks, and multidimensional scaling, just to name a few [4:16].'
  id: totrans-1863
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些更多的替代技术，列作参考文献：因子分析、主因子分析、最大似然因子分析、独立成分分析、随机投影、非线性ICA、Kohonen的自组织映射、神经网络和多维尺度，仅举几例
    [4:16]。
- en: Manifold learning algorithms such as classifiers and dimension reduction techniques
    are associated with semi-supervised learning.
  id: totrans-1864
  prefs: []
  type: TYPE_NORMAL
  zh: 流形学习方法，如分类器和降维技术，与半监督学习相关联。
- en: Performance considerations
  id: totrans-1865
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能考虑
- en: The three unsupervised learning techniques share the same limitation—a high
    computational complexity.
  id: totrans-1866
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种无监督学习技术具有相同的局限性——高计算复杂度。
- en: K-means
  id: totrans-1867
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K-means
- en: 'The K-means has the computational complexity of *O(iKnm)*, where *i* is the
    number of iterations (or recursions), *K* is the number of clusters, *n* is the
    number of observations, and *m* is the number of features. Here are some remedies
    to the poor performance of the K-means algorithm:'
  id: totrans-1868
  prefs: []
  type: TYPE_NORMAL
  zh: K-means的计算复杂度为*O(iKnm)*，其中*i*是迭代次数（或递归次数），*K*是簇的数量，*n*是观测的数量，*m*是特征的数量。以下是针对K-means算法性能不佳的一些补救措施：
- en: Reducing the average number of iterations by seeding the centroid using a technique
    such as initialization by ranking the variance of the initial cluster, as described
    in the beginning of this chapter
  id: totrans-1869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用如本章开头所述的通过对初始簇的方差进行排序的初始化技术来播种质心，以减少平均迭代次数
- en: Using a parallel implementation of K-means and leveraging a large-scale framework
    such as Hadoop or Spark
  id: totrans-1870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Hadoop或Spark等大规模框架并行实现K-means
- en: Reducing the number of outliers and features by filtering out the noise with
    a smoothing algorithm such as a discrete Fourier transform or a Kalman filter
  id: totrans-1871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用离散傅里叶变换或卡尔曼滤波等平滑算法过滤噪声来减少异常值和特征的数量
- en: 'Decreasing the dimensions of the model by following a two-step process:'
  id: totrans-1872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过两步过程降低模型的维度：
- en: Execute a first pass with a smaller number of clusters *K* and/or a loose exit
    condition regarding the reassignment of data points. The data points close to
    each centroid are aggregated into a single observation.
  id: totrans-1873
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用较少的聚类数*K*和/或关于数据点重新分配的宽松退出条件执行第一次遍历。接近每个质心的数据点被汇总为一个单独的观察结果。
- en: Execute a second pass on the aggregated observations.
  id: totrans-1874
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对汇总观察结果执行第二次遍历。
- en: EM
  id: totrans-1875
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EM
- en: The computational complexity of the expectation-maximization algorithm for each
    iteration (E + M steps) is *O(m²n)*, where *m* is the number of hidden or latent
    variables and *n* is the number of observations.
  id: totrans-1876
  prefs: []
  type: TYPE_NORMAL
  zh: 期望最大化算法每轮迭代（E + M步骤）的计算复杂度为*O(m²n)*，其中*m*是隐藏或潜在变量的数量，*n*是观察数。
- en: 'A partial list of suggested performance improvement includes:'
  id: totrans-1877
  prefs: []
  type: TYPE_NORMAL
  zh: 建议的性能改进的部分列表包括：
- en: Filtering of raw data to remove noise and outliers
  id: totrans-1878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对原始数据进行过滤以去除噪声和异常值
- en: Using a sparse matrix on a large feature set to reduce the complexity of the
    covariance matrix, if possible
  id: totrans-1879
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大型特征集上使用稀疏矩阵以降低协方差矩阵的复杂性，如果可能的话
- en: Applying the Gaussian mixture model wherever possible—the assumption of Gaussian
    distribution simplifies the computation of the log likelihood
  id: totrans-1880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可能的情况下应用高斯混合模型——高斯分布的假设简化了似然对数的计算
- en: Using a parallel data processing framework such as Apache Hadoop or Spark, as
    discussed in the *Apache Spark* section in [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*
  id: totrans-1881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Apache Hadoop或Spark等并行数据处理框架，如第12章中*Apache Spark*部分所述，*可扩展框架*
- en: Using a kernel function to reduce the estimate of covariance in the E-step
  id: totrans-1882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在E步骤中使用核函数来降低协方差的估计
- en: PCA
  id: totrans-1883
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PCA
- en: The computational complexity of the extraction of the principal components is
    *O(m²n + n³)*, where *m* is the number of features and *n* is the number of observations.
    The first term represents the computational complexity for computing the covariance
    matrix. The second term reflects the computational complexity of the eigenvalue
    decomposition.
  id: totrans-1884
  prefs: []
  type: TYPE_NORMAL
  zh: 提取主成分的计算复杂度为*O(m²n + n³)*，其中*m*是特征数，*n*是观察数。第一项表示计算协方差矩阵的计算复杂度。第二项反映了特征值分解的计算复杂度。
- en: 'The list of potential performance improvements or alternative solutions for
    PCA includes the following:'
  id: totrans-1885
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的潜在性能改进或替代解决方案的列表包括以下内容：
- en: Assuming that the variance is Gaussian
  id: totrans-1886
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设方差是高斯分布
- en: Using a sparse matrix to compute eigenvalues for problems with large feature
    sets and missing data
  id: totrans-1887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用稀疏矩阵计算具有大型特征集和缺失数据的特征值
- en: Investigating alternatives to PCA to reduce the dimension of a model such as
    the **discrete Fourier transform** (**DFT**) or **singular value decomposition**
    (**SVD**) [4:17]
  id: totrans-1888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查PCA的替代方案以降低模型维度，例如**离散傅里叶变换**（**DFT**）或**奇异值分解**（**SVD**）[4:17]
- en: Using PCA in conjunction with EM (at the research stage)
  id: totrans-1889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在研究阶段结合PCA和EM（期望最大化算法）
- en: Deploying a dataset on a parallel data processing framework such as Apache Hadoop
    or Spark, as described in the *Apache Spark* section in [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*
  id: totrans-1890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Apache Hadoop或Spark等并行数据处理框架上部署数据集，如第12章中*Apache Spark*部分所述，*可扩展框架*
- en: Summary
  id: totrans-1891
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This completes the overview of three of the most commonly used unsupervised
    learning techniques:'
  id: totrans-1892
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了对三种最常用的无监督学习技术的概述：
- en: K-means for clustering fully observed features of a model with reasonable dimensions
  id: totrans-1893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-means用于聚类具有合理维度的模型的全观测特征
- en: Expectation-maximization for clustering a combination of observed and latent
    features
  id: totrans-1894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测聚类中观察到的和潜在特征的期望最大化
- en: Principal components analysis to transform and extract the most critical features
    in terms of variance for linear models
  id: totrans-1895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主成分分析用于转换和提取线性模型中关于方差的最重要的特征
- en: Manifold learning for non-linear models is a technically challenging field with
    great potential in terms of dynamic object recognition [4:18].
  id: totrans-1896
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性模型的多维学习是一个技术上有挑战性但具有巨大潜力的领域，特别是在动态对象识别方面[4:18]。
- en: 'The key point to remember is that unsupervised learning techniques are used:'
  id: totrans-1897
  prefs: []
  type: TYPE_NORMAL
  zh: 要记住的关键点是，无监督学习技术被用于：
- en: By themselves to extract structures and associations from unlabelled observations
  id: totrans-1898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过自身从未标记的观察中提取结构和关联
- en: As a preprocessing stage to supervised learning in reducing the number of features
    prior to the training phase
  id: totrans-1899
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为监督学习在训练阶段之前减少特征数量的预处理阶段
- en: The distinction between unsupervised and supervised learning is not as strict
    as you may think. For instance, the K-means algorithm can be enhanced to support
    classification.
  id: totrans-1900
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习和监督学习之间的区别并不像你想象的那样严格。例如，K-means算法可以被增强以支持分类。
- en: In the next chapter, we will address the second use case and cover supervised
    learning techniques starting with generative models.
  id: totrans-1901
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将解决第二个用例，并从生成模型开始介绍监督学习技术。
- en: Chapter 5. Naïve Bayes Classifiers
  id: totrans-1902
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。朴素贝叶斯分类器
- en: This chapter introduces the most common and simple generative classifiers—Naïve
    Bayes. As mentioned earlier, generative classifiers are supervised learning algorithms
    that attempt to fit a *joint probability distribution p(X,Y)* of two *X* and *Y*
    events, representing two sets of observed and hidden (or latent) variables, *x*
    and *y*.
  id: totrans-1903
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了最常见和最简单的生成分类器——朴素贝叶斯。如前所述，生成分类器是监督学习算法，试图拟合两个事件X和Y的联合概率分布p(X,Y)，代表两组观察到的和隐藏（或潜在）变量x和y。
- en: In this chapter, you will learn, and hopefully appreciate, the simplicity of
    the Naïve Bayes technique through a concrete example. Then, you will learn how
    to build a Naïve Bayes classifier to predict the stock price movement, given some
    prior technical indicators in the analysis of financial markets.
  id: totrans-1904
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习，并希望你能欣赏，通过一个具体的例子来展示朴素贝叶斯技术的简单性。然后，你将学习如何构建一个朴素贝叶斯分类器，根据金融市场分析中的一些先验技术指标来预测股价走势。
- en: Finally, you will learn how to apply Naïve Bayes to text mining by predicting
    stock prices using financial news feed and press releases.
  id: totrans-1905
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你将学习如何通过使用金融新闻和新闻稿来预测股价，将朴素贝叶斯应用于文本挖掘。
- en: Probabilistic graphical models
  id: totrans-1906
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率图模型
- en: Let's start with a refresher course in basic statistics.
  id: totrans-1907
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基础统计学复习开始。
- en: Given two events or observations *X* and *Y*, the joint probability of *X* and
    *Y* is defined as *p(X,Y) = p(X∩Y)*. If the observations *X* and *Y* are not related,
    an assumption known as conditional independence, then *p(X,Y) = p(X).p(Y)*. The
    conditional probability of an event *Y*, given *X*, is defined as *p(Y|X) = p(X,Y)/p(X)*.
  id: totrans-1908
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个事件或观察X和Y，X和Y的联合概率定义为*p(X,Y) = p(X∩Y)*。如果观察X和Y不相关，那么有一个被称为条件独立性的假设，则*p(X,Y)
    = p(X).p(Y)*。事件Y在X条件下的条件概率定义为*p(Y|X) = p(X,Y)/p(X)*。
- en: These two definitions are quite simple. However, **probabilistic reasoning**
    can be difficult to read in the case of large numbers of variables and sequences
    of conditional probabilities. As a picture is worth a thousand words, researchers
    introduced **graphical models** to describe a probabilistic relation between random
    variables using graphs [5:1].
  id: totrans-1909
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个定义相当简单。然而，在大量变量和条件概率序列的情况下，**概率推理**可能难以阅读。正如一图胜千言，研究人员引入了**图模型**来描述随机变量之间的概率关系[5:1]。
- en: 'There are two categories of graphs, and therefore, graphical models, which
    are as follows:'
  id: totrans-1910
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种类型的图，因此，图模型，如下所示：
- en: Directed graphs such as Bayesian networks
  id: totrans-1911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如贝叶斯网络这样的有向图
- en: Undirected graphs such as conditional random fields (refer to the *Conditional
    random fields* section in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential
    Data Models"), *Sequential Data Models*)
  id: totrans-1912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如条件随机字段（参考第7章中的*条件随机字段*部分，*序列数据模型*），无向图
- en: '**Directed graphical models** are directed acyclic graphs that have been introduced
    to:'
  id: totrans-1913
  prefs: []
  type: TYPE_NORMAL
  zh: '**有向图模型**是有向无环图，已被引入用于：'
- en: Provide a simple way to visualize a probabilistic model
  id: totrans-1914
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一种简单的方式来可视化概率模型
- en: Describe the conditional dependence between variables
  id: totrans-1915
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述变量之间的条件依赖关系
- en: Represent a statistical inference in terms of connectivity between graphical
    objects
  id: totrans-1916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用图形对象之间的连接来表示统计推理
- en: A Bayesian network is a directed graphical model that defines a joint probability
    over a set of variables [5:2].
  id: totrans-1917
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络是一种有向图模型，它定义了一组变量上的联合概率[5:2]。
- en: 'The two joint probabilities *p(X,Y)* and *p(X,Y,Z)* can be graphically modeled
    using Bayesian networks, as follows:'
  id: totrans-1918
  prefs: []
  type: TYPE_NORMAL
  zh: 两个联合概率 *p(X,Y)* 和 *p(X,Y,Z)* 可以使用贝叶斯网络进行图形建模，如下所示：
- en: '![Probabilistic graphical models](img/image01356.jpeg)'
  id: totrans-1919
  prefs: []
  type: TYPE_IMG
  zh: '![概率图形模型](img/image01356.jpeg)'
- en: Examples of probabilistic graphical models
  id: totrans-1920
  prefs: []
  type: TYPE_NORMAL
  zh: 概率图形模型的例子
- en: The conditional probability *p(Y|X)* is represented by an arrow directed from
    the output (or symptoms) *Y* to the input (or cause) *X*. Elaborate models can
    be described as a large directed graph between variables.
  id: totrans-1921
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率 *p(Y|X)* 由从输出（或症状）*Y* 到输入（或原因）*X* 的箭头表示。详细模型可以描述为变量之间的大型有向图。
- en: Note
  id: totrans-1922
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: '**A metaphor for graphical models**'
  id: totrans-1923
  prefs: []
  type: TYPE_NORMAL
  zh: '**图形模型的隐喻**'
- en: From a software engineering perspective, graphical models visualize probabilistic
    equations in the same way the UML class diagram visualizes the object-oriented
    source code.
  id: totrans-1924
  prefs: []
  type: TYPE_NORMAL
  zh: 从软件工程的角度来看，图形模型以与UML类图以相同的方式可视化概率方程。
- en: 'Here is an example of a real-world Bayesian network; the functioning of a smoke
    detector:'
  id: totrans-1925
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个真实世界贝叶斯网络的例子；烟雾探测器的功能：
- en: A fire may generate smoke.
  id: totrans-1926
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 火灾可能会产生烟雾。
- en: Smoke may trigger an alarm.
  id: totrans-1927
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 烟雾可能会触发警报。
- en: A depleted battery may trigger an alarm.
  id: totrans-1928
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 空电池可能会触发警报。
- en: The alarm may alert the homeowner.
  id: totrans-1929
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 警报可能会通知房主。
- en: The alarm may alert the fire department.
  id: totrans-1930
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 警报可能会通知消防部门。
- en: 'The flow diagram is as follows:'
  id: totrans-1931
  prefs: []
  type: TYPE_NORMAL
  zh: 流程图如下：
- en: '![Probabilistic graphical models](img/image01357.jpeg)'
  id: totrans-1932
  prefs: []
  type: TYPE_IMG
  zh: '![概率图形模型](img/image01357.jpeg)'
- en: A Bayesian network for smoke detectors
  id: totrans-1933
  prefs: []
  type: TYPE_NORMAL
  zh: 烟雾探测器的贝叶斯网络
- en: This representation may be a bit counterintuitive, as the vertices are directed
    from the symptoms (or output) to the cause (or input). Directed graphical models
    are used in many different models, besides Bayesian networks [5:3].
  id: totrans-1934
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示可能有点反直觉，因为顶点是从症状（或输出）指向原因（或输入）。除了贝叶斯网络外，有向图模型还用于许多不同的模型[5:3]。
- en: Note
  id: totrans-1935
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: '**Plate models**'
  id: totrans-1936
  prefs: []
  type: TYPE_NORMAL
  zh: '**板模型**'
- en: There are several alternate representations of probabilistic models, besides
    the directed acyclic graph, such as the plate model commonly used for the **Latent
    Dirichlet Allocation** (**LDA**) [5:4].
  id: totrans-1937
  prefs: []
  type: TYPE_NORMAL
  zh: 除了有向无环图之外，概率模型还有几种不同的表示方式，例如常用的**潜在狄利克雷分配**（**LDA**）的板模型[5:4]。
- en: The Naïve Bayes models are probabilistic models based on the Bayes's theorem
    under the assumption of features independence, as mentioned in the *Generative
    models* section under *Supervised learning* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*.
  id: totrans-1938
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯模型是基于贝叶斯定理的概率模型，在特征独立性的假设下，如[第1章](part0155.xhtml#aid-4JQ761 "第1章。入门")中“监督学习”下的“生成模型”部分所述，*入门*。
- en: Naïve Bayes classifiers
  id: totrans-1939
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器
- en: The conditional independence between *X* features is an essential requirement
    for the Naïve Bayes classifier. It also restricts its applicability. The Naïve
    Bayes classification is better understood through simple and concrete examples
    [5:5].
  id: totrans-1940
  prefs: []
  type: TYPE_NORMAL
  zh: '*X* 特征之间的条件独立性是朴素贝叶斯分类器的一个基本要求。它也限制了其适用性。通过简单和具体的例子可以更好地理解朴素贝叶斯分类[5:5]。'
- en: Introducing the multinomial Naïve Bayes
  id: totrans-1941
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍多项式朴素贝叶斯
- en: Let's consider the problem of how to predict a change in interest rates.
  id: totrans-1942
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑如何预测利率变化的问题。
- en: The first step is to list the factors that potentially may trigger or cause
    an increase or decrease in the interest rates. For the sake of illustrating Naïve
    Bayes, we will select the **consumer price index** (**CPI**) and change the **Federal
    fund rate** (**FDF**) and the **gross domestic product** (**GDP**), as the first
    set of features. The terminology is described in the *Terminology* section under
    *Finances 101* in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*.
  id: totrans-1943
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是列出可能触发或导致利率增加或减少的因素。为了说明朴素贝叶斯，我们将选择**消费者价格指数**（**CPI**）和改变**联邦基金利率**（**FDF**）以及**国内生产总值**（**GDP**），作为第一组特征。术语在[附录A](part0229.xhtml#aid-6QCGQ2
    "附录A。基本概念")中“金融101”下的“术语”部分进行了描述，*基本概念*。
- en: The use case is used to predict the direction of the change in the yield of
    the **1-year Treasury bill** (**1yTB**), taking into account the change in the
    current CPI, FDF, and GDP. The objective is, therefore, to create a predictive
    model using a combination of these three features.
  id: totrans-1944
  prefs: []
  type: TYPE_NORMAL
  zh: 该用例用于预测1年期国债收益率（**1yTB**）的变化方向，同时考虑当前CPI、FDF和GDP的变化。因此，目标是创建一个预测模型，结合这三个特征。
- en: It is assumed that there is no available financial investment expert who can
    supply rules or policies to predict interest rates. Therefore, the model depends
    highly on the historical data. Intuitively, if one feature always increases when
    the yield of the 1-year Treasury bill increases, then we can conclude that there
    is a strong correlation of causal relationship between the features and the output
    variation in interest rates.
  id: totrans-1945
  prefs: []
  type: TYPE_NORMAL
  zh: 假设没有可用的金融投资专家能够提供规则或政策来预测利率。因此，该模型高度依赖于历史数据。直观上，如果一个特征在1年期国债收益率增加时总是增加，那么我们可以得出结论，这些特征与利率输出变化之间存在强烈的因果关系。
- en: '![Introducing the multinomial Naïve Bayes](img/image01358.jpeg)'
  id: totrans-1946
  prefs: []
  type: TYPE_IMG
  zh: '![介绍多项式朴素贝叶斯](img/image01358.jpeg)'
- en: The Naive Bayes model for predicting the change in the yield of the 1-year T-bill
  id: totrans-1947
  prefs: []
  type: TYPE_NORMAL
  zh: 预测1年期T-bill收益率变化的朴素贝叶斯模型
- en: 'The correlation (or cause-effect relationship) is derived from the historical
    data. The methodology consists of counting the number of times each feature either
    increases (**UP**) or decreases (**DOWN**) and recording the corresponding expected
    outcome, as illustrated in the following table:'
  id: totrans-1948
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性（或因果关系）是从历史数据中得出的。该方法包括计算每个特征增加（**上升**）或减少（**下降**）的次数，并记录相应的预期结果，如下表所示：
- en: '| ID | GDP | FDF | CPI | 1y-TB |'
  id: totrans-1949
  prefs: []
  type: TYPE_TB
  zh: '| ID | GDP | FDF | CPI | 1y-TB |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-1950
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **1** | UP | DOWN | UP | UP |'
  id: totrans-1951
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 上升 | 下降 | 上升 | 上升 |'
- en: '| **2** | UP | UP | UP | UP |'
  id: totrans-1952
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 上升 | 上升 | 上升 | 上升 |'
- en: '| **3** | DOWN | UP | DOWN | DOWN |'
  id: totrans-1953
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 下降 | 上升 | 下降 | 下降 |'
- en: '| **4** | UP | DOWN | DOWN | DOWN |'
  id: totrans-1954
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 上升 | 下降 | 下降 | 下降 |'
- en: '| … |'
  id: totrans-1955
  prefs: []
  type: TYPE_TB
  zh: '| … |'
- en: '| **256** | DOWN | DOWN | UP | DOWN |'
  id: totrans-1956
  prefs: []
  type: TYPE_TB
  zh: '| **256** | 下降 | 下降 | 上升 | 下降 |'
- en: 'First, let''s tabulate the number of occurrences of each change (**UP** and
    **DOWN**) for the three features and the output value (the direction of the change
    in the yield of the 1-year Treasury bill):'
  id: totrans-1957
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们列出三个特征和输出值（1年期国债收益率变化的方向）的每个变化（**上升**和**下降**）的次数：
- en: '| Number | GDP | FDF | CPI | 1yTB |'
  id: totrans-1958
  prefs: []
  type: TYPE_TB
  zh: '| 数量 | GDP | FDF | CPI | 1yTB |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-1959
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| UP | 169 | 184 | 175 | 159 |'
  id: totrans-1960
  prefs: []
  type: TYPE_TB
  zh: '| 上升 | 169 | 184 | 175 | 159 |'
- en: '| DOWN | 97 | 72 | 81 | 97 |'
  id: totrans-1961
  prefs: []
  type: TYPE_TB
  zh: '| 下降 | 97 | 72 | 81 | 97 |'
- en: '| Total | 256 | 256 | 256 | 256 |'
  id: totrans-1962
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 256 | 256 | 256 | 256 |'
- en: '| UP/Total | 0.66 | 0.72 | 0.68 | **0.625** |'
  id: totrans-1963
  prefs: []
  type: TYPE_TB
  zh: '| 总/上升 | 0.66 | 0.72 | 0.68 | **0.625** |'
- en: 'Next, let''s compute the number of positive directions for each of the features
    when the yield of the 1-year Treasury bill increases (159 occurrences):'
  id: totrans-1964
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们计算当1年期国债收益率增加时（共发生159次）每个特征的正面方向数量：
- en: '| Number | GDP | Fed Funds | CPI |'
  id: totrans-1965
  prefs: []
  type: TYPE_TB
  zh: '| 数量 | GDP | 联邦基金 | CPI |'
- en: '| --- | --- | --- | --- |'
  id: totrans-1966
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| UP | 110 | 136 | 127 |'
  id: totrans-1967
  prefs: []
  type: TYPE_TB
  zh: '| 上升 | 110 | 136 | 127 |'
- en: '| DOWN | 49 | 23 | 32 |'
  id: totrans-1968
  prefs: []
  type: TYPE_TB
  zh: '| 下降 | 49 | 23 | 32 |'
- en: '| Total | 159 | 159 | 159 |'
  id: totrans-1969
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 159 | 159 | 159 |'
- en: '| UP/Total | 0.69 | 0.85 | **0.80** |'
  id: totrans-1970
  prefs: []
  type: TYPE_TB
  zh: '| 总/上升 | 0.69 | 0.85 | **0.80** |'
- en: From the preceding table, we conclude that the yield of the 1-year Treasury
    bill increases when the GDP increases (69 percent of the time), the rate of the
    Federal funds increases (85 percent of the time), and the CPI increases (80 percent
    of the time).
  id: totrans-1971
  prefs: []
  type: TYPE_NORMAL
  zh: 从前表可以得出结论，当GDP增加时（69%的时间），联邦基金利率增加（85%的时间），以及CPI增加（80%的时间），1年期国债收益率会增加。
- en: Let's formalize the Naïve Bayes model before turning these findings into a probabilistic
    model.
  id: totrans-1972
  prefs: []
  type: TYPE_NORMAL
  zh: 在将这些发现转化为概率模型之前，让我们将朴素贝叶斯模型形式化。
- en: Formalism
  id: totrans-1973
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 形式化
- en: 'Let''s start by clarifying the terminologies used in the Bayesian model:'
  id: totrans-1974
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先明确贝叶斯模型中使用的术语：
- en: '**Class prior probability or class prior**: This is the probability of a class'
  id: totrans-1975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类先验概率或类先验**：这是一个类的概率'
- en: '**Likelihood**: This is the probability to observe a value or event, given
    a class, also known as the probability of the predictor, given a class'
  id: totrans-1976
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**似然**：这是在给定一个类的情况下观察到一个值或事件的概率，也称为给定一个类的预测概率'
- en: '**Evidence**: This is the probability of observations that occur, also known
    as the prior probability of the predictor'
  id: totrans-1977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**证据**：这是发生观察到的概率，也称为预测者的先验概率'
- en: '**Posterior probability**: This is the probability of an observation *x* being
    in a given class'
  id: totrans-1978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后验概率**：这是观测 *x* 在给定类别中的概率'
- en: No model can be simpler! The log likelihood, *log p(x[i]|C[j])*, is commonly
    used instead of the likelihood in order to reduce the impact of the features *x[i]*
    that have a low likelihood.
  id: totrans-1979
  prefs: []
  type: TYPE_NORMAL
  zh: 没有模型可以比这更简单！通常使用对数似然率 *log p(x[i]|C[j])* 而不是似然率，以减少具有低似然率的特征 *x[i]* 的影响。
- en: The objective of the Naïve Bayes classification of a new observation is to compute
    the class that has the highest log likelihood. The mathematical notation for the
    Naïve Bayes model is also straightforward.
  id: totrans-1980
  prefs: []
  type: TYPE_NORMAL
  zh: 新观测的朴素贝叶斯分类的目标是计算具有最高对数似然率的类别。朴素贝叶斯模型的数学符号也很简单。
- en: Note
  id: totrans-1981
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The Naïve Bayes classification**'
  id: totrans-1982
  prefs: []
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯分类**'
- en: 'M1: The posterior probability *p(C[j]|x)* is defined as:'
  id: totrans-1983
  prefs: []
  type: TYPE_NORMAL
  zh: M1：后验概率 *p(C[j]|x)* 定义为：
- en: '![Formalism](img/image01359.jpeg)'
  id: totrans-1984
  prefs: []
  type: TYPE_IMG
  zh: '![形式化](img/image01359.jpeg)'
- en: Here, *x = {x[i]} (0, n-1)* is a set of *n* features. *{C[j]}* is a set of classes
    with their class prior *p(C[j])*. *x = {x[i]} (0, n-1)* with a set of *n* features.
    *p(x|C[j])* is the likelihood for each feature
  id: totrans-1985
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x = {x[i]} (0, n-1)* 是一组 *n* 个特征。*{C[j]}* 是一组具有其类别先验 *p(C[j])* 的类别。*x =
    {x[i]} (0, n-1)* 是一组具有 *n* 个特征的。*p(x|C[j])* 是每个特征的概率
- en: 'M2: The computation of the posterior probability *p(C[j]| x)* is simplified
    by the assumption of conditional independence of features:'
  id: totrans-1986
  prefs: []
  type: TYPE_NORMAL
  zh: M2：通过假设特征的条件独立性，后验概率 *p(C[j]| x)* 的计算被简化。
- en: '![Formalism](img/image01360.jpeg)'
  id: totrans-1987
  prefs: []
  type: TYPE_IMG
  zh: '![形式化](img/image01360.jpeg)'
- en: Here, *x[i]* are independent and the probabilities are normalized for evidence
    *p(x) = 1*.
  id: totrans-1988
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x[i]* 是独立的，并且概率已归一化，证据 *p(x) = 1*。
- en: 'M3: The **maximum likelihood estimate** (**MLE**) is defined as:'
  id: totrans-1989
  prefs: []
  type: TYPE_NORMAL
  zh: M3：**最大似然估计**（**MLE**）定义为：
- en: '![Formalism](img/image01361.jpeg)'
  id: totrans-1990
  prefs: []
  type: TYPE_IMG
  zh: '![形式化](img/image01361.jpeg)'
- en: 'M4: The Naïve Bayes classification of an observation *x* of a class *C[m]*
    is defined as:'
  id: totrans-1991
  prefs: []
  type: TYPE_NORMAL
  zh: M4：类别 *C[m]* 的观测 *x* 的朴素贝叶斯分类定义为：
- en: '![Formalism](img/image01362.jpeg)'
  id: totrans-1992
  prefs: []
  type: TYPE_IMG
  zh: '![形式化](img/image01362.jpeg)'
- en: This particular use case has a major drawback—the GDP statistics are provided
    quarterly, while the CPI data is made available once a month and a change in FDF
    rate is rather infrequent.
  id: totrans-1993
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的用例有一个主要的缺点——GDP统计数据是按季度提供的，而CPI数据每月提供一次，FDF利率的变化相对较少。
- en: The frequentist perspective
  id: totrans-1994
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 经验主义视角
- en: The ability to compute the posterior probability depends on the formulation
    of the likelihood using historical data. A simple solution is to count the occurrences
    of observations for each class and compute the frequency.
  id: totrans-1995
  prefs: []
  type: TYPE_NORMAL
  zh: 计算后验概率的能力取决于使用历史数据对似然率的公式化。一个简单的解决方案是计算每个类别的观测发生次数并计算频率。
- en: Let's consider the first example that predicts the direction of the change in
    the yield of the 1-year Treasury bill, given changes in the GDP, FDF, and CPI.
  id: totrans-1996
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑第一个例子，预测1年期国债收益率的变动方向，给定GDP、FDF和CPI的变化。
- en: 'The results are expressed with simple probabilistic formulas and a directed
    graphical model:'
  id: totrans-1997
  prefs: []
  type: TYPE_NORMAL
  zh: 结果用简单的概率公式和有向图模型表示：
- en: '[PRE169]'
  id: totrans-1998
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '![The frequentist perspective](img/image01363.jpeg)'
  id: totrans-1999
  prefs: []
  type: TYPE_IMG
  zh: '![经验主义视角](img/image01363.jpeg)'
- en: The Bayesian network for the prediction of the change of the yield of the 1-year
    Treasury bill
  id: totrans-2000
  prefs: []
  type: TYPE_NORMAL
  zh: 预测1年期国债收益率变化的贝叶斯网络
- en: Note
  id: totrans-2001
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Overfitting**'
  id: totrans-2002
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合**'
- en: The Naïve Bayes model is not immune to overfitting if the number of observations
    is not large enough relative to the number of features. One approach to address
    this problem is to perform a feature selection using the mutual information exclusion
    [5:6].
  id: totrans-2003
  prefs: []
  type: TYPE_NORMAL
  zh: 如果观测的数量相对于特征的数量不足，朴素贝叶斯模型不会免疫过拟合。解决这个问题的方法之一是使用互信息排除法进行特征选择[5:6]。
- en: 'This problem is not a good candidate for a Bayesian classification for the
    following two reasons:'
  id: totrans-2004
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题不适合作为贝叶斯分类的候选者，以下有两个原因：
- en: The training set is not large enough to compute accurate prior probabilities
    and generate a stable model. Decades of quarterly GDP data is needed to train
    and validate the model.
  id: totrans-2005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集不够大，无法计算准确的先验概率并生成稳定的模型。需要数十年的季度GDP数据来训练和验证模型。
- en: The features have different rates of change, which predominately favor the features
    with the highest frequency; in this case, the CPI.
  id: totrans-2006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征有不同的变化率，这主要有利于频率最高的特征；在这种情况下，是CPI。
- en: Let's select another use case for which a large historical dataset is available
    and can be automatically labeled.
  id: totrans-2007
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们选择另一个具有大量可用历史数据并可自动标记的用例。
- en: The predictive model
  id: totrans-2008
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测模型
- en: The predictive model is the second use case that consists of predicting the
    direction of the change of the closing price of a stock, *pr[t+1] = {UP, DOWN}*,
    at trading day *t + 1*, given the history of its direction of the price, volume,
    and volatility for the previous *t* days, *pr[i]* for *i = 0* to *i = t*. The
    volume and volatility features have already been used in the *Writing a simple
    workflow* section in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting
    Started"), *Getting Started*.
  id: totrans-2009
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型是第二个用例，它包括预测股票收盘价变化方向，*pr[t+1] = {UP, DOWN}*，在交易日 *t + 1*，给定其价格、成交量、波动率的历史记录，*pr[i]*
    对于 *i = 0* 到 *i = t*。体积和波动率特征已在 [第 1 章](part0155.xhtml#aid-4JQ761 "第 1 章。入门")
    的 *编写简单工作流* 部分中使用，*入门*。
- en: 'Therefore, the three features under consideration are as follows:'
  id: totrans-2010
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，考虑的三个特征如下：
- en: The closing price *pr[t]* of the last trading session, *t*, is above or below
    the average closing price over the *n* previous trading days, *[t-n, t]*.
  id: totrans-2011
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个交易会话，*t*，的收盘价 *pr[t]* 高于或低于过去 *n* 个交易日平均收盘价，*[t-n, t]*。
- en: The volume of the last trading day *vl[t]* is above or below the average volume
    of the *n* previous trading days
  id: totrans-2012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个交易日的成交量 *vl[t]* 高于或低于过去 *n* 个交易日平均成交量。
- en: The volatility on the last trading day *vt[t]* is above or below the average
    volatility of the previous *n* trading days
  id: totrans-2013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个交易日的波动率 *vt[t]* 高于或低于过去 *n* 个交易日平均波动率。
- en: 'The directed graphic model can be expressed using one output variable (the
    price at session *t + 1* is greater than the price at session *t*) and three features:
    the price condition (1), volume condition (2), and volatility condition (3).'
  id: totrans-2014
  prefs: []
  type: TYPE_NORMAL
  zh: 有向图形模型可以使用一个输出变量（第 *t + 1* 个会话的价格高于第 *t* 个会话的价格）和三个特征来表示：价格条件（1）、成交量条件（2）和波动率条件（3）。
- en: '![The predictive model](img/image01364.jpeg)'
  id: totrans-2015
  prefs: []
  type: TYPE_IMG
  zh: '![预测模型](img/image01364.jpeg)'
- en: The Bayesian model for predicting the future direction of the stock price
  id: totrans-2016
  prefs: []
  type: TYPE_NORMAL
  zh: 预测股价未来方向的贝叶斯模型
- en: This model works under the assumption that there is at least one observation
    or ideally few observations for each feature and expected value.
  id: totrans-2017
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型基于以下假设：每个特征和期望值至少有一个观测值，理想情况下观测值很少。
- en: The zero-frequency problem
  id: totrans-2018
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零频率问题
- en: It is possible that the training set does not contain any data actually observed
    for a feature for a specific label or class. In this case, the mean is *0/N =
    0*, and therefore, the likelihood is null, making classification unfeasible. The
    case for which there are only few observations for a feature in a given class
    is also an issue, as it skews the likelihood.
  id: totrans-2019
  prefs: []
  type: TYPE_NORMAL
  zh: 可能训练集不包含任何特定标签或类别的特征的实际观测数据。在这种情况下，平均值为 *0/N = 0*，因此，似然值为空，使得分类不可行。对于给定类别中特征观测值很少的情况也是一个问题，因为它会扭曲似然值。
- en: There are a couple of correcting or smoothing formulas for unobserved features
    or features with a low number of occurrences that address this issue, such as
    the **Laplace** and **Lidstone** smoothing formulas.
  id: totrans-2020
  prefs: []
  type: TYPE_NORMAL
  zh: 对于未观测特征或出现次数较少的特征，存在一些校正或平滑公式来解决这个问题，例如**拉普拉斯**和**利德斯顿**平滑公式。
- en: Note
  id: totrans-2021
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The smoothing factor for counters**'
  id: totrans-2022
  prefs: []
  type: TYPE_NORMAL
  zh: '**计数器的平滑因子**'
- en: 'M5: The Laplace smoothing formula of the mean *k/N* out of *N* observations
    of features of dimension *n* is defined as:'
  id: totrans-2023
  prefs: []
  type: TYPE_NORMAL
  zh: M5：维度为 *n* 的特征 *N* 个观测值中平均 *k/N* 的拉普拉斯平滑公式定义为：
- en: '![The zero-frequency problem](img/image01365.jpeg)'
  id: totrans-2024
  prefs: []
  type: TYPE_IMG
  zh: '![零频率问题](img/image01365.jpeg)'
- en: 'M6: The Lidstone smoothing formula with a factor *α* is defined as:'
  id: totrans-2025
  prefs: []
  type: TYPE_NORMAL
  zh: M6：具有因子 *α* 的利德斯顿平滑公式定义为：
- en: '![The zero-frequency problem](img/image01366.jpeg)'
  id: totrans-2026
  prefs: []
  type: TYPE_IMG
  zh: '![零频率问题](img/image01366.jpeg)'
- en: The two formulas are commonly used in natural language processing applications,
    for which the occurrence of a specific word or tag is a feature [5:7].
  id: totrans-2027
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个公式在自然语言处理应用中常用，其中特定单词或标签的出现是一个特征 [5:7]。
- en: Implementation
  id: totrans-2028
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: I think it is time to write some Scala code and toy around with Naïve Bayes.
    Let's start with an overview of the software components.
  id: totrans-2029
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为现在是时候写一些 Scala 代码，并尝试使用朴素贝叶斯。让我们从软件组件的概述开始。
- en: Design
  id: totrans-2030
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计
- en: 'Our implementation of the Naïve Bayes classifier uses the following components:'
  id: totrans-2031
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的朴素贝叶斯分类器使用了以下组件：
- en: A generic model, `NaiveBayesModel`, of the `Model` type that is initialized
    through training during the instantiation of the class.
  id: totrans-2032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Model` 类型的通用模型，`NaiveBayesModel`，在类实例化过程中通过训练初始化。'
- en: A model for the `BinNaiveBayesModel` binomial classification, which subclasses
    `NaiveBayesModel`. The model consists of a pair of positive and negative `Likelihood`
    class instances.
  id: totrans-2033
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BinNaiveBayesModel`二项式分类模型的模型，它是`NaiveBayesModel`的子类。该模型由一对正负`Likelihood`类实例组成。'
- en: A model for the `MultiNaiveBayesModel` multinomial classification.
  id: totrans-2034
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiNaiveBayesModel`多项式分类的模型。'
- en: 'The `NaiveBayes` classifier class has four parameters: a smoothing function,
    such as Laplace and a set of observations of the `XVSeries` type, a set of labels
    of the `DblVector` type, a log density function of the `LogDensity` type, and
    the number of classes.'
  id: totrans-2035
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NaiveBayes`分类器类有四个参数：一个平滑函数，如拉普拉斯，以及一组`XVSeries`类型的观察值，一组`DblVector`类型的标签，一个`LogDensity`类型的对数密度函数，以及类的数量。'
- en: The principle of software architecture applied to the implementation of classifiers
    is described in the *Design template for immutable classifiers* section in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-2036
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于分类器实现的软件架构原则在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")的*不可变分类器设计模板*部分中描述，*基本概念*。
- en: 'The key software components of the Naïve Bayes classifier are described in
    the following UML class diagram:'
  id: totrans-2037
  prefs: []
  type: TYPE_NORMAL
  zh: Naïve Bayes分类器的关键软件组件在以下UML类图中描述：
- en: '![Design](img/image01367.jpeg)'
  id: totrans-2038
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01367.jpeg)'
- en: The UML class diagram for the Naive Bayes classifier
  id: totrans-2039
  prefs: []
  type: TYPE_NORMAL
  zh: Naïve Bayes分类器的UML类图
- en: The UML diagram omits the helper traits or classes such as `Monitor` or Apache
    Commons Math components.
  id: totrans-2040
  prefs: []
  type: TYPE_NORMAL
  zh: UML图省略了`Monitor`或Apache Commons Math组件等辅助特性或类。
- en: Training
  id: totrans-2041
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: 'The objective of the training phase is to build a model consisting of the likelihood
    for each feature and the class prior. The likelihood for a feature is identified
    as follows:'
  id: totrans-2042
  prefs: []
  type: TYPE_NORMAL
  zh: 训练阶段的目标是构建一个模型，该模型由每个特征的似然和类先验组成。一个特征的似然被识别如下：
- en: The number of occurrences *k* of this feature for *N > k* observations in the
    case of binary features or counters
  id: totrans-2043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于二进制特征或计数器，在*N > k*个观察值中此特征的*出现次数*k
- en: The mean value for all the observations for this feature in the case of numeric
    or continuous features
  id: totrans-2044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于数值或连续特征，此特征的所有观察值的平均值
- en: It is assumed, for the sake of this test case, that the features, that is, technical
    analysis indicators, such as price, volume, and volatility are conditionally independent.
    This assumption is not actually correct.
  id: totrans-2045
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个测试案例，假设特征，即技术分析指标，如价格、体积和波动性是条件独立的。这个假设实际上并不正确。
- en: Note
  id: totrans-2046
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Conditional dependency**'
  id: totrans-2047
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件依赖**'
- en: Recent models, known as **Hidden Naïve Bayes** (**HNB**), relax the restrictions
    on the independence between features. The HNB algorithm uses conditional mutual
    information to describe the interdependency between some of the features [5:8].
  id: totrans-2048
  prefs: []
  type: TYPE_NORMAL
  zh: 近期模型，被称为**隐式朴素贝叶斯**（**HNB**），放宽了特征之间独立性的限制。HNB算法使用条件互信息来描述某些特征之间的相互依赖性[5:8]。
- en: Let's write the code to train the binomial and multinomial Naïve Bayes.
  id: totrans-2049
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码来训练二项式和多项式朴素贝叶斯。
- en: Class likelihood
  id: totrans-2050
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 类似然
- en: 'The first step is to define the class likelihood for each feature using historical
    data. The `Likelihood` class has the following attributes (line `1`):'
  id: totrans-2051
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用历史数据为每个特征定义类似然。`Likelihood`类具有以下属性（行`1`）：
- en: The label for the `label` observation
  id: totrans-2052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label`观察值的标签'
- en: An array of tuple Laplace or Lidstone smoothed mean and standard deviation,
    `muSigma`
  id: totrans-2053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元组拉普拉斯或Lidstone平滑均值和标准差的数组，`muSigma`
- en: The prior probability of a `prior` class
  id: totrans-2054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prior`类的先验概率'
- en: 'As with any code snippet presented in this book, the validation of class parameters
    and method arguments are omitted in order to keep the code readable:'
  id: totrans-2055
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中展示的任何代码片段一样，为了保持代码的可读性，省略了类参数和方法参数的验证：
- en: '[PRE170]'
  id: totrans-2056
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: 'The parameterized `Likelihood` class has the following two purposes:'
  id: totrans-2057
  prefs: []
  type: TYPE_NORMAL
  zh: 参数化的`Likelihood`类有两个目的：
- en: 'Define the statistics regarding a class *C[k]*: its label, its mean and standard
    deviation, and the prior probability *p(C[k])*.'
  id: totrans-2058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义关于类*C[k]*的统计信息：其标签、其均值和标准差，以及先验概率*p(C[k])*。
- en: Compute the score of a new observation for its runtime classification (line
    `2`). The computation of the log of the likelihood uses a `logDensity` method
    of the `LogDensity` type (line `3`). As seen in the next section, the log density
    can be either a Gaussian or a Bernoulli distribution. The `score` method uses
    Scala's `zipped` method to merge the observation values with the labeled values
    and implements the **M3** formula (line `4`).
  id: totrans-2059
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算新观察值的分数以进行其运行时分类（第 `2` 行）。计算似然的对数使用 `LogDensity` 类的 `logDensity` 方法（第 `3`
    行）。如下一节所示，对数密度可以是高斯分布或伯努利分布。`score` 方法使用 Scala 的 `zipped` 方法将观察值与标记值合并，并实现了 **M3**
    公式（第 `4` 行）。
- en: The Gaussian mixture is particularly suited for modeling datasets, for which
    the features have large sets of discrete values or are continuous variables. The
    conditional probabilities for the feature *x* is described by the normal probability
    density function [5:9].
  id: totrans-2060
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯混合模型特别适合于建模特征具有大量离散值或连续变量的数据集。特征 *x* 的条件概率由正态概率密度函数 [5:9] 描述。
- en: Note
  id: totrans-2061
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The log likelihood using the Gaussian density**'
  id: totrans-2062
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用高斯密度的对数似然**'
- en: 'M7: For a Lidstone or Laplace smoothed mean *µ''* and a standard deviation
    *σ*, the log likelihood of a posterior probability for a Gaussian distribution
    is defined as:'
  id: totrans-2063
  prefs: []
  type: TYPE_NORMAL
  zh: M7：对于 Lidstone 或 Laplace 平滑的均值 *µ* 和标准差 *σ*，高斯分布的后验概率的对数似然定义为：
- en: '![Class likelihood](img/image01368.jpeg)'
  id: totrans-2064
  prefs: []
  type: TYPE_IMG
  zh: '![类别似然](img/image01368.jpeg)'
- en: 'The log of the Gauss, `logGauss`, and the log of the Normal distribution, `logNormal`,
    are defined in the `stats` class, which was introduced in the *Profiling data*
    section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello
    World!*:'
  id: totrans-2065
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯的对数 `logGauss` 和正态分布的对数 `logNormal` 在 `stats` 类中定义，该类在 [第 2 章](part0165.xhtml#aid-4TBCQ2
    "第 2 章. Hello World!") 的 *数据概要* 节中介绍，*Hello World!*：
- en: '[PRE171]'
  id: totrans-2066
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: The `logNormal` computation is implemented as a partial applied function.
  id: totrans-2067
  prefs: []
  type: TYPE_NORMAL
  zh: '`logNormal` 的计算实现为一个部分应用函数。'
- en: 'The functions of the `LogDensity` type compute the probability density for
    each feature (line `5`):'
  id: totrans-2068
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogDensity` 类的函数计算每个特征的概率密度（第 `5` 行）：'
- en: '[PRE172]'
  id: totrans-2069
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: Binomial model
  id: totrans-2070
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 二项式模型
- en: 'The next step is to define the `BinNaiveBayesModel` model for a two-class classification
    scheme. The two-class model consists of two `Likelihood` instances: `positives`
    for the label UP (value `1`) and `negatives` for the label DOWN (value `0`).'
  id: totrans-2071
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义用于双类分类方案的 `BinNaiveBayesModel` 模型。双类模型由两个 `Likelihood` 实例组成：`positives`
    用于标签 UP（值 `1`）和 `negatives` 用于标签 DOWN（值 `0`）。
- en: 'In order to make the model generic, we created a `NaiveBayesModel` trait that
    can be extended as needed to support both the binomial and multinomial Naïve Bayes
    models, as follows:'
  id: totrans-2072
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使模型通用，我们创建了一个 `NaiveBayesModel` 特质，可以根据需要扩展以支持二项式和多项式朴素贝叶斯模型，如下所示：
- en: '[PRE173]'
  id: totrans-2073
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: The `classify` method uses the trained model to classify a multivariate observation
    `x` of the `Array[T]` type given a `logDensity` probability density function (line
    `5`). The method returns the class the observation belongs to.
  id: totrans-2074
  prefs: []
  type: TYPE_NORMAL
  zh: '`classify` 方法使用训练好的模型对给定 `logDensity` 概率密度函数的 `Array[T]` 类型的多变量观察值 `x` 进行分类（第
    `5` 行）。该方法返回观察值所属的类别。'
- en: 'Let''s start with the definition of the `BinNaiveBayesModel` class that implements
    the binomial Naïve Bayes:'
  id: totrans-2075
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从实现二项式朴素贝叶斯 `BinNaiveBayesModel` 类的定义开始：
- en: '[PRE174]'
  id: totrans-2076
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: 'The constructor for the `BinNaiveBayesModel` class takes two arguments:'
  id: totrans-2077
  prefs: []
  type: TYPE_NORMAL
  zh: '`BinNaiveBayesModel` 类的构造函数接受两个参数：'
- en: '`pos`: Class likelihood for observations with a positive outcome'
  id: totrans-2078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pos`: 正面结果的观察值的类别似然'
- en: '`neg`: Class likelihood for observations with a negative outcome (line `6`)'
  id: totrans-2079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`neg`: 负面结果的观察值的类别似然（第 `6` 行）'
- en: The `classify` method is called by the `|>` operator in the Naïve Bayes classifier.
    It returns `1` if the observation `x` matches the `Likelihood` class that contains
    the positive cases, and `0` otherwise (line `7`).
  id: totrans-2080
  prefs: []
  type: TYPE_NORMAL
  zh: '`classify` 方法在朴素贝叶斯分类器中通过 `|>` 操作符被调用。如果观察值 `x` 与包含正例的 `Likelihood` 类匹配，则返回
    `1`，否则返回 `0`（第 `7` 行）。'
- en: Note
  id: totrans-2081
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Model validation**'
  id: totrans-2082
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型验证**'
- en: The parameters of the Naïve Bayes model (likelihood) are computed through training
    and the `model` value is instantiated regardless of whether the model is actually
    validated in this example. A commercial application would require the model to
    be validated using a methodology such as the K-fold validation and F1 measure,
    as described in the *Design template for immutable classifiers* section in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-2083
  prefs: []
  type: TYPE_NORMAL
  zh: Naïve Bayes模型（似然）的参数通过训练计算得出，无论在此示例中模型是否实际经过验证，`model`值都会实例化。商业应用需要使用如K折验证和F1度量等方法验证模型，如[附录A](part0229.xhtml#aid-6QCGQ2
    "附录A。基本概念")中“不可变分类器设计模板”部分所述，*基本概念*。
- en: The multinomial model
  id: totrans-2084
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多项式模型
- en: 'The multinomial Naïve Bayes model defined by the `MultiNaiveBayesModel` class
    is very similar to the `BinNaiveBayesModel`:'
  id: totrans-2085
  prefs: []
  type: TYPE_NORMAL
  zh: 由`MultiNaiveBayesModel`类定义的多项式朴素贝叶斯模型与`BinNaiveBayesModel`非常相似：
- en: '[PRE175]'
  id: totrans-2086
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: 'The multinomial Naïve Bayes model differs from its binomial counterpart as
    follows:'
  id: totrans-2087
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式朴素贝叶斯模型与其二项式对应模型的不同之处如下：
- en: Its constructor requires a sequence of class likelihood `likelihoodSet` (line
    `8`).
  id: totrans-2088
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其构造函数需要一个类似然序列`likelihoodSet`（第8行）。
- en: The `classify` runtime classification method sorts the class likelihoods by
    their score (posterior probability) using the `<<<` function (line `9`). The method
    returns the ID of the class with the highest log likelihood (line `10`).
  id: totrans-2089
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classify`运行时分类方法使用`<<<`函数按分数（后验概率）对类似然进行排序（第9行）。该方法返回具有最高对数似然值的类ID（第10行）。'
- en: Classifier components
  id: totrans-2090
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类器组件
- en: The Naïve Bayes algorithm is implemented as a data transformation using a model
    implicitly extracted from a training set of the `ITransform` type, as described
    in the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*
  id: totrans-2091
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法作为数据转换实现，使用从`ITransform`类型训练集隐式提取的模型，如[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中“单态数据转换”部分所述，*Hello World!*。
- en: 'The attributes of the multinomial Naïve Bayes are as follows:'
  id: totrans-2092
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式朴素贝叶斯属性如下：
- en: The smoothing formula (Laplace, Lidstone, and so on), `smoothing`
  id: totrans-2093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑公式（拉普拉斯、Lidstone等），`smoothing`
- en: The set of multivariable observations defined as `xt`
  id: totrans-2094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义为`xt`的多变量观测值集合
- en: The expected values (or labels) associated with the set of observations, `expected`
  id: totrans-2095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与一组观测值相关联的期望值（或标签），`expected`
- en: The log of the probability density function, `logDensity`
  id: totrans-2096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率密度函数的对数，`logDensity`
- en: The number of classes—two for the binomial Naïve Bayes with the `BinNaiveBayesModel`
    type or more for the multinomial Naïve Bayes with the `MultiNaiveBayesModel` type
    (line `11`)
  id: totrans-2097
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类的数量——对于二项式朴素贝叶斯和`BinNaiveBayesModel`类型为两个，对于多项式朴素贝叶斯和`MultiNaiveBayesModel`类型则更多（第11行）
- en: 'The code will be as follows:'
  id: totrans-2098
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE176]'
  id: totrans-2099
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: The `Monitor` trait defines miscellaneous logging and display functions.
  id: totrans-2100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Monitor`特质定义了各种日志和显示函数。'
- en: 'Data transformation of the `ITransform` type requires the output type `V` to
    be specified (line `12`). The output of the Naïve Bayes is the index of the class
    an observation belongs to. The `model` type of the model can be either `BinNaiveBayesModel`
    for two classes or `MultiNaiveBayesModel` for a multinomial model (line `13`):'
  id: totrans-2101
  prefs: []
  type: TYPE_NORMAL
  zh: '`ITransform`类型的数据转换需要指定输出类型`V`（第12行）。朴素贝叶斯输出是观测值所属类的索引。模型的`model`类型可以是`BinNaiveBayesModel`（用于两个类）或`MultiNaiveBayesModel`（用于多项式模型）（第13行）：'
- en: '[PRE177]'
  id: totrans-2102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: Note
  id: totrans-2103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Training and class instantiation**'
  id: totrans-2104
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练和类实例化**'
- en: There are several benefits of allowing the instantiation of the Naïve Bayes
    mode only once when it is trained. It prevents the client code from invoking the
    algorithm on an untrained or partially trained model, and it reduces the number
    of states of the model (untrained, partially trained, trained, validated, and
    so on). It is an elegant way to hide the details of the training of the model
    from the user.
  id: totrans-2105
  prefs: []
  type: TYPE_NORMAL
  zh: 允许在训练时仅实例化一次Naïve Bayes模型具有几个优点。它防止客户端代码在未训练或部分训练的模型上调用算法，并减少了模型的状态数量（未训练、部分训练、训练、验证等）。这是一种优雅的方式，将模型训练的细节隐藏给用户。
- en: 'The `train` method is applied to each class. It takes the index or label of
    the class and generates its log likelihood data (line `14`):'
  id: totrans-2106
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法应用于每个类。它接受类的索引或标签，并生成其对数似然数据（第14行）：'
- en: '[PRE178]'
  id: totrans-2107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: The training set is generated by zipping the `xt` vector of observations with
    expected classes, `expected` (line `15`). The method filters out the observation
    for which the label does not correspond to this class (line `16`). The `meanStd`
    pair (mean and standard deviation) is computed using the Lidstone smoothing factor
    (line `17`). Finally, the training method returns the class likelihood corresponding
    to the index `label` (line `18`).
  id: totrans-2108
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集通过将观测的 `xt` 向量与预期类别 `expected` 进行压缩生成（行 `15`）。该方法过滤掉标签与该类别不对应的观测（行 `16`）。使用
    Lidstone 平滑因子计算 `meanStd` 对（均值和标准差）（行 `17`）。最后，训练方法返回与索引 `label` 对应的类别似然（行 `18`）。
- en: The `NaiveBayes` class also defines the `|>` runtime classification method and
    the F[1] validation methods. Both methods are described in the next section.
  id: totrans-2109
  prefs: []
  type: TYPE_NORMAL
  zh: '`NaiveBayes` 类还定义了 `|>` 运行时分类方法和 F[1] 验证方法。这两种方法将在下一节中描述。'
- en: Note
  id: totrans-2110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Handling missing data**'
  id: totrans-2111
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理缺失数据**'
- en: Naïve Bayes has a no-nonsense approach to handling missing data. You just ignore
    the attribute in the observations for which the value is missing. In this case,
    the prior for this particular attribute for these observations is not computed.
    This workaround is obviously made possible because of the conditional independence
    between features.
  id: totrans-2112
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯在处理缺失数据方面采用无废话的方法。你只需忽略观测中值缺失的属性。在这种情况下，这些观测的特定属性的先验不进行计算。这种解决方案显然是由于特征之间的条件独立性而成为可能的。
- en: 'The `apply` constructor for `NaiveBayes` returns the `NaiveBayes` type:'
  id: totrans-2113
  prefs: []
  type: TYPE_NORMAL
  zh: '`NaiveBayes` 的 `apply` 构造函数返回 `NaiveBayes` 类型：'
- en: '[PRE179]'
  id: totrans-2114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: Classification
  id: totrans-2115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: The likelihood and class prior that have been computed through training is used
    for validating the model and classifying new observations.
  id: totrans-2116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过训练计算出的似然和类先验用于验证模型和分类新观测。
- en: The score represents the log of likelihood estimate (or the posterior probability),
    which is computed as the summation of the log of the Gaussian distribution using
    the mean and standard deviation extracted from the training phase and the log
    of the class likelihood.
  id: totrans-2117
  prefs: []
  type: TYPE_NORMAL
  zh: 该分数代表似然估计的对数（或后验概率），它是通过使用从训练阶段提取的均值和标准差计算的高斯分布的对数之和以及类似然的对数。
- en: 'The Naïve Bayes classification using the Gaussian distribution is illustrated
    using the two *C[1]* and *C[2]* classes and a model with two features (*x* and
    *y*):'
  id: totrans-2118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用高斯分布的朴素贝叶斯分类通过两个 *C[1]* 和 *C[2]* 类别以及具有两个特征 (*x* 和 *y*) 的模型进行说明：
- en: '![Classification](img/image01369.jpeg)'
  id: totrans-2119
  prefs: []
  type: TYPE_IMG
  zh: '![分类](img/image01369.jpeg)'
- en: An illustration of the Gaussian Naive Bayes using 2-dimensional model
  id: totrans-2120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二维模型说明高斯朴素贝叶斯
- en: 'The `|>` method returns the partial function that implements the runtime classification
    of a new `x` observation using one of the two Naïve Bayes models. The `model`
    and the `logDensity` functions are used to assign the `x` observation to the appropriate
    class (line `19`):'
  id: totrans-2121
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>` 方法返回部分函数，该函数使用其中一个朴素贝叶斯模型对新的 `x` 观测进行运行时分类。`model` 和 `logDensity` 函数用于将
    `x` 观测分配到适当的类别（行 `19`）：'
- en: '[PRE180]'
  id: totrans-2122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: F1 validation
  id: totrans-2123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F1 验证
- en: 'Finally, the Naïve Bayes classifier is implemented by the `NaiveBayes` class.
    It implements the training and runtime classification using the Naïve Bayes formula.
    In order to force the developer to define a validation for any new supervised
    learning technique, the class inherits from the `Supervised` trait that declares
    the `validate` validation method:'
  id: totrans-2124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，朴素贝叶斯分类器通过 `NaiveBayes` 类实现。它使用朴素贝叶斯公式实现训练和运行时分类。为了强制开发者为任何新的监督学习技术定义验证，该类从声明
    `validate` 验证方法的 `Supervised` 特性继承：
- en: '[PRE181]'
  id: totrans-2125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: The validation of a model applies only to a data transformation of the `ITransform`
    type (line `20`).
  id: totrans-2126
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的验证仅适用于 `ITransform` 类型的数据转换（行 `20`）。
- en: 'The `validate` method takes the following arguments (line `21`):'
  id: totrans-2127
  prefs: []
  type: TYPE_NORMAL
  zh: '`validate` 方法接受以下参数（行 `21`）：'
- en: An `xt` time series of multidimensional observations
  id: totrans-2128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多维观测的 `xt` 时间序列
- en: An `expected` vector of expected class values
  id: totrans-2129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期类值的 `expected` 向量
- en: By default, the `validate` method returns the F[1] score for the model, as described
    in the *Assessing a model* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*
  id: totrans-2130
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`validate` 方法返回模型的 F[1] 分数，如 [第 2 章](part0165.xhtml#aid-4TBCQ2 "第 2 章。Hello
    World!") 中 *评估模型* 一节所述，*Hello World!*
- en: 'Let''s implement the key functionality of the `Supervised` trait for the Naïve
    Bayes classifier:'
  id: totrans-2131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现朴素贝叶斯分类器的 `Supervised` 特性的关键功能：
- en: '[PRE182]'
  id: totrans-2132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: The predictive `predict` partially applied function is created by assigning
    a predicted class to a new `x` observation (line `23`), and then the prediction,
    the index of classes, is loaded into the `MultiFValidation` class to compute the
    F[1] score (line `24`).
  id: totrans-2133
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将预测类别分配给新的`x`观测值（第`23`行），创建预测`predict`部分应用函数，然后将预测和类别的索引加载到`MultiFValidation`类中，以计算F[1]分数（第`24`行）。
- en: Feature extraction
  id: totrans-2134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征提取
- en: The most critical element in the training of a supervised learning algorithm
    is the creation of labeled data. Fortunately, in this case, the labels (or expected
    classes) can be automatically generated. The objective is to predict the direction
    of the price of a stock for the next trading day, taking into account the moving
    average price, volume, and volatility over the last *n* days.
  id: totrans-2135
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习算法训练中最关键的因素是创建标记数据。幸运的是，在这种情况下，标签（或预期类别）可以自动生成。目标是预测下一个交易日股票价格的方向，考虑到过去*n*天的移动平均价格、成交量和波动性。
- en: 'The extraction of features follows these six steps:'
  id: totrans-2136
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取遵循以下六个步骤：
- en: Extract historical trading data of each feature (that is, price, volume, and
    volatility).
  id: totrans-2137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取每个特征的历 史交易数据（即价格、成交量波动性）。
- en: Compute the simple moving average of each feature.
  id: totrans-2138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个特征的简单移动平均。
- en: Compute the difference between the value and moving average of each feature.
  id: totrans-2139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个特征的值和移动平均之间的差异。
- en: Normalize the difference by assigning 1 for positive values and 0 for negative
    values.
  id: totrans-2140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将正值赋值为1，负值赋值为0来归一化差异。
- en: Generate a time series of the difference between the closing price of the stock
    and the closing price of the previous trading session.
  id: totrans-2141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成股票收盘价与前一交易日收盘价之间的差异的时间序列。
- en: Normalize the difference by assigning 1 for positive values and 0 for negative
    values.
  id: totrans-2142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将正值赋值为1，负值赋值为0来归一化差异。
- en: 'The following diagram illustrates the feature extractions for steps 1 to 4:'
  id: totrans-2143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了步骤1到4的特征提取：
- en: '![Feature extraction](img/image01370.jpeg)'
  id: totrans-2144
  prefs: []
  type: TYPE_IMG
  zh: '![特征提取](img/image01370.jpeg)'
- en: Binary quantization of the difference value—moving average
  id: totrans-2145
  prefs: []
  type: TYPE_NORMAL
  zh: 差异值的二进制量化——移动平均
- en: The first step is to extract the average price, volume, and volatility (that
    is, *1 – low/high*) for each stock during the period of Jan 1, 2000 and Dec 31,
    2014 with daily and weekly closing prices. Let's use the simple moving average
    to compute these averages for the *[t-n, t]*window.
  id: totrans-2146
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是提取每个股票在2000年1月1日至2014年12月31日期间的平均价格、成交量波动性（即*1 – 低/高*），使用每日和每周收盘价。让我们使用简单移动平均来计算*[t-n,
    t]*窗口的平均值。
- en: 'The `extractor` variable defines the list of features to extract from the financial
    data source, as described in the *Data extraction* and *Data sources* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*:'
  id: totrans-2147
  prefs: []
  type: TYPE_NORMAL
  zh: '`extractor`变量定义了从金融数据源中提取的特征列表，如[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中*数据提取*和*数据源*部分所述，*基本概念*：'
- en: '[PRE183]'
  id: totrans-2148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: The naming convention for the trading data and metrics is described in the *Trading
    data* section under *Technical analysis* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-2149
  prefs: []
  type: TYPE_NORMAL
  zh: 交易数据和度量名称约定在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中*技术分析*下的*交易数据*部分描述，*基本概念*。
- en: 'The training and validation of the binomial Naïve Bayes is implemented using
    a monadic composition:'
  id: totrans-2150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单子组合实现二项朴素贝叶斯的训练和验证：
- en: '[PRE184]'
  id: totrans-2151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: The first step is to distribute the observations between the training set and
    validation set. The `trainRatio` value (line `25`) defines the ratio of the original
    observation set to be included in the training set. The simple moving average
    values are generated by the `pfnMv` partial function (line `26`). The extracting
    `pfnSrc` partial function (line `27`) is used to generate the three trading time
    series, price, volatility, and volume (line `28`).
  id: totrans-2152
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将观测值分布在训练集和验证集之间。`trainRatio`值（第`25`行）定义了要包含在训练集中的原始观测集的比例。简单移动平均值由`pfnMv`部分函数（第`26`行）生成。用于生成三个交易时间序列（价格、波动性和成交量）的提取`pfnSrc`部分函数（第`27`行）。
- en: 'The next step consists of applying the `pfnMv` simple moving average to the
    `obs` multidimensional time series (line `29`) using the `computeRatios` method:'
  id: totrans-2153
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是应用`pfnMv`简单移动平均到`obs`多维时间序列（第`29`行），使用`computeRatios`方法：
- en: '[PRE185]'
  id: totrans-2154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: The `computeDeltas` method computes the time series of the `sm` observations
    smoothed with a simple moving average (line `35`). The method generates a time
    series of 0 and 1 for each of the three features in the `xs` observation set and
    `sm` smoothed dataset (line `36`).
  id: totrans-2155
  prefs: []
  type: TYPE_NORMAL
  zh: '`computeDeltas`方法计算了使用简单移动平均平滑的`sm`观察值的时序（第35行）。该方法为`xs`观察集和`sm`平滑数据集中的每个三个特征生成一个0和1的时序（第36行）。'
- en: 'Next, the call to the `difference` differential computation generates the labels
    (0 and 1) representing the change in the direction of the price of a security
    between two consecutive trading sessions: 0 if the price is decreased and 1 if
    the price is increased (line `30`) (refer to the *The differential operator* section
    under *Time series in Scala* in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing*).'
  id: totrans-2156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，调用`difference`微分计算生成标签（0和1），代表在连续两个交易日之间证券价格的变动方向：如果价格下降则为0，如果价格上升则为1（第30行）（参考[第3章](part0172.xhtml#aid-5410O2
    "第3章。数据预处理")中*Scala中的时间序列*部分的*微分算子*，*数据预处理*）。
- en: The features for the training of the Naïve Bayes model are extracted from these
    ratios by transposing the ratios-time series matrix in the `transpose` method
    of the `XTSeries` singleton (line `31`).
  id: totrans-2157
  prefs: []
  type: TYPE_NORMAL
  zh: Naïve Bayes模型的训练特征是从这些比率中提取的，通过在`XTSeries`单例的`transpose`方法中转置比率-时间序列矩阵（第31行）。
- en: Next, the training set and validation set are extracted from the `features`
    set using the `OneFoldXValidation` class, which was introduced in the *One-fold
    cross validation* section under *Cross-validation* in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!* (line `32`).
  id: totrans-2158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用`OneFoldXValidation`类从`features`集中提取训练集和验证集，该类在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中*交叉验证*部分的*单折交叉验证*中介绍，*Hello World!*（第32行）。
- en: Note
  id: totrans-2159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Selecting the training data**'
  id: totrans-2160
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择训练数据**'
- en: In our example, the training set is simplistically the first `trainRatio` multiplied
    by the size of dataset observations. Practical applications use a K-fold cross-validation
    technique to validate models, as described in the *K-fold cross validation* section
    under *Assessing a model* in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*. A simpler alternative is to create the training set
    by picking observations randomly and using the remaining data for validation.
  id: totrans-2161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，训练集是简单地第一个`trainRatio`乘以数据集观察的大小。实际应用使用K折交叉验证技术来验证模型，如[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中*评估模型*部分的*K折交叉验证*中所述，*Hello World!*。一个更简单的替代方案是通过随机选择观察值来创建训练集，并使用剩余的数据进行验证。
- en: The last two stages in the workflow consists of training the Naïve Bayes model
    by instantiating the `NaiveBayes` class (line `33`) and computing the F[1] score
    for different values of the smoothing coefficient of the simple moving average
    applied to the stock price, volatility, and volume (line `34`).
  id: totrans-2162
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程的最后两个阶段包括通过实例化`NaiveBayes`类（第33行）并计算应用于股票价格、波动性和成交量的简单移动平均平滑系数的不同值的F[1]分数来训练Naive
    Bayes模型（第34行）。
- en: Note
  id: totrans-2163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**The implicit conversion**'
  id: totrans-2164
  prefs: []
  type: TYPE_NORMAL
  zh: '**隐式转换**'
- en: 'The `NaiveBayes` class operates on elements of the `Int` and `Double` types,
    and therefore, assumes that there is conversion between `Int` and `Double` (view
    bounded). The Scala compiler may generate a warning because the conversion from
    `Int` to `Double` has not been defined. Although Scala relies on its own conversion
    functions, I would recommend that you explicitly define and control your conversion
    function:'
  id: totrans-2165
  prefs: []
  type: TYPE_NORMAL
  zh: '`NaiveBayes`类操作`Int`和`Double`类型的元素，因此假设存在`Int`和`Double`之间的转换（查看有界）。Scala编译器可能会生成警告，因为`Int`到`Double`的转换尚未定义。尽管Scala依赖于其自己的转换函数，但我建议您显式定义并控制您的转换函数：'
- en: '[PRE186]'
  id: totrans-2166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: Testing
  id: totrans-2167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试
- en: 'The next chart plots the value of the F[1] measure of the predictor of the
    direction of the IBM stock using price, volume, and volatility over the previous
    *n* trading days, with *n* varying from 1 to 12 trading days:'
  id: totrans-2168
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表绘制了使用价格、成交量波动以及过去 *n* 个交易日的数据，来预测IBM股票方向的预测器F[1]值的图表，其中 *n* 的范围从1到12个交易日：
- en: '![Testing](img/image01371.jpeg)'
  id: totrans-2169
  prefs: []
  type: TYPE_IMG
  zh: '![测试](img/image01371.jpeg)'
- en: A graph of the F1-measure for the validation of the Naive Bayes model
  id: totrans-2170
  prefs: []
  type: TYPE_NORMAL
  zh: Naive Bayes模型的验证F1度量图
- en: The preceding chart illustrates the impact of the value of the averaging period
    (number of trading days) on the quality of the multinomial Naïve Bayes prediction,
    using the value of the stock price, volatility, and volume relative to their average
    over the averaging period.
  id: totrans-2171
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表说明了平均周期（交易天数）的值对多项式朴素贝叶斯预测质量的影响，使用的是股票价格、波动性和成交量相对于平均周期的值。
- en: 'From this experiment, we conclude the following:'
  id: totrans-2172
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个实验中，我们得出以下结论：
- en: The prediction of the stock movement using the average price, volume, and volatility
    is not very good. The F[1] score for the models using weekly (with respect to
    daily) closing prices varies between 0.68 and 0.74 (with respect to 0.56 and 0.66).
  id: totrans-2173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用平均价格、成交量波动预测股票走势并不很好。使用每周（相对于每日）收盘价的模型F[1]分数在0.68到0.74之间变化（相对于0.56和0.66）。
- en: The prediction using weekly closing prices is more accurate than the prediction
    using the daily closing prices. In this particular example, the distribution of
    the weekly closing prices is more reflective of an intermediate term trend than
    the distribution of daily prices.
  id: totrans-2174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用每周收盘价进行的预测比使用每日收盘价进行的预测更准确。在这个特定的例子中，每周收盘价的分布比每日价格的分布更能反映中期趋势。
- en: The prediction is somewhat independent of the period used to average the features.
  id: totrans-2175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测与用于平均特征的周期多少有些独立。
- en: The Multivariate Bernoulli classification
  id: totrans-2176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多变量伯努利分类
- en: The previous example uses the Gaussian distribution for features that are essentially
    binary (*UP = 1* and *DOWN = 0*) to represent the change in value. The mean value
    is computed as the ratio of the number of observations for which *x[i] = UP* over
    the total number of observations.
  id: totrans-2177
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子使用高斯分布来表示本质上为二元的特征（*UP = 1*和*DOWN = 0*），以表示价值的变动。均值计算为*x[i] = UP*的观察次数与总观察次数的比率。
- en: As stated in the first section, the Gaussian distribution is more appropriate
    for either continuous features or binary features for very large labeled datasets.
    The example is the perfect candidate for the **Bernoulli** model.
  id: totrans-2178
  prefs: []
  type: TYPE_NORMAL
  zh: 如第一部分所述，高斯分布对于非常大的标记数据集的连续特征或二元特征更为合适。该示例是**伯努利**模型的理想候选。
- en: Model
  id: totrans-2179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: The Bernoulli model differs from the Naïve Bayes classifier in such a way that
    it penalizes the feature *x* that does not have any observation; the Naïve Bayes
    classifier ignores it [5:10].
  id: totrans-2180
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利模型与朴素贝叶斯分类器不同，它对没有观察到的特征*x*进行惩罚；朴素贝叶斯分类器忽略它[5:10]。
- en: Note
  id: totrans-2181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The Bernoulli mixture model**'
  id: totrans-2182
  prefs: []
  type: TYPE_NORMAL
  zh: '**伯努利混合模型**'
- en: 'M8: For a feature function *f[k]* with *f[k]* *= 1*, if the feature is observed,
    and a value of 0 otherwise, and the probability *p* of the observed feature *x[k]*
    belongs to the class *C[j]*, then the posterior probability is computed as follows:'
  id: totrans-2183
  prefs: []
  type: TYPE_NORMAL
  zh: M8：对于特征函数*f[k]*，当*f[k]*等于1时，如果特征被观察到，否则为0，观察到特征*x[k]*属于类别*C[j]*的概率*p*，后验概率计算如下：
- en: '![Model](img/image01372.jpeg)'
  id: totrans-2184
  prefs: []
  type: TYPE_IMG
  zh: '![模型](img/image01372.jpeg)'
- en: Implementation
  id: totrans-2185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: 'The implementation of the Bernoulli model consists of modifying the `score`
    function in the `Likelihood` class using the Bernoulli density method, `bernoulli`,
    defined in the `Stats` object:'
  id: totrans-2186
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利模型的实现包括在`Likelihood`类中使用伯努利密度方法`bernoulli`修改`score`函数，该方法定义在`Stats`对象中：
- en: '[PRE187]'
  id: totrans-2187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE187]'
- en: The first version of the Bernoulli algorithm is the direct implementation of
    the **M8** mathematical formula. The second version uses the signature of the
    `Density (Double*) => Double` type.
  id: totrans-2188
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利算法的第一个版本是直接实现**M8**数学公式。第二个版本使用`Density (Double*) => Double`类型的签名。
- en: The mean value is the same as in the Gaussian density function. The binary feature
    is implemented as an `Int` type with the value *UP = 1* (with respect to *DOWN
    = 0*) for the upward (with respect to downward) direction of the financial technical
    indicator.
  id: totrans-2189
  prefs: []
  type: TYPE_NORMAL
  zh: 均值与高斯密度函数中的相同。二元特征以`Int`类型实现，值为*UP = 1*（相对于*DOWN = 0*），表示向上（相对于向下）的金融技术指标方向。
- en: Naïve Bayes and text mining
  id: totrans-2190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯与文本挖掘
- en: 'The multinomial Naïve Bayes classifier is particularly suited for **text mining**.
    The Naïve Bayes formula is quite effective to classify the following entities:'
  id: totrans-2191
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式朴素贝叶斯分类器特别适合于**文本挖掘**。朴素贝叶斯公式在分类以下实体时非常有效：
- en: E-mail spams
  id: totrans-2192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子邮件垃圾邮件
- en: Business news stories
  id: totrans-2193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业新闻故事
- en: Movie reviews
  id: totrans-2194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影评论
- en: Technical papers as per field of expertise
  id: totrans-2195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按专业领域划分的技术论文
- en: 'This third use case consists of predicting the direction of a stock given the
    financial news. There are two type of news that affect the stock of a particular
    company:'
  id: totrans-2196
  prefs: []
  type: TYPE_NORMAL
  zh: 这第三个用例包括根据财务新闻预测股票的方向。有两种类型的新闻会影响特定公司的股票：
- en: '**Macro trends**: Economic or social news such as conflicts, economic trends,
    or labor market statistics'
  id: totrans-2197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宏观趋势**：如冲突、经济趋势或劳动力市场统计等经济或社会新闻'
- en: '**Micro updates**: Financial or market news related to a specific company such
    as earnings, change in ownership, or press releases'
  id: totrans-2198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微观更新**：与特定公司相关的财务或市场新闻，如收益、所有权变更或新闻稿'
- en: Macroeconomic news related to a specific company have the potential to affect
    the sentiments of investors toward the company and may lead to a sudden shift
    in the price of its stock. Another important feature is the average time it takes
    for investors to react to the news and affect the price of the stock.
  id: totrans-2199
  prefs: []
  type: TYPE_NORMAL
  zh: 与特定公司相关的宏观经济新闻有可能影响投资者对公司的情绪，并可能导致其股价突然变动。另一个重要特征是投资者对新闻做出反应并影响股价的平均时间。
- en: Long-term investors may react within days or even weeks
  id: totrans-2200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长期投资者可能在几天或几周内做出反应
- en: Short-term traders adjust their positions within hours, sometimes within the
    same trading session
  id: totrans-2201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 短期交易者会在几小时内调整他们的头寸，有时甚至在同一交易时段内
- en: 'The average time the market takes to react to a significant financial news
    on a company is illustrated in the following chart:'
  id: totrans-2202
  prefs: []
  type: TYPE_NORMAL
  zh: 市场对一家公司重大财务新闻的平均反应时间在以下图表中展示：
- en: '![Naïve Bayes and text mining](img/image01373.jpeg)'
  id: totrans-2203
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯和文本挖掘](img/image01373.jpeg)'
- en: An illustration of the reaction of investors on the price of a stock following
    a news release
  id: totrans-2204
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻发布后投资者对股票价格的反应示意图
- en: 'The delay in the market response is a relevant feature only if the variance
    of the response time is significant. The distribution of the frequencies of the
    delay in the market response to any newsworthy articles regarding TSLA is fairly
    constant. It shows that the stock prices react within the same day in 82 percent
    of the cases, as seen in the following bar chart:'
  id: totrans-2205
  prefs: []
  type: TYPE_NORMAL
  zh: 市场反应的延迟只有在反应时间的方差显著时才是一个相关特征。对于任何有关TSLA的新闻文章，市场反应延迟的频率分布相当恒定。这表明在82%的情况下，股价在同一天内做出反应，如下面的条形图所示：
- en: '![Naïve Bayes and text mining](img/image01374.jpeg)'
  id: totrans-2206
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯和文本挖掘](img/image01374.jpeg)'
- en: The distribution of the frequencies of the reaction of investors on the price
    of a stock following a news release
  id: totrans-2207
  prefs: []
  type: TYPE_NORMAL
  zh: 投资者对股票价格的反应频率分布，在新闻发布后
- en: The frequency peak for a market response delay of 1.75 days can be explained
    by the fact that some news are released over the weekend and investors have to
    wait until the following Monday to drive the stock price higher or lower. Another
    challenge is to assign any shift of a stock price to a specific news release,
    taking into account that some news can be redundant, confusing, or simultaneous.
  id: totrans-2208
  prefs: []
  type: TYPE_NORMAL
  zh: 市场反应延迟1.75天的频率峰值可以解释为，有些新闻在周末发布，投资者必须等到下周一才能推动股价上涨或下跌。另一个挑战是在考虑某些新闻可能重复、混淆或同时发生的情况下，将任何股价变动归因于特定的新闻发布。
- en: Therefore, the model features for predicting the stock price *pr[t+1]* are the
    relative frequency *f[i]* of an occurrence of a term *T[i]* within a time window
    *[t-n, t]*, where *t* and *n* are trading days.
  id: totrans-2209
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，预测股票价格 *pr[t+1]* 的模型特征是某个术语 *T[i]* 在时间窗口 *[t-n, t]* 内出现的相对频率 *f[i]*，其中 *t*
    和 *n* 是交易日。
- en: 'The following graphical model formally describes the causal relation or conditional
    dependency of the relative change of the stock price between two consecutive trading
    sessions *t* and *t + 1*, given the relative frequency of appearance of some key
    terms in the media:'
  id: totrans-2210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图形模型正式描述了两个连续交易日 *t* 和 *t + 1* 之间股票价格相对变化的因果关系或条件依赖性，给定媒体中某些关键术语出现的相对频率：
- en: '![Naïve Bayes and text mining](img/image01375.jpeg)'
  id: totrans-2211
  prefs: []
  type: TYPE_IMG
  zh: '![朴素贝叶斯和文本挖掘](img/image01375.jpeg)'
- en: The Bayesian model for the prediction of the stock movement given financial
    news
  id: totrans-2212
  prefs: []
  type: TYPE_NORMAL
  zh: 根据财务新闻预测股票走势的贝叶斯模型
- en: For this exercise, the observation sets are the corpus of news feeds and articles
    released by the most prominent financial news organizations, such as Bloomberg
    or CNBC. The first step is to devise a methodology to extract and select the most
    relevant terms associated with a specific stock.
  id: totrans-2213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，观测集是最著名的金融新闻机构发布的新闻和文章的语料库，例如彭博社或CNBC。第一步是制定一种方法来提取和选择与特定股票相关的最相关术语。
- en: Basics of information retrieval
  id: totrans-2214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信息检索基础
- en: 'A full discussion of information retrieval and text mining is beyond the scope
    of this book [5:11]. For the sake of simplicity, the model will rely on a very
    simple scheme for extracting relevant terms and computing their relative frequency.
    The following 10-step sequence of actions describe one of the numerous methodologies
    used to extract the most relevant terms from a corpus:'
  id: totrans-2215
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索和文本挖掘的全面讨论超出了本书的范围 [5:11]。为了简化，模型将依赖于一个非常简单的方案来提取相关术语并计算它们的相对频率。以下 10 个步骤的序列描述了从语料库中提取最相关术语的多种方法之一：
- en: Create or extract the timestamp for each news article.
  id: totrans-2216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每篇新闻文章创建或提取时间戳。
- en: Extract the title, paragraph, and sentences of each article using a Markovian
    classifier.
  id: totrans-2217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用马尔可夫分类器提取每篇文章的标题、段落和句子。
- en: Extract the terms from each sentence using regular expressions.
  id: totrans-2218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用正则表达式从每个句子中提取术语。
- en: Correct terms for typos using a dictionary and metric such as the **Levenstein**
    distance.
  id: totrans-2219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用字典和度量标准（如 **Levenstein** 距离）更正错别字。
- en: Remove the nonstop words.
  id: totrans-2220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除停用词。
- en: Perform **stemming** and **lemmatization**.
  id: totrans-2221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行 **词干提取** 和 **词形还原**。
- en: Extract bags of words and generate a list of **n-grams** (as a sequence of *n*
    terms).
  id: totrans-2222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取词袋并生成 **n-gram**（*n* 个术语的序列）列表。
- en: Apply a **tagging model** build using a maximum entropy or conditional random
    field to extract nouns and adjectives (for example, *NN*, *NNP*, and so on).
  id: totrans-2223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用使用最大熵或条件随机字段构建的 **标记模型** 来提取名词和形容词（例如，*NN*，*NNP* 等）。
- en: Match the terms against a dictionary that supports senses, hyponyms, and synonyms,
    such as **WordNet**.
  id: totrans-2224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将术语与支持词义、下位词和同义词的字典相匹配，例如 **WordNet**。
- en: Disambiguate word sense using Wikipedia's repository **DBpedia** [5:12].
  id: totrans-2225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用维基百科的存储库 **DBpedia** [5:12] 来消除词义歧义。
- en: Note
  id: totrans-2226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Text extraction from the Web**'
  id: totrans-2227
  prefs: []
  type: TYPE_NORMAL
  zh: '**从网络中提取文本**'
- en: The methodology discussed in this section does not include the process of searching
    and extracting news and articles from the Web that requires additional steps such
    as search, crawling, and scraping [5:13].
  id: totrans-2228
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论的方法不包括从网络中搜索和提取新闻和文章的过程，这需要额外的步骤，如搜索、爬取和抓取 [5:13]。
- en: Implementation
  id: totrans-2229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: 'Let''s apply the text mining methodology template to predict the direction
    of a stock, given the financial news. The algorithm relies on a sequence of seven
    simple steps:'
  id: totrans-2230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将文本挖掘方法论模板应用于预测基于金融新闻的股票走势。该算法依赖于一系列七个简单的步骤：
- en: Searching and loading the news articles related to a given company and its stock
    as a *Ɗ[t]* document of the `Document` type.
  id: totrans-2231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索和加载与给定公司和其股票相关的新闻文章，作为 `Document` 类的 *Ɗ[t]* 文档。
- en: 'Extracting the `date: T` timestamp of the article using a regular expression.'
  id: totrans-2232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用正则表达式提取文章的 `date: T` 时间戳。'
- en: Ordering the *Ɗ[t]* documents as per the timestamp.
  id: totrans-2233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按时间戳对 *Ɗ[t]* 文档进行排序。
- en: Extracting the *{T[i,D]}* terms from the content of each *Ɗ**t* document.
  id: totrans-2234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每个 *Ɗ**t* 文档的内容中提取 *{T[i,D]}* 项。
- en: Aggregating the *{T[t,D]}* terms for all the *Ɗ[t]* documents that share the
    same publication date *t*.
  id: totrans-2235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚合所有具有相同发布日期 *t* 的 *Ɗ[t]* 文档的 *{T[t,D]}* 项。
- en: Computing the *rtf* relative frequency of each *{T[i,D]}* term for the date
    *t*, as the ratio of number of its occurrences in all the articles released at
    *t* to the total number of its occurrences of the term in the entire corpus.
  id: totrans-2236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个 *{T[i,D]}* 项在日期 *t* 上的 *rtf* 相对频率，即其在所有在 *t* 日期发布的文章中出现的次数与整个语料库中该术语出现总次数的比率。
- en: Normalizing the relative frequency for the average number of articles per date,
    *nrtf*.
  id: totrans-2237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相对频率标准化为平均每天文章数，*nrtf*。
- en: Note
  id: totrans-2238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Text analysis metrics**'
  id: totrans-2239
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本分析指标**'
- en: 'M9: The relative frequency of occurrences for term (or keyword) *t[i]* with
    *n[i]^a* occurrences in the article *a* is defined as follows:'
  id: totrans-2240
  prefs: []
  type: TYPE_NORMAL
  zh: M9：在文章 *a* 中，术语（或关键词）*t[i]* 的相对频率定义为 *n[i]^a* 次出现与文章中所有术语出现的总次数的比率。
- en: '![Implementation](img/image01376.jpeg)'
  id: totrans-2241
  prefs: []
  type: TYPE_IMG
  zh: '![实现](img/image01376.jpeg)'
- en: 'M10: The relative frequency of occurrences of a term *t[i]* normalized by the
    daily average number of articles for which *N[a]* is the total number of articles
    and *N[d]* is the number of days in the survey is defined as follows:'
  id: totrans-2242
  prefs: []
  type: TYPE_NORMAL
  zh: M10：术语 *t[i]* 的出现频率相对于每天平均文章数进行归一化，其中 *N[a]* 是文章总数，*N[d]* 是调查的天数，其定义为以下：
- en: '![Implementation](img/image01377.jpeg)'
  id: totrans-2243
  prefs: []
  type: TYPE_IMG
  zh: '![实现](img/image01377.jpeg)'
- en: 'The news articles are *minimalist* documents with a timestamp, title, and content,
    as implemented by the `Document` class:'
  id: totrans-2244
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻文章是具有时间戳、标题和内容的 *极简主义* 文档，由 `Document` 类实现：
- en: '[PRE188]'
  id: totrans-2245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: The `date` timestamp has a type bounded to the `Long` type, so `T` can be converted
    to the current time in milliseconds of the JVM (line `1`).
  id: totrans-2246
  prefs: []
  type: TYPE_NORMAL
  zh: '`date`时间戳的类型限制为`Long`类型，因此`T`可以转换为JVM的当前时间（行`1`）的毫秒数。'
- en: Analyzing documents
  id: totrans-2247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析文档
- en: This section is dedicated to the implementation of the simple text analyzer.
    Its purpose is to convert a set of documents of the `Document` type; in our case,
    news articles, into a distribution of relative frequencies of keywords.
  id: totrans-2248
  prefs: []
  type: TYPE_NORMAL
  zh: 本节专门用于实现简单的文本分析器。其目的是将一组`Document`类型的文档；在我们的案例中，是新闻文章，转换为关键词的相对频率分布。
- en: The `TextAnalyzer` class implements a data transformation of the `ETransform`
    type, as described in the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*. It transforms a sequence of documents
    into a sequence of relative frequency distribution.
  id: totrans-2249
  prefs: []
  type: TYPE_NORMAL
  zh: '`TextAnalyzer`类实现了`ETransform`类型的数据转换，如第2章中*单调数据转换*部分所述，*Hello World!*。它将文档序列转换为相对频率分布序列。'
- en: 'The `TextAnalyzer` class has the following two arguments (line `4`):'
  id: totrans-2250
  prefs: []
  type: TYPE_NORMAL
  zh: '`TextAnalyzer`类有以下两个参数（行`4`）：'
- en: A simple text parser, `parser`, that extracts an array of keywords from the
    title and content of each news articles (line `2`).
  id: totrans-2251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个简单的文本解析器`parser`，从每篇新闻文章的标题和内容中提取关键词数组（行`2`）。
- en: A `lexicon` type that lists keywords used in monitoring news related to a company
    and their synonyms. The synonyms or terms that are semantically similar to each
    keywords are defined in an immutable map.
  id: totrans-2252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`lexicon`类型，列出了用于监控与公司相关的新闻及其同义词的关键词。与每个关键词语义相似的同义词或术语定义在一个不可变映射中。
- en: 'The code will be as follows:'
  id: totrans-2253
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将如下所示：
- en: '[PRE189]'
  id: totrans-2254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: The `U` type of an input into the data transformation `|>` is the corpus or
    sequence of news articles (line `5`). The `V` type of the output from the data
    transformation is the sequence of relative frequency distribution of the `TermsRF`
    type (line `6`).
  id: totrans-2255
  prefs: []
  type: TYPE_NORMAL
  zh: 输入到数据转换`|>`中的`U`类型是语料库或新闻文章的序列（行`5`）。数据转换输出的`V`类型是`TermsRF`类型的相对频率分布序列（行`6`）。
- en: The `score` private method does the heavy lifting for the class (line `7`).
    The `quantize` method creates a homogenous set of observed features (line `8`)
    and the `count` method counts the number of occurrences of terms or keywords across
    the documents or news articles that share the same publication date (line `9`).
  id: totrans-2256
  prefs: []
  type: TYPE_NORMAL
  zh: '`score`私有方法为类执行繁重的工作（行`7`）。`quantize`方法创建一个同质化的观察特征集（行`8`），而`count`方法计算具有相同发布日期的文档或新闻文章中术语或关键词的出现次数（行`9`）。'
- en: 'The following diagram describes the different components of the text mining
    process:'
  id: totrans-2257
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图描述了文本挖掘过程的不同组件：
- en: '![Analyzing documents](img/image01378.jpeg)'
  id: totrans-2258
  prefs: []
  type: TYPE_IMG
  zh: '![分析文档](img/image01378.jpeg)'
- en: An illustration of the components of the text mining procedure
  id: totrans-2259
  prefs: []
  type: TYPE_NORMAL
  zh: 文本挖掘过程组件的说明
- en: Extracting the frequency of relative terms
  id: totrans-2260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提取相对术语的频率
- en: 'Let''s dive into the `score` method:'
  id: totrans-2261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解`score`方法：
- en: '[PRE190]'
  id: totrans-2262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: 'The first step in the execution of the `score` method is the computation of
    the number of occurrences of keywords of the `lexicon` type on each of the document/news
    article (line `10`). The computation of the number of occurrences is implemented
    by the `count` method:'
  id: totrans-2263
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`score`方法的第一个步骤是计算每个文档/新闻文章中`lexicon`类型关键词的出现次数（行`10`）。出现次数的计算是通过`count`方法实现的：
- en: '[PRE191]'
  id: totrans-2264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: The method relies on the term `Counter` counting class that subclasses `mutable.Map[String,
    Int]`, as described in the *Counter* section under *Scala programming* in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*.
    It uses a fold to update the count for each of the terms associated with a keyword
    (line `16`). The `count` term for the entire corpus is computed by aggregating
    the terms count for all the documents (line `11`).
  id: totrans-2265
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法依赖于`Counter`计数类，它继承自`mutable.Map[String, Int]`，如附录A中*Scala编程*下的*Counter*部分所述，*基本概念*。它使用折叠来更新与关键词相关的每个术语的计数（行`16`）。整个语料库的`count`术语是通过聚合所有文档的术语计数来计算的（行`11`）。
- en: The next step consists of aggregating the count of the keywords across the document
    for each timestamp. A `termsCountMap` map with the date as the key and keywords
    counter, as values are generated by invoking the `groupBy` higher-order method
    (line `11`). Next, the `score` method extracts a sorted sequence of keywords counts,
    `termsCountPerDate` (line `12`). The total counts for each keyword over the `allTermsCounts`
    entire corpus (line `13`) is used to compute the relative or normalized keywords
    frequencies (formulas **M9** and **M10**) (line `14`).
  id: totrans-2266
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是对每个时间戳在整个文档中关键词的计数进行汇总。通过调用`groupBy`高阶方法（第11行）生成以日期为键、关键词计数器为值的`termsCountMap`映射。接下来，`score`方法提取关键词计数的排序序列，`termsCountPerDate`（第12行）。使用整个语料库`allTermsCounts`中每个关键词的总计数来计算相对或归一化的关键词频率（公式**M9**和**M10**）（第14行）。
- en: Generating the features
  id: totrans-2267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成特征
- en: 'There is no guarantee that all the news articles associated with a specific
    publication date are used in the model. The `quantize` method assigns a relative
    frequency of **0.0** for keywords that are missing from the news articles, as
    illustrated in the following table:'
  id: totrans-2268
  prefs: []
  type: TYPE_NORMAL
  zh: 没有保证所有与特定出版日期相关的新闻文章都被用于模型中。`quantize`方法为缺失的新闻文章中的关键词分配相对频率**0.0**，如下表所示：
- en: '![Generating the features](img/image01379.jpeg)'
  id: totrans-2269
  prefs: []
  type: TYPE_IMG
  zh: '![生成特征](img/image01379.jpeg)'
- en: A table on relative frequencies of keywords as per the publishing date
  id: totrans-2270
  prefs: []
  type: TYPE_NORMAL
  zh: 按出版日期列出的关键词相对频率表
- en: 'The `quantize` method transforms a sequence of term-relative frequencies into
    a pair keywords and observations:'
  id: totrans-2271
  prefs: []
  type: TYPE_NORMAL
  zh: '`quantize`方法将术语相对频率序列转换为关键词和观察值的对：'
- en: '[PRE192]'
  id: totrans-2272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: The `quantize` method extracts an array of keywords from the lexicon (line `15`).
    The `relFrequencies` vector of features is generated by assigning the relative
    `0.0` keyword frequency for keywords that are not detected across the news articles
    published at a specific date (line `16`). Finally, the key-value pair (keywords
    and relative keyword frequency) (line 17).
  id: totrans-2273
  prefs: []
  type: TYPE_NORMAL
  zh: '`quantize`方法从词典中提取关键词数组（第15行）。通过为在特定日期发布的新闻文章中未检测到的关键词分配相对`0.0`关键词频率，生成特征向量`relFrequencies`（第16行）。最后，在行17中生成（关键词和相对关键词频率）键值对。'
- en: Note
  id: totrans-2274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Sparse relative frequencies vector**'
  id: totrans-2275
  prefs: []
  type: TYPE_NORMAL
  zh: '**稀疏相对频率向量**'
- en: Text analysis and natural language processing deals with very large feature
    sets, with potentially hundreds of thousands of features or keywords. Such computations
    would be almost intractable if it was not for the fact that the vast majority
    of keywords are not present in each document. It is a common practice to use sparse
    vectors and sparse matrices to reduce the memory consumption during training.
  id: totrans-2276
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分析和自然语言处理处理非常大的特征集，可能有数十万个特征或关键词。如果不是因为大多数关键词在每个文档中都不存在，这样的计算几乎是不可能的。使用稀疏向量和稀疏矩阵来减少训练期间的内存消耗是一种常见的做法。
- en: Testing
  id: totrans-2277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: For testing purpose, let's select the news articles that mention Tesla Motors
    and its ticker symbol TSLA over a period of 2 months.
  id: totrans-2278
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试目的，让我们选择在2个月期间提及特斯拉汽车及其股票代码TSLA的新闻文章。
- en: Retrieving the textual information
  id: totrans-2279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取文本信息
- en: 'Let''s start implementing and defining the two components of `TextAnalyzer`:
    the `parsing` function and the `lexicon` variable:'
  id: totrans-2280
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从实现和定义`TextAnalyzer`的两个组件开始：`parsing`函数和`lexicon`变量：
- en: '[PRE193]'
  id: totrans-2281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: The lexicon is loaded from a file (line `18`). The `parse` method uses a simple
    `regExpr` regular expression to replace any punctuation into a space character
    (line `19`), which is used as a word delimiter (line `20`). All the words shorter
    than three characters are discounted (line 21).
  id: totrans-2282
  prefs: []
  type: TYPE_NORMAL
  zh: 词典从文件中加载（第18行）。`parse`方法使用简单的`regExpr`正则表达式将任何标点符号替换为空格字符（第19行），这用作单词分隔符（第20行）。所有长度小于三个字符的单词都被忽略（第21行）。
- en: Let's describe the workflow to load, parse, and analyze news articles related
    to the company, Tesla Inc. and its stock, ticker symbol TSLA.
  id: totrans-2283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们描述加载、解析和分析与公司特斯拉公司及其股票（股票代码TSLA）相关的新闻文章的工作流程。
- en: 'The first step is to load and clean all the articles (corpus) defined in the
    `pathCorpus` directory (line `22`). This task is performed by the `DocumentsSource`
    class, as described in the *Data extraction* section under *Scala programming*
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*:'
  id: totrans-2284
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是加载和清理在`pathCorpus`目录中定义的所有文章（语料库）（第22行）。这项任务由`DocumentsSource`类执行，如附录A中在*Scala编程*部分下的*数据提取*部分所述，*基本概念*：
- en: '[PRE194]'
  id: totrans-2285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE194]'
- en: 'A document source is fully defined by the path of the data input files and
    the format used in the timestamp (line `23`). The text analyzer and its explicit
    `pfnText` data transformation is instantiated (line `24`). The text processing
    pipeline is defined by the following steps:'
  id: totrans-2286
  prefs: []
  type: TYPE_NORMAL
  zh: 文档源由数据输入文件路径和用于时间戳的格式完全定义（第`23`行）。文本分析器和其显式的`pfnText`数据转换被实例化（第`24`行）。文本处理管道由以下步骤定义：
- en: The transformation of an input source file into a corpus (a sequence of news
    articles) using the `pfnDoc` partial function (line `25`).
  id: totrans-2287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pfnDoc`部分函数（第`25`行）将输入源文件转换为语料库（一系列新闻文章）。
- en: The transformation of a corpus into a sequence of a `termsFreq` relative keyword
    frequency vector using the `pfnText` partial function (line `26`).
  id: totrans-2288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pfnText`部分函数（第`26`行）将语料库转换为一系列`termsFreq`相对关键词频率向量。
- en: The transformation of a sequence of relative keywords frequency vector into
    a `featuresSet` using `quantize` (line `27`) (refer to the *The differential operator*
    section under *Time series in Scala* in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*).
  id: totrans-2289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`quantize`（第`27`行）将一系列相对关键词频率向量转换为`featuresSet`（参考[第3章](part0172.xhtml#aid-5410O2
    "第3章 数据预处理")下*时间序列在Scala*中的*微分算子*部分，*数据预处理*）。
- en: The creation of the binomial `NaiveBayes` model using the pair (`featuresSet._2`
    and `expected`) as training data (line `29`).
  id: totrans-2290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用对（`featuresSet._2`和`expected`）作为训练数据创建二项式`NaiveBayes`模型（第`29`行）。
- en: 'The expected class values (0,1) are extracted from the daily stock price for
    Tesla Motors, `TSLA_QUOTES`:'
  id: totrans-2291
  prefs: []
  type: TYPE_NORMAL
  zh: 从特斯拉汽车的每日股票价格`TSLA_QUOTES`中提取预期的类别值（0，1）。
- en: '[PRE195]'
  id: totrans-2292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE195]'
- en: Note
  id: totrans-2293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The semantic analysis**'
  id: totrans-2294
  prefs: []
  type: TYPE_NORMAL
  zh: '**语义分析**'
- en: This example uses a very primitive semantic map (lexicon) for the sake of illustrating
    the benefits and inner workings of the multinomial Naïve Bayes algorithm. Commercial
    applications involving sentiment analysis or topic analysis require a deeper understanding
    of semantic associations and extraction of topics using advanced generative models,
    such as the Latent Dirichlet allocation.
  id: totrans-2295
  prefs: []
  type: TYPE_NORMAL
  zh: 本例使用一个非常原始的语义图（词典）来展示多项式朴素贝叶斯算法的益处和内部工作原理。涉及情感分析或主题分析的商用应用需要更深入地理解语义关联，并使用高级生成模型，如潜在狄利克雷分配来提取主题。
- en: Evaluating the text mining classifier
  id: totrans-2296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估文本挖掘分类器
- en: 'The following chart describes the frequency of occurrences of some of the keywords
    related to either Tesla Motors or its stock ticker TSLA:'
  id: totrans-2297
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了与特斯拉汽车或其股票代码TSLA相关的某些关键词出现的频率：
- en: '![Evaluating the text mining classifier](img/image01380.jpeg)'
  id: totrans-2298
  prefs: []
  type: TYPE_IMG
  zh: '![评估文本挖掘分类器](img/image01380.jpeg)'
- en: A graph of the relative frequency of a partial list of stock-related terms
  id: totrans-2299
  prefs: []
  type: TYPE_NORMAL
  zh: 一部分与股票相关的术语相对频率图
- en: 'The following chart plots the expected change in the direction of the stock
    price for the trading day following the press release(s) or news article(s):'
  id: totrans-2300
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了发布（或新闻文章）后的交易日股票价格预期变化方向：
- en: '![Evaluating the text mining classifier](img/image01381.jpeg)'
  id: totrans-2301
  prefs: []
  type: TYPE_IMG
  zh: '![评估文本挖掘分类器](img/image01381.jpeg)'
- en: A graph of the stock price and movement for the Tesla Motors stock
  id: totrans-2302
  prefs: []
  type: TYPE_NORMAL
  zh: 特斯拉汽车股票价格和走势图
- en: The preceding chart displays the historical price of the stock TSLA with the
    direction (UP and DOWN). The classification of 15 percent of the labeled data
    selected for the validation of the classifier has an F[1] score of 0.71\. You
    need to keep in mind that no preprocessing or clustering was performed to isolate
    the most relevant features/keywords. We initially selected the keywords according
    to the frequency of their occurrences in the financial news.
  id: totrans-2303
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了股票TSLA的历史价格及其方向（上升和下降）。为验证分类器而选择的15%标记数据的分类中，F[1]得分为0.71。需要记住的是，没有进行预处理或聚类来隔离最相关的特征/关键词。我们最初根据金融新闻中关键词出现的频率选择关键词。
- en: 'It is fair to assume that some of the keywords have a more significant impact
    on the direction of the stock price than others. One simple but interesting exercise
    is to record the value of the F[1] score for a validation for which only the observations
    that have a high number of occurrences of a specific keyword are used, as shown
    in the following graph:'
  id: totrans-2304
  prefs: []
  type: TYPE_NORMAL
  zh: 有理由假设某些关键词对股票价格方向的影响比其他关键词更大。一个简单但有趣的练习是记录只使用具有特定关键词高出现次数的观察值进行验证的F[1]分数，如下面的图表所示：
- en: '![Evaluating the text mining classifier](img/image01382.jpeg)'
  id: totrans-2305
  prefs: []
  type: TYPE_IMG
  zh: '![评估文本挖掘分类器](img/image01382.jpeg)'
- en: A bar chart representing predominant keywords in predicting the TSLA stock movement
  id: totrans-2306
  prefs: []
  type: TYPE_NORMAL
  zh: 表示预测TSLA股票走势的主要关键词的条形图
- en: The preceding bar chart shows that the terms **China**, representing all the
    mentions of the activities of Tesla Motors in China, and **Charger**, which covers
    all the references to the charging stations, have a significant positive impact
    on the direction of the stock with a probability averaging to 75 percent. The
    terms under the **Risk** category have a negative impact on the direction of the
    stock with a probability of 68 percent, or a positive impact of the direction
    of the stock with a probability of 32 percent. Within the remaining eight categories,
    72 percent of them were unusable as a predictor of the direction of the stock
    price.
  id: totrans-2307
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的条形图显示，代表中国所有特斯拉汽车在中国活动提及的**中国**，以及涵盖所有充电站引用的**充电器**，对股票方向有显著的积极影响，概率平均达到75%。**风险**类别下的术语对股票方向的负面影响概率为68%，或对股票方向有32%的积极影响。在剩余的八个类别中，有72%的它们无法作为股票价格方向的预测指标。
- en: This approach can be used for selecting features as an alternative to mutual
    information for using classifiers that are more elaborate. However, it should
    not regarded as the primary methodology for selecting features, but instead as
    a by-product of the Naïve Bayes formula applied to models with a very small number
    of relevant features. Techniques such as the principal components analysis, as
    described in the *Principal components analysis* section under *Dimension reduction*
    in [Chapter 4](part0178.xhtml#aid-59O442 "Chapter 4. Unsupervised Learning"),
    *Unsupervised Learning*, are available to reduce the dimension of the problem
    and make Naïve Bayes a viable classifier.
  id: totrans-2308
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以用作选择特征，作为使用更复杂的分类器的替代方案，而不是互信息的特征选择。然而，它不应被视为选择特征的主要方法，而应被视为将朴素贝叶斯公式应用于具有非常少量相关特征的模型时的副产品。例如，在[第4章](part0178.xhtml#aid-59O442
    "第4章。无监督学习")中“降维”部分描述的主成分分析等技术，可用于降低问题的维度，使朴素贝叶斯成为一个可行的分类器。
- en: Pros and cons
  id: totrans-2309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优缺点
- en: The examples selected in this chapter do not do justice to the versatility and
    accuracy of the Naïve Bayes family of classifiers.
  id: totrans-2310
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所选的示例并没有充分体现朴素贝叶斯分类器家族的多样性和准确性。
- en: 'The Naïve Bayes algorithm is a simple and robust generative classifier that
    relies on prior conditional probabilities to extract a model from a training dataset.
    The Naïve Bayes model has its benefits, as mentioned here:'
  id: totrans-2311
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法是一个简单且健壮的生成分类器，它依赖于先验条件概率从训练数据集中提取模型。朴素贝叶斯模型具有其优点，如以下所述：
- en: It is easy to implement and parallelize
  id: totrans-2312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它易于实现和并行化
- en: 'It has a very low computational complexity: *O((n+c)*m)*, where *m* is the
    number of features, *C* is the number of classes, and *n* is the number of observations'
  id: totrans-2313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的计算复杂度非常低：*O((n+c)*m)*，其中*m*是特征的数量，*C*是类别的数量，而*n*是观察的数量
- en: It handles missing data
  id: totrans-2314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它处理缺失数据
- en: It supports incremental updates, insertions, and deletions
  id: totrans-2315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持增量更新、插入和删除
- en: 'However, Naïve Bayes is not a silver bullet. It has the following disadvantages:'
  id: totrans-2316
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，朴素贝叶斯并不是万能的。它有以下缺点：
- en: It requires a large training set to achieve reasonable accuracy
  id: totrans-2317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要一个大的训练集才能达到合理的准确性
- en: The assumption of the independence of features is not practical in the real
    world
  id: totrans-2318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在现实世界中，特征独立性的假设并不实用
- en: It requires dealing with the zero-frequency problem for counters
  id: totrans-2319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要处理计数器的零频率问题
- en: Summary
  id: totrans-2320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'There is a reason why the Naïve Bayes model is one of the first supervised
    learning techniques taught in a machine learning course: it is simple and robust.
    As a matter of fact, this is the first technique that should come to mind when
    you are considering creating a model from a labeled dataset, as long as the features
    are conditionally independent.'
  id: totrans-2321
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个原因使得朴素贝叶斯模型是机器学习课程中最早教授的有监督学习技术之一：它简单且健壮。实际上，这是当你考虑从标记数据集中创建模型时，首先应该想到的技术，只要特征是条件独立的。
- en: This chapter also introduced you to the basics of text mining as an application
    of Naïve Bayes.
  id: totrans-2322
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还介绍了朴素贝叶斯作为文本挖掘应用的基础知识。
- en: 'Despite all its benefits, the Naïve Bayes classifier assumes that the features
    are conditionally independent, a limitation that cannot be always overcome. In
    the case of the classification of documents or news releases, Naïve Bayes incorrectly
    assumes that terms are semantically independent: the two entities'' age and date
    of birth are highly correlated. The discriminative classifiers described in the
    next few chapters address some of Naïve Bayes'' limitations [5:14].'
  id: totrans-2323
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它有诸多优点，但朴素贝叶斯分类器假设特征是条件独立的，这是一个无法总是克服的限制。在文档或新闻发布的分类中，朴素贝叶斯错误地假设术语在语义上是独立的：两个实体的年龄和出生日期高度相关。下一章中描述的判别分类器解决了朴素贝叶斯的一些限制[5:14]。
- en: This chapter does not treat temporal dependencies, sequence of events, or conditional
    dependencies between observed and hidden features. These types of dependencies
    necessitate a different approach to modeling that is the subject of [Chapter 7](part0193.xhtml#aid-5O1SI1
    "Chapter 7. Sequential Data Models"), *Sequential Data Models*.
  id: totrans-2324
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不处理时间依赖性、事件序列或观察到的特征和隐藏特征之间的条件依赖性。这些类型的依赖性需要不同的建模方法，这是[第7章](part0193.xhtml#aid-5O1SI1
    "第7章。序列数据模型")“序列数据模型”的主题。
- en: Chapter 6. Regression and Regularization
  id: totrans-2325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。回归与正则化
- en: In the first chapter, we briefly introduced the binary logistic regression (the
    binomial logistic regression for a single variable) as our first test case. The
    purpose was to illustrate the concept of discriminative classification. There
    are many more regression models, starting with the ubiquitous ordinary least square
    linear regression and the logistic regression [6:1].
  id: totrans-2326
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们简要介绍了二元逻辑回归（单变量的二项逻辑回归）作为我们的第一个测试案例。其目的是说明判别分类的概念。还有许多更多的回归模型，从无处不在的普通最小二乘线性回归和逻辑回归[6:1]开始。
- en: The purpose of regression is to minimize a loss function, with the **residual
    sum of squares** (**RSS**) being one that is commonly used. The problem of overfitting
    described in the *Overfitting* section under *Assessing a model* in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*, can be addressed by adding a **penalty
    term** to the loss function. The penalty term is an element of the larger concept
    of **regularization**.
  id: totrans-2327
  prefs: []
  type: TYPE_NORMAL
  zh: 回归的目的是最小化损失函数，其中**残差平方和**（**RSS**）是常用的一个。在[第2章](part0165.xhtml#aid-4TBCQ2 "第2章。Hello
    World!")中“评估模型”部分下的“过拟合”章节中描述的过拟合问题可以通过向损失函数中添加**惩罚项**来解决。惩罚项是**正则化**这一更大概念的一个元素。
- en: The first section of this chapter will describe and implement the linear **least-squares
    regression**. The second section will introduce the concept of regularization
    with an implementation of the **ridge regression**. Finally, the logistic regression
    will be revisited in detail from the perspective of a classification model.
  id: totrans-2328
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分将描述并实现线性**最小二乘回归**。第二部分将介绍正则化的概念，并通过**岭回归**的实现来展示。最后，将从分类模型的角度详细回顾逻辑回归。
- en: Linear regression
  id: totrans-2329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: Linear regression is by far the most widely used, or at least the most commonly
    known, regression method. The terminology is usually associated with the concept
    of fitting a model to data and minimizing the errors between the expected and
    predicted values by computing the sum of square errors, residual sum of square
    errors, or least-square errors.
  id: totrans-2330
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归到目前为止是最广泛使用，或者至少是最常见的回归方法。术语通常与将模型拟合到数据的概念相关联，并通过计算平方误差和、残差平方和或最小二乘误差来最小化预期值和预测值之间的误差。
- en: 'The least squares problems fall into the following two categories:'
  id: totrans-2331
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘问题分为以下两类：
- en: Ordinary least squares
  id: totrans-2332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普通最小二乘
- en: Nonlinear least squares
  id: totrans-2333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性最小二乘
- en: One-variate linear regression
  id: totrans-2334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单变量线性回归
- en: Let's start with the simplest form of linear regression, which is the single
    variable regression, in order to introduce the terms and concepts behind linear
    regression. In its simplest interpretation, the one-variate linear regression
    consists of fitting a line to a set of data points *{x, y}*.
  id: totrans-2335
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最简单的线性回归形式开始，即单变量回归，以便介绍线性回归背后的术语和概念。在最简单的解释中，单变量线性回归包括拟合一条线到一组数据点*{x, y}*。
- en: Note
  id: totrans-2336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注记
- en: 'M1: A single variable linear regression for a model *f* with weights *w[j]*
    for features *x[j]* and labels (or expected values) *y[j]* is given by the following
    formula:'
  id: totrans-2337
  prefs: []
  type: TYPE_NORMAL
  zh: M1：对于模型*f*，其特征*x[j]*的权重为*w[j]*，标签（或预期值）为*y[j]*的单变量线性回归如下公式所示：
- en: '![One-variate linear regression](img/image01383.jpeg)'
  id: totrans-2338
  prefs: []
  type: TYPE_IMG
  zh: '![一元线性回归](img/image01383.jpeg)'
- en: Here, *w[1]* is the slope, *w[0]* is the intercept, *f* is the linear function
    that minimizes the RSS, and (*x[j], y[j]*) is a set of *n* observations.
  id: totrans-2339
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*w[1]* 是斜率，*w[0]* 是截距，*f* 是最小化均方误差（RSS）的线性函数，而 (*x[j], y[j]*) 是一组 *n* 个观测值。
- en: The RSS is also known as the **sum of squared errors** (**SSE**). The **mean
    squared error** (**MSE**) for *n* observations is defined as the ratio *RSS/n*.
  id: totrans-2340
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差（RSS）也称为**平方误差之和**（**SSE**）。对于 *n* 个观测值的**均方误差**（**MSE**）定义为 *RSS/n* 的比率。
- en: Note
  id: totrans-2341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Terminology**'
  id: totrans-2342
  prefs: []
  type: TYPE_NORMAL
  zh: '**术语**'
- en: The terminology used in the scientific literature regarding regression is a
    bit confusing at times. Regression weights are also known as regression coefficients
    or regression parameters. The weights are referred to as *w* in formulas and the
    source code throughout the chapter, although *β* is also used in reference books.
  id: totrans-2343
  prefs: []
  type: TYPE_NORMAL
  zh: 科学文献中关于回归的术语有时会有些混乱。回归权重也被称为回归系数或回归参数。在整个章节中，权重被称为 *w*，尽管参考书中也使用了 *β*。
- en: Implementation
  id: totrans-2344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: Let's create a `SingleLinearRegression` parameterized class to implement the
    **M1** formula. The linear regression is a data transformation that uses a model
    implicitly derived or built from data. Therefore, the simple linear regression
    implements the `ITransform` trait, as described in the *Monadic data transformation*
    section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello
    World!*
  id: totrans-2345
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个 `SingleLinearRegression` 参数化类来实现 **M1** 公式。线性回归是一种使用从数据隐式导出或构建的模型进行数据转换的方法。因此，简单线性回归实现了在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章 Hello World!")中“单调数据转换”部分所描述的 `ITransform` 特性，*Hello World!*。
- en: 'The `SingleLinearRegression` class takes the following two arguments:'
  id: totrans-2346
  prefs: []
  type: TYPE_NORMAL
  zh: '`SingleLinearRegression` 类接受以下两个参数：'
- en: An `xt` vector of single variable observations
  id: totrans-2347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单变量观测值的 `xt` 向量
- en: A vector of `expected` values or labels (line `1`)
  id: totrans-2348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期值或标签的向量（行 `1`）
- en: 'The code will be as follows:'
  id: totrans-2349
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE196]'
  id: totrans-2350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE196]'
- en: The `Monitor` trait is used to collect the profiling information during training
    (refer to the *Monitor* section under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-2351
  prefs: []
  type: TYPE_NORMAL
  zh: '`Monitor` 特性用于在训练期间收集配置文件信息（请参阅[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中“实用类”下的*Monitor*部分，*基本概念*）。'
- en: The class has to define the type of the output of the `|>` prediction method,
    which is a `Double` (line `2`).
  id: totrans-2352
  prefs: []
  type: TYPE_NORMAL
  zh: 该类必须定义 `|>` 预测方法的输出类型，它是一个 `Double`（行 `2`）。
- en: Note
  id: totrans-2353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Model instantiation**'
  id: totrans-2354
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型实例化**'
- en: The model parameters are computed through training and the model is instantiated
    regardless of whether the model is actually validated. A commercial application
    requires the model to be validated using a methodology such as the K-fold validation,
    as described in the *Design template for immutable classifiers* section in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-2355
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数是通过训练计算得出的，无论模型是否实际经过验证，模型都会被实例化。商业应用需要使用如K折验证等方法来验证模型，正如在[附录A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念")中“不可变分类器设计模板”部分所描述的，*基本概念*。
- en: 'The training generates the model defined as the regression weights (slope and
    intercept) (line `3`). The model is set as `None` if an exception is thrown during
    training:'
  id: totrans-2356
  prefs: []
  type: TYPE_NORMAL
  zh: 训练生成定义为回归权重（斜率和截距）的模型（行 `3`）。如果在训练期间抛出异常，则模型设置为 `None`：
- en: '[PRE197]'
  id: totrans-2357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: The regression weights or coefficients, that is the `model` tuple, are computed
    using the `SimpleRegression` class from the `stats.regression` package of the
    Apache Commons Math library with the `true` argument to trigger the computation
    of the intercept (line `4`). The input time series and the labels (or expected
    values) are zipped to generate an array of two values (input and expected) (line
    `5`). The `model` is initialized with the slope and intercept computed during
    the training (line `6`).
  id: totrans-2358
  prefs: []
  type: TYPE_NORMAL
  zh: 回归权重或系数，即模型元组，使用Apache Commons Math库中的`stats.regression`包的`SimpleRegression`类计算得出，使用`true`参数触发截距的计算（行
    `4`）。输入时间序列和标签（或预期值）被压缩生成一个包含两个值（输入和预期）的数组（行 `5`）。`model` 使用训练期间计算的斜率和截距进行初始化（行
    `6`）。
- en: The `zipToSeries` method of the `XTSeries` object is described in the *Time
    series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing*.
  id: totrans-2359
  prefs: []
  type: TYPE_NORMAL
  zh: '`XTSeries` 对象的 `zipToSeries` 方法在[第3章](part0172.xhtml#aid-5410O2 "第3章 数据预处理")中“Scala中的时间序列”部分进行了描述，*数据预处理*。'
- en: Note
  id: totrans-2360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**private versus private[this]**'
  id: totrans-2361
  prefs: []
  type: TYPE_NORMAL
  zh: '**private 与 private[this]**'
- en: A `private` value or variable can be accessed only by all the instances of a
    class. A value declared `private[this]` can be manipulated only by the `this`
    instance. For example, the value model can be accessed only by the `this` instance
    of `SingleLinearRegression`.
  id: totrans-2362
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `private` 值或变量只能被类的所有实例访问。声明为 `private[this]` 的值只能由 `this` 实例操作。例如，model
    值只能由 `SingleLinearRegression` 的 `this` 实例访问。
- en: Test case
  id: totrans-2363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试用例
- en: 'For our first test case, we compute the single variate linear regression of
    the price of the Copper ETF (ticker symbol: CU) over a period of 6 months (January
    1, 2013 to June 30, 2013):'
  id: totrans-2364
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个测试用例，我们计算了铜 ETF（股票代码：CU）在 6 个月（2013 年 1 月 1 日至 2013 年 6 月 30 日）期间的单一变量线性回归。
- en: '[PRE198]'
  id: totrans-2365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: The daily closing `price` of the ETF CU is extracted from a CSV file (line `7`)
    as the expected values using a `DataSource` instance, as described in the *Data
    extraction and Data sources* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*. The x values `days` are automatically
    generated as a linear function (line `8`). The expected values (`price`) and sessions
    (`days`) are the inputs to the instantiation of the simple linear regression (line
    `9`).
  id: totrans-2366
  prefs: []
  type: TYPE_NORMAL
  zh: ETF CU 的每日收盘价从 CSV 文件中提取（第 `7` 行）作为预期值，使用 `DataSource` 实例，如 [附录 A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念") 中 *数据提取和数据源* 部分所述，*基本概念*。x 值 `days` 自动生成为一个线性函数（第 `8` 行）。预期值（`price`）和会话（`days`）是简单线性回归实例化的输入（第
    `9` 行）。
- en: 'Once the model is created successfully, the test code computes the `mse` mean
    squared error of the predicted and expected values (line `10`):'
  id: totrans-2367
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型创建成功，测试代码计算预测值和预期值的 `mse` 均方误差（第 `10` 行）：
- en: '[PRE199]'
  id: totrans-2368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: 'The mean least squared error is computed using the `mse` method of `XTSeries`
    (line `11`). The original stock price and linear regression equation are plotted
    on the following chart:'
  id: totrans-2369
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `XTSeries` 的 `mse` 方法计算平均最小二乘误差（第 `11` 行）。原始股价和线性回归方程在下面的图表中绘制：
- en: '![Test case](img/image01384.jpeg)'
  id: totrans-2370
  prefs: []
  type: TYPE_IMG
  zh: '![测试用例](img/image01384.jpeg)'
- en: The total least square error is 0.926.
  id: totrans-2371
  prefs: []
  type: TYPE_NORMAL
  zh: 总最小二乘误差为 0.926。
- en: Although the single variable linear regression is convenient, it is limited
    to a scalar time series. Let's consider the case of multiple variables.
  id: totrans-2372
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管单变量线性回归很方便，但它仅限于标量时间序列。让我们考虑多变量情况。
- en: Ordinary least squares regression
  id: totrans-2373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 普通最小二乘回归
- en: The **ordinary least squares regression** computes the parameters *w* of a linear
    function *y = f(x[0], x[2] … x[d])* by minimizing the residual sum of squares.
    The optimization problem is solved by performing vector and matrix operations
    (transposition, inversion, and substitution).
  id: totrans-2374
  prefs: []
  type: TYPE_NORMAL
  zh: 普通最小二乘回归通过最小化残差平方和来计算线性函数 *y = f(x[0], x[2] … x[d])* 的参数 *w*。优化问题通过执行向量和矩阵运算（转置、求逆和替换）来解决。
- en: Note
  id: totrans-2375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M2: The minimization of the loss function is given by the following formula:'
  id: totrans-2376
  prefs: []
  type: TYPE_NORMAL
  zh: M2：损失函数的最小化由以下公式给出：
- en: '![Ordinary least squares regression](img/image01385.jpeg)'
  id: totrans-2377
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘回归](img/image01385.jpeg)'
- en: Here, *wj* is the weights or parameters of the regression, *(x[i], y[i])[i:0,
    n-1]* is the *n* observations of a vector *x* and an expected output value *y*,
    and *f* is the linear multivariate function, *y = f (x0, x1, …,xd)*.
  id: totrans-2378
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*wj* 是回归的权重或参数，*(x[i], y[i])[i:0, n-1]* 是向量 *x* 和预期输出值 *y* 的 *n* 个观测值，*f*
    是线性多元函数，*y = f (x0, x1, …,xd)*。
- en: 'There are several methodologies to minimize the residual sum of squares for
    a linear regression:'
  id: totrans-2379
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归，有几种方法可以最小化残差平方和：
- en: Resolution of the set of *n* equations with *d* variables (weights) using the
    **QR decomposition** of the *n* by *d* matrix, representing the time series of
    *n* observations of a vector of *d* dimensions with *n >= d* [6:2]
  id: totrans-2380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 *n* 行 *d* 列矩阵的 **QR 分解**来解决具有 *d* 个变量（权重）的 *n* 个方程组，该矩阵表示具有 *n >= d* 的 *d*
    维向量 *n* 个观测值的时间序列[6:2]
- en: '**Singular value decomposition** on the observations-features matrix, in the
    case where the dimension *d* exceeds the number of observations *n* [6:3]'
  id: totrans-2381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**奇异值分解**在观测-特征矩阵上，在维度 *d* 超过观测数 *n* 的情况下[6:3]'
- en: '**Gradient descent** [6:4]'
  id: totrans-2382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度下降** [6:4]'
- en: '**Stochastic** **gradient descent** [6:5]'
  id: totrans-2383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机** **梯度下降** [6:5]'
- en: An overview of these matrix decompositions and optimization techniques can be
    found in the *Linear algebra* and *Summary of optimization techniques* sections
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*.
  id: totrans-2384
  prefs: []
  type: TYPE_NORMAL
  zh: 这些矩阵分解和优化技术的概述可以在 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念") 的 *线性代数* 和
    *优化技术总结* 部分找到，*基本概念*。
- en: The QR decomposition generates the smallest relative error MSE for the most
    common least squares problem. The technique is used in our implementation of the
    least squares regression.
  id: totrans-2385
  prefs: []
  type: TYPE_NORMAL
  zh: QR 分解为最常见的最小二乘问题生成最小的相对误差 MSE。该技术在我们的最小二乘回归实现中得到了应用。
- en: Design
  id: totrans-2386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计
- en: The implementation of the least squares regression leverages the Apache Commons
    Math library implementation of the ordinary least squares regression [6:6].
  id: totrans-2387
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘回归的实现利用了 Apache Commons Math 库对普通最小二乘回归的实现 [6:6]。
- en: This chapter describes several types of regression algorithms. It makes sense
    to define a generic `Regression` trait that defines the key element component
    of a regression algorithm.
  id: totrans-2388
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了几种回归算法。定义一个通用的 `Regression` 特质，以定义回归算法的关键元素组件是有意义的。
- en: A model of the `RegressionModel` type (line `1`)
  id: totrans-2389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `RegressionModel` 类型的模型（第 `1` 行）
- en: 'Two methods to access the components of the regression model: `weights` and
    `rss` (line `2` and `3`)'
  id: totrans-2390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两种访问回归模型组件的方法：`weights` 和 `rss`（第 `2` 行和第 `3` 行）
- en: A `train` polymorphic method that implements the training of this specific regression
    algorithm (line `4`)
  id: totrans-2391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `train` 多态方法，实现了此特定回归算法的训练（第 `4` 行）
- en: A `training` protected method that wraps `train` into a `Try` monad
  id: totrans-2392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个将 `train` 包装到 `Try` 单子中的 `training` 受保护方法
- en: 'The code will be as follows:'
  id: totrans-2393
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE200]'
  id: totrans-2394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: 'The model is simply defined by its `weights` and its residual sum of squares
    (line `5`):'
  id: totrans-2395
  prefs: []
  type: TYPE_NORMAL
  zh: 模型简单地由其 `weights` 和残差平方和定义（第 `5` 行）：
- en: '[PRE201]'
  id: totrans-2396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: The `RegressionModel` companion object implements the computation of the `dot`
    inner product of the `weights` regression and an observation, `x` (line `6`).
    The `dot` method is used throughout the chapter.
  id: totrans-2397
  prefs: []
  type: TYPE_NORMAL
  zh: '`RegressionModel` 伴生对象实现了 `weights` 回归和观察值 `x` 的 `dot` 内积的计算，`dot` 方法在本章中得到了广泛应用。'
- en: 'Let''s create a `MultiLinearRegression` class as a data transformation whose
    model is implicitly derived from the input data (training set), as described in
    the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*:'
  id: totrans-2398
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个 `MultiLinearRegression` 类，作为一个数据转换，其模型隐式地从输入数据（训练集）推导出来，如 [第 2 章](part0165.xhtml#aid-4TBCQ2
    "第 2 章. Hello World!") 中 *单调数据转换* 部分所述，*Hello World!*：
- en: '[PRE202]'
  id: totrans-2399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
- en: 'The `MultiLinearRegression` class takes two arguments: the multidimensional
    time series of the `xt` observations and the vector of `expected` values (line
    `7`). The class implements the `ITransform` trait and needs to define the type
    of the output value for the prediction or regression, `V` as a `Double` (line
    `8`). The constructor for `MultiLinearRegression` creates the `model` through
    training (line `9`). The `ITransform` trait''s `|>` method implements the runtime
    prediction for the multilinear regression (line `10`).'
  id: totrans-2400
  prefs: []
  type: TYPE_NORMAL
  zh: '`MultiLinearRegression` 类接受两个参数：`xt` 观察值的多元时间序列和 `expected` 值的向量（第 `7` 行）。该类实现了
    `ITransform` 特质，并需要定义预测或回归的输出值类型，`V` 作为 `Double`（第 `8` 行）。`MultiLinearRegression`
    的构造函数通过训练创建 `model`（第 `9` 行）。`ITransform` 特质的 `|>` 方法实现了多线性回归的运行时预测（第 `10` 行）。'
- en: The `Monitor` trait is used to collect the profiling information during training
    (refer to the *Monitor* section under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-2401
  prefs: []
  type: TYPE_NORMAL
  zh: '`Monitor` 特质用于在训练过程中收集配置文件信息（参见 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")
    下 *实用类* 部分的 *Monitor* 部分，*基本概念*）。'
- en: Note
  id: totrans-2402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The regression model**'
  id: totrans-2403
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归模型**'
- en: The RSS is included in the model because it provides the client code with the
    important information regarding the accuracy of the underlying technique used
    to minimize the loss function.
  id: totrans-2404
  prefs: []
  type: TYPE_NORMAL
  zh: RSS 包含在模型中，因为它向客户端代码提供了有关用于最小化损失函数的底层技术准确性的重要信息。
- en: 'The relationship between the different components of the multilinear regression
    is described in the following UML class diagram:'
  id: totrans-2405
  prefs: []
  type: TYPE_NORMAL
  zh: 多线性回归的不同组件之间的关系在以下 UML 类图中描述：
- en: '![Design](img/image01386.jpeg)'
  id: totrans-2406
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01386.jpeg)'
- en: The UML class diagram for the multilinear (OLS) regression
  id: totrans-2407
  prefs: []
  type: TYPE_NORMAL
  zh: 多线性（OLS）回归的 UML 类图
- en: The UML diagram omits the helper traits and classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-2408
  prefs: []
  type: TYPE_NORMAL
  zh: UML图省略了`Monitor`或Apache Commons Math组件等辅助特性和类。
- en: Implementation
  id: totrans-2409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: 'The training is performed during the instantiation of the `MultiLinearRegression`
    class (refer to the *Design template for immutable classifiers* section in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*):'
  id: totrans-2410
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是在`MultiLinearRegression`类的实例化过程中进行的（参考[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*不可变分类器设计模板*部分，*基本概念*）：
- en: '[PRE203]'
  id: totrans-2411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE203]'
- en: The functionality of the ordinary least squares regression in the Apache Commons
    Math library is accessed through an `olsMlr` reference to the `MultiLinearRAdapter`
    adapter class (line `11`).
  id: totrans-2412
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对`MultiLinearRAdapter`适配器类的`olsMlr`引用访问Apache Commons Math库中普通最小二乘回归的功能（第`11`行）。
- en: 'The `train` method creates the model by invoking the `OLSMultipleLinearRegression`
    Apache Commons Math class (line `12`) and returns the regression model (line `13`).
    The various methods of the class are accessed through the `MultiLinearRAdapter`
    adapter class:'
  id: totrans-2413
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法通过调用Apache Commons Math类的`OLSMultipleLinearRegression`（第`12`行）创建模型，并返回回归模型（第`13`行）。该类的方法通过`MultiLinearRAdapter`适配器类访问：'
- en: '[PRE204]'
  id: totrans-2414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE204]'
- en: The `createModel`, `weights`, and `rss` methods route the request to the corresponding
    methods in `OLSMultipleLinearRegression`.
  id: totrans-2415
  prefs: []
  type: TYPE_NORMAL
  zh: '`createModel`、`weights`和`rss`方法将请求路由到`OLSMultipleLinearRegression`中的相应方法。'
- en: The `Try{}` Scala exception handling monad is used as the return type for the
    `train` method in order to catch the different types of exceptions thrown by the
    Apache Commons Math library such as `MathIllegalArgumentException`, `MathRuntimeException`,
    or `OutOfRangeException`.
  id: totrans-2416
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕获Apache Commons Math库抛出的不同类型的异常，如`MathIllegalArgumentException`、`MathRuntimeException`或`OutOfRangeException`，`train`方法的返回类型使用了Scala异常处理单子`Try{}`。
- en: Note
  id: totrans-2417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Exception handling**'
  id: totrans-2418
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常处理**'
- en: 'Wrapping up invocation of methods in a third party with a `Try {}` Scala exception
    handler matters for a couple of reasons:'
  id: totrans-2419
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Try {}` Scala异常处理单子包装第三方方法调用的调用对于几个原因很重要：
- en: It makes debugging easier by segregating your code from the third party
  id: totrans-2420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将代码与第三方库分离，这使得调试变得更加容易。
- en: It allows your code to recover from the exception by reexecuting the same function
    with an alternative third-party library method, whenever possible
  id: totrans-2421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当可能时，它允许你的代码通过重新执行具有替代第三方库方法的相同函数来从异常中恢复。
- en: 'The predictive algorithm for the ordinary least squares regression is implemented
    by the `|>` data transformation. The method predicts the output value, given a
    model and an input value, `x`:'
  id: totrans-2422
  prefs: []
  type: TYPE_NORMAL
  zh: 普通最小二乘回归的预测算法通过`|>`数据转换实现。该方法根据模型和输入值`x`预测输出值：
- en: '[PRE205]'
  id: totrans-2423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: The predictive value is computed using the `dot` method defined in the `RegressionModel`
    singleton, which was introduced earlier in this section (line `14`).
  id: totrans-2424
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在前面本节中引入的`RegressionModel`单例中定义的`dot`方法计算预测值（第`14`行）。
- en: Test case 1 – trending
  id: totrans-2425
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试用例1 – 趋势
- en: '**Trending** consists of extracting the long-term movement in a time series.
    Trend lines are detected using a multivariate least squares regression. The objective
    of this first test is to evaluate the filtering capability of the ordinary least
    squares regression.'
  id: totrans-2426
  prefs: []
  type: TYPE_NORMAL
  zh: '**趋势**包括从时间序列中提取长期运动。使用多元最小二乘回归检测趋势线。这个第一个测试的目的是评估普通最小二乘回归的滤波能力。'
- en: 'The regression is performed on the relative price variation of the Copper ETF
    (ticker symbol: CU). The selected features are `volatility` and `volume`, and
    the label or target variable is the price change between two consecutive `y` trading
    sessions.'
  id: totrans-2427
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是在铜ETF（股票代码：CU）的相对价格变动上进行的。选定的特征是`波动性`和`成交量`，标签或目标变量是两个连续`y`交易会话之间的价格变动。
- en: The naming convention for the trading data and metrics is described in the *Trading
    data* section under *Technical analysis* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-2428
  prefs: []
  type: TYPE_NORMAL
  zh: 交易数据和指标命名规范在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")的*技术分析*部分下的*交易数据*章节中描述，*基本概念*。
- en: 'The volume, volatility, and price variation for CU between January 1, 2013
    and June 30, 2013 are plotted on the following chart:'
  id: totrans-2429
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图表中绘制了2013年1月1日至2013年6月30日之间CU的成交量、波动性和价格变动：
- en: '![Test case 1 – trending](img/image01387.jpeg)'
  id: totrans-2430
  prefs: []
  type: TYPE_IMG
  zh: '![测试用例1 – 趋势](img/image01387.jpeg)'
- en: The chart for price variation, volatility, and trading volume for Copper ETF
  id: totrans-2431
  prefs: []
  type: TYPE_NORMAL
  zh: 铜ETF的价格变动、波动性和交易量图表
- en: 'Let''s write the client code to compute the multivariate linear regression,
    *price change = w[0] + volatility.w[1] + volume.w[2]*:'
  id: totrans-2432
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写客户端代码来计算多元线性回归，*价格变化 = w[0] + 波动性.w[1] + 体积.w[2]*：
- en: '[PRE206]'
  id: totrans-2433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE206]'
- en: 'Let''s take a look at the steps required for the execution of the test: it
    consists of collecting data, extracting the features and expected values, and
    training the multilinear regression model:'
  id: totrans-2434
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看执行测试所需的步骤：它包括收集数据、提取特征和期望值，以及训练多线性回归模型：
- en: Locate the CSV formatted data source file (line `15`).
  id: totrans-2435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位CSV格式的数据源文件（行`15`）。
- en: Create a data source extractor, `DataSource`, for the trading session closing
    `price`, the `volatility` session, and the `volume` session for the ETF CU (line
    `16`).
  id: totrans-2436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为交易会话收盘`price`、`volatility`会话和`volume`会话创建一个数据源提取器，`DataSource`，用于ETF CU（行`16`）。
- en: Extract the price of the ETF (line `17`), its volatility within a trading session
    (line `18`), and the trading volume during the session (line `19`) using the `DataSource`
    transform.
  id: totrans-2437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DataSource`转换提取ETF的价格（行`17`）、交易会话内的波动性（行`18`）和会话期间的交易量（行`19`）。
- en: Generate the labeled data as a pair of features (relative volatility and relative
    volume for the ETF) and expected outcome (0, 1) for training the model for which
    `1` represents the increase in the price and `0` represents the decrease in the
    price (line `20`). The `differentialData` generic method of the `XTSeries` singleton
    is described in the *Time series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*.
  id: totrans-2438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成标记数据作为特征对（ETF的相对波动性和相对成交量）和期望结果（0，1）的配对，用于训练模型，其中`1`代表价格上涨，`0`代表价格下跌（行`20`）。`XTSeries`单例的`differentialData`通用方法在[第3章](part0172.xhtml#aid-5410O2
    "第3章。数据预处理")的*Scala中的时间序列*部分中描述，*数据预处理*。
- en: The multilinear regression is instantiated using the `features` set and the
    `expected` change in the daily ETF price (line `21`).
  id: totrans-2439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`features`集和每日ETF价格预期的`expected`变化（行`21`）实例化多线性回归。
- en: Display the expected and trending values using JFreeChart (line `22`).
  id: totrans-2440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用JFreeChart显示期望值和趋势值（行`22`）。
- en: 'The time series of expected values and the data predicted by the regression
    are plotted on the following chart:'
  id: totrans-2441
  prefs: []
  type: TYPE_NORMAL
  zh: 期望值的时间序列和回归预测的数据绘制在以下图表中：
- en: '![Test case 1 – trending](img/image01388.jpeg)'
  id: totrans-2442
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例1 – 趋势](img/image01388.jpeg)'
- en: The price variation and the least squares regression for the Copper ETF according
    to volatility and volume
  id: totrans-2443
  prefs: []
  type: TYPE_NORMAL
  zh: 根据波动性和成交量对铜ETF的价格变动和最小二乘回归
- en: 'The least squares regression model is defined by the linear function for the
    estimation of price variation as follows:'
  id: totrans-2444
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘回归模型通过以下线性函数定义来估计价格变动：
- en: '*price(t+1)-price(t) = -0.01 + 0.014 volatility – 0.0042.volume*'
  id: totrans-2445
  prefs: []
  type: TYPE_NORMAL
  zh: '*价格(t+1)-价格(t) = -0.01 + 0.014波动性 – 0.0042体积*'
- en: The estimated price change (the dotted line in the preceding chart) represents
    the long-term trend from which the noise is filtered out. In other words, the
    least squares regression operates as a simple low-pass filter as an alternative
    to some of the filtering techniques such as the discrete Fourier transform or
    the Kalman filter, as described in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing* [6:7].
  id: totrans-2446
  prefs: []
  type: TYPE_NORMAL
  zh: 估计的价格变动（前一个图表中的虚线）代表了过滤掉噪声的长期趋势。换句话说，最小二乘回归作为一种简单的低通滤波器，作为一些过滤技术（如离散傅里叶变换或卡尔曼滤波器）的替代，如[第3章](part0172.xhtml#aid-5410O2
    "第3章。数据预处理")的*数据预处理*部分所述 [6:7]。
- en: 'Although trend detection is an interesting application of the least squares
    regression, the method has limited filtering capabilities for time series [6:8]:'
  id: totrans-2447
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然趋势检测是最小二乘回归的一个有趣应用，但该方法对于时间序列的过滤能力有限 [6:8]：
- en: It is sensitive to outliers
  id: totrans-2448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对异常值敏感
- en: The first and last few observations need to be discarded
  id: totrans-2449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要丢弃第一个和最后几个观测值
- en: As a deterministic method, it does not support noise analysis (distribution,
    frequencies, and so on)
  id: totrans-2450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一种确定性方法，它不支持噪声分析（分布、频率等）
- en: Test case 2 – feature selection
  id: totrans-2451
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试案例2 – 特征选择
- en: The second test case is related to feature selection. The objective is to discover
    which subset of initial features generates the most accurate regression model,
    that is, the model with the smallest residual sum of squares on the training set.
  id: totrans-2452
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个测试案例与特征选择相关。目标是发现哪个初始特征子集能生成最准确的回归模型，即训练集上残差平方和最小的模型。
- en: 'Let''s consider an initial set of *D* features *{x[i]}*. The objective is to
    estimate the subset of features *{x[id]}* that are most relevant to the set of
    observations using a least squares regression. Each subset of features is associated
    with a *f[j](x|w[j])* model:'
  id: totrans-2453
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个初始特征集*{x[i]}*。目标是使用最小二乘回归估计与观测集最相关的特征子集*{x[id]}*。每个特征子集都与一个*f[j](x|w[j])*模型相关联：
- en: '![Test case 2 – feature selection](img/image01389.jpeg)'
  id: totrans-2454
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例2 – 特征选择](img/image01389.jpeg)'
- en: A diagram for the features set selection
  id: totrans-2455
  prefs: []
  type: TYPE_NORMAL
  zh: 特征集选择图
- en: The ordinary least square regression is used to select the model parameters
    *w* in the case the feature set is small. Performing the regression of each subset
    of a large original feature set is not practical.
  id: totrans-2456
  prefs: []
  type: TYPE_NORMAL
  zh: 当特征集较小时，使用普通最小二乘回归来选择模型参数*w*。对大型原始特征集的每个子集进行回归并不实际。
- en: Note
  id: totrans-2457
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: 'M3: The features selection can be expressed mathematically as follows:'
  id: totrans-2458
  prefs: []
  type: TYPE_NORMAL
  zh: M3：特征选择可以用以下数学公式表示：
- en: '![Test case 2 – feature selection](img/image01390.jpeg)'
  id: totrans-2459
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例2 – 特征选择](img/image01390.jpeg)'
- en: Here, *w[jk]* is the weights of the regression for the function/model *f[j],
    (x[i], y[i])[i:0,n-1]* is the *n* observations of a vector *x* and expected output
    value *y*, and *f* is the linear multivariate function, *y = f (x[0], x[1], …,x[d])*.
  id: totrans-2460
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*w[jk]*是回归函数/模型的权重，*(x[i], y[i])[i:0,n-1]*是向量*x*的*n*个观测值和预期输出值*y*，*f*是线性多元函数，*y
    = f (x[0], x[1], …,x[d])*。
- en: 'Let''s consider the following four financial time series over the period from
    January 1, 2009 to December 31, 2013:'
  id: totrans-2461
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑从2009年1月1日到2013年12月31日这段时间内的以下四个金融时间序列：
- en: The exchange rate of Chinese Yuan to US Dollar
  id: totrans-2462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人民币兑美元汇率
- en: The S&P 500 index
  id: totrans-2463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标普500指数
- en: The spot price of gold
  id: totrans-2464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黄金现货价格
- en: The 10-year Treasury bond price
  id: totrans-2465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10年期国债价格
- en: The problem is to estimate which combination of the S&P 500 index, gold price,
    and 10-year Treasury bond price variables is the most correlated to the exchange
    rate of the Yuan. For practical reasons, we use the Exchange Trade Funds CYN as
    the proxy for the Yuan/US dollar exchange rate (similarly, SPY, GLD, and TLT for
    the S&P 500 index, spot price of gold, and 10-year Treasury bond price, respectively).
  id: totrans-2466
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是要估计哪个S&P 500指数、金价和10年期国债价格变量的组合与人民币汇率的相关性最高。出于实际考虑，我们使用交易所交易基金CYN作为人民币/美元汇率（类似地，SPY、GLD和TLT分别代表标普500指数、现货金价和10年期国债价格）的代理。
- en: Note
  id: totrans-2467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Automation of features extraction**'
  id: totrans-2468
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征提取自动化**'
- en: The code in this section implements an ad hoc extraction of features with an
    arbitrary fixed set of models. The process can be easily automated with an optimizer
    (the gradient descent, genetic algorithm, and so on) using *1/RSS* as the objective
    function.
  id: totrans-2469
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码实现了一个使用任意固定模型集的特征提取。该过程可以使用优化器（梯度下降、遗传算法等）通过将*1/RSS*作为目标函数来轻松自动化。
- en: 'The number of models to evaluate is relatively small, so an ad hoc approach
    to compute the RSS for each combination is acceptable. Let''s take a look at the
    following graph:'
  id: totrans-2470
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估的模型数量相对较小，因此对每个组合计算RSS的临时方法是可以接受的。让我们看一下以下图表：
- en: '![Test case 2 – feature selection](img/image01391.jpeg)'
  id: totrans-2471
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例2 – 特征选择](img/image01391.jpeg)'
- en: The graph of the Chinese Yuan exchange rate, gold price, 10-year Treasury bond
    price, and S&P 500 index
  id: totrans-2472
  prefs: []
  type: TYPE_NORMAL
  zh: 人民币汇率、金价、10年期国债价格和标普500指数的图表
- en: 'The `getRss` method implements the computation of the RSS value given a set
    of `xt` observations, `y` expected (smoothed) values, and `featureLabels` labels
    for features and then returns a textual result:'
  id: totrans-2473
  prefs: []
  type: TYPE_NORMAL
  zh: '`getRss`方法实现了给定一组`xt`观测值、`y`预期（平滑）值和`featureLabels`特征标签的RSS值的计算，然后返回一个文本结果：'
- en: '[PRE207]'
  id: totrans-2474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE207]'
- en: The `getRss` method merely trains the model by instantiating the multilinear
    regression class (line `23`). Once the regression model is trained during the
    instantiation of the `MultiLinearRegression` class, the coefficients of the regression
    weights and the RSS values are stringized (line `24`). The `getRss` method is
    invoked for any combination of the ETF, GLD, SPY, and TLT variables against the
    CNY label.
  id: totrans-2475
  prefs: []
  type: TYPE_NORMAL
  zh: '`getRss`方法仅通过实例化多线性回归类（第23行）来训练模型。一旦在`MultiLinearRegression`类的实例化过程中训练了回归模型，回归权重的系数和RSS值就会被字符串化（第24行）。`getRss`方法被调用于ETF、GLD、SPY和TLT变量对CNY标签的任何组合。'
- en: 'Let''s take a look at the following test code:'
  id: totrans-2476
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下下面的测试代码：
- en: '[PRE208]'
  id: totrans-2477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE208]'
- en: 'The dataset is large (1,260 trading sessions) and noisy enough to warrant filtering
    using a simple moving average with a period of 16 trading sessions (line `25`).
    The purpose of the test is to evaluate the possible correlation between the four
    ETFs: CNY, GLD, SPY, and TLT (line `26`). The execution test instantiates the
    simple moving average (line `27`), as described in the *The simple moving average*
    section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"),
    *Data Preprocessing*.'
  id: totrans-2478
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集很大（1,260 个交易日）且噪声足够，需要使用16个交易日的简单移动平均进行过滤（第 `25` 行）。测试的目的是评估四个ETF（CNY、GLD、SPY
    和 TLT）之间可能的相关性。执行测试时实例化了简单移动平均（第 `27` 行），如第3章中 *简单移动平均* 部分所述，[第3章](part0172.xhtml#aid-5410O2
    "第3章。数据预处理")，*数据预处理*。
- en: 'The workflow executes the following steps:'
  id: totrans-2479
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程执行以下步骤：
- en: Instantiate a simple moving average `pfnMovAve` partial function (line `28`).
  id: totrans-2480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个简单的移动平均 `pfnMovAve` 部分函数（第 `28` 行）。
- en: 'Generate smoothed historical prices for the CNY, GLD, SPY, and TLT ETFs using
    the `filter` function (line `29`):'
  id: totrans-2481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `filter` 函数（第 `29` 行）为 CNY、GLD、SPY 和 TLT ETFs 生成平滑的历史价格：
- en: '[PRE209]'
  id: totrans-2482
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: 'Generate the list of features for each model using the `createModels` method
    (line `30`):'
  id: totrans-2483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `createModels` 方法（第 `30` 行）为每个模型生成特征列表：
- en: '[PRE210]'
  id: totrans-2484
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: The smoothed values for CNY are used as the expected values. Therefore, they
    are removed from the features list (line `33`). The five models are evaluated
    by adding or removing elements from the features list (line `34`).
  id: totrans-2485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 CNY 的平滑值作为预期值。因此，它们被从特征列表中移除（第 `33` 行）。通过向特征列表中添加或删除元素来评估五个模型（第 `34` 行）。
- en: 'Next, the workflow computes the residual sum of squares for all the models
    using `getModelsRss` (line `31`). The method invokes `getRss`, which was introduced
    earlier in this section, for each model (line `35`):'
  id: totrans-2486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，工作流程使用 `getModelsRss`（第 `31` 行）计算所有模型的残差平方和。该方法对每个模型调用 `getRss`，该函数在本节前面已介绍（第
    `35` 行）：
- en: '[PRE211]'
  id: totrans-2487
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: 'Finally, the last step of the workflow consists of computing the `mses` mean
    squared errors for each model and the total squared errors (line `33`):'
  id: totrans-2488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，工作流程的最后一个步骤是计算每个模型的 `mses` 平均平方误差和总平方误差（第 `33` 行）：
- en: '[PRE212]'
  id: totrans-2489
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: The `totalSquaresError` method computes the error for each model by summing
    the RSS value, `rssSum`, for each model (line `36`). The method returns a pair
    of an array of the mean squared error for each model and the total squared error
    (line `37`).
  id: totrans-2490
  prefs: []
  type: TYPE_NORMAL
  zh: '`totalSquaresError` 方法通过为每个模型累加 RSS 值 `rssSum` 来计算每个模型的误差（第 `36` 行）。该方法返回一个包含每个模型的平均平方误差数组和总平方误差的数组（第
    `37` 行）。'
- en: The RSS does not always provide an accurate visualization of the fitness of
    the regression model. The fitness of the regression model is commonly assessed
    using the **r² statistics**. The r² value is a number that indicates how well
    data fits into a statistical model.
  id: totrans-2491
  prefs: []
  type: TYPE_NORMAL
  zh: RSS 并不总是能准确展示回归模型的适用性。回归模型的适用性通常通过 **r² 统计量** 来评估。r² 值是一个数字，表示数据与统计模型拟合的程度。
- en: Note
  id: totrans-2492
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M4: The RSS and r² statistics are defined by the following formulae:'
  id: totrans-2493
  prefs: []
  type: TYPE_NORMAL
  zh: M4：RSS 和 r² 统计量由以下公式定义：
- en: '![Test case 2 – feature selection](img/image01392.jpeg)'
  id: totrans-2494
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例 2 – 特征选择](img/image01392.jpeg)'
- en: 'The implementation of the computation of the r² statistics is simple. For each
    model *f[j]*, the `rssSum` method computes the tuple (rss and least squares errors),
    as defined in the **M4** formula:'
  id: totrans-2495
  prefs: []
  type: TYPE_NORMAL
  zh: r² 统计量的计算实现很简单。对于每个模型 *f[j]*，`rssSum` 方法计算由 **M4** 公式定义的元组（rss 和最小二乘误差）：
- en: '[PRE213]'
  id: totrans-2496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE213]'
- en: 'The `rssSum` method instantiates the `MultiLinearRegression` class (line `38`),
    retrieves the RSS value, and then validates the `pfnRegr` regressive model (line
    `39`) against the expected values (line `40`). The output of the test is presented
    in the following screenshot:'
  id: totrans-2497
  prefs: []
  type: TYPE_NORMAL
  zh: '`rssSum` 方法实例化 `MultiLinearRegression` 类（第 `38` 行），检索 RSS 值，然后验证 `pfnRegr`
    回归模型（第 `39` 行）与预期值（第 `40` 行）的匹配度。测试的输出结果如下截图所示：'
- en: '![Test case 2 – feature selection](img/image01393.jpeg)'
  id: totrans-2498
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例 2 – 特征选择](img/image01393.jpeg)'
- en: The output results clearly show that the three variable regression, *CNY = f
    (SPY, GLD, TLT)*, is the most accurate or fittest model for the CNY time series,
    followed by *CNY = f (SPY, TLT)*. Therefore, the feature selection process generates
    the features set, *{SPY, GLD, TLT}*.
  id: totrans-2499
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果清楚地显示，三个变量回归，*CNY = f (SPY, GLD, TLT)*，是最准确或最合适的模型，其次是 *CNY = f (SPY, TLT)*。因此，特征选择过程生成了特征集，*{SPY,
    GLD, TLT}*。
- en: 'Let''s plot the model against the raw data:'
  id: totrans-2500
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制模型与原始数据的关系图：
- en: '![Test case 2 – feature selection](img/image01394.jpeg)'
  id: totrans-2501
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例 2 – 特征选择](img/image01394.jpeg)'
- en: Ordinary least regression on the Chinese Yuan ETF (CNY)
  id: totrans-2502
  prefs: []
  type: TYPE_NORMAL
  zh: 对人民币ETF（CNY）的普通最小二乘回归
- en: 'The regression model smoothed the original CNY time series. It weeded out all
    but the most significant price variation. The graph plotting the r² value for
    each of the model confirms that the three features model *CNY=f (SPY, GLD, TLT)*
    is the most accurate:'
  id: totrans-2503
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型对原始人民币时间序列进行了平滑处理。它去除了除了最显著的价格变动之外的所有变动。绘制每个模型r²值的图表证实，三个特征模型*CNY=f (SPY,
    GLD, TLT)*是最准确的：
- en: '![Test case 2 – feature selection](img/image01395.jpeg)'
  id: totrans-2504
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例2 – 特征选择](img/image01395.jpeg)'
- en: Note
  id: totrans-2505
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The general linear regression**'
  id: totrans-2506
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般线性回归**'
- en: 'The concept of a linear regression is not restricted to polynomial fitting
    models such as *y = w[0] + w[1].x + w[2].x² + …+ w[n]x^n*. Regression models can
    be also defined as a linear combination of basis functions such as *ϕ[j]: y =
    w[0] + w[1].ϕ[1](x) + w[2]ϕ[2](x) + … + w[n].ϕ[n](x)* [6:9].'
  id: totrans-2507
  prefs: []
  type: TYPE_NORMAL
  zh: '线性回归的概念不仅限于多项式拟合模型，如*y = w[0] + w[1].x + w[2].x² + …+ w[n]x^n*。回归模型也可以定义为基函数的线性组合，如*ϕ[j]:
    y = w[0] + w[1].ϕ[1](x) + w[2]ϕ[2](x) + … + w[n].ϕ[n](x)* [6:9]。'
- en: Regularization
  id: totrans-2508
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化
- en: The ordinary least squares method for finding the regression parameters is a
    specific case of the maximum likelihood. Therefore, regression models are subject
    to the same challenge in terms of overfitting as any other discriminative models.
    You are already aware of the fact that regularization is used to reduce model
    complexity and avoid overfitting, as stated in the *Overfitting* section in [Chapter
    2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*
  id: totrans-2509
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找回归参数的普通最小二乘法是最大似然的一个特例。因此，回归模型在过拟合方面面临着与其他任何判别模型相同的挑战。您已经知道，正则化用于减少模型复杂度并避免过拟合，正如在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中的*过拟合*部分所述，*Hello World!*。
- en: L[n] roughness penalty
  id: totrans-2510
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: L[n]粗糙度惩罚
- en: '**Regularization** consists of adding a *J(w)* penalty function to the loss
    function (or RSS in the case of a regressive classifier) in order to prevent the
    model parameters (also known as weights) from reaching high values. A model that
    fits a training set very well tends to have many features variables with relatively
    large weights. This process is known as **shrinkage**. Practically, shrinkage
    involves adding a function with model parameters as an argument to the loss function
    (**M5**):'
  id: totrans-2511
  prefs: []
  type: TYPE_NORMAL
  zh: '**正则化**包括向损失函数（或回归分类中的均方误差）中添加一个*J(w)*惩罚函数，以防止模型参数（也称为权重）达到高值。一个非常适合训练集的模型往往具有许多具有相对较大权重的特征变量。这个过程被称为**收缩**。实际上，收缩涉及将一个以模型参数为参数的函数添加到损失函数中（**M5**）：'
- en: '![Ln roughness penalty](img/image01396.jpeg)'
  id: totrans-2512
  prefs: []
  type: TYPE_IMG
  zh: '![L[n]粗糙度惩罚](img/image01396.jpeg)'
- en: 'The penalty function is completely independent of the training set *{x,y}*.
    The penalty term is usually expressed as a power to the function of the norm of
    the model parameters (or weights) *w[d]*. For a model of *D* dimension, the generic
    **L[p] -norm** is defined as follows (**M6**):'
  id: totrans-2513
  prefs: []
  type: TYPE_NORMAL
  zh: 惩罚函数与训练集*x,y*完全独立。惩罚项通常表示为模型参数（或权重）*w[d]*的范数的函数的幂。对于一个*D*维度的模型，通用的**L[p] -范数**定义为以下（**M6**）：
- en: '![Ln roughness penalty](img/image01397.jpeg)'
  id: totrans-2514
  prefs: []
  type: TYPE_IMG
  zh: '![L[n]粗糙度惩罚](img/image01397.jpeg)'
- en: Note
  id: totrans-2515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Notation**'
  id: totrans-2516
  prefs: []
  type: TYPE_NORMAL
  zh: '**符号**'
- en: Regularization applies to parameters or weights associated with observations.
    In order to be consistent with our notation, *w[0]* being the intercept value,
    the regularization applies to the parameters *w[1]…w[d]*.
  id: totrans-2517
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化适用于与观测值相关的参数或权重。为了与我们的符号一致，*w[0]*是截距值，正则化适用于参数*w[1]…w[d]*。
- en: The two most commonly used penalty functions for regularization are L[1] and
    L[2].
  id: totrans-2518
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的两种正则化惩罚函数是L[1]和L[2]。
- en: Note
  id: totrans-2519
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Regularization in machine learning**'
  id: totrans-2520
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习中的正则化**'
- en: The regularization technique is not specific to the linear or logistic regression.
    Any algorithm that minimizes the residual sum of squares, such as a support vector
    machine or feed-forward neural network, can be regularized by adding a roughness
    penalty function to the RSS.
  id: totrans-2521
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化技术不仅限于线性或逻辑回归。任何最小化残差平方和的算法，如支持向量机或前馈神经网络，都可以通过向均方误差添加粗糙度惩罚函数来进行正则化。
- en: The L[1] regularization applied to the linear regression is known as the **lasso
    regularization**. The **ridge regression** is a linear regression that uses the
    L[2] regularization penalty.
  id: totrans-2522
  prefs: []
  type: TYPE_NORMAL
  zh: 应用到线性回归的L[1]正则化被称为**lasso正则化**。**岭回归**是一种使用L[2]正则化惩罚的线性回归。
- en: 'You may wonder which regularization makes sense for a given training set. In
    a nutshell, L[2] and L[1] regularizations differ in terms of computation efficiency,
    estimation, and features selection [6:10] [6:11]:'
  id: totrans-2523
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道哪种正则化对给定的训练集有意义。简而言之，L[2] 和 L[1] 正则化在计算效率、估计和特征选择方面有所不同 [6:10] [6:11]：
- en: '**Model estimation**: L[1] generates a sparser estimation of the regression
    parameters than L[2]. For a large nonsparse dataset, L[2] has a smaller estimation
    error than L[1].'
  id: totrans-2524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型估计**：L[1] 生成的回归参数估计比 L[2] 更稀疏。对于大型非稀疏数据集，L[2] 的估计误差比 L[1] 小。'
- en: '**Feature selection**: L[1] is more effective in reducing the regression weights
    for features with a higher value than L[2]. Therefore, L1 is a reliable features
    selection tool.'
  id: totrans-2525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**：L[1] 在减少具有较高值的特征回归权重方面比 L[2] 更有效。因此，L1 是一个可靠的特性选择工具。'
- en: '**Overfitting**: Both L[1] and L[2] reduce the impact of overfitting. However,
    L[1] has a significant advantage in overcoming overfitting (or excessive complexity
    of a model); for the same reason, L[1] is more appropriate for selecting features.'
  id: totrans-2526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：L[1] 和 L[2] 都能减少过拟合的影响。然而，L[1] 在克服过拟合（或模型过度复杂性）方面具有显著优势；因此，L[1] 更适合于特征选择。'
- en: '**Computation**: L[2] is conducive to a more efficient computation model. The
    summation of the loss function and L[2] penalty, *w²*, is a continuous and differentiable
    function for which the first and second derivatives can be computed (**convex
    minimization**). The L1 term is the summation of *|w[i]|* and therefore not differentiable.'
  id: totrans-2527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算**：L[2] 有助于更高效的计算模型。损失函数和 L[2] 惩罚项 *w²* 的和是一个连续且可微的函数，其第一和第二导数可以计算（**凸最小化**）。L1
    项是 *|w[i]|* 的和，因此不可微。'
- en: Note
  id: totrans-2528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Terminology**'
  id: totrans-2529
  prefs: []
  type: TYPE_NORMAL
  zh: '**术语**'
- en: The ridge regression is sometimes called the **penalized least squares regression**.
    The L[2] regularization is also known as the **weight decay**.
  id: totrans-2530
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归有时被称为 **惩罚最小二乘回归**。L[2] 正则化也称为 **权重衰减**。
- en: Let's implement the ridge regression, and then evaluate the impact of the L[2]-norm
    penalty factor.
  id: totrans-2531
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现岭回归，然后评估 L[2]-范数惩罚因子的影响。
- en: Ridge regression
  id: totrans-2532
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 岭回归
- en: 'The ridge regression is a multivariate linear regression with an L[2]-norm
    penalty term (**M7**):'
  id: totrans-2533
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归是一个具有 L[2]-范数惩罚项的多变量线性回归（**M7**）：
- en: '![Ridge regression](img/image01398.jpeg)'
  id: totrans-2534
  prefs: []
  type: TYPE_IMG
  zh: '![岭回归](img/image01398.jpeg)'
- en: The computation of the ridge regression parameters requires the resolution of
    a system of linear equations that are similar to the linear regression.
  id: totrans-2535
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归参数的计算需要解决与线性回归相似的线性方程组。
- en: Note
  id: totrans-2536
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: 'M8: The matrix representation of ridge regression closed form for an input
    dataset *X*, a regularization factor *λ*, and expected values vector *y* is defined
    as follows (*I* is the identity matrix):'
  id: totrans-2537
  prefs: []
  type: TYPE_NORMAL
  zh: M8：对于输入数据集 *X*、正则化因子 *λ* 和期望值向量 *y* 的岭回归闭式矩阵表示定义为以下（*I* 是单位矩阵）：
- en: '![Ridge regression](img/image01399.jpeg)'
  id: totrans-2538
  prefs: []
  type: TYPE_IMG
  zh: '![岭回归](img/image01399.jpeg)'
- en: 'M9: The matrices equation is resolved using the QR decomposition as follows:'
  id: totrans-2539
  prefs: []
  type: TYPE_NORMAL
  zh: M9：矩阵方程通过以下 QR 分解求解：
- en: '![Ridge regression](img/image01400.jpeg)'
  id: totrans-2540
  prefs: []
  type: TYPE_IMG
  zh: '![岭回归](img/image01400.jpeg)'
- en: Design
  id: totrans-2541
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计
- en: 'The implementation of the ridge regression adds the L[2] regularization term
    to the multiple linear regression computation of the Apache Commons Math Library.
    The methods of `RidgeRegression` have the same signature as their ordinary least
    squares counterparts except for the `lambda` L[2] penalty term (line `1`):'
  id: totrans-2542
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归的实现将 L[2] 正则化项添加到 Apache Commons Math 库的多元线性回归计算中。`RidgeRegression` 方法与它们的普通最小二乘对应方法具有相同的签名，除了
    `lambda` L[2] 惩罚项（行 `1`）：
- en: '[PRE214]'
  id: totrans-2543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE214]'
- en: The `RidgeRegression` class is implemented as an `ITransform` data transformation
    whose model is implicitly derived from the input data (training set), as described
    in the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!* (line `2`). The `V` type of the output
    of the `|>` predictive function is a `Double` (line `3`). The model is created
    through training during the instantiation of the class (line `4`).
  id: totrans-2544
  prefs: []
  type: TYPE_NORMAL
  zh: '`RidgeRegression` 类被实现为一个 `ITransform` 数据转换，其模型隐式地从输入数据（训练集）中导出，如第 2 章中 *Monadic
    数据转换* 部分所述，*Hello World!*（行 `2`）。`|>` 预测函数的输出 `V` 类型是 `Double`（行 `3`）。模型在类的实例化过程中通过训练创建（行
    `4`）。'
- en: 'The relationship between the different components of the ridge regression is
    described in the following UML class diagram:'
  id: totrans-2545
  prefs: []
  type: TYPE_NORMAL
  zh: Ridge回归的不同组件之间的关系在以下UML类图中描述：
- en: '![Design](img/image01401.jpeg)'
  id: totrans-2546
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01401.jpeg)'
- en: The UML class diagram for the ridge regression
  id: totrans-2547
  prefs: []
  type: TYPE_NORMAL
  zh: Ridge回归的UML类图
- en: The UML diagram omits the helper traits or classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-2548
  prefs: []
  type: TYPE_NORMAL
  zh: UML图省略了如`Monitor`或Apache Commons Math组件等辅助特性和类。
- en: Implementation
  id: totrans-2549
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: 'Let''s take a look at the training method, `train`:'
  id: totrans-2550
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看训练方法`train`：
- en: '[PRE215]'
  id: totrans-2551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE215]'
- en: It is rather simple; it initialized and executed the regression algorithm implemented
    in the `RidgeRAdapter` class (line `5`), which acts as an adapter to the internal
    Apache Commons Math library `AbstractMultipleLinearRegression` class in the `org.apache.commons.math3.stat.regression`
    package (line `6`). The method returns a fully initialized regression model that
    is similar to the ordinary least squared regression (line `7`).
  id: totrans-2552
  prefs: []
  type: TYPE_NORMAL
  zh: 它相当简单；它初始化并执行了`RidgeRAdapter`类（行`5`）中实现的回归算法，该类作为适配器，适配`org.apache.commons.math3.stat.regression`包中内部Apache
    Commons Math库的`AbstractMultipleLinearRegression`类（行`6`）。该方法返回一个完全初始化的回归模型，类似于普通最小二乘回归（行`7`）。
- en: 'Let''s take a look at the `RidgeRAdapter` adapter class:'
  id: totrans-2553
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`RidgeRAdapter`适配器类：
- en: '[PRE216]'
  id: totrans-2554
  prefs: []
  type: TYPE_PRE
  zh: '[PRE216]'
- en: 'The constructor for the `RidgeRAdapter` class takes two parameters: the `lambda`
    L[2] penalty parameter and the number of features, `dim`, in an observation. The
    QR decomposition in the `AbstractMultipleLinearRegression` base class does not
    process the penalty term (line `8`). Therefore, the creation of the model has
    to be redefined in the `createModel` method (line `9`), which requires to override
    the `newXSampleData` method (line `10`):'
  id: totrans-2555
  prefs: []
  type: TYPE_NORMAL
  zh: '`RidgeRAdapter`类的构造函数接受两个参数：`lambda` L[2]惩罚参数和观察中的特征数量`dim`。`AbstractMultipleLinearRegression`基类中的QR分解不处理惩罚项（行`8`）。因此，必须在`createModel`方法（行`9`）中重新定义模型的创建，这需要覆盖`newXSampleData`方法（行`10`）：'
- en: '[PRE217]'
  id: totrans-2556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE217]'
- en: The `newXSampleData` method overrides the default observations-features `r`
    matrix (line `12`) by adding the `lambda` coefficient to its diagonal elements
    (line `13`), and then updating the QR decomposition components (line `14`).
  id: totrans-2557
  prefs: []
  type: TYPE_NORMAL
  zh: '`newXSampleData`方法通过向其对角线元素添加`lambda`系数（行`13`）来覆盖默认的观察-特征`r`矩阵（行`12`），然后更新QR分解组件（行`14`）。'
- en: 'The weights for the ridge regression models is computed by implementing the
    **M6** formula (line `11`) in the `calculateBeta` overridden method (line `15`):'
  id: totrans-2558
  prefs: []
  type: TYPE_NORMAL
  zh: Ridge回归模型的权重通过在`calculateBeta`覆盖方法（行`15`）中实现**M6**公式（行`11`）来计算：
- en: '[PRE218]'
  id: totrans-2559
  prefs: []
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'The predictive algorithm for the ordinary least squares regression is implemented
    by the `|>` data transformation. The method predicts the output value, given a
    model and an input `x` value (line `16`):'
  id: totrans-2560
  prefs: []
  type: TYPE_NORMAL
  zh: 普通最小二乘回归的预测算法通过`|>`数据转换实现。该方法根据模型和输入的`x`值（行`16`）预测输出值：
- en: '[PRE219]'
  id: totrans-2561
  prefs: []
  type: TYPE_PRE
  zh: '[PRE219]'
- en: Test case
  id: totrans-2562
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试案例
- en: The objective of the test case is to identify the impact of the L[2] penalization
    on the RSS value and then compare the predicted values with the original values.
  id: totrans-2563
  prefs: []
  type: TYPE_NORMAL
  zh: 测试案例的目标是确定L[2]惩罚对RSS值的影响，然后比较预测值与原始值。
- en: 'Let''s consider the first test case related to the regression on the daily
    price variation of the Copper ETF (symbol: CU) using the stock daily volatility
    and volume as features. The implementation of the extraction of observations is
    identical to that for the least squares regression, as described in the previous
    section:'
  id: totrans-2564
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑与铜ETF（符号：CU）每日价格变动回归相关的第一个测试案例，使用股票每日波动性和成交量作为特征。观察提取的实现与上一节中描述的最小二乘回归相同：
- en: '[PRE220]'
  id: totrans-2565
  prefs: []
  type: TYPE_PRE
  zh: '[PRE220]'
- en: 'Let''s take a look at the steps required for the execution of the test. The
    steps consist of collecting data, extracting the features and expected values,
    and training the ridge regression model:'
  id: totrans-2566
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看执行测试所需的步骤。这些步骤包括收集数据、提取特征和期望值，以及训练Ridge回归模型：
- en: Create a data source extractor for the `price` trading session closing, the
    `volatility` session, and the `volume` session for the ETF CU using the `DataSource`
    transformation (line `17`).
  id: totrans-2567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DataSource`转换创建ETF CU的`价格`交易时段收盘、`波动性`时段和`成交量`时段的数据源提取器（行`17`）。
- en: Extract the closing `price` of the ETF (line `18`), its `volatility` within
    a trading session (line `19`), and the `volume` trading during the same session
    (line `20`).
  id: totrans-2568
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取ETF（交易代码：CU）的收盘`价格`（行`18`），交易时段内的`波动性`（行`19`），以及同一时段内的`成交量`（行`20`）。
- en: Generate the labeled data as a pair of features (the relative volatility and
    relative volume for the ETF) and the `expected` outcome *{0, 1}* for training
    the model, where `1` represents the increase in the price and `0` represents the
    decrease in the price (line 21). The `differentialData` generic method of the
    `XTSeries` singleton is described in the *Time series in Scala* section in [Chapter
    3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"), *Data Preprocessing*.
  id: totrans-2569
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成标记数据作为特征对（ETF的相对波动性和相对成交量）以及用于训练模型的预期结果 *{0, 1}*，其中`1`代表价格上涨，`0`代表价格下跌（第21行）。`XTSeries`单例的`differentialData`通用方法在[第3章](part0172.xhtml#aid-5410O2
    "第3章 数据预处理")的*Scala中的时间序列*部分中描述，*数据预处理*。
- en: Instantiate the ridge regression using the `features` set and the `expected`
    change in the daily stock price (line `22`).
  id: totrans-2570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`features`集和每日股票价格预期的变化（第22行）来实例化岭回归。
- en: Compute the `trend` values using the `dot` function of the `RegressionModel`
    singleton (line `23`).
  id: totrans-2571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`RegressionModel`单例的`dot`函数计算`trend`值（第23行）。
- en: Execute a using the ridge regression is implemented by the `predict` method
    (line `24`).
  id: totrans-2572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过`predict`方法实现岭回归的执行（第24行）。
- en: 'The code is as follows:'
  id: totrans-2573
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE221]'
  id: totrans-2574
  prefs: []
  type: TYPE_PRE
  zh: '[PRE221]'
- en: 'The observations are extracted from the `volatility` and `volume` time series
    (line `25`). The predictive method for the `fnRegr` ridge regression (line `26`)
    is applied to each observation (line `27`). The RSS value, `rss`, is plotted for
    different values of *λ*, as shown in the following chart:'
  id: totrans-2575
  prefs: []
  type: TYPE_NORMAL
  zh: 观察值是从`volatility`和`volume`时间序列中提取的（第25行）。将`fnRegr`岭回归的预测方法（第26行）应用于每个观察值（第27行）。RSS值，`rss`，以不同λ值绘制，如下面的图表所示：
- en: '![Test case](img/image01402.jpeg)'
  id: totrans-2576
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例](img/image01402.jpeg)'
- en: The graph of RSS versus lambda for the Copper ETF
  id: totrans-2577
  prefs: []
  type: TYPE_NORMAL
  zh: 铜ETF的RSS与λ的图形
- en: The residual sum of squares decreases as *λ* increases. The curve seems to be
    reaching for a minimum around *λ = 1*. The case of *λ = 0* corresponds to the
    least squares regression.
  id: totrans-2578
  prefs: []
  type: TYPE_NORMAL
  zh: 随着λ的增加，残差平方和减少。曲线似乎在λ ≈ 1附近达到最小值。λ = 0的情况对应于最小二乘回归。
- en: 'Next, let''s plot the RSS value for *λ* varying between 1 and 100:'
  id: totrans-2579
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们绘制λ在1到100之间变化的RSS值图：
- en: '![Test case](img/image01403.jpeg)'
  id: totrans-2580
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例](img/image01403.jpeg)'
- en: The graph of RSS versus a large value Lambda for the Copper ETF
  id: totrans-2581
  prefs: []
  type: TYPE_NORMAL
  zh: 铜ETF的RSS与一个大的Lambda值的图形
- en: This time around, the value of RSS increases with *λ* before reaching a maximum
    for *λ > 60*. This behavior is consistent with other findings [6:12]. As *λ* increases,
    the overfitting gets more expensive, and therefore, the RSS value increases.
  id: totrans-2582
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，RSS值随着λ的增加而增加，在λ > 60时达到最大值。这种行为与其他发现[6:12]一致。随着λ的增加，过拟合的成本更高，因此RSS值增加。
- en: 'Let''s plot the predicted price variation of the Copper ETF using the ridge
    regression with different values of lambda (*λ*):'
  id: totrans-2583
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用不同值的 lambda (*λ*) 来绘制铜ETF的预测价格变化图：
- en: '![Test case](img/image01404.jpeg)'
  id: totrans-2584
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例](img/image01404.jpeg)'
- en: The graph of ridge regression on the Copper ETF price variation with a variable,
    lambda
  id: totrans-2585
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归在铜ETF价格变化上的图形，λ值可变
- en: 'The original price variation of the Copper ETF, *Δ = price(t + 1) - price(t)*,
    is plotted as *λ = 0*. Let''s analyze the behavior of the predictive model for
    different values of *λ*:'
  id: totrans-2586
  prefs: []
  type: TYPE_NORMAL
  zh: 铜ETF的原价变化 *Δ = price(t + 1) - price(t)*，以λ = 0绘制。让我们分析不同λ值的预测模型的行为：
- en: The predicted values for *λ = 0.8* is very similar to the original data.
  id: totrans-2587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测值 *λ = 0.8* 与原始数据非常相似。
- en: The predicted values for *λ = 2* follow the pattern of the original data with
    a reduction of large variations (peaks and troves).
  id: totrans-2588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测值 *λ = 2* 沿着原始数据模式，但大幅度变化（峰值和低谷）减少。
- en: The predicted values for *λ = 5* corresponds to a smoothed dataset. The pattern
    of the original data is preserved but the magnitude of the price variation is
    significantly reduced.
  id: totrans-2589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测值 *λ = 5* 对应于一个平滑的数据集。原始数据模式得以保留，但价格变化的幅度显著降低。
- en: The logistic regression, which was briefly introduced in the *Let's kick the
    tires* section in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"),
    *Getting Started*, is the next logical regression model to be discussed. The logistic
    regression relies on optimization methods. Let's go through a short refresher
    course in optimization before diving into the logistic regression.
  id: totrans-2590
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](part0155.xhtml#aid-4JQ761 "第1章 入门")的*让我们试试看*部分简要介绍的逻辑回归是下一个要讨论的逻辑回归模型。逻辑回归依赖于优化方法。在深入研究逻辑回归之前，让我们先快速复习一下优化课程。
- en: Numerical optimization
  id: totrans-2591
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值优化
- en: This section briefly introduces the different optimization algorithms that can
    be applied to minimize the loss function, with or without a penalty term. These
    algorithms are described in more detail in the *Summary of optimization techniques*
    section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*.
  id: totrans-2592
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要介绍了可以应用于最小化损失函数的不同的优化算法，无论是否有惩罚项。这些算法在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")的*优化技术总结*部分有更详细的描述，*基本概念*。
- en: First, let's define the **least squares problem**. The minimization of the loss
    function consists of nullifying the first order derivatives, which in turn generates
    a system of *D* equations (also known as the gradient equations), *D* being the
    number of regression weights (parameters). The weights are iteratively computed
    by solving the system of equations using a numerical optimization algorithm.
  id: totrans-2593
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义**最小二乘问题**。损失函数的最小化包括消除一阶导数，这反过来又生成一个包含 *D* 个方程的系统（也称为梯度方程），其中 *D* 是回归权重（参数）的数量。权重通过使用数值优化算法求解该方程组进行迭代计算。
- en: Note
  id: totrans-2594
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M10: The definition of the least squares-based loss function for residual *r[i]*,
    weights *w*, a model *f*, input data *x[i]*, and expected values *y[i]* is as
    follows:'
  id: totrans-2595
  prefs: []
  type: TYPE_NORMAL
  zh: M10：基于最小二乘法的残差 *r[i]*、权重 *w*、模型 *f*、输入数据 *x[i]* 和期望值 *y[i]* 的损失函数定义如下：
- en: '![Numerical optimization](img/image01405.jpeg)'
  id: totrans-2596
  prefs: []
  type: TYPE_IMG
  zh: '![数值优化](img/image01405.jpeg)'
- en: 'M10: The generation of gradient equations with a Jacobian *J* matrix (refer
    to the *Mathematics* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*) after minimization of the loss function *L* is defined
    as follows:'
  id: totrans-2597
  prefs: []
  type: TYPE_NORMAL
  zh: M10：在损失函数 *L* 最小化后，生成具有雅可比矩阵 *J* 的梯度方程（参见[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*数学*部分，*基本概念*）的定义如下：
- en: '![Numerical optimization](img/image01406.jpeg)'
  id: totrans-2598
  prefs: []
  type: TYPE_IMG
  zh: '![数值优化](img/image01406.jpeg)'
- en: 'M11: The iterative approximation using the Taylor series on the model *f* for
    *k* iterations on the computation of weights *w* is defined as follows:'
  id: totrans-2599
  prefs: []
  type: TYPE_NORMAL
  zh: M11：使用泰勒级数在模型 *f* 上对权重 *w* 进行 *k* 次迭代的迭代近似定义为以下内容：
- en: '![Numerical optimization](img/image01407.jpeg)'
  id: totrans-2600
  prefs: []
  type: TYPE_IMG
  zh: '![数值优化](img/image01407.jpeg)'
- en: 'The logistic regression is a nonlinear function. Therefore, it requires the
    nonlinear minimization of the sum of least squares. The optimization algorithms
    for the nonlinear least squares problems can be divided into two categories:'
  id: totrans-2601
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一个非线性函数。因此，它需要最小化平方和的非线性最小化。非线性最小二乘问题的优化算法可以分为两类：
- en: '**Newton** (or 2nd order techniques): These algorithms calculate the second
    order derivatives (the Hessian matrix) to compute the regression weights that
    nullify the gradient. The two most common algorithms in this category are the
    Gauss-Newton and Levenberg-Marquardt methods (refer to the *Nonlinear least squares
    minimization* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*). Both algorithms are included in the Apache Commons
    Math library.'
  id: totrans-2602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**牛顿**（或二阶技术）：这些算法通过计算二阶导数（Hessian 矩阵）来计算消除梯度的回归权重。这一类别中最常见的两种算法是高斯-牛顿法和Levenberg-Marquardt方法（参见[附录A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念")中的*非线性最小二乘最小化*部分，*基本概念*）。这两种算法都包含在Apache Commons Math库中。'
- en: '**Quasi-Newton** (or 1^(st) order techniques): First order algorithms do not
    compute but estimate the second order derivatives of the least squares residuals
    from the Jacobian matrix. These methods can minimize any real-valued functions,
    not just the least squares summation. This category of algorithms includes the
    Davidon-Fletcher-Powell and the Broyden-Fletcher-Goldfarb-Shannon methods (refer
    to the *Quasi-Newton algorithms* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).'
  id: totrans-2603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拟牛顿**（或一阶技术）：一阶算法不计算而是估计从雅可比矩阵中得到的平方残差的一阶导数。这些方法可以最小化任何实值函数，而不仅仅是平方和。这一类算法包括Davidon-Fletcher-Powell和Broyden-Fletcher-Goldfarb-Shannon方法（参见[附录A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念")中的*拟牛顿算法*部分，*基本概念*）。'
- en: Logistic regression
  id: totrans-2604
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Despite its name, the *logistic regression is a classifier*. As a matter of
    fact, the logistic regression is one of the most commonly used discriminative
    learning techniques because of its simplicity and its ability to leverage a large
    variety of optimization algorithms. The technique is used to quantify the relationship
    between an observed target (or expected) variable *y* and a set of variables *x*
    that it depends on. Once the model is created (trained), it is available to classify
    real-time data.
  id: totrans-2605
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管名为“逻辑回归”，但它实际上是一个分类器。事实上，由于它的简单性和能够利用大量优化算法的能力，逻辑回归是最常用的判别学习技术之一。该技术用于量化观察到的目标（或预期）变量
    *y* 与它所依赖的一组变量 *x* 之间的关系。一旦模型创建（训练）完成，它就可以用于对实时数据进行分类。
- en: A logistic regression can be either binomial (two classes) or multinomial (three
    or more classes). In a binomial classification, the observed outcome is defined
    as *{true, false}*, *{0, 1}*, or *{-1, +1}*.
  id: totrans-2606
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归可以是二项分类（两个类别）或多项分类（三个或更多类别）。在二项分类中，观察到的结果被定义为 *{true, false}*, *{0, 1}*,
    或 *{-1, +1}*。
- en: Logistic function
  id: totrans-2607
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: The conditional probability in a linear regression model is a linear function
    of its weights [6:13]. The logistic regression model addresses the nonlinear regression
    problem by defining the logarithm of the conditional probability as a linear function
    of its parameters.
  id: totrans-2608
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型中的条件概率是其权重的线性函数[6:13]。逻辑回归模型通过将条件概率的对数定义为参数的线性函数来解决非线性回归问题。
- en: 'First, let''s introduce the logistic function and its derivative, which are
    defined as follows (M12):'
  id: totrans-2609
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们介绍逻辑函数及其导数，它们被定义为以下（M12）：
- en: '![Logistic function](img/image01408.jpeg)'
  id: totrans-2610
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑函数](img/image01408.jpeg)'
- en: 'The logistic function and its derivative are illustrated in the following graph:'
  id: totrans-2611
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数及其导数在以下图中展示：
- en: '![Logistic function](img/image01409.jpeg)'
  id: totrans-2612
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑函数](img/image01409.jpeg)'
- en: The graph of the logistic function and its derivative
  id: totrans-2613
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数及其导数的图形
- en: The remainder of this section is dedicated to the application of the multivariate
    logistic regression to the binomial classification.
  id: totrans-2614
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的剩余部分致力于将多元逻辑回归应用于二项分类。
- en: Binomial classification
  id: totrans-2615
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二项分类
- en: 'The logistic regression is popular for several reasons; some are as follows:'
  id: totrans-2616
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归因其几个原因而广受欢迎；以下是一些原因：
- en: It is available with most statistical software packages and open source libraries
  id: totrans-2617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在大多数统计软件包和开源库中都是可用的
- en: Its S-shape describes the combined effect of several explanatory variables
  id: totrans-2618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的S形描述了多个解释变量的综合效应
- en: Its range of values [0, 1] is intuitive from a probabilistic perspective
  id: totrans-2619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的值域 [0, 1] 从概率的角度来看是直观的
- en: 'Let''s consider the classification problem using two classes. As discussed
    in the *Validation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*, even the best classifier produces false positives and
    false negatives. The training procedure for a binomial classification is illustrated
    in the following diagram:'
  id: totrans-2620
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑使用两个类别的分类问题。如第2章中“验证”部分所述[part0165.xhtml#aid-4TBCQ2 "第2章。Hello World!"]，“Hello
    World!”，即使是最好的分类器也会产生假阳性和假阴性。二项分类的训练过程在以下图中展示：
- en: '![Binomial classification](img/image01410.jpeg)'
  id: totrans-2621
  prefs: []
  type: TYPE_IMG
  zh: '![二项分类](img/image01410.jpeg)'
- en: An illustration of the binomial classification for a two-dimension dataset
  id: totrans-2622
  prefs: []
  type: TYPE_NORMAL
  zh: 一个二维数据集的二项分类示意图
- en: The purpose of the training is to compute the **hyperplane** that separates
    the observations into two categories or classes. Mathematically speaking, a hyperplane
    in an n-dimensional space (number of features) is a subspace of *n - 1* dimensions,
    as described in the *Manifolds* section in [Chapter 4](part0178.xhtml#aid-59O442
    "Chapter 4. Unsupervised Learning"), *Unsupervised Learning*. The separating hyperplane
    of a three-dimension space is a curved surface. The separating hyperplane of a
    two-dimension problem (plane) is a line. In our preceding example, the hyperplane
    segregates/separates a training set into two very distinct classes (or groups),
    **Class 1** and **Class 2**, in an attempt to reduce the overlap (false positive
    and false negative).
  id: totrans-2623
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的目的是计算将观察值分为两类或类别的 **超平面**。从数学上讲，n 维空间（特征数量）中的超平面是 *n - 1* 维的子空间，如第 4 章 [第
    4. 无监督学习](part0178.xhtml#aid-59O442 "第 4 章。无监督学习")中的 *流形* 部分所述，*无监督学习*。三维空间中的分隔超平面是一个曲面。二维问题（平面）的分隔超平面是一条线。在我们前面的例子中，超平面将训练集分割成两个非常不同的类别（或组），**类别
    1** 和 **类别 2**，试图减少重叠（假阳性和假阴性）。
- en: The equation of the hyperplane is defined as the logistic function of the dot
    product of the regression parameters (or weights) and features.
  id: totrans-2624
  prefs: []
  type: TYPE_NORMAL
  zh: 超平面的方程定义为回归参数（或权重）与特征的点积的逻辑函数。
- en: The logistic function accentuates the difference between the two groups of training
    observations, separated by the hyperplane. It *pushes the observations away* from
    the separating hyperplane toward either classes.
  id: totrans-2625
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数强调了由超平面分隔的两个训练观察组之间的差异。它 *将观察值推向* 分隔超平面的任一类别。
- en: In the case of two classes, *c1* and *c2* with their respective probabilities,
    *p(C=c1| X=x[i]|w) = p(x[i]|w)* and *p(C=c2 |X= x[i]|w) = 1- p(x[i]|w)*, where
    *w* is the model parameters set or weights in the case of the logistic regression.
  id: totrans-2626
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个类别 *c1* 和 *c2* 及其相应概率的情况下，*p(C=c1| X=x[i]|w) = p(x[i]|w)* 和 *p(C=c2 |X= x[i]|w)
    = 1- p(x[i]|w)*，其中 *w* 是模型参数集或权重，在逻辑回归的情况下。
- en: Note
  id: totrans-2627
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The logistic regression**'
  id: totrans-2628
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**'
- en: 'M13: The log likelihood for *N* observations *x[i]* given regression weights
    *w* is defined as:'
  id: totrans-2629
  prefs: []
  type: TYPE_NORMAL
  zh: M13：给定回归权重 *w* 的 *N* 个观察值 *x[i]* 的对数似然定义为：
- en: '![Binomial classification](img/image01411.jpeg)'
  id: totrans-2630
  prefs: []
  type: TYPE_IMG
  zh: '![二项式分类](img/image01411.jpeg)'
- en: 'M14: Conditional probabilities *p(x|w)* with regression weights *w*, using
    the logistic function for *N* observations with *d* features *{x[ij]} [j=0;d-1]*
    is defined as:'
  id: totrans-2631
  prefs: []
  type: TYPE_NORMAL
  zh: M14：使用逻辑函数对 *N* 个观察值 *x[i]* 和 *d* 个特征 *{x[ij]} [j=0;d-1]* 的条件概率 *p(x|w)* 定义如下：
- en: '![Binomial classification](img/image01412.jpeg)'
  id: totrans-2632
  prefs: []
  type: TYPE_IMG
  zh: '![二项式分类](img/image01412.jpeg)'
- en: 'M15: The sum of square errors, *sse*, for the binomial logistic regression
    with weights *w*, input values *x [i]*, and expected binary outcome *y* is as
    follows:'
  id: totrans-2633
  prefs: []
  type: TYPE_NORMAL
  zh: M15：对于具有权重 *w*、输入值 *x [i]* 和预期二元结果 *y* 的二项式逻辑回归，其平方误差和 *sse* 如下：
- en: '![Binomial classification](img/image01413.jpeg)'
  id: totrans-2634
  prefs: []
  type: TYPE_IMG
  zh: '![二项式分类](img/image01413.jpeg)'
- en: 'M16: The computation of the weights *w* of the logistic regression by maximizing
    the log likelihood, given the input data *x[i]* and expected outcome (labels)
    *y[i]* is defined as:'
  id: totrans-2635
  prefs: []
  type: TYPE_NORMAL
  zh: M16：通过最大化给定输入数据 *x[i]* 和预期结果（标签）*y[i]* 的对数似然来计算逻辑回归的权重 *w* 定义如下：
- en: '![Binomial classification](img/image01414.jpeg)'
  id: totrans-2636
  prefs: []
  type: TYPE_IMG
  zh: '![二项式分类](img/image01414.jpeg)'
- en: Let's implement the logistic regression without regularization using the Apache
    Commons Math library. The library contains several least squares optimizers that
    allow you to specify the `optimizer` minimizing algorithm for the loss function
    in the logistic regression class, `LogisticRegression`.
  id: totrans-2637
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Apache Commons Math 库来实现不带正则化的逻辑回归。该库包含几个最小二乘优化器，允许您为逻辑回归类 `LogisticRegression`
    中的损失函数指定 `optimizer` 最小化算法。
- en: 'The constructor for the `LogisticRegression` class follows a very familiar
    pattern: it defines an `ITransform` data transformation, whose model is implicitly
    derived from the input data (training set), as described in the *Monadic data
    transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!* (line `2`). The output of the `|>` predictor is a class
    ID, and therefore, the `V` type of the output is an `Int` (line `3`):'
  id: totrans-2638
  prefs: []
  type: TYPE_NORMAL
  zh: '`LogisticRegression` 类的构造函数遵循一个非常熟悉的模式：它定义了一个 `ITransform` 数据转换，其模型隐式地从输入数据（训练集）中导出，如第
    2 章 [第 2. Hello World!](part0165.xhtml#aid-4TBCQ2 "第 2 章。Hello World!")中的 *单子数据转换*
    部分所述，*Hello World!*（行 `2`）。`|>` 预测器的输出是一个类别 ID，因此输出 `V` 的类型是 `Int`（行 `3`）：'
- en: '[PRE222]'
  id: totrans-2639
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: The parameters of the logistic regression class are the multivariate `xt` time
    series (features), the target or expected classes, `expected`, and the `optimizer`
    used to minimize the loss function or residual sum of squares (line `1`). In the
    case of the binomial logistic regression, `expected` are assigned the value of
    `1` for one class and `0` for the other.
  id: totrans-2640
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归类的参数是多变量 `xt` 时间序列（特征），目标或预期类别 `expected`，以及用于最小化损失函数或残差平方和的 `optimizer`（行
    `1`）。在二项式逻辑回归的情况下，`expected` 被分配给一个类为 `1`，另一个类为 `0` 的值。
- en: The `Monitor` trait is used to collect the profiling information during training
    (refer to the *Monitor* section under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-2641
  prefs: []
  type: TYPE_NORMAL
  zh: '`Monitor` 特性用于在训练过程中收集配置文件信息（参见 [附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")
    中 *实用类* 下的 *Monitor* 部分，*基本概念*）。'
- en: The purpose of the training is to determine the regression weights that minimize
    the loss function, as defined in the **M14** formula as well as the residual sum
    of squares (line `4`).
  id: totrans-2642
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的目的是确定回归权重，以最小化损失函数，如 **M14** 公式定义以及残差平方和（行 `4`）。
- en: Note
  id: totrans-2643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Target values**'
  id: totrans-2644
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标值**'
- en: 'There is no specific rule to assign the two values to the observed data for
    the binomial logistic regression: *{-1, +1}*, *{0, 1}*, or *{false, true}*. The
    values pair *{0, 1}* is convenient because it allows the developer to reuse the
    code for multinomial logistic regression using normalized class values.'
  id: totrans-2645
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二项式逻辑回归，没有将两个值分配给观测数据的特定规则：*{-1, +1}*，*{0, 1}*，或 *{false, true}*. 值对 *{0,
    1}* 很方便，因为它允许开发者重用用于多项式逻辑回归的代码，并使用归一化类别值。
- en: For convenience, the definition and configuration of the optimizer are encapsulated
    in the `LogisticRegressionOptimizer` class.
  id: totrans-2646
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，优化器的定义和配置被封装在 `LogisticRegressionOptimizer` 类中。
- en: Design
  id: totrans-2647
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计
- en: 'The implementation of the logistic regression uses the following components:'
  id: totrans-2648
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的实现使用了以下组件：
- en: A `RegressionModel` model of the `Model` type that is initialized through training
    during the instantiation of the classifier. We reuse the `RegressionModel` type,
    which was introduced in the *Linear regression* section.
  id: totrans-2649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RegressionModel` 模型是 `Model` 类型的，在分类器的实例化过程中通过训练进行初始化。我们重用了在 *线性回归* 部分介绍的
    `RegressionModel` 类型。'
- en: The logistic regression class, `LogisticRegression`, that implements an `ITransform`
    for the prediction of future observations
  id: totrans-2650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现了对未来观测预测的 `ITransform` 的 `LogisticRegression` 类
- en: An adapter class named `RegressionJacobian` for the computation of the Jacobian
  id: totrans-2651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 `RegressionJacobian` 的适配器类，用于计算雅可比矩阵
- en: An adapter class named `RegressionConvergence` to manage the convergence criteria
    and exit condition of the minimization of the sum of square errors
  id: totrans-2652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 `RegressionConvergence` 的适配器类，用于管理平方误差和最小化的收敛标准和退出条件
- en: 'The key software components of the logistic regression are described in the
    following UML class diagram:'
  id: totrans-2653
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的关键软件组件在以下 UML 类图中描述：
- en: '![Design](img/image01415.jpeg)'
  id: totrans-2654
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01415.jpeg)'
- en: The UML class diagram for the logistic regression
  id: totrans-2655
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的 UML 类图
- en: The UML diagram omits the helper traits or classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-2656
  prefs: []
  type: TYPE_NORMAL
  zh: UML 图省略了如 `Monitor` 或 Apache Commons Math 组件之类的辅助特性和类。
- en: The training workflow
  id: totrans-2657
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练工作流程
- en: Our implementation of the training of the logistic regression model leverages
    either the Gauss-Newton or the Levenberg-Marquardt nonlinear least squares optimizers,
    (refer to the *Nonlinear least squares minimization* section in the [Appendix
    A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*)
    packaged with the Apache Commons Math library.
  id: totrans-2658
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对逻辑回归模型的训练实现利用了高斯-牛顿或Levenberg-Marquardt非线性最小二乘优化器，这些优化器包含在 Apache Commons
    Math 库中（参见 [附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念") 中的 *非线性最小二乘最小化* 部分，*基本概念*）。
- en: The training of the logistic regression is performed by the `train` method.
  id: totrans-2659
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的训练是通过 `train` 方法执行的。
- en: Note
  id: totrans-2660
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Handling exceptions from the Apache Commons Math library**'
  id: totrans-2661
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理 Apache Commons Math 库的异常**'
- en: The training of the logistic regression using the Apache Commons Math library
    requires handling the `ConvergenceException`, `DimensionMismatchException`, `TooManyEvaluationsException`,
    `TooManyIterationsException`, and `MathRuntimeException` exceptions. Debugging
    is greatly facilitated by understanding the context of these exceptions in the
    Apache library source code.
  id: totrans-2662
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Apache Commons Math 库训练逻辑回归需要处理 `ConvergenceException`、`DimensionMismatchException`、`TooManyEvaluationsException`、`TooManyIterationsException`
    和 `MathRuntimeException` 异常。通过理解这些异常在 Apache 库源代码中的上下文，调试过程将大大简化。
- en: 'The implementation of the training method, `train`, relies on the following
    five steps:'
  id: totrans-2663
  prefs: []
  type: TYPE_NORMAL
  zh: 训练方法 `train` 的实现依赖于以下五个步骤：
- en: Select and configure the least squares optimizer.
  id: totrans-2664
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择并配置最小二乘优化器。
- en: Define the logistic function and its Jacobian.
  id: totrans-2665
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义逻辑函数及其雅可比矩阵。
- en: Specify the convergence and exit criteria.
  id: totrans-2666
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定收敛和退出准则。
- en: Compute the residuals using the least squares problem builder.
  id: totrans-2667
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最小二乘问题构建器计算残差。
- en: Run the optimizer.
  id: totrans-2668
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行优化器。
- en: 'The workflow and the Apache Commons Math classes used in the training of the
    logistic regression are visualized by the following flow diagram:'
  id: totrans-2669
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的流程图可视化了用于训练逻辑回归的工作流程和 Apache Commons Math 类：
- en: '![The training workflow](img/image01416.jpeg)'
  id: totrans-2670
  prefs: []
  type: TYPE_IMG
  zh: '![训练工作流程](img/image01416.jpeg)'
- en: The workflow for training the logistic regression using the Apache Commons Math
    library
  id: totrans-2671
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Apache Commons Math 库训练逻辑回归的工作流程
- en: 'The first four steps are required by the Apache Commons Math library to initialize
    the configuration of the logistic regression prior to the minimization of the
    loss function. Let''s start with the configuration of the least squares optimizer:'
  id: totrans-2672
  prefs: []
  type: TYPE_NORMAL
  zh: 前四个步骤是 Apache Commons Math 库在损失函数最小化之前初始化逻辑回归配置所必需的。让我们从最小二乘优化器的配置开始：
- en: '[PRE223]'
  id: totrans-2673
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: 'The `train` method implements the last four steps of the computation of the
    regression model:'
  id: totrans-2674
  prefs: []
  type: TYPE_NORMAL
  zh: '`train` 方法实现了回归模型计算的最后四个步骤：'
- en: Computation of logistic values and the Jacobian matrix (line `5`).
  id: totrans-2675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算逻辑值和雅可比矩阵（第 `5` 行）。
- en: Initialization of the convergence criteria (line `6`).
  id: totrans-2676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收敛准则的初始化（第 `6` 行）。
- en: Definition of the least square problem (line `7`).
  id: totrans-2677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义最小二乘问题（第 `7` 行）。
- en: Minimization of the sum of square errors (line `8`). It is performed by the
    optimizer as part of the constructor of `LogisticRegression`.
  id: totrans-2678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化平方误差和（第 `8` 行）。这是由优化器在 `LogisticRegression` 构造函数中作为损失函数最小化的一部分来执行的。
- en: Step 1 – configuring the optimizer
  id: totrans-2679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 1 步 – 配置优化器
- en: 'In this step, you have to specify the algorithm to minimize the residual of
    the sum of the squares. The `LogisticRegressionOptimizer` class is responsible
    for configuring the optimizer. The class has the following two purposes:'
  id: totrans-2680
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，您必须指定用于最小化平方和残差的算法。`LogisticRegressionOptimizer` 类负责配置优化器。该类具有以下两个目的：
- en: Encapsulating the configuration parameters for the optimizer
  id: totrans-2681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装优化器的配置参数
- en: Invoking the `LeastSquaresOptimizer` interface defined in the Apache Commons
    Math library
  id: totrans-2682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 Apache Commons Math 库中定义的 `LeastSquaresOptimizer` 接口
- en: 'The code will be as follows:'
  id: totrans-2683
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE224]'
  id: totrans-2684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE224]'
- en: The configuration of the logistic regression optimizer is defined as the maximum
    number of iterations, `maxIters`, the maximum number of evaluations, `maxEval`,
    for the logistic function and its derivatives, the `eps` convergence criteria
    of the residual sum of squares, and the instance of the least squares problem
    (line `9`).
  id: totrans-2685
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归优化器的配置定义为最大迭代次数 `maxIters`、最大评估次数 `maxEval`（针对逻辑函数及其导数）、残差平方和的收敛标准 `eps`
    以及最小二乘问题的实例（第 `9` 行）。
- en: Step 2 – computing the Jacobian matrix
  id: totrans-2686
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 2 步 – 计算雅可比矩阵
- en: 'The next step consists of computing the value of the logistic function and
    its first order partial derivatives with respect to the weights by overriding
    the `value` method of the `fitting.leastsquares.MultivariateJacobianFunction`
    Apache Commons Math interface:'
  id: totrans-2687
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步包括通过覆盖 `fitting.leastsquares.MultivariateJacobianFunction` Apache Commons
    Math 接口的 `value` 方法来计算逻辑函数及其关于权重的第一阶偏导数的值：
- en: '[PRE225]'
  id: totrans-2688
  prefs: []
  type: TYPE_PRE
  zh: '[PRE225]'
- en: 'The constructor for the `RegressionJacobian` class requires the following two
    arguments (line `10`):'
  id: totrans-2689
  prefs: []
  type: TYPE_NORMAL
  zh: '`RegressionJacobian` 类的构造函数需要以下两个参数（第 `10` 行）：'
- en: The `xv` time series of observations
  id: totrans-2690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察的 `xv` 时间序列
- en: The `weights0` initial regression weights
  id: totrans-2691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weights0` 初始回归权重'
- en: The `value` method uses the `RealVector`, `RealMatrix`, `ArrayRealVector`, and
    `Array2DRowRealMatrix` primitive types defined in the `org.apache.commons.math3.linear`
    Apache Commons Math package (line `11`). It takes the `w` regression weight as
    an argument, computes the `gradient` (line `12`) of the logistic function (line
    `13`) for each data point, and returns the value and its derivative (line `14`).
  id: totrans-2692
  prefs: []
  type: TYPE_NORMAL
  zh: '`value`方法使用在`org.apache.commons.math3.linear` Apache Commons Math包中定义的原始类型`RealVector`、`RealMatrix`、`ArrayRealVector`和`Array2DRowRealMatrix`（第`11`行）。它将`w`回归权重作为参数，计算每个数据点的逻辑函数的`gradient`（第`12`行），并返回值及其导数（第`14`行）。'
- en: The Jacobian matrix is populated with the values of the derivative of the logistic
    function (line `15`). The first element of each column of the Jacobian matrix
    is set to `1.0` to take into account the intercept (line `16`). Finally, the `value`
    function returns the pair of gradient values and the Jacobian matrix using types
    that comply with the signature of the `value` method in the Apache Commons Math
    library (line `17`).
  id: totrans-2693
  prefs: []
  type: TYPE_NORMAL
  zh: 雅可比矩阵被填充为逻辑函数的导数值（第`15`行）。雅可比矩阵每一列的第一个元素被设置为`1.0`以考虑截距（第`16`行）。最后，`value`函数使用符合Apache
    Commons Math库中`value`方法签名的类型返回梯度值对和雅可比矩阵（第`17`行）。
- en: Step 3 – managing the convergence of the optimizer
  id: totrans-2694
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步 – 管理优化器的收敛
- en: 'The third step defines the exit condition for the optimizer. It is accomplished
    by overriding the `converged` method of the parameterized `ConvergenceChecker`
    interface in the `org.apache.commons.math3.optim` Java package:'
  id: totrans-2695
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步定义了优化器的退出条件。这是通过在`org.apache.commons.math3.optim` Java包中覆盖参数化`ConvergenceChecker`接口的`converged`方法来实现的：
- en: '[PRE226]'
  id: totrans-2696
  prefs: []
  type: TYPE_PRE
  zh: '[PRE226]'
- en: 'This implementation computes the convergence or exit condition as follows:'
  id: totrans-2697
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现计算收敛或退出条件如下：
- en: The `sse` sum of square errors between weights of two consecutive iterations
    is smaller than the `eps` convergence criteria
  id: totrans-2698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两次连续迭代权重之间的`sse`平方误差之和小于`eps`收敛标准
- en: The `iters` value exceeds the maximum number of iterations, `maxIters`, allowed
    (line `18`)
  id: totrans-2699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iters`值超过了允许的最大迭代次数`maxIters`（第`18`行）'
- en: Step 4 – defining the least squares problem
  id: totrans-2700
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 定义最小二乘问题
- en: 'The Apache Commons Math least squares optimizer package requires all the input
    to the nonlinear least squares minimizer to be defined as an instance of the `LeastSquareProblem`
    generated by the factory `LeastSquareBuilder` class:'
  id: totrans-2701
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Commons Math最小二乘优化器包要求所有输入到非线性最小二乘求解器的都定义为由`LeastSquareBuilder`工厂类生成的`LeastSquareProblem`实例：
- en: '[PRE227]'
  id: totrans-2702
  prefs: []
  type: TYPE_PRE
  zh: '[PRE227]'
- en: The diagonal elements of the weights matrix are initialized to `1.0` (line `20`).
    Besides the initialization of the model with the `lrJacobian` Jacobian matrix
    (line `19`), the sequence of method invocations sets the maximum number of evaluations
    (line `23`), maximum number of iterations (line `25`), and the exit condition
    (line `22`).
  id: totrans-2703
  prefs: []
  type: TYPE_NORMAL
  zh: 权重矩阵的对角元素被初始化为`1.0`（第`20`行）。除了使用`lrJacobian`雅可比矩阵初始化模型（第`19`行）之外，方法调用的序列设置了最大评估次数（第`23`行）、最大迭代次数（第`25`行）和退出条件（第`22`行）。
- en: The regression weights are initialized with the `weights0` weights as arguments
    of the constructor for `LogisticRegression` (line `24`). Finally, the expected
    or target values are initialized (line `21`).
  id: totrans-2704
  prefs: []
  type: TYPE_NORMAL
  zh: 回归权重使用`LogisticRegression`构造函数的`weights0`权重作为参数进行初始化（第`24`行）。最后，预期的或目标值被初始化（第`21`行）。
- en: Step 5 – minimizing the sum of square errors
  id: totrans-2705
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第5步 – 最小化平方误差之和
- en: 'The training is executed with a simple call to the `lsp` least squares minimizer:'
  id: totrans-2706
  prefs: []
  type: TYPE_NORMAL
  zh: 训练通过简单调用`lsp`最小二乘法求解器执行：
- en: '[PRE228]'
  id: totrans-2707
  prefs: []
  type: TYPE_PRE
  zh: '[PRE228]'
- en: The regression coefficients (or weights) and the **residuals mean square** (**RMS**)
    are returned by invoking the `getPoint` method on the `Optimum` class of the Apache
    Commons Math library.
  id: totrans-2708
  prefs: []
  type: TYPE_NORMAL
  zh: 回归系数（或权重）以及**残差均方**（**RMS**）是通过在Apache Commons Math库的`Optimum`类上调用`getPoint`方法返回的。
- en: Test
  id: totrans-2709
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试
- en: 'Let''s test our implementation of the binomial multivariate logistic regression
    using the example of the price variation versus volatility and volume of the Copper
    ETF, which is used in the previous two sections. The only difference is that we
    need to define the target values as 0 if the ETF price decreases between two consecutive
    trading sessions, and 1 otherwise:'
  id: totrans-2710
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用前两节中提到的铜ETF的价格变动与波动性和成交量示例来测试我们的二项式多元逻辑回归实现。唯一的区别是我们需要将目标值定义为如果ETF价格在连续两个交易日之间下降为0，否则为1：
- en: '[PRE229]'
  id: totrans-2711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: 'Let''s take a look at the steps required for the execution of the test that
    consists of collecting data, initializing the parameters for the minimization
    of the sum of square errors, training a logistic regression model, and running
    the prediction:'
  id: totrans-2712
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看执行测试所需的步骤，该测试包括收集数据、初始化平方误差最小化参数、训练逻辑回归模型和运行预测：
- en: Create a `src` data source to extract the market and trading data (line `26`).
  id: totrans-2713
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`src`数据源以提取市场和交易数据（第`26`行）。
- en: Select the `LevenbergMarquardtOptimizer` Levenberg-Marquardt algorithm as `optimizer`
    (line `27`).
  id: totrans-2714
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`LevenbergMarquardtOptimizer` Levenberg-Marquardt算法作为`optimizer`（第`27`行）。
- en: Load the daily closing `price` (line `28`), `volatility` within a trading session
    (line `29`), and the `volume` daily trading (line `30`) for the ETF CU.
  id: totrans-2715
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载ETF的每日收盘`价格`（第`28`行），交易时段内的`波动性`（第`29`行），以及ETF的`成交量`每日交易（第`30`行）。
- en: Generate the labeled data as a pair of features (the relative volatility and
    relative volume for the ETF) and the `expected` outcome *{0, 1}* for training
    the model for which `1` represents the increase in the price and `0` represents
    the decrease in the price (line `31`). The `differentialData` generic method of
    the `XTSeries` singleton is described in the *Time series in Scala* section in
    [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"), *Data
    Preprocessing*.
  id: totrans-2716
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成标记数据作为特征对（ETF的相对波动性和相对成交量）以及`expected`结果*{0, 1}*，用于训练模型，其中`1`表示价格上涨，`0`表示价格下跌（第`31`行）。`XTSeries`单例的`differentialData`通用方法在[第3章](part0172.xhtml#aid-5410O2
    "第3章 数据预处理")的*时间序列在Scala中*部分进行描述，*数据预处理*）。
- en: Instantiate the `lsOpt` optimizer to minimize the sum of square errors during
    training (line `32`).
  id: totrans-2717
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`lsOpt`优化器以在训练过程中最小化平方误差之和（第`32`行）。
- en: Train the `regr` model and return the `pfnRegr` predictor partial function (line
    `33`).
  id: totrans-2718
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练`regr`模型并返回`pfnRegr`预测部分函数（第`33`行）。
- en: There are many alternative optimizers available to minimize the sum of square
    errors optimizers (refer to the *Nonlinear least squares minimization* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*).
  id: totrans-2719
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的替代优化器可以最小化平方误差优化器（请参阅[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*非线性最小二乘法*部分，*基本概念*）。
- en: Note
  id: totrans-2720
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Levenberg-Marquardt parameters**'
  id: totrans-2721
  prefs: []
  type: TYPE_NORMAL
  zh: '**Levenberg-Marquardt参数**'
- en: The driver code uses the `LevenbergMarquardtOptimizer` with the default tuning
    parameters' configuration to keep the implementation simple. However, the algorithm
    has a few important parameters, such as the relative tolerance for cost and matrix
    inversion, that are worth tuning for commercial applications (refer to the *Levenberg-Marquardt*
    section under *Nonlinear least squares minimization* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-2722
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动代码使用默认调整参数配置的`LevenbergMarquardtOptimizer`以保持实现简单。然而，该算法有几个重要的参数，如成本和矩阵求逆的相对容差，对于商业应用来说值得调整（请参阅[附录A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念")下的*非线性最小二乘法*中的*Levenberg-Marquardt*部分，*基本概念*）。
- en: 'The execution of the test produces the following results:'
  id: totrans-2723
  prefs: []
  type: TYPE_NORMAL
  zh: 测试执行产生了以下结果：
- en: '**The residual mean square** is 0.497'
  id: totrans-2724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残差均方**为0.497'
- en: '**Weights** are -0.124 for intercept, 0.453 for ETF volatility, and -0.121
    for ETF volume'
  id: totrans-2725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**权重**为截距-0.124，ETF波动性0.453，ETF成交量-0.121'
- en: The last step is the classification of the real-time data.
  id: totrans-2726
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是对实时数据的分类。
- en: Classification
  id: totrans-2727
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: 'As mentioned earlier and despite its name, the binomial logistic regression
    is actually a binary classifier. The classification method is implemented as an
    implicit data transformation `|>`:'
  id: totrans-2728
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，尽管名为二项式逻辑回归，但实际上它是一个二元分类器。分类方法实现为一个隐式数据转换`|>`：
- en: '[PRE230]'
  id: totrans-2729
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: The `dot` (or inner) product of the observation `x` with the `weights` model
    is evaluated against the hyperplane. The predicted class is `1` if the produce
    exceeds `HYPERPLANE`, and `0` otherwise (line `34`).
  id: totrans-2730
  prefs: []
  type: TYPE_NORMAL
  zh: 观测`x`与`weights`模型的点积（或内积）与超平面进行比较。如果产生的值超过`HYPERPLANE`，则预测类别为`1`，否则为`0`（第`34`行）。
- en: Note
  id: totrans-2731
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Class identification**'
  id: totrans-2732
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别识别**'
- en: The class that the new data *x* belongs to is determined by the *dot(x, weights)
    > 0.5* test, where *dot* is the product of the features and the regression weights
    (*w[0]+w[1].volatility + w[2].volume*). You may find different classification
    schemes in the scientific literature.
  id: totrans-2733
  prefs: []
  type: TYPE_NORMAL
  zh: 新数据*x*所属的类别由*dot(x, weights) > 0.5*测试确定，其中*dot*是特征与回归权重（*w[0]+w[1].volatility
    + w[2].volume*）的乘积。你可能在科学文献中找到不同的分类方案。
- en: 'The direction of the price variation of the Copper ETF, *CU price(t+1) – price(t)*,
    is compared to the direction predicted by the logistic regression. The result
    is plotted with the **success** value if the positive or negative direction is
    correctly predicted; otherwise, it is plotted with the **failure** value:'
  id: totrans-2734
  prefs: []
  type: TYPE_NORMAL
  zh: 铜ETF价格变动的方向，*CU price(t+1) – price(t)*，与逻辑回归预测的方向进行比较。如果正确预测了正向或负向，则结果以**成功**值绘制；否则，以**失败**值绘制：
- en: '![Classification](img/image01417.jpeg)'
  id: totrans-2735
  prefs: []
  type: TYPE_IMG
  zh: '![分类](img/image01417.jpeg)'
- en: The prediction of the direction of the variation of price of the Copper ETF
    using the logistic regression
  id: totrans-2736
  prefs: []
  type: TYPE_NORMAL
  zh: 使用逻辑回归预测铜ETF价格变动的方向
- en: The logistic regression was able to classify 78 out of 121 trading sessions
    (65 percent accuracy).
  id: totrans-2737
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归能够对121个交易时段中的78个进行分类（准确率达到65%）。
- en: 'Now, let''s use the logistic regression to predict the positive price variation
    for the Copper ETF, given its volatility and trading volume. This trading or investment
    strategy is known as being *long on the market*. This particular use case ignores
    the trading sessions for which the price was either flat or declined:'
  id: totrans-2738
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用逻辑回归来预测铜ETF的正向价格变动，考虑到其波动性和交易量。这种交易或投资策略被称为在市场上*多头*。这个特定的用例忽略了价格要么持平要么下跌的交易时段：
- en: '![Classification](img/image01418.jpeg)'
  id: totrans-2739
  prefs: []
  type: TYPE_IMG
  zh: '![分类](img/image01418.jpeg)'
- en: The prediction of the direction of the variation of price of the Copper ETF
    using the logistic regression
  id: totrans-2740
  prefs: []
  type: TYPE_NORMAL
  zh: 使用逻辑回归预测铜ETF价格变动的方向
- en: The logistic regression was able to correctly predict the positive price variation
    for 58 out of 64 trading sessions (90.6 percent accuracy). What is the difference
    between the first and second test cases?
  id: totrans-2741
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归能够正确预测64个交易时段中的58个时段的正向价格变动（准确率达到90.6%）。第一次和第二次测试案例之间的区别是什么？
- en: In the first case, the *w[0] + w[1].volatility + w[2].volume* separating hyperplane
    equation is used to segregate the features generating either the positive or negative
    price variation. Therefore, the overall accuracy of the classification is negatively
    impacted by the overlap of the features from the two classes.
  id: totrans-2742
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，*w[0] + w[1].volatility + w[2].volume*分离超平面方程用于将产生正向或负向价格变动的特征分开。因此，分类的整体准确率受到两个类别特征重叠的负面影响。
- en: In the second case, the classifier has to consider only the *observations located
    on the positive side* of the hyperplane equation, without taking into account
    the false negatives.
  id: totrans-2743
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种情况下，分类器只需考虑超平面方程的*正侧*的观察结果，而不考虑假阴性。
- en: Note
  id: totrans-2744
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Impact of rounding errors**'
  id: totrans-2745
  prefs: []
  type: TYPE_NORMAL
  zh: '**舍入误差的影响**'
- en: Under some circumstances, the generation of the rounding errors during the computation
    of the Jacobian matrix has an impact on the accuracy of the *w[0] + w[1].volatility
    + w[2].volume* separating hyperplane equation. It reduces the accuracy of the
    prediction of both the positive and negative price variation.
  id: totrans-2746
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，计算雅可比矩阵时产生的舍入误差会影响*w[0] + w[1].volatility + w[2].volume*分离超平面方程的准确性。这降低了预测正向和负向价格变动的准确性。
- en: The accuracy of the binary classifier can be further improved by considering
    the positive variation of the price using a margin error EPS as *price(t+1) –
    price(t) > EPS*.
  id: totrans-2747
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑价格的正向变动并使用边缘误差EPS（*price(t+1) – price(t) > EPS*）来进一步提高二元分类器的准确度。
- en: Note
  id: totrans-2748
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The validation methodology**'
  id: totrans-2749
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证方法**'
- en: The validation set is generated by randomly selecting observations from the
    original labeled dataset. A formal validation requires you to use a K-fold validation
    methodology to compute the recall, precision, and F1 measure for the logistic
    regression model.
  id: totrans-2750
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集是通过从原始标记数据集中随机选择观察结果生成的。正式验证需要你使用K折验证方法来计算逻辑回归模型的召回率、精确率和F1度量。
- en: Summary
  id: totrans-2751
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This concludes the description and implementation of the linear and logistic
    regression and the concept of regularization to reduce overfitting. Your first
    analytical projects using machine learning will (or did) likely involve a regression
    model of some type. Regression models, along with the Naïve Bayes classification,
    are the most understood techniques for those without a deep knowledge of statistics
    or machine learning.
  id: totrans-2752
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了线性回归和逻辑回归以及正则化概念的描述和实现，以减少过拟合。你的第一个使用机器学习的分析项目（或已经涉及）可能涉及某种类型的回归模型。回归模型，连同朴素贝叶斯分类，是那些没有深入了解统计学或机器学习的人最理解的技巧。
- en: 'After the completion of this chapter, you will hopefully have a grasp on the
    following topics:'
  id: totrans-2753
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成本章之后，你可能会希望掌握以下主题：
- en: The concept of linear and nonlinear least squares-based optimization
  id: totrans-2754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于线性和非线性最小二乘优化的概念
- en: The implementation of ordinary least square regression as well as logistic regression
  id: totrans-2755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普通最小二乘回归以及逻辑回归的实现
- en: The impact of regularization with an implementation of the ridge regression
  id: totrans-2756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化的影响，以及岭回归的实现
- en: The logistic regression is also the foundation of the conditional random fields,
    as described in the *Conditional random fields* section in [Chapter 7](part0193.xhtml#aid-5O1SI1
    "Chapter 7. Sequential Data Models"), *Sequential Data Models*, and multilayer
    perceptrons, which was introduced in the *The multilayer perceptron* section in
    [Chapter 9](part0207.xhtml#aid-65D4E1 "Chapter 9. Artificial Neural Networks"),
    *Artificial Neural Networks*.
  id: totrans-2757
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归也是条件随机字段的基础，如[第7章](part0193.xhtml#aid-5O1SI1 "第7章。序列数据模型")中*条件随机字段*部分所述，*序列数据模型*，以及多层感知器，这在[第9章](part0207.xhtml#aid-65D4E1
    "第9章。人工神经网络")中*多层感知器*部分介绍。
- en: 'Contrary to the Naïve Bayes models (refer to [Chapter 5](part0182.xhtml#aid-5DI6C1
    "Chapter 5. Naïve Bayes Classifiers"), *Naïve Bayes Classifiers*), the least squares
    or logistic regression does not impose the condition that the features have to
    be independent. However, the regression models do not take into account the sequential
    nature of a time series such as asset pricing. The next chapter, which is dedicated
    to models for sequential data, introduces two classifiers that take into account
    the time dependency in a time series: the hidden Markov model and conditional
    random fields.'
  id: totrans-2758
  prefs: []
  type: TYPE_NORMAL
  zh: 与朴素贝叶斯模型（参见[第5章](part0182.xhtml#aid-5DI6C1 "第5章。朴素贝叶斯分类器")，*朴素贝叶斯分类器*）相反，最小二乘法或逻辑回归并不强加条件，即特征必须是独立的。然而，回归模型并没有考虑到时间序列（如资产定价）的序列性质。下一章，即专门针对序列数据模型的章节，介绍了两种考虑时间序列时间依赖性的分类器：隐藏马尔可夫模型和条件随机字段。
- en: Chapter 7. Sequential Data Models
  id: totrans-2759
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。序列数据模型
- en: The universe of Markov models is vast and encompasses computational concepts
    such as the Markov decision process, discrete Markov, Markov chain Monte Carlo
    for Bayesian networks, and hidden Markov models.
  id: totrans-2760
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫模型的世界是广阔的，包括马尔可夫决策过程、离散马尔可夫、贝叶斯网络的马尔可夫链蒙特卡洛以及隐藏马尔可夫模型等计算概念。
- en: Markov processes, and more specifically, the **hidden Markov model** (**HMM**),
    are commonly used in speech recognition, language translation, text classification,
    document tagging, and data compression and decoding.
  id: totrans-2761
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫过程，更具体地说，**隐藏马尔可夫模型**（**HMM**），在语音识别、语言翻译、文本分类、文档标记、数据压缩和解码中通常被使用。
- en: The first section of this chapter introduces and describes the hidden Markov
    model with the full implementation of the three canonical forms of the hidden
    Markov model using Scala. This section covers the different dynamic programming
    techniques used in the evaluation, decoding, and training of the hidden Markov
    model. The design of the classifier follows the same pattern as the logistic and
    linear regression, as described in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression
    and Regularization"), *Regression and Regularization*.
  id: totrans-2762
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分介绍了并描述了使用Scala实现隐藏马尔可夫模型的三种经典形式的完整实现。本节涵盖了在隐藏马尔可夫模型的评估、解码和训练中使用的不同动态规划技术。分类器的设计遵循与逻辑回归和线性回归相同的模式，如[第6章](part0188.xhtml#aid-5J99O2
    "第6章。回归和正则化")中所述，*回归和正则化*。
- en: 'The second and last section of this chapter is dedicated to a discriminative
    (labels conditional to observations) alternative to the hidden Markov model: conditional
    random fields. The open source CRF Java library authored by Sunita Sarawagi from
    the Indian Institute of Technology, Bombay, is used to create a predictive model
    using conditional random fields [7:1].'
  id: totrans-2763
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第二部分和最后一部分致力于隐马尔可夫模型的判别性（标签对观察条件）替代方案：条件随机字段。印度理工学院孟买分校的Sunita Sarawagi编写的开源CRF
    Java库用于创建使用条件随机字段的预测模型 [7:1]。
- en: Markov decision processes
  id: totrans-2764
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫决策过程
- en: This first section also describes the basic concepts you need to know in order
    to understand, develop, and apply the hidden Markov model. The foundation of the
    Markovian universe is the concept known as the **Markov property**.
  id: totrans-2765
  prefs: []
  type: TYPE_NORMAL
  zh: 本节还描述了您需要了解的基本概念，以便理解、开发和应用隐马尔可夫模型。马尔可夫宇宙的基础是被称为**马尔可夫性质**的概念。
- en: The Markov property
  id: totrans-2766
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 马尔可夫性质
- en: The Markov property is a characteristic of a stochastic process where the conditional
    probability distribution of a future state depends on the current state and not
    on its past states. In this case, the transition between the states occurs at
    a discrete time, and the Markov property is known as the **discrete Markov chain**.
  id: totrans-2767
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫性质是随机过程的特征，其中未来状态的条件概率分布取决于当前状态，而不是其过去状态。在这种情况下，状态之间的转换发生在离散时间，马尔可夫性质被称为**离散马尔可夫链**。
- en: The first order discrete Markov chain
  id: totrans-2768
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一阶离散马尔可夫链
- en: The following example is taken from *Introduction to Machine Learning*, *E.
    Alpaydin* [7:2].
  id: totrans-2769
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例摘自 *《机器学习导论》，E. Alpaydin* [7:2]。
- en: 'Let''s consider the following use case. *N* balls of different colors are hidden
    in *N* boxes (one each). The balls can have only three colors (Blue, Red, and
    Green). The experimenter draws the balls one by one. The state of the discovery
    process is defined by the color of the latest ball drawn from one of the boxes:
    *S[0] = Blue, S[1] = Red, and S[2] = Green*.'
  id: totrans-2770
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下用例。*N* 个不同颜色的球隐藏在 *N* 个盒子中（每个盒子一个）。球只能有三种颜色（蓝色、红色和绿色）。实验者逐个抽取球。发现过程的状态由从其中一个盒子中抽取的最新球的颜色定义：*S[0]
    = 蓝色，S[1] = 红色，S[2] = 绿色*。
- en: Let *{π[0], π[1], π[2]}* be the initial probabilities for having an initial
    set of color in each of the boxes.
  id: totrans-2771
  prefs: []
  type: TYPE_NORMAL
  zh: 设 *{π[0], π[1], π[2]}* 为每个盒子中初始颜色集合的初始概率。
- en: 'Let *q[t]* denote the color of the ball drawn at the time *t*. The probability
    of drawing a ball of color *S[k]* at the time *k* after drawing a ball of the
    color *S* *j* at the time *j* is defined as *p(q[t] = S[k] q[t-1] = S[j]) = a[jk]*.
    The probability of drawing a red ball in the first attempt is *p(q[t0] = S[1])
    = π[1]*. The probability of drawing a blue ball in the second attempt is *p(q[0]
    = S[1]) p(q[1] = S[0]|q[0] = S[1]) = π[1] a[10]*. The process is repeated to create
    a sequence of the state *{S[t]} = {Red, Blue, Blue, Green, …}* with the following
    probability: *p(q[[0]] = S[1]).p(q[1] = S[0]|q[0] = S[1]).p(q[2] = S[0]|q[1] =
    S[0]).p(q[3] = S[2]|q[2] = S[0])… = π[1].a[10].a[00].a2…*. The sequence of states/colors
    can be represented as follows:'
  id: totrans-2772
  prefs: []
  type: TYPE_NORMAL
  zh: 用 *q[t]* 表示在时间 *t* 抽取的球的颜色。在时间 *t* 抽取颜色为 *S* *j* 的球之后，在时间 *k* 抽取颜色为 *S[k]* 的球的概率定义为
    *p(q[t] = S[k] q[t-1] = S[j]) = a[jk]*。第一次尝试抽取红色球的概率为 *p(q[t0] = S[1]) = π[1]*。第二次尝试抽取蓝色球的概率为
    *p(q[0] = S[1]) p(q[1] = S[0]|q[0] = S[1]) = π[1] a[10]*。该过程重复进行，以创建以下概率的状态序列
    *{S[t]} = {红色，蓝色，蓝色，绿色，…}*：*p(q[[0]] = S[1]).p(q[1] = S[0]|q[0] = S[1]).p(q[2]
    = S[0]|q[1] = S[0]).p(q[3] = S[2]|q[2] = S[0])… = π[1].a[10].a[00].a2…*。状态/颜色的序列可以表示如下：
- en: '![The first order discrete Markov chain](img/image01419.jpeg)'
  id: totrans-2773
  prefs: []
  type: TYPE_IMG
  zh: '![第一阶离散马尔可夫链](img/image01419.jpeg)'
- en: An illustration of the ball and boxes example
  id: totrans-2774
  prefs: []
  type: TYPE_NORMAL
  zh: 球和盒子示例的插图
- en: 'Let''s estimate the probabilities *p* using historical data (learning phase):'
  id: totrans-2775
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用历史数据（学习阶段）估计概率 *p*：
- en: The estimation of the probability of drawing a red ball (*S[1]*) in the first
    attempt is *π[1]*, which is computed as the number of sequences starting with
    *S[1]* *(red) / total number of balls*.
  id: totrans-2776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一次尝试中抽取红色球（*S[1]*）的概率估计为 *π[1]*，其计算方式为以 *S[1]* （红色）开头的序列数除以球的总数。
- en: The estimation of the probability of retrieving a blue ball in the second attempt
    is *a[10]*, the number of sequences for which a blue ball is drawn after a red
    ball / total number of sequences, and so on.
  id: totrans-2777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二次尝试中检索蓝色球的概率估计为 *a[10]*，即在红色球之后抽取蓝色球的序列数除以序列总数，依此类推。
- en: Note
  id: totrans-2778
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Nth-order Markov**'
  id: totrans-2779
  prefs: []
  type: TYPE_NORMAL
  zh: '**N阶马尔可夫**'
- en: The Markov property is popular mainly because of its simplicity. As you will
    discover while studying the hidden Markov model, having a state solely dependent
    on the previous state allows us to apply efficient dynamic programming techniques.
    However, some problems require dependencies between more than two states. These
    models are known as Markov random fields.
  id: totrans-2780
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫属性之所以流行，主要是因为其简单性。当你学习隐藏马尔可夫模型时，你会发现状态仅依赖于前一个状态，这使我们能够应用有效的动态规划技术。然而，一些问题需要超过两个状态之间的依赖关系。这些模型被称为马尔可夫随机场。
- en: Although the discrete Markov process can be applied to trial and error types
    of applications, its applicability is limited to solving problems for which the
    observations do not depend on hidden states. Hidden Markov models are a commonly
    applied technique to meet such a challenge.
  id: totrans-2781
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然离散马尔可夫过程可以应用于试错类型的应用，但其适用性仅限于解决那些观测不依赖于隐藏状态的问题。隐藏马尔可夫模型是解决此类挑战的常用技术。
- en: The hidden Markov model
  id: totrans-2782
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型
- en: The hidden Markov model has numerous applications related to speech recognition,
    face identification (biometrics), and pattern recognition in pictures and videos
    [7:3].
  id: totrans-2783
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型在语音识别、人脸识别（生物识别）以及图片和视频中的模式识别等方面有众多应用[7:3]。
- en: A hidden Markov model consists of a Markov process (also known as a Markov chain)
    for observations with a discrete time. The main difference with the Markov processes
    is that the states are not observable. A new observation is emitted with a probability
    known as the emission probability each time the state of the system or model changes.
  id: totrans-2784
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型由一个具有离散时间的观测马尔可夫过程（也称为马尔可夫链）组成。与马尔可夫过程的主要区别在于状态是不可观测的。每次系统或模型的状态改变时，都会以称为发射概率的概率发射一个新的观测。
- en: 'There are two sources of randomness, which are as follows:'
  id: totrans-2785
  prefs: []
  type: TYPE_NORMAL
  zh: 存在两种随机性的来源，如下所述：
- en: Transition between states
  id: totrans-2786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态之间的转换
- en: Emission of an observation when a state is given
  id: totrans-2787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当给定状态时观测的发射
- en: 'Let''s reuse the boxes and balls example. If the boxes are hidden states (nonobservable),
    then the user draws the balls whose color is not visible. The emission probability
    is the probability *b[ik] =p(o[t] = colork|q[t] =S[i])* to retrieve a ball of
    the color *k* from a hidden box *I*, as shown in the following diagram:'
  id: totrans-2788
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重用盒子与球体的例子。如果盒子是隐藏状态（不可观测的），那么用户抽取的球的颜色是不可见的。发射概率是检索到颜色为*k*的球从隐藏盒子*I*的概率*b[ik]
    =p(o[t] = colork|q[t] =S[i])*，如下图所示：
- en: '![The hidden Markov model](img/image01420.jpeg)'
  id: totrans-2789
  prefs: []
  type: TYPE_IMG
  zh: '![隐藏马尔可夫模型](img/image01420.jpeg)'
- en: The hidden Markov model for the balls and boxes example
  id: totrans-2790
  prefs: []
  type: TYPE_NORMAL
  zh: 球和盒子示例的隐藏马尔可夫模型
- en: In this example, we do not assume that all the boxes contain balls of different
    colors. We cannot make any assumptions on the order as defined by the transition
    *a[ij]*. The HMM does not assume that the number of colors (observations) is identical
    to the number of boxes (states).
  id: totrans-2791
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不假设所有盒子都包含不同颜色的球。我们不能对由转换*a[ij]*定义的顺序做出任何假设。HMM不假设颜色（观测）的数量与盒子（状态）的数量相同。
- en: Note
  id: totrans-2792
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Time invariance**'
  id: totrans-2793
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间不变性**'
- en: Contrary to the Kalman filter, for example, the hidden Markov model requires
    that the transition elements, *a[ji]*, are independent of time. This property
    is known as stationary or homogeneous restriction.
  id: totrans-2794
  prefs: []
  type: TYPE_NORMAL
  zh: 与卡尔曼滤波器等不同，隐藏马尔可夫模型要求转换元素*a[ji]*与时间无关。这一属性被称为平稳性或齐次性限制。
- en: 'Keep in mind that the observations, in this case the color of the balls, are
    the only tangible data available to the experimenter. From this example, we can
    conclude that a formal HMM has three components:'
  id: totrans-2795
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在这个例子中，观测（球的颜色）是实验者唯一可用的有形数据。从这个例子中，我们可以得出结论，一个正式的HMM有三个组件：
- en: A set of observations
  id: totrans-2796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组观测
- en: A sequence of hidden states
  id: totrans-2797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列隐藏状态
- en: A model that maximizes the joint probability of the observations and hidden
    states, known as the Lambda model
  id: totrans-2798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大化观测和隐藏状态联合概率的模型，称为Lambda模型
- en: 'A Lambda model, *λ*, is composed of initial probabilities *π*, the probabilities
    of state transitions as defined by the matrix *A*, and the probabilities of states
    emitting one or more observations, as shown in the following diagram:'
  id: totrans-2799
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda模型，*λ*，由初始概率*π*、由矩阵*A*定义的状态转换概率以及状态发射一个或多个观测的概率组成，如下图所示：
- en: '![The hidden Markov model](img/image01421.jpeg)'
  id: totrans-2800
  prefs: []
  type: TYPE_IMG
  zh: '![隐藏马尔可夫模型](img/image01421.jpeg)'
- en: The visualization of the HMM key components
  id: totrans-2801
  prefs: []
  type: TYPE_NORMAL
  zh: HMM关键组件的可视化
- en: 'The preceding diagram illustrates that, given a sequence of observations, the
    HMM tackles the following three problems known as canonical forms:'
  id: totrans-2802
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示说明了，给定一个观察值序列，HMM处理以下三个被称为规范形式的问题：
- en: '**CF1 (evaluation)**: This evaluates the probability of a given sequence of
    observations *O**t*, given a model *λ = (π, A, B)*'
  id: totrans-2803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CF1 (评估)**：这评估了给定观察序列 *O**t*，在模型 *λ = (π, A, B)* 下的概率'
- en: '**CF2 (training)**: This identifies (or learns) a model *λ = (π, A, B)*, given
    a set of observations *O*'
  id: totrans-2804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CF2 (训练)**：这识别（或学习）给定观察值集合 *O* 的模型 *λ = (π, A, B)*'
- en: '**CF3 (decoding)**: This estimates the state sequence *Q* with the highest
    probability to generate a given set of observations *O* and a model *λ*'
  id: totrans-2805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CF3 (解码)**：这估计了生成给定观察值集合 *O* 和模型 *λ* 的最高概率的状态序列 *Q*'
- en: The solution to these three problems uses dynamic programming techniques. However,
    we need to clarify the notations prior to diving into the mathematical foundation
    of the hidden Markov model.
  id: totrans-2806
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这三个问题的解决方案使用了动态规划技术。然而，在深入隐藏马尔可夫模型的数学基础之前，我们需要明确符号。
- en: Notations
  id: totrans-2807
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号
- en: 'One of the challenges of describing the hidden Markov model is the mathematical
    notation that sometimes differs from author to author. From now on, we will use
    the following notation:'
  id: totrans-2808
  prefs: []
  type: TYPE_NORMAL
  zh: 描述隐藏马尔可夫模型的一个挑战是数学符号有时会因作者而异。从现在开始，我们将使用以下符号：
- en: '|   | Description | Formulation |'
  id: totrans-2809
  prefs: []
  type: TYPE_TB
  zh: '|   | 描述 | 公式 |'
- en: '| --- | --- | --- |'
  id: totrans-2810
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| *N* | The number of hidden states |   |'
  id: totrans-2811
  prefs: []
  type: TYPE_TB
  zh: '| *N* | 隐藏状态的数量 |   |'
- en: '| *S* | A finite set of *N* hidden states | *S = {S[0], S[1], … S[N-1]}* |'
  id: totrans-2812
  prefs: []
  type: TYPE_TB
  zh: '| *S* | 一个包含 *N* 个隐藏状态的有限集合 | *S = {S[0], S[1], … S[N-1]}* |'
- en: '| *M* | The number of observation symbols |   |'
  id: totrans-2813
  prefs: []
  type: TYPE_TB
  zh: '| *M* | 观察符号的数量 |   |'
- en: '| *qt* | The state at time or step *t* |   |'
  id: totrans-2814
  prefs: []
  type: TYPE_TB
  zh: '| *qt* | 时间或步骤 *t* 的状态 |   |'
- en: '| *Q* | A time sequence of states | *Q = {q[0], q[1], … q[n-1]} = Q[0:n-1]*
    |'
  id: totrans-2815
  prefs: []
  type: TYPE_TB
  zh: '| *Q* | 状态的时间序列 | *Q = {q[0], q[1], … q[n-1]} = Q[0:n-1]* |'
- en: '| *T* | The number of observations |   |'
  id: totrans-2816
  prefs: []
  type: TYPE_TB
  zh: '| *T* | 观察值的数量 |   |'
- en: '| *ot* | The observation at time *t* |   |'
  id: totrans-2817
  prefs: []
  type: TYPE_TB
  zh: '| *ot* | 时间 *t* 的观察值 |   |'
- en: '| *O* | A finite sequence of *T* observations | *O = {o[0], o[1], … o[T-1]}
    = O[0:T-1]* |'
  id: totrans-2818
  prefs: []
  type: TYPE_TB
  zh: '| *O* | 一个由 *T* 个观察值组成的有限序列 | *O = {o[0], o[1], … o[T-1]} = O[0:T-1]* |'
- en: '| *A* | The state transition probability matrix | *a[ji] = p(q[t+1]=S[i]&#124;
    q[t]=S[j])* |'
  id: totrans-2819
  prefs: []
  type: TYPE_TB
  zh: '| *A* | 状态转移概率矩阵 | *a[ji] = p(q[t+1]=S[i] | q[t]=S[j])* |'
- en: '| *B* | The emission probability matrix | *b[jk] = p(o[t]=O[k]&#124; q[t]=S[j])*
    |'
  id: totrans-2820
  prefs: []
  type: TYPE_TB
  zh: '| *B* | 发射概率矩阵 | *b[jk] = p(o[t]=O[k] | q[t]=S[j])* |'
- en: '| *π* | The initial state probability vector | *π[i] = p(q[0]=S[j])* |'
  id: totrans-2821
  prefs: []
  type: TYPE_TB
  zh: '| *π* | 初始状态概率向量 | *π[i] = p(q[0]=S[j])* |'
- en: '| *λ* | The hidden Markov model | *λ = (π, A, B)* |'
  id: totrans-2822
  prefs: []
  type: TYPE_TB
  zh: '| *λ* | 隐藏马尔可夫模型 | *λ = (π, A, B)* |'
- en: Note
  id: totrans-2823
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Variance in the notation**'
  id: totrans-2824
  prefs: []
  type: TYPE_NORMAL
  zh: '**符号的方差**'
- en: Some authors use the symbol *z* to represent the hidden states instead of *q*
    and *x* to represent the observations *O*.
  id: totrans-2825
  prefs: []
  type: TYPE_NORMAL
  zh: 一些作者使用符号 *z* 来表示隐藏状态，而不是 *q*，使用 *x* 来表示观察值 *O*。
- en: 'For convenience, let''s simplify the notation of the sequence of observations
    and states using the condensed form: *p(O[0:T], q[t]| λ) = p(O[0], O[1], … O[T],
    q[t]| λ)*. It is quite common to visualize a hidden Markov model with a lattice
    of states and observations, which is similar to our description of the boxes and
    balls examples, as shown here:'
  id: totrans-2826
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，让我们使用简化的形式来表示观察值和状态的序列：*p(O[0:T], q[t]| λ) = p(O[0], O[1], … O[T], q[t]|
    λ)*。用网格状的状态和观察值来可视化隐藏马尔可夫模型是很常见的，这与我们描述的箱子和球例子类似，如下所示：
- en: '![Notations](img/image01422.jpeg)'
  id: totrans-2827
  prefs: []
  type: TYPE_IMG
  zh: '![符号](img/image01422.jpeg)'
- en: The formal HMM-directed graph
  id: totrans-2828
  prefs: []
  type: TYPE_NORMAL
  zh: 正式的HMM有向图
- en: The state *Si* is observed as *O[k]* at time *t*, before being transitioned
    to the state *S[j]* observed as *O[m]* at the time *t+1*. The first step in the
    creation of our HMM is the definition of the class that implements the lambda
    model *λ = (π, A, B)* [7:4].
  id: totrans-2829
  prefs: []
  type: TYPE_NORMAL
  zh: 状态 *Si* 在时间 *t* 被观察到 *O[k]*，然后过渡到状态 *S[j]*，在时间 *t+1* 被观察到 *O[m]*。创建我们的HMM的第一步是定义实现lambda模型
    *λ = (π, A, B)* [7:4] 的类。
- en: The lambda model
  id: totrans-2830
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda模型
- en: 'The three canonical forms of the hidden Markov model rely heavily on manipulation
    and operations on matrices and vectors. For convenience, let''s define an `HMMConfig`
    class that contains the dimensions used in the HMM:'
  id: totrans-2831
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型的三个规范形式在很大程度上依赖于矩阵和向量的操作。为了方便起见，让我们定义一个 `HMMConfig` 类，它包含HMM中使用的维度：
- en: '[PRE231]'
  id: totrans-2832
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: 'The input parameters for the class are as follows:'
  id: totrans-2833
  prefs: []
  type: TYPE_NORMAL
  zh: 类的输入参数如下：
- en: '`numObs`: This is the number of observations'
  id: totrans-2834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numObs`：这是观察值的数量'
- en: '`numStates`: This is the number of hidden states'
  id: totrans-2835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numStates`：这是隐藏状态的数量'
- en: '`numSymbols`: This is the number of observation symbols or features'
  id: totrans-2836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numSymbols`：这是观测符号或特征的数量'
- en: '`maxIters`: This is the maximum number of iterations required for the HMM training'
  id: totrans-2837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxIters`：这是 HMM 训练所需的最大迭代次数'
- en: '`eps`: This is the convergence criteria for the HMM training'
  id: totrans-2838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eps`：这是 HMM 训练的收敛标准'
- en: Note
  id: totrans-2839
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Consistency with a mathematical notation**'
  id: totrans-2840
  prefs: []
  type: TYPE_NORMAL
  zh: '**与数学符号的一致性**'
- en: The implementation uses `numObs` (with respect to `numStates` and `numSymbols`)
    to represent programmatically the number of observations `T` (with respect to
    the `N` hidden states and `M` features). As a general rule, the implementation
    reuses the mathematical symbols as much as possible.
  id: totrans-2841
  prefs: []
  type: TYPE_NORMAL
  zh: 实现使用 `numObs`（相对于 `numStates` 和 `numSymbols`）来程序化地表示观测数量 `T`（相对于 `N` 个隐藏状态和
    `M` 个特征）。一般来说，实现尽可能地重用数学符号。
- en: 'The `HMMConfig` companion object defines the operations on ranges of index
    of matrix rows and columns. The `foreach` (line `1`), `foldLeft` (`/:`) (line
    `2`), and `maxBy` (line `3`) methods are regularly used in each of the three canonical
    forms:'
  id: totrans-2842
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMMConfig` 伴随对象定义了对矩阵行和列索引范围的运算。`foreach`（行 `1`），`foldLeft` (`/:`)（行 `2`），和
    `maxBy`（行 `3`）方法在每个三个规范形式中经常使用：'
- en: '[PRE232]'
  id: totrans-2843
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: Note
  id: totrans-2844
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The λ notation**'
  id: totrans-2845
  prefs: []
  type: TYPE_NORMAL
  zh: '**λ 符号**'
- en: The *λ* model in the HMM should not be confused with the regularization factor
    discussed in the *L[n]* *roughness penalty* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*.
  id: totrans-2846
  prefs: []
  type: TYPE_NORMAL
  zh: HMM 中的 *λ* 模型不应与 [第 6 章](part0188.xhtml#aid-5J99O2 "第 6 章。回归和正则化") 中 *L[n]*
    *粗糙度惩罚* 部分讨论的正则化因子混淆，*回归和正则化*。
- en: 'As mentioned earlier, the lambda model is defined as a tuple of the transition
    probability matrix *A*, emission probability matrix *B*, and the initial probability
    *π*. It is easily implemented as an `HMMModel` class using the `DMatrix` class,
    as defined in the *Utility classes* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*. The simplest constructor for
    the `HMMModel` class is invoked in the case where the state-transition probability
    matrix, the emission probability matrix, and the initial states are known, as
    shown in the following code:'
  id: totrans-2847
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，λ 模型定义为转移概率矩阵 *A*，发射概率矩阵 *B* 和初始概率 *π* 的元组。它可以通过在 [附录 A](part0229.xhtml#aid-6QCGQ2
    "附录 A. 基本概念") 中定义的 `DMatrix` 类轻松实现为 `HMMModel` 类，如 *实用类* 部分所述，*基本概念*。当状态转移概率矩阵、发射概率矩阵和初始状态已知时，将调用
    `HMMModel` 类的最简单构造函数，如下面的代码所示：
- en: '[PRE233]'
  id: totrans-2848
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: 'The constructor of the `HMMModel` class has the following four arguments (line
    `4`):'
  id: totrans-2849
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMMModel` 类的构造函数有以下四个参数（行 `4`）：'
- en: '`A`: This is the state transition probabilities matrix'
  id: totrans-2850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A`：这是状态转移概率矩阵'
- en: '`B`: This is the omission probabilities matrix'
  id: totrans-2851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`B`：这是缺失概率矩阵'
- en: '`pi`: This is the initial probability for the states'
  id: totrans-2852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pi`：这是状态的初始概率'
- en: '`numObs`: This is the number of observations'
  id: totrans-2853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numObs`：这是观测的数量'
- en: The number of states and symbols are extracted from the dimension of the `A`
    and `B` matrices.
  id: totrans-2854
  prefs: []
  type: TYPE_NORMAL
  zh: 从矩阵 `A` 和 `B` 的维度中提取了状态和符号的数量。
- en: The `HMMModel` class has several methods that will be described in detail whenever
    they are required for the execution of the model. The probabilities for the `pi`
    initial states are unknown, and therefore, they are initialized with a random
    generator of values [0, 1].
  id: totrans-2855
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMMModel` 类有几个方法，当它们在执行模型时需要时将详细描述。对于 `pi` 初始状态的概率是未知的，因此，它们使用值 [0, 1] 的随机生成器进行初始化。'
- en: Note
  id: totrans-2856
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Normalization**'
  id: totrans-2857
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化**'
- en: Input states and observation data may have to be normalized and converted to
    probabilities before we initialize the `A` and `B` matrices.
  id: totrans-2858
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们初始化 `A` 和 `B` 矩阵之前，输入状态和观测数据可能需要归一化并转换为概率。
- en: The other two components of the HMM are the sequence of observations and the
    sequence of hidden states.
  id: totrans-2859
  prefs: []
  type: TYPE_NORMAL
  zh: HMM 的其他两个组成部分是观测序列和隐藏状态序列。
- en: Design
  id: totrans-2860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计
- en: 'The canonical forms of the HMM are implemented through dynamic programming
    techniques. These techniques rely on variables that define the state of the execution
    of the HMM for any of the canonical forms:'
  id: totrans-2861
  prefs: []
  type: TYPE_NORMAL
  zh: HMM 的规范形式通过动态规划技术实现。这些技术依赖于定义 HMM 任何规范形式的执行状态的变量：
- en: '`Alpha` (the forward pass): The probability of observing the first *t < T*
    observations for a specific state at *S[i]* for the observation *t* is *α[t](i)
    = p(O[0:t], q[t]=S[i]|λ)*'
  id: totrans-2862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Alpha`（正向传递）：在特定状态 `S[i]` 下，观察第一个 *t < T* 观测的概率是 *α[t](i) = p(O[0:t], q[t]=S[i]|λ)*'
- en: '`Beta` (the backward pass): The probability of observing the remainder of the
    sequence *q**t* for a specific state is *β[t](i) =p(O[t+1:T-1]|q[t]=S[i],λ)*'
  id: totrans-2863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Beta`（反向传递）：对于特定状态，观察序列 *q**t* 的剩余部分的概率是 *β[t](i) =p(O[t+1:T-1]|q[t]=S[i],λ)*'
- en: '`Gamma`: The probability of being in a specific state given a sequence of observations
    and a model is *γ[t](i) =p(q[t]=S[i]|O[0:T-1], λ)*'
  id: totrans-2864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Gamma`: 在给定观测序列和模型的情况下，处于特定状态的概率是 *γ[t](i) =p(q[t]=S[i]|O[0:T-1], λ)*'
- en: '`Delta`: This is the sequence that has the highest probability path for the
    first *i* observations defined for a specific test *δ[t](i)*'
  id: totrans-2865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Delta`: 这是对于特定测试定义的第一个 *i* 个观测的最高概率路径序列，定义为 *δ[t](i)*'
- en: '`Qstar`: This is the optimum sequence *q** of states *Q[0:T-1]*'
  id: totrans-2866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Qstar`: 这是最优状态序列 *q** 的 *Q[0:T-1]*'
- en: '`DiGamma`: The probability of being in a specific state at *t* and another
    defined state at *t + 1* given the sequence of observations and the model is *γ*[t](i,j)
    = p(q[t]=S[i],q[t+1]=S[j]|O[0:T-1], λ)'
  id: totrans-2867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DiGamma`: 在给定观测序列和模型的情况下，处于特定状态 *t* 和另一个定义状态 *t + 1* 的概率是 *γ*[t](i,j) = p(q[t]=S[i],q[t+1]=S[j]|O[0:T-1],
    λ)'
- en: Each of the parameters is described mathematically and programmatically in the
    section related to each specific canonical form. The `Gamma` and `DiGamma` classes
    are used and described in the evaluation canonical form. The `DiGamma` singleton
    is described as part of the Viterbi algorithm to extract the sequence of states
    with the highest probability given a *λ* model and a set of observations.
  id: totrans-2868
  prefs: []
  type: TYPE_NORMAL
  zh: 每个参数都在与每个特定标准形式相关的部分以数学和程序方式描述。在评估标准形式中使用了`Gamma`和`DiGamma`类，并进行了描述。`DiGamma`单例作为维特比算法的一部分进行描述，用于根据给定的
    *λ* 模型和一组观测值提取具有最高概率的状态序列。
- en: 'The list of dynamic programming-related algorithms used in any of the three
    canonical forms is visualized through the class hierarchy of our implementation
    of the HMM:'
  id: totrans-2869
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何三种标准形式中使用的与动态规划相关的算法列表通过我们实现HMM的类层次结构进行可视化：
- en: '![Design](img/image01423.jpeg)'
  id: totrans-2870
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01423.jpeg)'
- en: Scala classes' hierarchy for HMM (the UML class diagram)
  id: totrans-2871
  prefs: []
  type: TYPE_NORMAL
  zh: HMM的Scala类层次结构（UML类图）
- en: The UML diagram omits the utility traits and classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-2872
  prefs: []
  type: TYPE_NORMAL
  zh: UML图省略了`Monitor`或Apache Commons Math组件等实用特性类。
- en: The *λ* model, the HMM state, and the sequence of observations are all the elements
    needed to implement the three canonical cases. Each class is described as needed
    in the description of the three canonical forms of HMM. It is time to dive into
    the implementation details of each of the canonical forms, starting with the evaluation.
  id: totrans-2873
  prefs: []
  type: TYPE_NORMAL
  zh: '*λ* 模型、HMM状态和观测序列都是实现三种标准情况所需的元素。每个类都在HMM三种标准形式的描述中按需进行描述。现在是时候深入研究每种标准形式的具体实现细节了，从评估开始。'
- en: The execution of any of the three canonical forms relies on dynamic programming
    techniques (refer to the *Overview of dynamic programming* section in the [Appendix
    A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*)
    [7:5]. The simplest of the dynamic programming techniques is a single traversal
    of the observations/state chain.
  id: totrans-2874
  prefs: []
  type: TYPE_NORMAL
  zh: 任何三种标准形式的执行都依赖于动态规划技术（请参阅[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*动态规划概述*部分，*基本概念*）[7:5]。动态规划技术中最简单的是对观测/状态链的单次遍历。
- en: Evaluation – CF-1
  id: totrans-2875
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估 – CF-1
- en: 'The objective is to compute the probability (or likelihood) of the observed
    sequence *O[t]* given a *λ* model. A dynamic programming technique is used to
    break down the probability of the sequence of observations into two probabilities
    (**M1**):'
  id: totrans-2876
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是计算给定 *λ* 模型观察序列 *O[t]* 的概率（或似然）。使用动态规划技术将观测序列的概率分解为两个概率（**M1**）：
- en: '![Evaluation – CF-1](img/image01424.jpeg)'
  id: totrans-2877
  prefs: []
  type: TYPE_IMG
  zh: '![评估 – CF-1](img/image01424.jpeg)'
- en: 'The likelihood is computed by marginalizing over all the hidden states *{S[i]}*
    [7:6] (**M2**):'
  id: totrans-2878
  prefs: []
  type: TYPE_NORMAL
  zh: 似然是通过对所有隐藏状态 *{S[i]}* [7:6] 进行边缘化来计算的（**M2**）：
- en: '![Evaluation – CF-1](img/image01425.jpeg)'
  id: totrans-2879
  prefs: []
  type: TYPE_IMG
  zh: '![评估 – CF-1](img/image01425.jpeg)'
- en: 'If we use the notation introduced in the previous chapter for alpha and beta
    variables, the probability for the observed sequence *O[t]* given a *λ* model
    can be expressed as follows (**M3**):'
  id: totrans-2880
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用前一章中引入的alpha和beta变量的符号，给定 *λ* 模型观察序列 *O[t]* 的概率可以表示如下（**M3**）：
- en: '![Evaluation – CF-1](img/image01426.jpeg)'
  id: totrans-2881
  prefs: []
  type: TYPE_IMG
  zh: '![评估 – CF-1](img/image01426.jpeg)'
- en: The product of the *α* and *β* probabilities can potentially underflow. Therefore,
    it is recommended that you use the log of the probabilities instead of the probabilities.
  id: totrans-2882
  prefs: []
  type: TYPE_NORMAL
  zh: '*α* 和 *β* 概率的乘积可能会下溢。因此，建议您使用概率的对数而不是概率本身。'
- en: Alpha – the forward pass
  id: totrans-2883
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Alpha – 前向传递
- en: 'The computation of the probability of observing a specific sequence given a
    sequence of hidden states and a *λ* model relies on a two-pass algorithm. The
    alpha algorithm consists of the following steps:'
  id: totrans-2884
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个隐藏状态序列和一个 *λ* 模型，计算观察特定序列的概率依赖于一个两遍算法。alpha 算法包括以下步骤：
- en: Compute the initial alpha value [**M4**]. The value is then normalized by the
    sum of alpha values across all the hidden states [**M5**].
  id: totrans-2885
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算初始 alpha 值 [**M4**]。然后通过所有隐藏状态的 alpha 值之和进行归一化 [**M5**]。
- en: Compute the alpha value iteratively for the time 0 to time *t*, and then normalize
    it by the sum of alpha values for all states [**M6**].
  id: totrans-2886
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 依次计算从时间 0 到时间 *t* 的 alpha 值，然后通过所有状态的 alpha 值之和进行归一化 [**M6**]。
- en: The final step is to compute of the log of the probability of observing the
    sequence [**M7**].
  id: totrans-2887
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终一步是计算观察序列 [**M7**] 的概率的对数。
- en: Note
  id: totrans-2888
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Performance consideration**'
  id: totrans-2889
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能考虑**'
- en: A direct computation of the probability of observing a specific sequence requires
    *2TN[2]* multiplications. The iterative alpha and beta classes reduce the number
    of multiplications to *N[2]T*.
  id: totrans-2890
  prefs: []
  type: TYPE_NORMAL
  zh: 直接计算观察特定序列的概率需要 *2TN[2]* 次乘法。迭代的 alpha 和 beta 类将乘法次数减少到 *N[2]T*。
- en: For those with some inclination toward mathematics, the computation of the alpha
    matrix is defined in the following information box.
  id: totrans-2891
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些对数学有些倾向的人来说，alpha 矩阵的计算定义在以下信息框中。
- en: Note
  id: totrans-2892
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Alpha (the forward pass)**'
  id: totrans-2893
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alpha（前向传递）**'
- en: 'M4: Initialization is defined as:'
  id: totrans-2894
  prefs: []
  type: TYPE_NORMAL
  zh: M4：初始化定义为：
- en: '![Alpha – the forward pass](img/image01427.jpeg)'
  id: totrans-2895
  prefs: []
  type: TYPE_IMG
  zh: '![Alpha – 前向传递](img/image01427.jpeg)'
- en: 'M5: Normalization of initial values *N – 1* is defined as:'
  id: totrans-2896
  prefs: []
  type: TYPE_NORMAL
  zh: M5：初始值归一化 *N – 1* 定义为：
- en: '![Alpha – the forward pass](img/image01428.jpeg)'
  id: totrans-2897
  prefs: []
  type: TYPE_IMG
  zh: '![Alpha – 前向传递](img/image01428.jpeg)'
- en: 'M6: Normalized summation is defined as:'
  id: totrans-2898
  prefs: []
  type: TYPE_NORMAL
  zh: M6：归一化求和定义为：
- en: '![Alpha – the forward pass](img/image01429.jpeg)'
  id: totrans-2899
  prefs: []
  type: TYPE_IMG
  zh: '![Alpha – 前向传递](img/image01429.jpeg)'
- en: 'M7: The probability of observing a sequence given a lambda model and states
    is defined as:'
  id: totrans-2900
  prefs: []
  type: TYPE_NORMAL
  zh: M7：给定一个 lambda 模型和状态，观察一个序列的概率定义为：
- en: '![Alpha – the forward pass](img/image01430.jpeg)'
  id: totrans-2901
  prefs: []
  type: TYPE_IMG
  zh: '![Alpha – 前向传递](img/image01430.jpeg)'
- en: 'Let''s take a look at the implementation of the alpha class in Scala, using
    the referenced number of the mathematical expressions of the alpha class. The
    alpha and beta values have to be normalized [M3], and therefore, we define an
    `HMMTreillis` base class for the alpha and beta algorithms that implements the
    normalization:'
  id: totrans-2902
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Scala 中 alpha 类的实现，使用 alpha 类的数学表达式引用编号。alpha 和 beta 值必须归一化 [M3]，因此我们定义了一个
    `HMMTreillis` 基类，用于 alpha 和 beta 算法，并实现了归一化：
- en: '[PRE234]'
  id: totrans-2903
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: 'The `HMMTreillis` class has two configuration parameters: the number of observations,
    `numObs`, and the number of states, `numStates` (line `5`). The `treillis` variable
    represents the scaling matrix used in the alpha (or forward) and beta (or backward)
    passes (line `6`).'
  id: totrans-2904
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMMTreillis` 类有两个配置参数：观察数 `numObs` 和状态数 `numStates`（第 `5` 行）。`treillis` 变量代表在
    alpha（或前向）和 beta（或后向）传递中使用的缩放矩阵（第 `6` 行）。'
- en: The normalization method, `normalize`, implements the **M6** formula by recomputing
    the `ct` scaling factor (line `7`).
  id: totrans-2905
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化方法 `normalize` 通过重新计算 `ct` 缩放因子（第 `7` 行）实现了 **M6** 公式。
- en: Note
  id: totrans-2906
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Computation efficiency**'
  id: totrans-2907
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算效率**'
- en: Scala's `reduce`, `fold`, and `foreach` methods are far more efficient iterators
    than the `for` loop. You need to keep in mind that the main purpose of the `for`
    loop in Scala is the monadic composition of the `map` and `flatMap` operations.
  id: totrans-2908
  prefs: []
  type: TYPE_NORMAL
  zh: Scala 的 `reduce`、`fold` 和 `foreach` 方法比 `for` 循环更高效的迭代器。你需要记住，Scala 中 `for`
    循环的主要目的是 `map` 和 `flatMap` 操作的单一组合。
- en: 'The computation of the `alpha` variable in the `Alpha` class follows the same
    computation flow as defined in the **M4**, **M5**, and **M6** mathematical expressions:'
  id: totrans-2909
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Alpha` 类中计算 `alpha` 变量的计算流程与在 **M4**、**M5** 和 **M6** 数学表达式中定义的计算流程相同：
- en: '[PRE235]'
  id: totrans-2910
  prefs: []
  type: TYPE_PRE
  zh: '[PRE235]'
- en: 'The `Alpha` class has two arguments: the `lambda` model and the `obsSeq` sequence
    of observations (line `8`). The definition of the scaling factor `alpha` initializes
    the `treillis` scaling matrix using the `HMMModel.setAlpha` method (line `9`),
    normalizes the initial value of the matrix by invoking the `HMMTreillis.normalize`
    method for the first observation (line `10`), and sums the matrix element to return
    the scaling factor by invoking `sumUp` (line `11`).'
  id: totrans-2911
  prefs: []
  type: TYPE_NORMAL
  zh: '`Alpha`类有两个参数：`lambda`模型和观测值序列`obsSeq`（行`8`）。缩放因子`alpha`的定义初始化`treillis`缩放矩阵使用`HMMModel.setAlpha`方法（行`9`），通过调用`HMMTreillis.normalize`方法对第一个观测值进行归一化以初始化矩阵的初始值（行`10`），并通过调用`sumUp`来返回缩放因子（行`11`）。'
- en: 'The `setAlpha` method implements the mathematical expression **M4** as follows:'
  id: totrans-2912
  prefs: []
  type: TYPE_NORMAL
  zh: '`setAlpha`方法实现了数学表达式**M4**，如下所示：'
- en: '[PRE236]'
  id: totrans-2913
  prefs: []
  type: TYPE_PRE
  zh: '[PRE236]'
- en: The fold generates an instance of the `DMatrix` class, as described in the *Utility
    classes* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*.
  id: totrans-2914
  prefs: []
  type: TYPE_NORMAL
  zh: 折叠生成了一个`DMatrix`类的实例，正如在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中*实用类*部分所描述的，*基本概念*。
- en: 'The `sumUp` method implements the mathematical expression **M6** as follows:'
  id: totrans-2915
  prefs: []
  type: TYPE_NORMAL
  zh: '`sumUp`方法实现了数学表达式**M6**，如下所示：'
- en: Update the `treillis` matrix of the scaling factor in the `updateAlpha` method
    (line `12`)
  id: totrans-2916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`updateAlpha`方法中更新缩放因子的`treillis`矩阵（行`12`）
- en: Normalize all the scaling factors for all the remaining observations (line `13`)
  id: totrans-2917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化所有剩余观测值的缩放因子（行`13`）
- en: The `updateAlpha` method updates the `treillis` scaling matrix by computing
    all the `alpha` factors for all states (line `14`). The `logProb` method implements
    the mathematical expression **M7**. It computes the logarithm of the probability
    of observing a specific sequence, given the sequence of states and a predefined
    *λ* model (line `15`).
  id: totrans-2918
  prefs: []
  type: TYPE_NORMAL
  zh: '`updateAlpha`方法通过计算所有状态的`alpha`因子来更新`treillis`缩放矩阵（行`14`）。`logProb`方法实现了数学表达式**M7**。它计算在给定状态序列和预定义的*λ*模型下观察特定序列的概率的对数（行`15`）。'
- en: Note
  id: totrans-2919
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The log probability**'
  id: totrans-2920
  prefs: []
  type: TYPE_NORMAL
  zh: '**对数概率**'
- en: The `logProb` method computes the logarithm of the probability instead of the
    probability itself. The summation of the logarithm of probabilities is less likely
    to cause an underflow than the product of probabilities.
  id: totrans-2921
  prefs: []
  type: TYPE_NORMAL
  zh: '`logProb`方法计算概率的对数而不是概率本身。概率对数的和比概率的乘积更不容易导致下溢。'
- en: Beta – the backward pass
  id: totrans-2922
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Beta – 反向传播
- en: The computation of beta values is similar to the `Alpha` class except that the
    iteration executes backward on the sequence of states.
  id: totrans-2923
  prefs: []
  type: TYPE_NORMAL
  zh: beta值的计算类似于`Alpha`类，除了迭代在状态序列上反向执行。
- en: 'The implementation of `Beta` is similar to the alpha class:'
  id: totrans-2924
  prefs: []
  type: TYPE_NORMAL
  zh: '`Beta`的实现与alpha类相似：'
- en: Compute (**M5**) and normalize (**M6**) the value of beta at *t = 0* across
    states.
  id: totrans-2925
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算（**M5**）并标准化（**M6**）时间*t = 0*的beta值在各个状态之间。
- en: Compute and normalize iteratively the beta value at time *T - 1* to *t*, which
    is updated from its value at *t + 1* (**M7**).
  id: totrans-2926
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归地计算并标准化时间*T - 1*到*t*的beta值，该值从*t + 1*的值更新（**M7**）。
- en: Note
  id: totrans-2927
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Beta (the backward pass)**'
  id: totrans-2928
  prefs: []
  type: TYPE_NORMAL
  zh: '**Beta（反向传播**）'
- en: 'M8: Initialization of beta *β[T-1](t) = 1*.'
  id: totrans-2929
  prefs: []
  type: TYPE_NORMAL
  zh: 'M8: 初始化beta *β[T-1](t) = 1*。'
- en: 'M9: Normalization of initial beta values is defined as:'
  id: totrans-2930
  prefs: []
  type: TYPE_NORMAL
  zh: 'M9: 初始beta值的归一化定义为：'
- en: '![Beta – the backward pass](img/image01431.jpeg)'
  id: totrans-2931
  prefs: []
  type: TYPE_IMG
  zh: '![Beta – 反向传播](img/image01431.jpeg)'
- en: 'M10: Normalized summation of beta is defined as:'
  id: totrans-2932
  prefs: []
  type: TYPE_NORMAL
  zh: 'M10: 归一化beta值的加和定义为：'
- en: '![Beta – the backward pass](img/image01432.jpeg)'
  id: totrans-2933
  prefs: []
  type: TYPE_IMG
  zh: '![Beta – 反向传播](img/image01432.jpeg)'
- en: 'The definition of the `Beta` class is very similar to the `Alpha` class:'
  id: totrans-2934
  prefs: []
  type: TYPE_NORMAL
  zh: '`Beta`类的定义与`Alpha`类非常相似：'
- en: '[PRE237]'
  id: totrans-2935
  prefs: []
  type: TYPE_PRE
  zh: '[PRE237]'
- en: 'Contrary to the `Alpha` class, the `Beta` class does not generate an output
    value. The `Beta` class has an `initialized` Boolean attribute to indicate whether
    the constructor has executed successfully (line `16`). The constructor updates
    and normalizes the beta matrix by traversing the sequence of observations backward
    from before the last observation to the first:'
  id: totrans-2936
  prefs: []
  type: TYPE_NORMAL
  zh: 与`Alpha`类相反，`Beta`类不生成输出值。`Beta`类有一个`initialized`布尔属性，用来指示构造函数是否成功执行（行`16`）。构造函数通过遍历从最后一个观测值之前到第一个观测值的观测序列来更新和归一化beta矩阵：
- en: '[PRE238]'
  id: totrans-2937
  prefs: []
  type: TYPE_PRE
  zh: '[PRE238]'
- en: The initialization of the `treillis` beta scaling matrix of the `DMatrix` type
    assigns the value `1.0` to the last observation (line `21`) and normalizes the
    beta values for the last observation, as defined in **M8** (line `22`). It implements
    the mathematical expressions **M9** and **M10** by invoking the `sumUp` method
    (line `23`).
  id: totrans-2938
  prefs: []
  type: TYPE_NORMAL
  zh: '`DMatrix` 类的 `treillis` beta 缩放矩阵的初始化将值 `1.0` 分配给最后一个观察值（第 21 行），并按 **M8**（第
    22 行）中定义的归一化 beta 值。它通过调用 `sumUp` 方法实现数学表达式 **M9** 和 **M10**（第 23 行）。'
- en: 'The `sumUp` method is similar to `Alpha.sumUp` (line `17`). It traverses the
    sequence of observations backward (line `18`) and updates the beta scaling matrix,
    as defined in the mathematical expression **M9** (line `19`). The implementation
    of the mathematical expression **M10** in the `updateBeta` method is similar to
    the alpha pass: it updates the `treillis` scaling matrix with the `newBeta` values
    computed in the `lambda` model (line `20`).'
  id: totrans-2939
  prefs: []
  type: TYPE_NORMAL
  zh: '`sumUp` 方法与 `Alpha.sumUp`（第 17 行）类似。它从观察序列的末尾开始遍历（第 18 行），并更新定义在数学表达式 **M9**（第
    19 行）中的 beta 缩放矩阵。`updateBeta` 方法中数学表达式 **M10** 的实现与 alpha 过程类似：它使用在 `lambda`
    模型中计算的 `newBeta` 值更新 `treillis` 缩放矩阵（第 20 行）。'
- en: Note
  id: totrans-2940
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Constructors and initialization**'
  id: totrans-2941
  prefs: []
  type: TYPE_NORMAL
  zh: '**构造函数和初始化**'
- en: The alpha and beta values are computed within the constructors of their respective
    classes. The client code has to validate these instances by invoking `isInitialized`.
  id: totrans-2942
  prefs: []
  type: TYPE_NORMAL
  zh: alpha 和 beta 值在各自类的构造函数中计算。客户端代码必须通过调用 `isInitialized` 验证这些实例。
- en: What is the value of a model if it cannot be created? The next canonical form
    CF2 leverages dynamic programming and recursive functions to extract the *λ* model.
  id: totrans-2943
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个模型无法创建，它的值是多少？下一个规范形式 CF2 利用动态规划和递归函数提取 *λ* 模型。
- en: Training – CF-2
  id: totrans-2944
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练 – CF-2
- en: The objective of this canonical form is to extract the *λ* model given a set
    of observations and a sequence of states. It is similar to the training of a classifier.
    The simple dependency of a current state on the previous state enables an implementation
    using an iterative procedure, known as the **Baum-Welch estimator** or **expectation-maximization**
    (**EM**).
  id: totrans-2945
  prefs: []
  type: TYPE_NORMAL
  zh: 该规范形式的目标是在给定一组观察值和状态序列的情况下提取 *λ* 模型。它与分类器的训练类似。当前状态对先前状态的简单依赖性使得可以使用迭代过程实现，称为
    **Baum-Welch 估计器** 或 **期望最大化**（**EM**）。
- en: The Baum-Welch estimator (EM)
  id: totrans-2946
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Baum-Welch 估计器（EM）
- en: 'At its core, the algorithm consists of three steps and an iterative method,
    which is similar to the evaluation canonical form:'
  id: totrans-2947
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，该算法由三个步骤和一个迭代方法组成，类似于评估规范形式：
- en: Compute the probability *π* (the gamma value at *t = 0*) (**M11**).
  id: totrans-2948
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算概率 *π*（*t = 0* 时的 gamma 值）（**M11**）。
- en: Compute and normalize the state's transition probabilities matrix *A* (**M12**).
  id: totrans-2949
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算并归一化状态的过渡概率矩阵 *A*（**M12**）。
- en: Compute and normalize the matrix of emission probabilities *B* (**M13**).
  id: totrans-2950
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算并归一化发射概率矩阵 *B*（**M13**）。
- en: Repeat steps 2 and 3 until the change of likelihood is insignificant.
  id: totrans-2951
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2 和 3，直到似然度的变化不显著。
- en: The algorithm uses the digamma and summation gamma classes.
  id: totrans-2952
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法使用 digamma 和求和 gamma 类。
- en: Note
  id: totrans-2953
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The Baum-Welch algorithm**'
  id: totrans-2954
  prefs: []
  type: TYPE_NORMAL
  zh: '**Baum-Welch 算法**'
- en: 'M11: The joint probability of the state *q[i]* at *t* and *q[j]* at *t+1* (digamma)
    is defined as:'
  id: totrans-2955
  prefs: []
  type: TYPE_NORMAL
  zh: M11：状态 *q[i]* 在 *t* 时刻和状态 *q[j]* 在 *t+1* 时刻的联合概率（digamma）定义为：
- en: '![The Baum-Welch estimator (EM)](img/image01433.jpeg)![The Baum-Welch estimator
    (EM)](img/image01434.jpeg)'
  id: totrans-2956
  prefs: []
  type: TYPE_IMG
  zh: '![Baum-Welch估计器（EM）](img/image01433.jpeg)![Baum-Welch估计器（EM）](img/image01434.jpeg)'
- en: 'M12: The initial probabilities vector *N−1* and sum of joint probabilities
    for all the states (gamma)are defined as:'
  id: totrans-2957
  prefs: []
  type: TYPE_NORMAL
  zh: M12：初始概率向量 *N−1* 和所有状态的联合概率之和（gamma）定义为：
- en: '![The Baum-Welch estimator (EM)](img/image01435.jpeg)'
  id: totrans-2958
  prefs: []
  type: TYPE_IMG
  zh: '![Baum-Welch估计器（EM）](img/image01435.jpeg)'
- en: 'M13: The update of the transition probabilities matrix is defined as:'
  id: totrans-2959
  prefs: []
  type: TYPE_NORMAL
  zh: M13：过渡概率矩阵的更新定义为：
- en: '![The Baum-Welch estimator (EM)](img/image01436.jpeg)'
  id: totrans-2960
  prefs: []
  type: TYPE_IMG
  zh: '![Baum-Welch估计器（EM）](img/image01436.jpeg)'
- en: 'M14: The update of the emission probabilities matrix is defined as:'
  id: totrans-2961
  prefs: []
  type: TYPE_NORMAL
  zh: M14：发射概率矩阵的更新定义为：
- en: '![The Baum-Welch estimator (EM)](img/image01437.jpeg)'
  id: totrans-2962
  prefs: []
  type: TYPE_IMG
  zh: '![Baum-Welch估计器（EM）](img/image01437.jpeg)'
- en: 'The Baum-Welch algorithm is implemented in the `BaumWelchEM` class and requires
    the following two inputs (line `24`):'
  id: totrans-2963
  prefs: []
  type: TYPE_NORMAL
  zh: Baum-Welch 算法在 `BaumWelchEM` 类中实现，并需要以下两个输入（第 24 行）：
- en: The *λ* model, `lambda`, computed from the `config` configuration
  id: totrans-2964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `config` 配置计算得到的 *λ* 模型
- en: The `obsSeq` sequence (vector) of observations
  id: totrans-2965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察序列 `obsSeq`（向量）
- en: 'The code will be as follows:'
  id: totrans-2966
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE239]'
  id: totrans-2967
  prefs: []
  type: TYPE_PRE
  zh: '[PRE239]'
- en: 'The `DiGamma` class defines the joint probabilities for any consecutive states
    (line `25`):'
  id: totrans-2968
  prefs: []
  type: TYPE_NORMAL
  zh: '`DiGamma`类定义了任何连续状态之间的联合概率（行`25`）：'
- en: '[PRE240]'
  id: totrans-2969
  prefs: []
  type: TYPE_PRE
  zh: '[PRE240]'
- en: The `diGamma` variable is an array of matrices that represents the joint probabilities
    of two consecutive states. It is initialized through an invocation of the `update`
    method, which implements the mathematical expression **M11**.
  id: totrans-2970
  prefs: []
  type: TYPE_NORMAL
  zh: '`diGamma`变量是一个矩阵数组，表示两个连续状态的联合概率。它通过调用`update`方法初始化，该方法实现了数学表达式**M11**。'
- en: 'The `Gamma` class computes the sum of the joint probabilities across all the
    states (line `26`):'
  id: totrans-2971
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gamma`类计算所有状态之间的联合概率总和（行`26`）：'
- en: '[PRE241]'
  id: totrans-2972
  prefs: []
  type: TYPE_PRE
  zh: '[PRE241]'
- en: The `update` method of the `Gamma` class implements the mathematical expression
    **M12**.
  id: totrans-2973
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gamma`类的`update`方法实现了数学表达式**M12**。'
- en: Note
  id: totrans-2974
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Source code for Gamma and DiGamma**'
  id: totrans-2975
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gamma和DiGamma的源代码**'
- en: The `Gamma` and `DiGamma` classes implement the mathematical expressions for
    the Baum-Welch algorithm. The `update` method uses simple linear algebra and is
    not described; refer to the documented source code for details.
  id: totrans-2976
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gamma`和`DiGamma`类实现了Baum-Welch算法的数学表达式。`update`方法使用简单的线性代数，此处未描述；请参阅文档化的源代码以获取详细信息。'
- en: 'The maximum likelihood, `maxLikelihood`, for the sequence of states given an
    existing lambda model and a sequence of observations (line `27`) is computed using
    the `getLikelihood` tail recursive method, as follows:'
  id: totrans-2977
  prefs: []
  type: TYPE_NORMAL
  zh: 给定现有的lambda模型和观察序列（行`27`），使用`getLikelihood`尾递归方法计算状态序列的最大似然`maxLikelihood`，如下所示：
- en: '[PRE242]'
  id: totrans-2978
  prefs: []
  type: TYPE_PRE
  zh: '[PRE242]'
- en: The `maxLikelihood` value implements the mathematical expressions **M13** and
    **M14**. The `getLikelihood` recursive method updates the lambda model matrices
    *A* and *B* and initial state probabilities *pi* (line `28`). The likelihood for
    the sequence of states is recomputed using the forward-backward lattice algorithm
    implemented in the `frwrBckwrdLattice` method (line `29`).
  id: totrans-2979
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxLikelihood`值实现了数学表达式**M13**和**M14**。`getLikelihood`递归方法更新lambda模型矩阵*A*和*B*以及初始状态概率*pi*（行`28`）。使用`frwrBckwrdLattice`方法实现的向前向后格算法重新计算状态序列的似然（行`29`）。'
- en: Note
  id: totrans-2980
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Update of lambda model**'
  id: totrans-2981
  prefs: []
  type: TYPE_NORMAL
  zh: '**lambda模型的更新**'
- en: The `update` method of the `HMMModel` object uses simple linear algebra and
    is not described; refer to the documented source code for details.
  id: totrans-2982
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMMModel`对象的`update`方法使用简单的线性代数，此处未描述；请参阅文档化的源代码以获取详细信息。'
- en: 'The core of the Baum-Welch expectation maximization is the iterative forward
    and backward update of the lattice of states and observations between time *t*
    and *t + 1*. The lattice-based iterative computation is illustrated in the following
    diagram:'
  id: totrans-2983
  prefs: []
  type: TYPE_NORMAL
  zh: Baum-Welch期望最大化算法的核心是迭代地更新时间`t`和`t + 1`之间状态和观察值的格。基于格的迭代计算在以下图中展示：
- en: '![The Baum-Welch estimator (EM)](img/image01438.jpeg)'
  id: totrans-2984
  prefs: []
  type: TYPE_IMG
  zh: '![Baum-Welch估计器（EM）](img/image01438.jpeg)'
- en: The visualization of the HMM graph lattice for the Baum-Welch algorithm
  id: totrans-2985
  prefs: []
  type: TYPE_NORMAL
  zh: Baum-Welch算法的HMM图格可视化
- en: 'The code will be as follows:'
  id: totrans-2986
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE243]'
  id: totrans-2987
  prefs: []
  type: TYPE_PRE
  zh: '[PRE243]'
- en: The forward-backward algorithm uses the `Alpha` class for the computation/update
    of the `lambda` model in the forward pass(line `33`) and the `Beta` class for
    the update of `lambda` in the backward pass (line `34`). The joint probabilities-related
    `gamma` and `diGamma` matrices are updated at each recursion (line `35`), reflecting
    the iteration of the mathematical expressions **M11** to **M14**.
  id: totrans-2988
  prefs: []
  type: TYPE_NORMAL
  zh: 向前向后算法在正向传递中使用`Alpha`类进行`lambda`模型的计算/更新（行`33`），在反向传递中使用`Beta`类更新`lambda`（行`34`）。与联合概率相关的`gamma`和`diGamma`矩阵在每个递归时更新（行`35`），反映了数学表达式**M11**到**M14**的迭代。
- en: The recursive computation of `maxLikelihood` exists if the algorithm converges
    (line `30`). It throws an exception if the maximum number of recursions is exceeded
    (line `31`).
  id: totrans-2989
  prefs: []
  type: TYPE_NORMAL
  zh: 如果算法收敛（行`30`），则存在`maxLikelihood`的递归计算。如果超过最大递归次数，则抛出异常（行`31`）。
- en: Decoding – CF-3
  id: totrans-2990
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码 – CF-3
- en: This last canonical form consists of extracting the most likely sequence of
    states *{q[t]}* given a set of observations *O[t]* and a *λ* model. Solving this
    problem requires, once again, a recursive algorithm.
  id: totrans-2991
  prefs: []
  type: TYPE_NORMAL
  zh: 最后这个规范形式包括在给定一组观察值*O[t]*和*λ*模型的情况下，提取最可能的状态序列*{q[t]}*。解决此问题需要再次使用递归算法。
- en: The Viterbi algorithm
  id: totrans-2992
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Viterbi算法
- en: The extraction of the best state sequence (the sequence of a state that has
    the highest probability) is very time consuming. An alternative consists of applying
    a dynamic programming technique to find the best sequence *{q[t]}* through iteration.
    This algorithm is known as the **Viterbi algorithm**. Given a sequence of states
    *{q[t]}* and sequence of observations *{o[j]}*, the probability *δ[t](i)* for
    any sequence to have the highest probability path for the first *T* observations
    is defined for the state *S[i]* [7:7].
  id: totrans-2993
  prefs: []
  type: TYPE_NORMAL
  zh: 提取最佳状态序列（具有最高概率的状态序列）非常耗时。一种替代方法是应用动态规划技术通过迭代找到最佳序列*{q[t]}*。这个算法被称为**维特比算法**。给定状态序列*{q[t]}*和观察序列*{o[j]}*，对于状态*S[i]*，定义了任何序列在第一个*T*观察中的最高概率路径的概率*δ[t](i)*
    [7:7]。
- en: Note
  id: totrans-2994
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The Viterbi algorithm**'
  id: totrans-2995
  prefs: []
  type: TYPE_NORMAL
  zh: '**维特比算法**'
- en: 'M12: The definition of the delta function is as follows:'
  id: totrans-2996
  prefs: []
  type: TYPE_NORMAL
  zh: M12：delta函数的定义如下：
- en: '![The Viterbi algorithm](img/image01439.jpeg)'
  id: totrans-2997
  prefs: []
  type: TYPE_IMG
  zh: '![维特比算法](img/image01439.jpeg)'
- en: 'M13: Initialization of delta is defined as:'
  id: totrans-2998
  prefs: []
  type: TYPE_NORMAL
  zh: M13：delta的初始化定义为：
- en: '![The Viterbi algorithm](img/image01440.jpeg)'
  id: totrans-2999
  prefs: []
  type: TYPE_IMG
  zh: '![维特比算法](img/image01440.jpeg)'
- en: 'M14: Recursive computation of delta is defined as:'
  id: totrans-3000
  prefs: []
  type: TYPE_NORMAL
  zh: M14：delta的递归计算定义为：
- en: '![The Viterbi algorithm](img/image01441.jpeg)'
  id: totrans-3001
  prefs: []
  type: TYPE_IMG
  zh: '![维特比算法](img/image01441.jpeg)'
- en: 'M15: The computation of the optimum state sequence {q} is defined as:'
  id: totrans-3002
  prefs: []
  type: TYPE_NORMAL
  zh: M15：最优状态序列{q}的计算定义为：
- en: '![The Viterbi algorithm](img/image01442.jpeg)'
  id: totrans-3003
  prefs: []
  type: TYPE_IMG
  zh: '![维特比算法](img/image01442.jpeg)'
- en: The `ViterbiPath` class implements the Viterbi algorithm whose purpose is to
    compute the optimum sequence (or path) of states given a set of observations and
    a *λ* model. The optimum sequence or path of states is computed by maximizing
    the delta function.
  id: totrans-3004
  prefs: []
  type: TYPE_NORMAL
  zh: '`ViterbiPath`类实现了维特比算法，其目的是在给定一组观察和*λ*模型的情况下计算最优状态序列（或路径）。最优状态序列或路径是通过最大化delta函数来计算的。'
- en: 'The constructors for the `ViterbiPath` class have the same arguments as the
    forward, backward, and Baum-Welch algorithm: the `lambda` model and the set of
    observations `obsSeq`:'
  id: totrans-3005
  prefs: []
  type: TYPE_NORMAL
  zh: '`ViterbiPath`类的构造函数与forward、backward和Baum-Welch算法的参数相同：`lambda`模型和观察集`obsSeq`：'
- en: '[PRE244]'
  id: totrans-3006
  prefs: []
  type: TYPE_PRE
  zh: '[PRE244]'
- en: 'As seen in the preceding information box containing the mathematical expressions
    for the Viterbi algorithm, the following matrices have to be defined:'
  id: totrans-3007
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，包含维特比算法数学表达式的信息框中，必须定义以下矩阵：
- en: '`psi`: This is the matrix of indices of `nObs` observations by indices of `nStates`
    states (line `35`).'
  id: totrans-3008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psi`：这是由*nObs*个观察的索引和*nStates*个状态的索引组成的矩阵（第`35`行）。'
- en: '`qStar`: This is the optimum sequence of states at each recursion of the Viterbi
    algorithm (line `36`).'
  id: totrans-3009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qStar`：这是维特比算法每次递归的最优状态序列（第`36`行）。'
- en: '`delta`: This is the sequence that has the highest probability path for the
    first *n* observations. It also sets the `psi` values for the first observation
    to 0 (line `37`).'
  id: totrans-3010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delta`：这是具有最高概率路径的前*n*个观察序列。它还设置了第一个观察的`psi`值为0（第`37`行）。'
- en: All members of the `ViterbiPath` class are private except `path` that defines
    the optimum sequence or path of states given the `obsSeq` observations (line `38`).
  id: totrans-3011
  prefs: []
  type: TYPE_NORMAL
  zh: '`ViterbiPath`类的所有成员都是私有的，除了定义给定`obsSeq`观察的最优状态序列或路径的`path`（第`38`行）。'
- en: 'The matrix that defines the maximum probability `delta` of any sequence of
    states given the `lambda` model and the `obsSeq` observation is initialized using
    the mathematical expression **M13** (line `37`). The predictive model returns
    the path or optimum sequence of states as an instance of `HMMPrediction`:'
  id: totrans-3012
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数学表达式**M13**（第`37`行）初始化定义了给定`lambda`模型和`obsSeq`观察的最大概率`delta`矩阵。预测模型返回路径或最优状态序列作为`HMMPrediction`实例：
- en: '[PRE245]'
  id: totrans-3013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE245]'
- en: The first argument of `likelihood` is computed by the `viterbi` recursive method.
    The indices of the states in the `states` optimum sequence is computed by the
    `QStar` class (line `38`).
  id: totrans-3014
  prefs: []
  type: TYPE_NORMAL
  zh: '`likelihood`的第一个参数是通过`viterbi`递归方法计算的。`states`最优序列中状态的下标是通过`QStar`类（第`38`行）计算的。'
- en: 'Let''s take a look under the hood of the Viterbi recursive method:'
  id: totrans-3015
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看维特比递归方法的内部结构：
- en: '[PRE246]'
  id: totrans-3016
  prefs: []
  type: TYPE_PRE
  zh: '[PRE246]'
- en: 'The recursion started on the second observation as the `qStar`, `psi`, and
    `delta` parameters have already been initialized in the constructor. The recursive
    implementation invokes the `updateMaxDelta` method to update the `psi` indexing
    matrix and the highest probability for any state, as follows:'
  id: totrans-3017
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`qStar`、`psi`和`delta`参数已经在构造函数中初始化，递归实现从第二个观察开始。递归实现调用`updateMaxDelta`方法来更新`psi`索引矩阵和任何状态的最高概率，如下所示：
- en: '[PRE247]'
  id: totrans-3018
  prefs: []
  type: TYPE_PRE
  zh: '[PRE247]'
- en: The `updateMaxDelta` method implements the mathematical expression **M14** that
    extracts the index of the state that maximizes `psi` (line `44`). The `delta`
    probability matrix and the `psi` indexing matrix are updated accordingly (line
    `45`).
  id: totrans-3019
  prefs: []
  type: TYPE_NORMAL
  zh: '`updateMaxDelta` 方法实现了数学表达式 **M14**，该表达式提取使 `psi` 最大的状态索引（行 `44`）。相应地更新 `delta`
    概率矩阵和 `psi` 索引矩阵（行 `45`）。'
- en: The `viterbi` method is called recursively for the remaining observations except
    the last one (line `43`). At the last observation of the `obsSeq.size-1` index,
    the algorithm executes the mathematical expression **M15,** which is implemented
    in the `QStar` class (line `42`).
  id: totrans-3020
  prefs: []
  type: TYPE_NORMAL
  zh: '`viterbi` 方法对剩余的观察值（除了最后一个）进行递归调用（行 `43`）。在 `obsSeq.size-1` 索引的最后观察值，算法执行 `QStar`
    类中实现的数学表达式 **M15**（行 `42`）。'
- en: Note
  id: totrans-3021
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The QStar class**'
  id: totrans-3022
  prefs: []
  type: TYPE_NORMAL
  zh: '**QStar 类**'
- en: The `QStar` class and its `update` method use linear algebra and are not described
    here; refer to the documented source code and Scaladocs files for details.
  id: totrans-3023
  prefs: []
  type: TYPE_NORMAL
  zh: '`QStar` 类及其 `update` 方法使用线性代数，此处未进行描述；请参阅文档化的源代码和 Scaladocs 文件以获取详细信息。'
- en: This implementation of the decoding form of the hidden Markov model completes
    the description of the hidden Markov model and its implementation in Scala. Now,
    let's put this knowledge into practice.
  id: totrans-3024
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现完成了对隐藏马尔可夫模型解码形式的描述及其在 Scala 中的实现。现在，让我们将此知识付诸实践。
- en: Putting it all together
  id: totrans-3025
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起
- en: The main `HMM` class implements the three canonical forms. A view bound to an
    array of integers is used to parameterize the `HMM` class. We assume that a time
    series of continuous or pseudo-continuous values is quantized into discrete symbol
    values.
  id: totrans-3026
  prefs: []
  type: TYPE_NORMAL
  zh: 主 `HMM` 类实现了三种规范形式。一个绑定到整数数组的视图用于参数化 `HMM` 类。我们假设连续或准连续值的时间序列被量化为离散符号值。
- en: The `@specialized` annotation ensures that the byte code is generated for the
    `Array[Int]` primitive without executing the conversion implicitly declared by
    the bound view.
  id: totrans-3027
  prefs: []
  type: TYPE_NORMAL
  zh: '`@specialized` 注解确保为 `Array[Int]` 原始类型生成字节码，而不执行隐式声明的绑定视图的转换。'
- en: 'There are two modes that execute any of the three canonical forms of the hidden
    Markov model:'
  id: totrans-3028
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种模式可以执行隐藏马尔可夫模型的任何三种规范形式：
- en: 'The `ViterbiPath` class: The constructor initializes/trains a model similar
    to any other learning algorithm, as described in the *Design template for immutable
    classifiers* section of the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*. The constructor generates the model by executing
    the Baum-Welch algorithm. Once the model is successfully created, it can be used
    for decoding or evaluation.'
  id: totrans-3029
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ViterbiPath` 类：构造函数初始化/训练一个类似于任何其他学习算法的模型，如 [附录A](part0229.xhtml#aid-6QCGQ2
    "附录A。基本概念") 中 *不可变分类器设计模板* 小节所述，*基本概念*。构造函数通过执行 Baum-Welch 算法生成模型。一旦模型成功创建，就可以用于解码或评估。'
- en: 'The `ViterbiPath` object: The companion provides the `decode` and `evaluate`
    methods for the decoding and evaluation of the sequence of observations using
    HMM.'
  id: totrans-3030
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ViterbiPath` 对象：伴随对象提供了使用 HMM 对观察序列进行解码和评估的 `decode` 和 `evaluate` 方法。'
- en: 'The two modes of operations are described in the following diagram:'
  id: totrans-3031
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了两种操作模式：
- en: '![Putting it all together](img/image01443.jpeg)'
  id: totrans-3032
  prefs: []
  type: TYPE_IMG
  zh: '![将所有内容整合在一起](img/image01443.jpeg)'
- en: The computational flow for the hidden Markov model
  id: totrans-3033
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型的计算流程
- en: 'Let''s complete our implementation of the HMM with the definition of its class.
    The `HMM` class is defined as a data transformation using a model implicitly generated
    from an `xt` training set, as described in the *Monadic data transformation* section
    in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*
    (line `46`):'
  id: totrans-3034
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们通过定义其类来完善我们对 HMM 的实现。`HMM` 类被定义为使用从 `xt` 训练集中隐式生成的模型进行数据转换，如第 [2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!") 中 *单态数据转换* 小节所述，*Hello World!*（行 `46`）:'
- en: '[PRE248]'
  id: totrans-3035
  prefs: []
  type: TYPE_PRE
  zh: '[PRE248]'
- en: 'The `HMM` constructor takes the following four arguments (line `46`):'
  id: totrans-3036
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMM` 构造函数接受以下四个参数（行 `46`）:'
- en: '`config`: This is the configuration of the HMM that is the dimension of `lambda`
    model and execution parameters'
  id: totrans-3037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`：这是 `lambda` 模型的维度和执行参数的 HMM 配置'
- en: '`xt`: This is the multidimensional time series of observations whose features
    have the `T` type'
  id: totrans-3038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xt`：这是具有 `T` 类型的观察值的多元时间序列'
- en: '`form`: This is the canonical form to be used once the model is generated (evaluation
    or decoding)'
  id: totrans-3039
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`form`：这是在模型生成后（评估或解码）要使用的规范形式'
- en: '`quantize`: This is the quantization function that converts an observation
    of the `Array[T]` type to an `Int` type'
  id: totrans-3040
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quantize`：这是一个量化函数，将 `Array[T]` 类型的观察转换为 `Int` 类型'
- en: '`f`: This is the implicit conversion from the `T` type to `Double`'
  id: totrans-3041
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`f`：这是从 `T` 类型到 `Double` 的隐式转换'
- en: The constructor has to override the `V` type (`HMMPrediction`) of the output
    data (line `47`) declared in the `ITransform` abstract class. The structure of
    the `HMMPrediction` class has been defined in the previous section.
  id: totrans-3042
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数必须覆盖在 `ITransform` 抽象类中声明的输出数据 `V` 类型（`HMMPrediction`）（第 `47` 行）。`HMMPrediction`
    类的结构已在上一节中定义。
- en: The `Monitor` trait is used to collect the profiling information during training
    (refer to the *Monitor* section under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-3043
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `Monitor` 特性在训练期间收集配置文件信息（请参阅 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")
    下的 *Monitor* 部分，在 *实用类* 中，*基本概念*）。
- en: The time series of `xt` observations is converted into a vector of `obsSeq`
    observed states by applying the `quantize` quantization function to each observation
    (line `48`).
  id: totrans-3044
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `xt` 观察的时间序列通过应用每个观察的 `quantize` 量化函数转换为 `obsSeq` 观察状态的向量（第 `48` 行）。
- en: As with any supervised learning technique, the model is created through training
    (line `49`). Finally, the `|>` polymorphic predictor invokes either the `decode`
    method or the `evaluate` method (line `50`).
  id: totrans-3045
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何监督学习技术一样，模型是通过训练创建的（第 `49` 行）。最后，`|>` 多态预测器调用 `decode` 方法或 `evaluate` 方法（第
    `50` 行）。
- en: 'The `train` method consists of the execution of the Baum-Welch algorithm and
    returns the `lambda` model:'
  id: totrans-3046
  prefs: []
  type: TYPE_NORMAL
  zh: '`train` 方法包括执行 Baum-Welch 算法，并返回 `lambda` 模型：'
- en: '[PRE249]'
  id: totrans-3047
  prefs: []
  type: TYPE_PRE
  zh: '[PRE249]'
- en: 'Finally. the `|>`predictor is a simple wrapper to the evaluation form (`evaluate`)
    and the decoding form (`decode`):'
  id: totrans-3048
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`|>` 预测器是一个简单的包装器，包装了评估形式（`evaluate`）和解码形式（`decode`）：
- en: '[PRE250]'
  id: totrans-3049
  prefs: []
  type: TYPE_PRE
  zh: '[PRE250]'
- en: 'The protected `evaluation` method of the `HMM` companion object is a wrapper
    around the `Alpha` computation:'
  id: totrans-3050
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMM` 伴随对象的受保护 `evaluation` 方法是围绕 `Alpha` 计算的包装器：'
- en: '[PRE251]'
  id: totrans-3051
  prefs: []
  type: TYPE_PRE
  zh: '[PRE251]'
- en: 'The `evaluate` method of the `HMM` object exposes the evaluation canonical
    form:'
  id: totrans-3052
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMM` 对象的 `evaluate` 方法公开了解释规范形式：'
- en: '[PRE252]'
  id: totrans-3053
  prefs: []
  type: TYPE_PRE
  zh: '[PRE252]'
- en: 'The `decoding` method wraps the Viterbi algorithm to extract the optimum sequence
    of states:'
  id: totrans-3054
  prefs: []
  type: TYPE_NORMAL
  zh: '`decoding` 方法包装了 Viterbi 算法以提取最佳状态序列：'
- en: '[PRE253]'
  id: totrans-3055
  prefs: []
  type: TYPE_PRE
  zh: '[PRE253]'
- en: 'The `decode` method of the `HMM` object exposes the decoding canonical form:'
  id: totrans-3056
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMM` 对象的 `decode` 方法公开了解码规范形式：'
- en: '[PRE254]'
  id: totrans-3057
  prefs: []
  type: TYPE_PRE
  zh: '[PRE254]'
- en: Note
  id: totrans-3058
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Normalized probabilities input**'
  id: totrans-3059
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化概率输入**'
- en: You need to make sure that the input probabilities for the *λ* model for evaluating
    and decoding canonical forms are normalized—the sum of the probabilities of all
    the states for the *π* vector and *A* and *B* matrices are equal to 1\. This validation
    code is omitted in the example code.
  id: totrans-3060
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要确保用于评估和解码规范形式的 *λ* 模型的输入概率已归一化——对于 *π* 向量和 *A* 和 *B* 矩阵中所有状态的概率之和等于 1。此验证代码在示例代码中省略。
- en: Test case 1 – training
  id: totrans-3061
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试案例 1 – 训练
- en: Our first test case is to train an HMM to predict the sentiment of investors
    as measured by the weekly sentiment survey of the members of the **American Association
    of Individual Investors** (**AAII**) [7:8]. The goal is to compute the transition
    probabilities matrix *A*, the emission probabilities matrix *B*, and the steady
    state probability distribution *π*, given the observations and hidden states (training
    canonical forms).
  id: totrans-3062
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个测试案例是训练一个HMM（隐马尔可夫模型）来预测投资者情绪，该情绪是通过**美国个人投资者协会**（**AAII**）每周情绪调查的成员来衡量的[7:8]。目标是计算给定观察和隐藏状态（训练规范形式）的转移概率矩阵
    *A*、发射概率矩阵 *B* 和稳态概率分布 *π*。
- en: We assume that the change in investor sentiments is independent of time, as
    required by the hidden Markov model.
  id: totrans-3063
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设投资者情绪的变化与时间无关，这是隐藏马尔可夫模型所要求的。
- en: 'The AAII sentiment survey grades the bullishness on the market in terms of
    percentage:'
  id: totrans-3064
  prefs: []
  type: TYPE_NORMAL
  zh: AAII 情绪调查按百分比评估市场的看涨情绪：
- en: '![Test case 1 – training](img/image01444.jpeg)'
  id: totrans-3065
  prefs: []
  type: TYPE_IMG
  zh: '![测试案例 1 – 训练](img/image01444.jpeg)'
- en: The weekly AAII market sentiment (reproduced by courtesy from AAII)
  id: totrans-3066
  prefs: []
  type: TYPE_NORMAL
  zh: 每周 AAII 市场情绪（由 AAII 借鉴）
- en: The sentiment of investors is known as a contrarian indicator of the future
    direction of the stock market. Refer to the *Terminology* section in the [Appendix
    A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-3067
  prefs: []
  type: TYPE_NORMAL
  zh: 投资者情绪被认为是股票市场未来方向的逆指标。请参阅 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念") 中的
    *术语* 部分，*基本概念*。
- en: 'Let''s select the ratio of the percentage of investors that are bullish over
    the percentage of investors that are bearish. The ratio is then normalized. The
    following table lists this:'
  id: totrans-3068
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们选择投资者上涨百分比与下跌百分比的比例。然后对这个比例进行归一化。以下表格列出了这个比例：
- en: '| Time | Bullish | Bearish | Neutral | Ratio | Normalized Ratio |'
  id: totrans-3069
  prefs: []
  type: TYPE_TB
  zh: '| 时间 | 上涨 | 下跌 | 中性 | 比率 | 标准化比率 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-3070
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| **t0** | 0.38 | 0.15 | 0.47 | 2.53 | 1.0 |'
  id: totrans-3071
  prefs: []
  type: TYPE_TB
  zh: '| **t0** | 0.38 | 0.15 | 0.47 | 2.53 | 1.0 |'
- en: '| **t1** | 0.41 | 0.25 | 0.34 | 1.68 | 0.53 |'
  id: totrans-3072
  prefs: []
  type: TYPE_TB
  zh: '| **t1** | 0.41 | 0.25 | 0.34 | 1.68 | 0.53 |'
- en: '| **t2** | 0.25 | 0.35 | 0.40 | 0.71 | 0.0 |'
  id: totrans-3073
  prefs: []
  type: TYPE_TB
  zh: '| **t2** | 0.25 | 0.35 | 0.40 | 0.71 | 0.0 |'
- en: '| … | … | … | … | … | …. |'
  id: totrans-3074
  prefs: []
  type: TYPE_TB
  zh: '| … | … | … | … | … | …. |'
- en: 'The sequence of nonnormalized observations (the ratio of bullish sentiments
    over bearish sentiments) is defined in a CSV file as follows:'
  id: totrans-3075
  prefs: []
  type: TYPE_NORMAL
  zh: 非归一化观察序列（上涨情绪与下跌情绪的比率）定义在CSV文件中如下：
- en: '[PRE255]'
  id: totrans-3076
  prefs: []
  type: TYPE_PRE
  zh: '[PRE255]'
- en: The constructor for the `HMM` class requires a `T => Array[Int]` implicit conversion,
    which is implemented by the `quantize` function (line `51`). The `hmm.model` model
    is created by instantiating an `HMM` class with a predefined configuration and
    an `obsSeq` sequence of observed states (line `52`).
  id: totrans-3077
  prefs: []
  type: TYPE_NORMAL
  zh: '`HMM`类的构造函数需要一个`T => Array[Int]`隐式转换，该转换由`quantize`函数实现（第`51`行）。`hmm.model`模型是通过使用预定义配置和观察状态序列`obsSeq`实例化`HMM`类创建的（第`52`行）。'
- en: 'The training of the HMM generates the following state transition probabilities
    matrix:'
  id: totrans-3078
  prefs: []
  type: TYPE_NORMAL
  zh: HMM的培训生成以下状态转移概率矩阵：
- en: '| A | 1 | 2 | 3 | 4 | 5 |'
  id: totrans-3079
  prefs: []
  type: TYPE_TB
  zh: '| A | 1 | 2 | 3 | 4 | 5 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-3080
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| **1** | 0.090 | 0.026 | 0.056 | 0.046 | 0.150 |'
  id: totrans-3081
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0.090 | 0.026 | 0.056 | 0.046 | 0.150 |'
- en: '| **2** | 0.094 | 0.123 | 0.074 | 0.058 | 0.0 |'
  id: totrans-3082
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 0.094 | 0.123 | 0.074 | 0.058 | 0.0 |'
- en: '| **3** | 0.093 | 0.169 | 0.087 | 0.061 | 0.056 |'
  id: totrans-3083
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 0.093 | 0.169 | 0.087 | 0.061 | 0.056 |'
- en: '| **4** | 0.033 | 0.342 | 0.017 | 0.031 | 0.147 |'
  id: totrans-3084
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 0.033 | 0.342 | 0.017 | 0.031 | 0.147 |'
- en: '| **5** | 0.386 | 0.47 | 0.314 | 0.541 | 0.271 |'
  id: totrans-3085
  prefs: []
  type: TYPE_TB
  zh: '| **5** | 0.386 | 0.47 | 0.314 | 0.541 | 0.271 |'
- en: 'The emission matrix is as follows:'
  id: totrans-3086
  prefs: []
  type: TYPE_NORMAL
  zh: 发射矩阵如下：
- en: '| B | 1 | 2 | 3 | 4 | 5 | 6 |'
  id: totrans-3087
  prefs: []
  type: TYPE_TB
  zh: '| B | 1 | 2 | 3 | 4 | 5 | 6 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-3088
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| **1** | 0.203 | 0.313 | 0.511 | 0.722 | 0.264 | 0.307 |'
  id: totrans-3089
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 0.203 | 0.313 | 0.511 | 0.722 | 0.264 | 0.307 |'
- en: '| **2** | 0.149 | 0.729 | 0.258 | 0.389 | 0.324 | 0.471 |'
  id: totrans-3090
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 0.149 | 0.729 | 0.258 | 0.389 | 0.324 | 0.471 |'
- en: '| **3** | 0.305 | 0.617 | 0.427 | 0.596 | 0.189 | 0.186 |'
  id: totrans-3091
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 0.305 | 0.617 | 0.427 | 0.596 | 0.189 | 0.186 |'
- en: '| **4** | 0.207 | 0.312 | 0.351 | 0.653 | 0.358 | 0.442 |'
  id: totrans-3092
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 0.207 | 0.312 | 0.351 | 0.653 | 0.358 | 0.442 |'
- en: '| **5** | 0.674 | 0.520 | 0.248 | 0.294 | 0.259 | 0.03 |'
  id: totrans-3093
  prefs: []
  type: TYPE_TB
  zh: '| **5** | 0.674 | 0.520 | 0.248 | 0.294 | 0.259 | 0.03 |'
- en: Test case 2 – evaluation
  id: totrans-3094
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试用例 2 – 评估
- en: 'The objective of the evaluation is to compute the probability of the `xt` observed
    data given a *λ* model (`A0`, `B0`, and `PI0`):'
  id: totrans-3095
  prefs: []
  type: TYPE_NORMAL
  zh: 评估的目标是计算给定*λ*模型（`A0`、`B0`和`PI0`）的`xt`观察数据的概率：
- en: '[PRE256]'
  id: totrans-3096
  prefs: []
  type: TYPE_PRE
  zh: '[PRE256]'
- en: The model is created directly by converting the `A0` state-transition probabilities
    and `B0` emission probabilities as matrices of the `DMatrix` type (line `53`).
    The evaluation method generates an `HMMPrediction` object, which is stringized,
    and then displays it in the standard output (line `54`).
  id: totrans-3097
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通过将`A0`状态转移概率和`B0`发射概率作为`DMatrix`类型的矩阵直接转换创建（第`53`行）。评估方法生成一个`HMMPrediction`对象，将其转换为字符串，然后显示在标准输出中（第`54`行）。
- en: The `quantization` method consists of normalizing the input data over the number
    (or range) of symbols associated with the `lambda` model. The number of symbols
    is the size of the rows of the emission probabilities matrix *B*. In this case,
    the range of the input data is [0.0, 3.0]. The range is normalized using the linear
    transform *f(x) = x/(max – min) + min*, then adjusted for the number of symbols
    (or values for states) (line `55`).
  id: totrans-3098
  prefs: []
  type: TYPE_NORMAL
  zh: '`quantization`方法包括在`lambda`模型关联的符号（或范围）的数量上归一化输入数据。符号的数量是发射概率矩阵*B*的行的大小。在这种情况下，输入数据的范围是[0.0,
    3.0]。使用线性变换*f(x) = x/(max – min) + min*进行归一化，然后根据符号的数量（或状态值）进行调整（第`55`行）。'
- en: The `quantize` quantization function has to be explicitly defined before invoking
    the evaluation method.
  id: totrans-3099
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用评估方法之前，必须显式定义`quantize`量化函数。
- en: Note
  id: totrans-3100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Test case for decoding**'
  id: totrans-3101
  prefs: []
  type: TYPE_NORMAL
  zh: '**解码测试用例**'
- en: Refer to the source code and the API documents for the test case related to
    the decoding form.
  id: totrans-3102
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考源代码和API文档中与解码形式相关的测试用例。
- en: HMM as a filtering technique
  id: totrans-3103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HMM作为过滤技术
- en: The evaluation form of the hidden Markov model is very suitable for filtering
    data for discrete states. Contrary to time series filters such as the Kalman filter
    introduced in the *The discrete Kalman filter* section in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*, the HMM requires data
    to be stationary in order to create a reliable model. However, the hidden Markov
    model overcomes some of the limitations of analytical time series analysis. Filters
    and smoothing techniques assume that the noise (frequency mean, variance, and
    covariance) is known and usually follows a Gaussian distribution.
  id: totrans-3104
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型（HMM）的评估形式非常适合过滤离散状态的数据。与第3章“数据预处理”中介绍的卡尔曼滤波器等时间序列滤波器相反，HMM要求数据在创建可靠模型时保持平稳。然而，隐藏马尔可夫模型克服了分析时间序列分析的一些局限性。滤波器和平滑技术假设噪声（频率均值、方差和协方差）是已知的，并且通常遵循高斯分布。
- en: The hidden Markov model does not have such a restriction. Filtering techniques,
    such as moving averaging techniques, discrete Fourier transforms, and Kalman filters
    apply to both discrete and continuous states while the HMM does not. Moreover,
    the extended Kalman filter can estimate nonlinear states.
  id: totrans-3105
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型没有这样的限制。滤波技术，如移动平均技术、离散傅里叶变换和卡尔曼滤波器，适用于离散和连续状态，而HMM则不适用。此外，扩展卡尔曼滤波器可以估计非线性状态。
- en: Conditional random fields
  id: totrans-3106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件随机场
- en: The **conditional random field** (**CRF**) is a discriminative machine learning
    algorithm introduced by John Lafferty, Andrew McCallum, and Fernando Pereira [7:9]
    at the turn of the century as an alternative to the HMM. The algorithm was originally
    developed to assign labels to a set of observation sequences.
  id: totrans-3107
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件随机场**（**CRF**）是由John Lafferty、Andrew McCallum和Fernando Pereira在世纪之交引入的一种判别式机器学习算法，作为HMM的替代方案。该算法最初是为了为一系列观测序列分配标签而开发的。'
- en: Let's consider a concrete example to understand the conditional relation between
    the observations and the label data.
  id: totrans-3108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个具体的例子，以理解观测值和标签数据之间的条件关系。
- en: Introduction to CRF
  id: totrans-3109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CRF简介
- en: 'Let''s consider the problem of detecting a foul during a soccer game using
    a combination of video and audio. The objective is to assist the referee and analyze
    the behavior of the players to determine whether an action on the field is dangerous
    (red card), inappropriate (yellow card), in doubt to be replayed, or legitimate.
    The following image is an example of the segmentation of a video frame for image
    processing:'
  id: totrans-3110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑在足球比赛中使用视频和音频的组合来检测犯规的问题。目标是协助裁判并分析球员的行为，以确定场上的动作是否危险（红牌）、不适当（黄牌）、有疑问需要回放，或者合法。以下图像是图像处理中视频帧分割的示例：
- en: '![Introduction to CRF](img/image01445.jpeg)'
  id: totrans-3111
  prefs: []
  type: TYPE_IMG
  zh: '![CRF简介](img/image01445.jpeg)'
- en: An example of an image processing problem requiring machine learning
  id: totrans-3112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要机器学习的图像处理问题示例
- en: 'The analysis of the video consists of segmenting each video frame and extracting
    image features such as colors or edges [7:10]. A simple segmentation scheme consists
    of breaking down each video frame into tiles or groups of pixels indexed by their
    coordinates on the screen. A time sequence is then created for each tile *S[ij]*,
    as represented in the following image:'
  id: totrans-3113
  prefs: []
  type: TYPE_NORMAL
  zh: 视频分析包括对每个视频帧进行分割并提取图像特征，如颜色或边缘[7:10]。一个简单的分割方案是将每个视频帧分解成瓦片或像素组，这些像素组按其在屏幕上的坐标索引。然后为每个瓦片
    *S[ij]* 创建一个时间序列，如下面的图像所示：
- en: '![Introduction to CRF](img/image01446.jpeg)'
  id: totrans-3114
  prefs: []
  type: TYPE_IMG
  zh: '![CRF简介](img/image01446.jpeg)'
- en: The learning strategy for pixels in a sequence of video frames
  id: totrans-3115
  prefs: []
  type: TYPE_NORMAL
  zh: 视频帧序列中像素的学习策略
- en: 'The image segment *S[ij]* is one of the labels that is associated with multiple
    observations. The same features extraction process applies to the audio associated
    with the video. The relation between the video/image segment and the hidden state
    of the altercation between the soccer players is illustrated in the following
    model graph:'
  id: totrans-3116
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割段 *S[ij]* 是与多个观测值相关联的标签之一。相同的特征提取过程也适用于视频相关的音频。以下模型图展示了视频/图像分割段与足球运动员之间争执的隐藏状态之间的关系：
- en: '![Introduction to CRF](img/image01447.jpeg)'
  id: totrans-3117
  prefs: []
  type: TYPE_IMG
  zh: '![CRF简介](img/image01447.jpeg)'
- en: The undirected graph representation of CRF for the soccer infraction detection
  id: totrans-3118
  prefs: []
  type: TYPE_NORMAL
  zh: 足球违规检测中CRF的无向图表示
- en: CRFs are discriminative models that can be regarded as a structured output extension
    of the logistic regression. CRFs address the problem of labeling a sequence of
    data, such as assigning a tag to each word in a sentence. The objective is to
    estimate the correlation among the output (observed) values *Y* that are conditional
    on the input values (features) *X*.
  id: totrans-3119
  prefs: []
  type: TYPE_NORMAL
  zh: CRFs是判别模型，可以被视为逻辑回归的结构化输出扩展。CRFs解决对数据序列进行标记的问题，例如为句子中的每个单词分配一个标签。目标是估计输出（观察）值
    *Y* 与输入值（特征）*X* 之间的相关性。
- en: The correlation between the output and input values is described as a graph
    (also known as a **graph-structured CRF**). A good example of graph-structured
    CRFs are cliques. Cliques are sets of connected nodes in a graph for which each
    vertex has an edge connecting it to every other vertex in the clique.
  id: totrans-3120
  prefs: []
  type: TYPE_NORMAL
  zh: 输出值与输入值之间的相关性描述为图（也称为**图结构CRF**）。图结构CRF的一个很好的例子是团。团是图中的一组连接节点，其中每个顶点都有一个边连接到团中其他所有顶点。
- en: 'Such models are complex and their implementation is challenging. Most real-world
    problems related to time series or ordered sequences of data can be solved as
    a correlation between a linear sequence of observations and a linear sequence
    of input data, which is similar to the HMM. Such a model is known as the **linear
    chain structured graph CRF** or **linear chain CRF** for short:'
  id: totrans-3121
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的模型很复杂，其实现具有挑战性。大多数与时间序列或有序数据序列相关的实际问题都可以作为观察线性序列与输入数据线性序列之间的相关性来解决，这与HMM类似。这样的模型被称为**线性链结构图CRF**或简称**线性链CRF**：
- en: '![Introduction to CRF](img/image01448.jpeg)'
  id: totrans-3122
  prefs: []
  type: TYPE_IMG
  zh: '![CRF简介](img/image01448.jpeg)'
- en: An illustration of a nonlinear and linear chain CRF
  id: totrans-3123
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性链和线性链CRF的示意图
- en: One main advantage of the linear chain CRF is that the maximum likelihood *p(Y|X,
    w)* can be estimated using dynamic programming techniques such as the Viterbi
    algorithm used in the HMM. From now on, the section focuses exclusively on the
    linear chain CRF in order to stay consistent with the HMM, as described in the
    previous section.
  id: totrans-3124
  prefs: []
  type: TYPE_NORMAL
  zh: 线性链CRF的一个主要优点是，可以使用动态规划技术（如HMM中使用的Viterbi算法）估计最大似然 *p(Y|X, w)*。从现在开始，本节将专门关注线性链CRF，以保持与上一节中描述的HMM的一致性。
- en: Linear chain CRF
  id: totrans-3125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性链CRF
- en: Let's consider a random variable *X={x[i]}[0:n-1]* representing *n* observations
    and a random variable *Y* representing a corresponding sequence of labels *Y={y[j]}[0:n-1]*.
    The hidden Markov model estimates the joint probability *p(X,Y)*, as any generative
    model requires the enumeration of all the sequences of observations.
  id: totrans-3126
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个随机变量 *X={x[i]}[0:n-1]*，它代表 *n* 个观察值，以及一个随机变量 *Y*，它代表相应的标签序列 *Y={y[j]}[0:n-1]*。隐藏马尔可夫模型估计联合概率
    *p(X,Y)*，因为任何生成模型都需要枚举所有观察值序列。
- en: If each element of *Y*, *y[j]*, obeys the first order of the Markov property,
    then *(Y, X)* is a CRF. The likelihood is defined as a conditional probability
    *p(Y|X, w)*, where *w* is the model parameters vector.
  id: totrans-3127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *Y* 的每个元素 *y[j]* 都遵循马尔可夫属性的零阶，那么 *(Y, X)* 是一个CRF。似然被定义为条件概率 *p(Y|X, w)*，其中
    *w* 是模型参数向量。
- en: Note
  id: totrans-3128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Observation dependencies**'
  id: totrans-3129
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察依赖性**'
- en: The purpose of CRF models is to estimate the maximum likelihood of *p(Y|X, w)*.
    Therefore, independence between *X* observations is not required.
  id: totrans-3130
  prefs: []
  type: TYPE_NORMAL
  zh: CRF模型的目的在于估计 *p(Y|X, w)* 的最大似然。因此，不需要 *X* 观察值之间的独立性。
- en: A graphical model is a probabilistic model for which a graph denotes the conditional
    independence between random variables (vertices). The conditional and joint probabilities
    of random variables are represented as edges. The graph for generic conditional
    random fields can indeed be complex. The most common and simplistic graph is the
    linear chain CRF.
  id: totrans-3131
  prefs: []
  type: TYPE_NORMAL
  zh: 图形模型是一种概率模型，其中图表示随机变量（顶点）之间的条件独立性。随机变量的条件概率和联合概率用边表示。通用条件随机场的图确实可能很复杂。最常见的最简单图是线性链CRF。
- en: 'A first order linear chain conditional random field can be visualized as an
    undirected graphical model, which illustrates the conditional probability of a
    label *Y[j]* given a set of observations *X*:'
  id: totrans-3132
  prefs: []
  type: TYPE_NORMAL
  zh: 一阶线性链条件随机场可以可视化为一个无向图模型，它说明了在给定一组观察值 *X* 的条件下，标签 *Y[j]* 的条件概率：
- en: '![Linear chain CRF](img/image01449.jpeg)'
  id: totrans-3133
  prefs: []
  type: TYPE_IMG
  zh: '![线性链CRF](img/image01449.jpeg)'
- en: A linear, conditional, random field undirected graph
  id: totrans-3134
  prefs: []
  type: TYPE_NORMAL
  zh: 一个线性、条件、无向随机场图
- en: The Markov property simplifies the conditional probabilities of *Y*, given *X*,
    by considering only the neighbor labels *p(Y[1]|X, Y[j] j ≠1) = p(Y[1]|X, Y[0],
    Y[2]) and p(Y[i]|X, Y[j] j ≠i) = p(Y[i]|X, Y[i-1], Y[i+1])*.
  id: totrans-3135
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫属性通过仅考虑相邻标签来简化给定*X*的*Y*的条件概率，即*p(Y[1]|X, Y[j] j ≠1) = p(Y[1]|X, Y[0], Y[2])
    和 p(Y[i]|X, Y[j] j ≠i) = p(Y[i]|X, Y[i-1], Y[i+1])*。
- en: 'The conditional random fields introduce a new set of entities and a new terminology:'
  id: totrans-3136
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机域引入了一组新的实体和新的术语：
- en: '**Potential functions** (*f**[i]*): These strictly positive and real value
    functions represent a set of constraints on the configurations of random variables.
    They do not have any obvious probabilistic interpretation.'
  id: totrans-3137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在函数** (*f**[i]*): 这些严格为正的实值函数代表了一组对随机变量配置的约束。它们没有明显的概率解释。'
- en: '**Identity potential functions**: These are potential functions *I(x, t)* that
    take 1 if the condition on the feature *x* at time *t* is true, and 0 otherwise.'
  id: totrans-3138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恒等潜在函数**：这些是*I(x, t)*潜在函数，如果时间*t*的特征*x*的条件为真，则取值为1，否则为0。'
- en: '**Transition feature functions**: Simply known as feature functions, *t[i]*,
    are potential functions that take a sequence of features *{X[i]}*, the previous
    label *Y[t-1]*, the current label *Y[t]*, and an index *i*. The transition feature
    function outputs a real value function. In a text analysis, a transition feature
    function would be defined by a sentence as a sequence of observed features, the
    previous word, the current word, and a position of a word in a sentence. Each
    transition feature function is assigned a weight that is similar to the weights
    or parameters in the logistic regression. Transition feature functions play a
    similar role to the state transition factors *a[ij]* in the HMM but without a
    direct probabilistic interpretation.'
  id: totrans-3139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转移特征函数**：简称为特征函数，*t[i]*，是接受一系列特征*{X[i]}*、前一个标签*Y[t-1]*、当前标签*Y[t]*和索引*i*的潜在函数。转移特征函数输出一个实值函数。在文本分析中，转移特征函数可以通过一个句子作为观察特征序列、前一个单词、当前单词和句子中单词的位置来定义。每个转移特征函数分配一个权重，类似于逻辑回归中的权重或参数。转移特征函数在HMM中的状态转移因子*a[ij]*扮演着类似的角色，但没有直接的概率解释。'
- en: '**State feature functions** (*s[j]*): These are potential functions that take
    the sequence of features *{X[i]}*, the current label *Y[i]*, and the index *i*.
    They play a similar role to the emission factors in the HMM.'
  id: totrans-3140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态特征函数** (*s[j]*): 这些是接受特征序列*{X[i]}*、当前标签*Y[i]*和索引*i*的潜在函数。它们在HMM中的发射因子扮演着类似的角色。'
- en: A CRF defines the log probability of a particular label sequence *Y*, given
    a sequence of observations *X* as the normalized product of the transition feature
    and state feature functions. In other words, the likelihood of a particular sequence
    *Y*, given the observed features *X*, is a logistic regression.
  id: totrans-3141
  prefs: []
  type: TYPE_NORMAL
  zh: CRF定义了在给定观察序列*X*的情况下，特定标签序列*Y*的对数概率，作为转移特征函数和状态特征函数的归一化乘积。换句话说，给定观察特征*X*的特定序列*Y*的似然性是一个逻辑回归。
- en: 'The mathematical notation to compute the conditional probabilities in the case
    of a first order linear chain CRF is described in the following information box:'
  id: totrans-3142
  prefs: []
  type: TYPE_NORMAL
  zh: 针对一阶线性链CRF计算条件概率的数学符号在以下信息框中描述：
- en: Note
  id: totrans-3143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The CRF conditional distribution**'
  id: totrans-3144
  prefs: []
  type: TYPE_NORMAL
  zh: '**CRF条件分布**'
- en: 'M1: The log probability of a label''s sequence *y*, given an observation *x*
    is defined as:'
  id: totrans-3145
  prefs: []
  type: TYPE_NORMAL
  zh: M1：给定观察*x*，标签序列*y*的对数概率定义为：
- en: '![Linear chain CRF](img/image01450.jpeg)'
  id: totrans-3146
  prefs: []
  type: TYPE_IMG
  zh: '![线性链式CRF](img/image01450.jpeg)'
- en: 'M2: Transition feature functions are defined as:'
  id: totrans-3147
  prefs: []
  type: TYPE_NORMAL
  zh: M2：转移特征函数定义为：
- en: '![Linear chain CRF](img/image01451.jpeg)'
  id: totrans-3148
  prefs: []
  type: TYPE_IMG
  zh: '![线性链式CRF](img/image01451.jpeg)'
- en: 'M3: Using the notation:'
  id: totrans-3149
  prefs: []
  type: TYPE_NORMAL
  zh: M3：使用以下符号：
- en: '![Linear chain CRF](img/image01452.jpeg)'
  id: totrans-3150
  prefs: []
  type: TYPE_IMG
  zh: '![线性链式CRF](img/image01452.jpeg)'
- en: 'M4: The conditional distribution of labels *y*, given *x*, using the Markov
    property is defined as:'
  id: totrans-3151
  prefs: []
  type: TYPE_NORMAL
  zh: M4：使用马尔可夫属性定义给定*x*的标签*y*的条件分布：
- en: '![Linear chain CRF](img/image01453.jpeg)'
  id: totrans-3152
  prefs: []
  type: TYPE_IMG
  zh: '![线性链式CRF](img/image01453.jpeg)'
- en: The weights *w[j]* are sometimes referred as *λ* in scientific papers, which
    may confuse the reader; *w* is used to avoid any confusion with the *λ* regularization
    factor.
  id: totrans-3153
  prefs: []
  type: TYPE_NORMAL
  zh: 科学论文中有时将权重*w[j]*称为*λ*，这可能会让读者感到困惑；*w*用于避免与*λ*正则化因子混淆。
- en: Now, let's get acquainted with the conditional random fields algorithm and its
    implementation by Sunita Sarawagi.
  id: totrans-3154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们熟悉条件随机域算法及其由Sunita Sarawagi实现的实现。
- en: Regularized CRFs and text analytics
  id: totrans-3155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化CRFs和文本分析
- en: Most of the examples used to demonstrate the capabilities of conditional random
    fields are related to text mining, intrusion detection, or bioinformatics. Although
    these applications have a great commercial merit, they are not suitable for introductory
    test cases because they usually require a lengthy description of the model and
    the training process.
  id: totrans-3156
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用于展示条件随机字段能力的示例都与文本挖掘、入侵检测或生物信息学相关。尽管这些应用具有很大的商业价值，但它们不适合作为入门测试案例，因为它们通常需要详细描述模型和训练过程。
- en: The feature functions model
  id: totrans-3157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征函数模型
- en: 'For our example, we will select a simple problem: how to collect and aggregate
    an analyst''s recommendation on any given stock from different sources with different
    formats.'
  id: totrans-3158
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，我们将选择一个简单的问题：如何从不同来源和不同格式的不同来源收集和汇总分析师对任何给定股票的推荐。
- en: 'Analysts at brokerage firms and investment funds routinely publish the list
    of recommendations or ratings for any stock. These analysts use different rating
    schemes from buy/hold/sell, A/B/C rating, and stars rating, to market perform/neutral/market
    underperform rating. For this example, the rating is normalized as follows:'
  id: totrans-3159
  prefs: []
  type: TYPE_NORMAL
  zh: 证券经纪公司和投资基金的分析师通常会发布任何股票的推荐或评级列表。这些分析师使用不同的评级方案，从买入/持有/卖出、A/B/C 评级和星级评级，到市场表现/中性/市场表现不佳评级。对于此示例，评级按以下方式归一化：
- en: 0 for a strong sell (F or 1 star rating)
  id: totrans-3160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 表示强烈卖出（F 或 1 星评级）
- en: 1 for sell (D, 2 stars, or marker underperform)
  id: totrans-3161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 表示卖出（D，2 星，或标记为表现不佳）
- en: 2 for neutral (C, hold, 3 stars, market perform, and so on)
  id: totrans-3162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 表示中性（C，持有，3 星，市场表现等）
- en: 3 for buy (B, 4 stars, market overperform, and so on)
  id: totrans-3163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 表示买入（B，4 星，市场表现良好等）
- en: 4 for strong buy (A, 5 stars, highly recommended, and so on)
  id: totrans-3164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 表示强烈买入（A，5 星，强烈推荐等）
- en: 'Here are examples of recommendations by stock analysts:'
  id: totrans-3165
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是股票分析师推荐的一些示例：
- en: '*Macquarie upgraded AUY from Neutral to Outperform rating*'
  id: totrans-3166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*摩根士丹利将AUY从中性评级上调为优于市场评级*'
- en: '*Raymond James initiates Ainsworth Lumber as Outperform*'
  id: totrans-3167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*雷蒙德·詹姆斯将艾恩斯沃斯木材评为优于市场*'
- en: '*BMO Capital Markets upgrades Bear Creek Mining to Outperform*'
  id: totrans-3168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*BMO资本市场将Bear Creek Mining升级为优于市场*'
- en: '*Goldman Sachs adds IBM to its conviction list*'
  id: totrans-3169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高盛将其对IBM的信心列入其信心名单*'
- en: The objective is to extract the name of the financial institution that publishes
    the recommendation or rating, the stock rated, the previous rating, if available,
    and the new rating. The output can be inserted into a database for further trend
    analysis, prediction, or simply the creation of reports.
  id: totrans-3170
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是从发布推荐或评级的金融机构、被评级的股票、如果有的话，前一次评级以及新评级中提取名称。输出可以插入数据库以进行进一步的趋势分析、预测，或者简单地创建报告。
- en: Note
  id: totrans-3171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**The scope of the application**'
  id: totrans-3172
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用范围**'
- en: Ratings from analysts are updated every day through different protocols (feed,
    e-mails, blogs, web pages, and so on). The data has to be extracted from HTML,
    JSON, plain text, or XML format before being processed. In this exercise, we assume
    that the input has already been converted into plain text (ASCII) using a regular
    expression or another classifier.
  id: totrans-3173
  prefs: []
  type: TYPE_NORMAL
  zh: 分析师的评级每天通过不同的协议（馈送、电子邮件、博客、网页等）更新。在处理之前，必须从 HTML、JSON、纯文本或 XML 格式中提取数据。在这个练习中，我们假设输入已经使用正则表达式或其他分类器转换为纯文本（ASCII）。
- en: 'The first step is to define the labels *Y* representing the categories or semantics
    of the rating. A segment or sequence is defined as a recommendation sentence.
    After reviewing the different recommendations, we are able to specify the following
    seven labels:'
  id: totrans-3174
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义代表评级类别或语义的标签 *Y*。一个段或序列被定义为推荐句子。在审查了不同的推荐后，我们能够指定以下七个标签：
- en: Source of the recommendation (Goldman Sachs and so on)
  id: totrans-3175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐来源（高盛等）
- en: Action (upgrades, initiates, and so on)
  id: totrans-3176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行动（升级、启动等）
- en: Stock (either the company name or the stock ticker symbol)
  id: totrans-3177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股票（公司名称或股票代码）
- en: From (an optional keyword)
  id: totrans-3178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自（可选的关键词）
- en: Rating (an optional previous rating)
  id: totrans-3179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评级（可选的前一次评级）
- en: To
  id: totrans-3180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收件人
- en: Rating (the new rating for the stock)
  id: totrans-3181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评级（股票的新评级）
- en: The training set is generated from the raw data by *tagging* the different components
    of the recommendation. The first (or initial) rating for a stock does not have
    the labels 4 and 5 from the preceding list defined.
  id: totrans-3182
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集是通过从原始数据中通过*标记*推荐的各个组成部分生成的。股票的第一个（或初始）评级没有前述列表中定义的 4 和 5 的标签。
- en: 'Consider the following example:'
  id: totrans-3183
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例：
- en: '[PRE257]'
  id: totrans-3184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE257]'
- en: Note
  id: totrans-3185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Tagging**'
  id: totrans-3186
  prefs: []
  type: TYPE_NORMAL
  zh: '**标记**'
- en: Tagging as a word may have a different meaning depending on the context. In
    **natural language processing** (**NLP**), tagging refers to the process of assigning
    an attribute (an adjective, pronoun, verb, proper name, and so on) to a word in
    a sentence [7:11].
  id: totrans-3187
  prefs: []
  type: TYPE_NORMAL
  zh: 标记作为一个词，其含义可能因上下文而异。在**自然语言处理**（**NLP**）中，标记是指将属性（形容词、代词、动词、专有名词等）分配给句子中一个词的过程[7:11]。
- en: 'A training sequence can be visualized in the following undirected graph:'
  id: totrans-3188
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在以下无向图中可视化训练序列：
- en: '![The feature functions model](img/image01454.jpeg)'
  id: totrans-3189
  prefs: []
  type: TYPE_IMG
  zh: '![特征函数模型](img/image01454.jpeg)'
- en: An example of a recommendation as a CRF training sequence
  id: totrans-3190
  prefs: []
  type: TYPE_NORMAL
  zh: 作为CRF训练序列的推荐示例
- en: You may wonder why we need to tag the *From* and *To* labels in the creation
    of the training set. The reason is that these keywords may not always be stated
    and/or their positions in the recommendation differ from one source to another.
  id: totrans-3191
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我们需要在创建训练集时标记*From*和*To*标签。原因是这些关键字可能并不总是被明确指出，并且/或者它们在推荐中的位置可能因来源而异。
- en: Design
  id: totrans-3192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计
- en: The implementation of the conditional random fields follows the design template
    for classifiers, which is described in the *Design template for immutable classifiers*
    section under *Source code considerations* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-3193
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机字段的实现遵循分类器的模板设计，这在[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中“源代码考虑”部分的*不可变分类器设计模板*一节有所描述，*基本概念*。
- en: 'Its key components are as follows:'
  id: totrans-3194
  prefs: []
  type: TYPE_NORMAL
  zh: 其关键组件如下：
- en: A `CrfModel` model of the `Model` type is initialized through training during
    the instantiation of the classifier. A model is an array of `weights`.
  id: totrans-3195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分类器的实例化过程中，通过训练初始化了一个`Model`类型的`CrfModel`模型。模型是一个`weights`的数组。
- en: The predictive or classification routine is implemented as an implicit data
    transformation of the `ITransform` type.
  id: totrans-3196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测或分类例程作为`ITransform`类型的隐式数据转换实现。
- en: 'The `Crf` conditional random field classifier has four parameters: the number
    of labels (or number of features), `nLabels`, configuration of the `CrfConfig`
    type, the sequence of delimiters of the `CrfSeqDelimiter` type, and a vector of
    name of files `xt` that contains the tagged observations.'
  id: totrans-3197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Crf`条件随机字段分类器有四个参数：标签数（或特征数），`nLabels`，`CrfConfig`类型的配置，`CrfSeqDelimiter`类型的分隔符序列，以及包含标记观察值的文件名`xt`的向量。'
- en: The `CrfAdapter` class interfaces with the IITB CRF library.
  id: totrans-3198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CrfAdapter`类与IITB CRF库接口。'
- en: The `CrfTagger` class extracts features from the tagged files.
  id: totrans-3199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CrfTagger`类从标记的文件中提取特征。'
- en: 'The key software components of the conditional random fields are described
    in the following UML class diagram:'
  id: totrans-3200
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机字段的以下UML类图描述了其关键软件组件：
- en: '![Design](img/image01455.jpeg)'
  id: totrans-3201
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01455.jpeg)'
- en: The UML class diagram for the conditional random fields
  id: totrans-3202
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机字段的UML类图
- en: The UML diagram omits the utility traits and classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-3203
  prefs: []
  type: TYPE_NORMAL
  zh: UML图省略了`Monitor`或Apache Commons Math组件等实用特性类。
- en: Implementation
  id: totrans-3204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现
- en: The test case uses the IIT-B's CRF Java implementation from the Indian Institute
    of Technology Bombay by Sunita Sarawagi. The JAR files can be downloaded from
    SourceForge ([http://sourceforge.net/projects/crf/](http://sourceforge.net/projects/crf/)).
  id: totrans-3205
  prefs: []
  type: TYPE_NORMAL
  zh: 测试案例使用了印度理工学院Bombay的Sunita Sarawagi提供的CRF Java实现。JAR文件可以从SourceForge下载([http://sourceforge.net/projects/crf/](http://sourceforge.net/projects/crf/))。
- en: 'The library is available as JAR files and source code. Some of the functionalities,
    such as the selection of a training algorithm, is not available through the API.
    The components (JAR files) of the library are as follows:'
  id: totrans-3206
  prefs: []
  type: TYPE_NORMAL
  zh: 库以JAR文件和源代码的形式提供。一些功能，如选择训练算法，无法通过API访问。库的组件（JAR文件）如下：
- en: A CRF for the implementation of the CRF algorithm
  id: totrans-3207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现CRF算法的CRF
- en: LBFGS for limited-memory Broyden-Fletcher-Goldfarb-Shanno nonlinear optimization
    of convex functions (used in training)
  id: totrans-3208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LBFGS用于凸函数的有限内存Broyden-Fletcher-Goldfarb-Shanno非线性优化（用于训练）。
- en: The CERN Colt library for the manipulation of a matrix
  id: totrans-3209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CERN Colt库用于矩阵操作
- en: The GNU generic hash container for indexing
  id: totrans-3210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GNU通用的哈希容器用于索引
- en: Configuring the CRF classifier
  id: totrans-3211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置CRF分类器
- en: 'Let''s take a look at the `Crf` class that implements the conditional random
    fields classifier. The `Crf` class is defined as a data transformation of the
    `ITransform` type, as described in the *Monadic data transformation* section in
    [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*
    (line `2`):'
  id: totrans-3212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实现条件随机字段分类器的`Crf`类。`Crf`类被定义为`ITransform`类型的数据转换，如[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章 Hello World!")中的*单调数据转换*部分所述，*Hello World!*（第`2`行）：
- en: '[PRE258]'
  id: totrans-3213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE258]'
- en: 'The constructor for `Crf` has the following four arguments (line `1`):'
  id: totrans-3214
  prefs: []
  type: TYPE_NORMAL
  zh: '`Crf` 构造函数有以下四个参数（第`1`行）：'
- en: '`nLabels`: These are the number of labels used for the classification'
  id: totrans-3215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nLabels`：这些是用于分类的标签数量'
- en: '`config`: This is the configuration parameter used to train `Crf`'
  id: totrans-3216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config`：这是用于训练`Crf`的配置参数'
- en: '`delims`: These are the delimiters used in raw and tagged files'
  id: totrans-3217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`delims`：这些是在原始和标记文件中使用的分隔符'
- en: '`xt`: This is a vector of name of files that contains raw and tagged data'
  id: totrans-3218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xt`：这是一个包含原始和标记数据的文件名的向量'
- en: Note
  id: totrans-3219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Filenames for raw and tagged data**'
  id: totrans-3220
  prefs: []
  type: TYPE_NORMAL
  zh: '**原始和标记数据的文件名**'
- en: 'For the sake of simplicity, the files for the raw observations and the tagged
    observations have the same name with different extensions: `filename.raw` and
    `filename.tagged`.'
  id: totrans-3221
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，原始观测和标记观测的文件名相同，但扩展名不同：`filename.raw`和`filename.tagged`。
- en: The `Monitor` trait is used to collect the profiling information during training
    (refer to the *Monitor* section under *Utility classes* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-3222
  prefs: []
  type: TYPE_NORMAL
  zh: '`Monitor` 特性用于在训练期间收集配置文件信息（请参阅[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")下的*Monitor*部分，*实用类*），*基本概念*）。'
- en: The `V` type of the output of the `|>` predictor is defined as `Double` (line
    `3`).
  id: totrans-3223
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>` 预测器的输出类型 `V` 被定义为 `Double`（第`3`行）。'
- en: 'The execution of the CRF algorithm is controlled by a wide variety of configuration
    parameters encapsulated in the `CrfConfig` configuration class:'
  id: totrans-3224
  prefs: []
  type: TYPE_NORMAL
  zh: CRF算法的执行由封装在`CrfConfig`配置类中的各种配置参数控制：
- en: '[PRE259]'
  id: totrans-3225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE259]'
- en: 'For the sake of simplicity, we use the default `CrfConfig` configuration parameters
    to control the execution of the learning algorithm, with the exception of the
    following four variables (line `8`):'
  id: totrans-3226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们使用默认的`CrfConfig`配置参数来控制学习算法的执行，除了以下四个变量（第`8`行）：
- en: Initialization of the `w0` weight that uses either a predefined or random value
    between 0 and 1 (default 0)
  id: totrans-3227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`w0` 权重的初始化使用预定义值或0到1之间的随机值（默认为0）'
- en: The maximum number of iterations, `maxIters`, that is used in the computation
    of the weights during the learning phase (default 50)
  id: totrans-3228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在学习阶段计算权重时使用的最大迭代次数，`maxIters`（默认50）
- en: The `lamdba` scaling factor for the L2 penalty function that is used to reduce
    observations with a high value (default 1.0)
  id: totrans-3229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于减少高值观测的L2惩罚函数的`lamdba`缩放因子（默认1.0）
- en: The `eps` convergence criteria that is used to compute the optimum values for
    the `wj` weights (default 1e-4)
  id: totrans-3230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于计算`wj`权重最优值的`eps`收敛标准（默认1e-4）
- en: Note
  id: totrans-3231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The L[2]** **regularization**'
  id: totrans-3232
  prefs: []
  type: TYPE_NORMAL
  zh: '**L[2]正则化**'
- en: This implementation of the conditional random fields support the L[2] regularization,
    as described in the *Regularization* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*.
    The regularization is turned off by setting *λ = 0*.
  id: totrans-3233
  prefs: []
  type: TYPE_NORMAL
  zh: 本实现的条件随机字段支持L[2]正则化，如[第6章](part0188.xhtml#aid-5J99O2 "第6章 回归和正则化")中的*正则化*部分所述，*回归和正则化*。通过将*λ
    = 0*来关闭正则化。
- en: 'The `CrfSeqDelimiter` case class specifies the following regular expressions:'
  id: totrans-3234
  prefs: []
  type: TYPE_NORMAL
  zh: '`CrfSeqDelimiter` 情况类指定以下正则表达式：'
- en: '`obsDelim` to parse each observation in the raw files'
  id: totrans-3235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`obsDelim` 用于解析原始文件中的每个观测'
- en: '`labelsDelim` to parse each labeled record in the tagged files'
  id: totrans-3236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labelsDelim` 用于解析标记文件中的每个标记记录'
- en: '`seqDelim` to extract records from raw and tagged files'
  id: totrans-3237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seqDelim` 用于从原始和标记文件中提取记录'
- en: 'The code will be as follows:'
  id: totrans-3238
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE260]'
  id: totrans-3239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE260]'
- en: 'The `DEFAULT_SEQ_DELIMITER` instance is the default sequence delimiter used
    in this implementation:'
  id: totrans-3240
  prefs: []
  type: TYPE_NORMAL
  zh: '`DEFAULT_SEQ_DELIMITER` 实例是本实现中使用的默认序列分隔符：'
- en: '[PRE261]'
  id: totrans-3241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE261]'
- en: The `CrfTagger` tag or label generator iterates through the tagged file and
    applies the relevant regular expressions of `CrfSeqDelimiter` to extract the symbols
    used in training (line `4`).
  id: totrans-3242
  prefs: []
  type: TYPE_NORMAL
  zh: '`CrfTagger`标签或标记生成器遍历标记文件，并应用`CrfSeqDelimiter`的相关正则表达式来提取用于训练的符号（第`4`行）。'
- en: 'The `CrfAdapter` object defines the different interfaces to the IITB CRF library
    (line `5`). The factory for CRF instances is implemented by the `apply` constructor
    as follows:'
  id: totrans-3243
  prefs: []
  type: TYPE_NORMAL
  zh: '`CrfAdapter` 对象定义了访问 IITB CRF 库的不同接口（第 `5` 行）。CRF 实例的工厂是通过 `apply` 构造函数实现的，如下所示：'
- en: '[PRE262]'
  id: totrans-3244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE262]'
- en: Note
  id: totrans-3245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Adapter classes to the IITB CRF library**'
  id: totrans-3246
  prefs: []
  type: TYPE_NORMAL
  zh: '**适配器类到 IITB CRF 库**'
- en: 'The training of the conditional random field for sequences requires to define
    a few key interfaces:'
  id: totrans-3247
  prefs: []
  type: TYPE_NORMAL
  zh: 对序列进行条件随机字段训练需要定义几个关键接口：
- en: '`DataSequence` to specify the mechanism to access observations and labels for
    training and testing data'
  id: totrans-3248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataSequence` 用于指定访问训练和测试数据中的观测和标签的机制'
- en: '`DataIter` to iterate through the sequence of data created using the `DataSequence`
    interface'
  id: totrans-3249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DataIter` 用于遍历使用 `DataSequence` 接口创建的数据序列'
- en: '`FeatureGenerator` to aggregate all the feature types'
  id: totrans-3250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FeatureGenerator` 用于聚合所有特征类型'
- en: 'These interfaces have default implementations bundled in the CRF Java library
    [7:12]. Each of these interfaces have to be implemented as adapter classes:'
  id: totrans-3251
  prefs: []
  type: TYPE_NORMAL
  zh: 这些接口在 CRF Java 库 [7:12] 中包含默认实现。每个接口都必须作为适配器类实现：
- en: '[PRE263]'
  id: totrans-3252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE263]'
- en: Refer to the documented source code and Scaladocs files for the description
    and implementation of these adapter classes.
  id: totrans-3253
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅文档化的源代码和 Scaladocs 文件，以了解这些适配器类的描述和实现。
- en: Training the CRF model
  id: totrans-3254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练 CRF 模型
- en: The objective of the training is to compute the weights *w[j]* that maximize
    the conditional log-likelihood function without the L[2] penalty function. Maximizing
    the log-likelihood function is equivalent to minimizing the loss with the L[2]
    penalty. The function is convex, and therefore, any variant gradient descent (greedy)
    algorithm can be applied iteratively.
  id: totrans-3255
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的目标是计算最大化条件对数似然函数的权重 *w[j]*，而不包含 L[2] 惩罚函数。最大化对数似然函数等同于最小化带有 L[2] 惩罚的损失。该函数是凸函数，因此可以迭代地应用任何变体梯度下降（贪婪）算法。
- en: Note
  id: totrans-3256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M5: The conditional log-likelihood for a linear chain CRF training set *D =
    {xi, yi}* is given as follows:'
  id: totrans-3257
  prefs: []
  type: TYPE_NORMAL
  zh: 'M5: 线性链 CRF 训练集 *D = {xi, yi}* 的条件对数似然如下所示：'
- en: '![Training the CRF model](img/image01456.jpeg)'
  id: totrans-3258
  prefs: []
  type: TYPE_IMG
  zh: '![训练 CRF 模型](img/image01456.jpeg)'
- en: 'M6: Maximization of the loss function and L2 penalty is given as follows:'
  id: totrans-3259
  prefs: []
  type: TYPE_NORMAL
  zh: 'M6: 损失函数和 L2 惩罚的最大化如下所示：'
- en: '![Training the CRF model](img/image01457.jpeg)'
  id: totrans-3260
  prefs: []
  type: TYPE_IMG
  zh: '![训练 CRF 模型](img/image01457.jpeg)'
- en: 'The training file consists of a pair of files:'
  id: totrans-3261
  prefs: []
  type: TYPE_NORMAL
  zh: 训练文件由一对文件组成：
- en: '**Raw datasets**: Recommendations (such as *Raymond James upgrades Gentiva
    Health Services from Underperform to Market perform*)'
  id: totrans-3262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原始数据集**：推荐（例如 *Raymond James 将 Gentiva Health Services 从表现不佳提升至市场表现*）'
- en: '**Tagged datasets**: Tagged recommendations (such as *Raymond James [1] upgrades
    [2] Gentiva Health Services [3], from [4] Underperform [5] to [6] Market perform
    [7]*)'
  id: totrans-3263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记数据集**：标记推荐（例如 *Raymond James [1] 提升 [2] Gentiva Health Services [3]，从 [4]
    表现不佳 [5] 提升至 [6] 市场表现 [7]*）'
- en: Note
  id: totrans-3264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Tags type**'
  id: totrans-3265
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签类型**'
- en: In this implementation, the tags have the `Int` type. However, alternative types,
    such as enumerators or even continuous values (that is, `Double`) can be used.
  id: totrans-3266
  prefs: []
  type: TYPE_NORMAL
  zh: 在此实现中，标签具有 `Int` 类型。然而，可以使用其他类型，例如枚举或甚至是连续值（即 `Double`）。
- en: 'The training or computation of weights can be quite expensive. It is highly
    recommended that you distribute the observations and tagged observations dataset
    across multiple files, so they can be processed concurrently:'
  id: totrans-3267
  prefs: []
  type: TYPE_NORMAL
  zh: 训练或计算权重可能相当昂贵。强烈建议您将观测数据和标记观测数据集分散到多个文件中，以便它们可以并行处理：
- en: '![Training the CRF model](img/image01458.jpeg)'
  id: totrans-3268
  prefs: []
  type: TYPE_IMG
  zh: '![训练 CRF 模型](img/image01458.jpeg)'
- en: The distribution of the computation of the weights of the CRF
  id: totrans-3269
  prefs: []
  type: TYPE_NORMAL
  zh: CRF 权重的计算分布
- en: 'The `train` method creates the model by computing the `weights` of the CRF.
    It is invoked by the constructor of `Crf`:'
  id: totrans-3270
  prefs: []
  type: TYPE_NORMAL
  zh: '`train` 方法通过计算 CRF 的 `weights` 创建模型。它由 `Crf` 的构造函数调用：'
- en: '[PRE264]'
  id: totrans-3271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE264]'
- en: We cannot assume that there is only one tagged dataset (that is, a single pair
    of `*.raw` and `*.tagged` files) (line `9`). The `computeWeights` method used
    for computation of weights for the CRF is applied to the first dataset if there
    is only one pair of raw and tagged file. In the case of multiple datasets, the
    `train` method computes the mean of all the weights extracted from each tagged
    dataset (line `10`). The mean of the weights are computed using the `statistics`
    method of the `XTSeries` object, which was introduced in the *Time series in Scala*
    section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"),
    *Data Preprocessing*. The `train` method returns `CrfModel` if successful, and
    `None` otherwise (line `11`).
  id: totrans-3272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能假设只有一个标记的数据集（即单一对`*.raw`和`*.tagged`文件）(第`9`行)。如果只有一对原始和标记文件，用于计算CRF权重的`computeWeights`方法将应用于第一个数据集。在存在多个数据集的情况下，`train`方法计算从每个标记数据集中提取的所有权重的平均值（第`10`行）。权重的平均值使用`XTSeries`对象的`statistics`方法计算，该方法在[第3章](part0172.xhtml#aid-5410O2
    "第3章 数据预处理")的*Scala中的时间序列*部分介绍，*数据预处理*。如果成功，`train`方法返回`CrfModel`，否则返回`None`（第`11`行）。
- en: 'For efficiency purpose, the map should be parallelized using the `ParVector`
    class as follows:'
  id: totrans-3273
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高效率，应该使用`ParVector`类将映射并行化，如下所示：
- en: '[PRE265]'
  id: totrans-3274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE265]'
- en: The parallel collections are described in detail in the *Parallel collections*
    section under *Scala* in [Chapter 12](part0223.xhtml#aid-6KLDE1 "Chapter 12. Scalable
    Frameworks"), *Scalable Frameworks*.
  id: totrans-3275
  prefs: []
  type: TYPE_NORMAL
  zh: 并行集合在[第12章](part0223.xhtml#aid-6KLDE1 "第12章 可扩展框架")的*Scala*部分的*并行集合*部分有详细描述，*可扩展框架*。
- en: Note
  id: totrans-3276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**CRF weights computation**'
  id: totrans-3277
  prefs: []
  type: TYPE_NORMAL
  zh: '**CRF权重计算**'
- en: It is assumed that input tagged files share the same list of tags or symbols,
    so each dataset produces the same array of weights.
  id: totrans-3278
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输入标记文件共享相同的标签或符号列表，因此每个数据集产生相同的权重数组。
- en: 'The `computeWeights` method extracts the weights from each pair of observations
    and tagged observation files. It invokes the `train` method of the `CrfTagger`
    tag generator (line `12`) to prepare, normalize, and set up the training set,
    and then invokes the training procedure on the IITB `CRF` class (line `13`):'
  id: totrans-3279
  prefs: []
  type: TYPE_NORMAL
  zh: '`computeWeights`方法从每个观测和标记观测文件对中提取权重。它调用`CrfTagger`标记生成器的`train`方法（第`12`行）来准备、归一化和设置训练集，然后在IITB
    `CRF`类上调用训练过程（第`13`行）：'
- en: '[PRE266]'
  id: totrans-3280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE266]'
- en: Note
  id: totrans-3281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The scope of the IITB CRF Java library evaluation**'
  id: totrans-3282
  prefs: []
  type: TYPE_NORMAL
  zh: '**IITB CRF Java库评估范围**'
- en: The CRF library has been evaluated with three simple text analytics test cases.
    Although the library is certainly robust enough to illustrate the internal workings
    of the CRF, I cannot vouch for its scalability or applicability in other fields
    of interests, such as bioinformatics or process control.
  id: totrans-3283
  prefs: []
  type: TYPE_NORMAL
  zh: CRF库已经通过三个简单的文本分析测试案例进行了评估。尽管该库肯定足够健壮，可以说明CRF的内部工作原理，但我不能保证其在其他领域（如生物信息学或过程控制）的可扩展性或适用性。
- en: Applying the CRF model
  id: totrans-3284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用CRF模型
- en: 'The predictive method implements the `|>` data transformation operator. It
    takes a new observation (the analyst''s recommendation on a stock) and returns
    the maximum likelihood, as shown here:'
  id: totrans-3285
  prefs: []
  type: TYPE_NORMAL
  zh: 预测方法实现了`|>`数据转换操作符。它接受一个新的观测（分析师对股票的建议）并返回最大似然，如下所示：
- en: '[PRE267]'
  id: totrans-3286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE267]'
- en: The `|>` method merely creates a `dataSeq` data sequence and invokes the constructor
    of the IITB `CRF` class (line `14`). The condition on the `obs` input argument
    to the partial function is rather rudimentary. A more elaborate condition of the
    observation should be implemented using a regular expression. The code to validate
    the arguments/parameters of the class and methods are omitted along with the exception
    handler for the sake of readability.
  id: totrans-3287
  prefs: []
  type: TYPE_NORMAL
  zh: '`|>`方法仅创建一个`dataSeq`数据序列并调用IITB `CRF`类的构造函数（第`14`行）。对部分函数的`obs`输入参数的条件相当基础。应该使用正则表达式实现更详细的观测条件。为了可读性，省略了验证类和方法参数的代码以及异常处理程序。'
- en: Note
  id: totrans-3288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**An advanced CRF configuration**'
  id: totrans-3289
  prefs: []
  type: TYPE_NORMAL
  zh: '**高级CRF配置**'
- en: The CRF model of the **IITB** library is highly configurable. It allows developers
    to specify a state-label undirected graph with any combination of flat and nested
    dependencies between states. The source code includes several training algorithms
    such as the exponential gradient.
  id: totrans-3290
  prefs: []
  type: TYPE_NORMAL
  zh: '**IITB**库的CRF模型高度可配置。它允许开发者指定具有任何组合的平坦和嵌套依赖关系的状态-标签无向图。源代码包括几种训练算法，如指数梯度。'
- en: Tests
  id: totrans-3291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: 'The client code to execute the test consists of defining the number of labels,
    `NLABELS` (that is, the number of tags for recommendation), the `LAMBDA` L2 penalty
    factor, the maximum of iterations, `MAX_ITERS`, allowed in the minimization of
    the loss function, and the `EPS` convergence criteria:'
  id: totrans-3292
  prefs: []
  type: TYPE_NORMAL
  zh: 执行测试的客户端代码包括定义标签数量，`NLABELS`（即推荐的标签数量），`LAMBDA` L2惩罚因子，允许在损失函数最小化中的最大迭代次数，`MAX_ITERS`，以及`EPS`收敛标准：
- en: '[PRE268]'
  id: totrans-3293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE268]'
- en: 'The three simple steps are as follows:'
  id: totrans-3294
  prefs: []
  type: TYPE_NORMAL
  zh: 三个简单步骤如下：
- en: Instantiate the `config` configuration for the CRF (line `15`)
  id: totrans-3295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化CRF的`config`配置（行`15`）
- en: Define the three `delims` delimiters to extract the tagged data (line `16`)
  id: totrans-3296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义三个`delims`分隔符以提取标记数据（行`16`）
- en: Instantiate and train the CRF classifier, `crf` (line `17`)
  id: totrans-3297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化和训练CRF分类器，`crf`（行`17`）
- en: For these tests, the initial value of the weights (with respect to the maximum
    number of iterations for the maximization of the log likelihood and the convergence
    criteria) are set to 0.7 (with respect to 100 and 1e-3). The delimiters for labels
    sequence, observed features sequence, and the training set are customized for
    the format of `rating.raw` and `rating.tagged` input data files.
  id: totrans-3298
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些测试，权重的初始值（相对于最大迭代次数以最大化对数似然和收敛标准）设置为0.7（相对于100和1e-3）。标签序列、观察特征序列和训练集的分隔符针对`rating.raw`和`rating.tagged`输入数据文件的格式进行了定制。
- en: The training convergence profile
  id: totrans-3299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练收敛曲线
- en: 'The first training run discovered 136 features from 34 analysts'' stock recommendations.
    The algorithm converged after 21 iterations. The value of the log of the likelihood
    for each of those iterations is plotted to illustrate the convergence toward a
    solution of optimum *w*:'
  id: totrans-3300
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次训练运行从34位分析师的股票推荐中发现了136个特征。算法在21次迭代后收敛。每个迭代的对数似然值被绘制出来，以说明向最优 *w* 解决方案的收敛：
- en: '![The training convergence profile](img/image01459.jpeg)'
  id: totrans-3301
  prefs: []
  type: TYPE_IMG
  zh: '![训练收敛曲线](img/image01459.jpeg)'
- en: The visualization of the log conditional probability of a CRF during training
  id: totrans-3302
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程中CRF的日志条件概率的可视化
- en: The training phase converges quickly toward a solution. It can be explained
    by the fact that there is little variation in the six-field format of the analyst's
    recommendations. A loose or free-style format would require a larger number of
    iterations during training to converge.
  id: totrans-3303
  prefs: []
  type: TYPE_NORMAL
  zh: 训练阶段快速收敛到解决方案。这可以解释为分析师推荐六字段格式变化很小。松散或自由风格的格式在训练期间需要更多的迭代才能收敛。
- en: Impact of the size of the training set
  id: totrans-3304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练集大小的影响
- en: 'The second test evaluates the impact of the size of the training set on the
    convergence of the training algorithm. It consists of computing the difference
    *Δw* of the model parameters (weights) between two consecutive iterations *{w[i]}[t+1]*
    and *{w[i]}[t]*:'
  id: totrans-3305
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次测试评估了训练集大小对训练算法收敛的影响。它包括计算两个连续迭代之间的模型参数（权重）差异 *Δw*：*{w[i]}[t+1]* 和 *{w[i]}[t]*：
- en: '![Impact of the size of the training set](img/image01460.jpeg)'
  id: totrans-3306
  prefs: []
  type: TYPE_IMG
  zh: '![训练集大小的影响](img/image01460.jpeg)'
- en: 'The test is run on 163 randomly chosen recommendations using the same model
    but with two different training sets:'
  id: totrans-3307
  prefs: []
  type: TYPE_NORMAL
  zh: 测试在163个随机选择的推荐中使用相同的模型，但使用两个不同的训练集进行：
- en: 34 analysts' stock recommendations
  id: totrans-3308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 34位分析师的股票推荐
- en: 55 stock recommendations
  id: totrans-3309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 55个股票推荐
- en: 'The larger training set is a superset of the 34 recommendations'' set. The
    following graph illustrates the comparison of features generated with 34 and 55
    CRF training sequences:'
  id: totrans-3310
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的训练集是34个推荐集的超集。以下图表展示了使用34和55个CRF训练序列生成的特征比较：
- en: '![Impact of the size of the training set](img/image01461.jpeg)'
  id: totrans-3311
  prefs: []
  type: TYPE_IMG
  zh: '![训练集大小的影响](img/image01461.jpeg)'
- en: The convergence of the CRF weight using training sets of different sizes
  id: totrans-3312
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同大小的训练集的CRF权重收敛
- en: The disparity between the test runs using two different sizes of training sets
    is very small. This can be easily explained by the fact that there is a small
    variation in the format between the analyst's recommendations.
  id: totrans-3313
  prefs: []
  type: TYPE_NORMAL
  zh: 使用两种不同大小的训练集进行测试运行之间的差异非常小。这可以很容易地解释为分析师推荐格式之间的小差异。
- en: Impact of the L[2] regularization factor
  id: totrans-3314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: L[2]正则化因子的影响
- en: 'The third test evaluates the impact of the L[2] regularization penalty on the
    convergence toward the optimum weights/features. The test is similar to the first
    test with a different value of *λ*. The following chart plots *log [p(Y|X, w)]*
    for different values of *λ = 1/σ2* (0.2, 0.5, and 0.8):'
  id: totrans-3315
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次测试评估了L[2]正则化惩罚对向最优权重/特征收敛的影响。该测试与第一次测试类似，但*λ*的值不同。以下图表绘制了不同*λ = 1/σ2*（0.2、0.5和0.8）的*log
    [p(Y|X, w)]*：
- en: '![Impact of the L2 regularization factor](img/image01462.jpeg)'
  id: totrans-3316
  prefs: []
  type: TYPE_IMG
  zh: '![L2正则化因子的影响](img/image01462.jpeg)'
- en: The impact of the L2 penalty on the convergence of the CRF training algorithm
  id: totrans-3317
  prefs: []
  type: TYPE_NORMAL
  zh: L2惩罚对CRF训练算法收敛的影响
- en: The log of the conditional probability decreases or the conditional probability
    increases with the number of iterations. The lower the L[2] regularization factor,
    the higher the conditional probability.
  id: totrans-3318
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率的对数随着迭代次数的增加而减少或增加。L[2]正则化因子越低，条件概率越高。
- en: The variation of the analysts' recommendations within the training set is small,
    which limits the risk of overfitting. A free-style recommendation format would
    have been more sensitive to overfitting.
  id: totrans-3319
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集中分析师建议的变化很小，这限制了过拟合的风险。自由式建议格式对过拟合会更敏感。
- en: Comparing CRF and HMM
  id: totrans-3320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较CRF和HMM
- en: The cost/benefit analysis of discriminative models relative to generative models
    applies to the comparison of the conditional random field with the hidden Markov
    model.
  id: totrans-3321
  prefs: []
  type: TYPE_NORMAL
  zh: 与生成模型相比，判别模型的成本/收益分析适用于条件随机字段与隐马尔可夫模型的比较。
- en: Contrary to the hidden Markov model, the conditional random field does not require
    the observations to be independent (conditional probability). The conditional
    random field can be regarded as a generalization of the HMM by extending the transition
    probabilities to arbitrary feature functions that can depend on the input sequence.
    The HMM assumes the transition probabilities matrix to be constant.
  id: totrans-3322
  prefs: []
  type: TYPE_NORMAL
  zh: 与隐马尔可夫模型不同，条件随机字段不需要观测值相互独立（条件概率）。条件随机字段可以通过扩展转移概率到任意特征函数（这些特征函数可以依赖于输入序列）来被视为HMM的推广。HMM假设转移概率矩阵是常数。
- en: The HMM learns the transition probabilities *a[ij]* on its own by processing
    more training data. The HMM can be regarded as a special case of CRF where the
    probabilities used in the state transition are constant.
  id: totrans-3323
  prefs: []
  type: TYPE_NORMAL
  zh: HMM通过处理更多的训练数据自行学习转移概率*a[ij]*。HMM可以被视为CRF的一个特例，其中状态转移中使用的概率是常数。
- en: Performance consideration
  id: totrans-3324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能考虑
- en: The time complexity for decoding and evaluating canonical forms of the hidden
    Markov model for *N* states and *T* observations is *O(N[2]T)*. The training of
    the HMM using the Baum-Welch algorithm is *O(N[2]TM)*, where *M* is the number
    of iterations.
  id: totrans-3325
  prefs: []
  type: TYPE_NORMAL
  zh: 对*N*个状态和*T*个观测值的隐马尔可夫模型的标准形式的解码和评估时间复杂度为*O(N[2]T)*。使用Baum-Welch算法训练HMM的时间复杂度为*O(N[2]TM)*，其中*M*是迭代次数的数量。
- en: 'There are several options to improve the performance of the HMM:'
  id: totrans-3326
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以提高HMM的性能：
- en: Avoid unnecessary multiplication by 0 in the emission probabilities matrix by
    either using sparse matrices or tracking the null entries.
  id: totrans-3327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用稀疏矩阵或跟踪空项来避免在发射概率矩阵中不必要的乘以0。
- en: Train the HMM on the most *relevant* subset of the training data. This technique
    can be particularly effective in the case of tagging of words or a bag of words
    in natural language processing.
  id: totrans-3328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练数据的最相关子集上训练HMM。在自然语言处理中标记单词或词袋的情况下，这项技术可能特别有效。
- en: The training of the linear chain conditional random fields is implemented using
    the same dynamic programming techniques as the HMM implementation (Viterbi, forward-backward
    passes, and so on). Its time complexity for training *T* data sequences, *N* labels
    (or expected outcomes), and *M* weights/features *λ* is *O(MTN[2])*.
  id: totrans-3329
  prefs: []
  type: TYPE_NORMAL
  zh: 线性链条件随机字段的训练使用与HMM实现相同的动态规划技术（维特比算法、前向-后向遍历等）。其训练时间复杂度为*O(MTN[2])*，其中*T*是数据序列的数量，*N*是标签（或预期结果）的数量，*M*是权重/特征*λ*的数量。
- en: The time complexity of the training of a CRF can be reduced by distributing
    the computation of the log likelihood and gradient over multiple nodes using a
    framework such as Akka or Apache Spark, as described in [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks* [7:13].
  id: totrans-3330
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用如Akka或Apache Spark等框架，可以将对数似然和梯度的计算分布到多个节点上，从而降低CRF训练的时间复杂度，如第12章所述，*可扩展框架*
    [7:13]。
- en: Summary
  id: totrans-3331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we had a closer look at modeling sequences of observations
    with hidden (or latent) states with the two commonly used algorithms:'
  id: totrans-3332
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们更详细地探讨了使用两种常用算法对具有隐藏（或潜在）状态的观测序列进行建模：
- en: The generative hidden Markov model to maximize *p(X,Y)*
  id: totrans-3333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式隐马尔可夫模型以最大化*p(X,Y)*
- en: The discriminative conditional random field to maximize *log p(Y|X)*
  id: totrans-3334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于最大化*log p(Y|X)*的判别性条件随机场
- en: The HMM is a special form of Bayes network. It requires the observations to
    be independent. Although restrictive, the conditional independence prerequisites
    make the HMM fairly easy to understand and validate, which is not the case for
    a CRF.
  id: totrans-3335
  prefs: []
  type: TYPE_NORMAL
  zh: HMM（隐马尔可夫模型）是贝叶斯网络的一种特殊形式。它要求观测值是独立的。尽管有局限性，但条件独立性前提使得HMM相对容易理解和验证，而CRF（条件随机场）则不然。
- en: 'You learned how to implement three dynamic programming techniques: Viterbi,
    Baum-Welch, and alpha/beta algorithms in Scala. These algorithms are used to solve
    diverse type of optimization problems. They should be an essential component of
    your algorithmic tool box.'
  id: totrans-3336
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了如何在Scala中实现三种动态规划技术：Viterbi、Baum-Welch和alpha/beta算法。这些算法用于解决各种类型的优化问题。它们应该是你的算法工具箱中的基本组成部分。
- en: 'The conditional random field relies on the logistic regression to estimate
    the optimal weights of the model. Such a technique is also used in the multiple
    layer perceptron, which was introduced in [Chapter 9](part0207.xhtml#aid-65D4E1
    "Chapter 9. Artificial Neural Networks"), *Artificial Neural Network*. The next
    chapter introduces two important alternatives to the logistic regression for discriminating
    between observations: the Kernel function for nonlinear models and the maximization
    of the margin between classes of observations.'
  id: totrans-3337
  prefs: []
  type: TYPE_NORMAL
  zh: 条件随机场依赖于逻辑回归来估计模型的最佳权重。这种技术也用于多层感知器，这在第9章（[第9章](part0207.xhtml#aid-65D4E1 "第9章.
    人工神经网络")，*人工神经网络*）中介绍过。下一章将介绍两种重要的逻辑回归替代方案，用于区分观测值：非线性模型的核函数和观测值类之间的边缘最大化。
- en: Chapter 8. Kernel Models and Support Vector Machines
  id: totrans-3338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章. 核模型与支持向量机
- en: This chapter introduces kernel functions, binary support vectors classifiers,
    one-class support vector machines for anomaly detection, and support vector regression.
  id: totrans-3339
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了核函数、二元支持向量机分类器、用于异常检测的单类支持向量机以及支持向量回归。
- en: 'In the *Binomial classification* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*,
    you learned the concept of hyperplanes to segregate observations from the training
    set and estimate the linear decision boundary. The logistic regression has at
    least one limitation: it requires that the datasets be linearly separated using
    a defined function (sigmoid). This limitation is especially an issue for high-dimension
    problems (large number of features that are highly nonlinearly dependent). **Support
    vector machines** (**SVMs**) overcome this limitation by estimating the optimal
    separating hyperplane using kernel functions.'
  id: totrans-3340
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](part0188.xhtml#aid-5J99O2 "第6章. 回归与正则化")的*二项分类*部分，*回归与正则化*中，你学习了超平面分割训练集观测值并估计线性决策边界的概念。逻辑回归至少有一个局限性：它要求使用定义好的函数（sigmoid）将数据集线性分离。对于高维问题（大量高度非线性相关的特征），这个问题尤为突出。**支持向量机**（**SVMs**）通过使用核函数估计最佳分离超平面来克服这一局限性。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3341
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: The impact of some of the SVM configuration parameters and the kernel method
    on the accuracy of the classification
  id: totrans-3342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些SVM配置参数和核方法对分类准确性的影响
- en: How to apply the binary support vector classifier to estimate the risk for a
    public company to curtail or eliminate its dividend
  id: totrans-3343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将二元支持向量机分类器应用于估计上市公司削减或消除股息的风险
- en: How to detect outliers with a one-class support vector classifier
  id: totrans-3344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用单类支持向量机检测异常值
- en: How the support vector regression is compared to the linear regression
  id: totrans-3345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量回归与线性回归的比较
- en: Support vector machines are formulated as a convex optimization problem. The
    mathematical foundation of the related algorithms is described in this chapter,
    for reference.
  id: totrans-3346
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机被表述为一个凸优化问题。本章描述了相关算法的数学基础，以供参考。
- en: Kernel functions
  id: totrans-3347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核函数
- en: Every machine learning model introduced in this book so far assumes that observations
    are represented by a feature vector of a fixed size. However, some real-world
    applications such as text mining or genomics do not lend themselves to this restriction.
    The critical element of the process of classification is to define a similarity
    or distance between two observations. Kernel functions allow developers to compute
    the similarity between observations without the need to encode them in feature
    vectors [8:1].
  id: totrans-3348
  prefs: []
  type: TYPE_NORMAL
  zh: 本书至今介绍的所有机器学习模型都假设观测值由一个固定大小的特征向量表示。然而，一些现实世界的应用，如文本挖掘或基因组学，并不适合这种限制。分类过程的关键是定义两个观测值之间的相似性或距离。核函数允许开发者计算观测值之间的相似性，而无需将它们编码在特征向量中
    [8:1]。
- en: An overview
  id: totrans-3349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The concept of kernel methods may be a bit odd at first to a novice. Let's consider
    the example of the classification of proteins. Proteins have different lengths
    and compositions, but they do not prevent scientists from classifying them [8:2].
  id: totrans-3350
  prefs: []
  type: TYPE_NORMAL
  zh: 核方法的概念可能一开始对新手来说有点奇怪。让我们以蛋白质分类的例子来考虑。蛋白质有不同的长度和组成，但这并不妨碍科学家对它们进行分类 [8:2]。
- en: Note
  id: totrans-3351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Proteins**'
  id: totrans-3352
  prefs: []
  type: TYPE_NORMAL
  zh: '**蛋白质**'
- en: Proteins are polymers of amino acids joined together by peptide bonds. They
    are composed of a carbon atom bonded to a hydrogen atom, another amino acid, or
    a carboxyl group.
  id: totrans-3353
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质是由肽键连接在一起的氨基酸聚合物。它们由一个碳原子与一个氢原子、另一个氨基酸或羧基键合而成。
- en: 'A protein is represented using a traditional molecular notation to which biochemists
    are familiar. Geneticists describe proteins in terms of a sequence of characters
    known as the **protein sequence annotation**. The sequence annotation encodes
    the structure and composition of the protein. The following image illustrates
    the molecular (left) and encoded (right) representation of a protein:'
  id: totrans-3354
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质使用生物化学家熟悉的传统分子符号来表示。遗传学家用被称为**蛋白质序列注释**的字符序列来描述蛋白质。序列注释编码了蛋白质的结构和组成。以下图像展示了蛋白质的分子（左侧）和编码（右侧）表示：
- en: '![An overview](img/image01463.jpeg)'
  id: totrans-3355
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01463.jpeg)'
- en: The sequence annotation of a protein
  id: totrans-3356
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质的序列注释
- en: 'The classification and the clustering of a set of proteins require the definition
    of a similarity factor or distance used to evaluate and compare the proteins.
    For example, the similarity between three proteins can be defined as a normalized
    dot product of their sequence annotation:'
  id: totrans-3357
  prefs: []
  type: TYPE_NORMAL
  zh: 对一组蛋白质的分类和聚类需要定义一个相似性因子或距离，用于评估和比较蛋白质。例如，三个蛋白质之间的相似性可以定义为它们序列注释的归一化点积：
- en: '![An overview](img/image01464.jpeg)'
  id: totrans-3358
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01464.jpeg)'
- en: The similarity between the sequence annotations of three proteins
  id: totrans-3359
  prefs: []
  type: TYPE_NORMAL
  zh: 三个蛋白质序列注释之间的相似性
- en: You do not have to represent the entire sequence annotation of the proteins
    as a feature vector in order to establish that they belong to the same class.
    You only need to compare each element of each sequence, one by one, and compute
    the similarity. For the same reason, the estimation of the similarity does not
    require the two proteins to have the same length.
  id: totrans-3360
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定蛋白质属于同一类，您不需要将整个序列注释表示为特征向量。您只需要逐个比较每个序列的每个元素，并计算相似性。同样，相似性的估计不需要两个蛋白质具有相同的长度。
- en: 'In this example, we do not have to assign a numerical value to each element
    of the annotation. Let''s consider an element of the protein annotation as its
    character *c* and position *p* (for example, K, 4). The dot product of the two
    protein annotations *x* and *x''* of the respective lengths *n* and *n''* are
    defined as the number of identical elements (character and position) between the
    two annotations divided by the maximum length between the two annotations (**M1**):'
  id: totrans-3361
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不需要给注释的每个元素分配一个数值。让我们考虑蛋白质注释的一个元素作为其字符 *c* 和位置 *p*（例如，K，4）。两个蛋白质注释
    *x* 和 *x'* 的点积，分别对应长度 *n* 和 *n'*，定义为两个注释之间相同元素（字符和位置）的数量除以两个注释之间的最大长度（**M1**）：
- en: '![An overview](img/image01465.jpeg)'
  id: totrans-3362
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01465.jpeg)'
- en: The computation of the similarity for the three proteins produces the result
    as *sim(x,x')=6/12 = 0.50*, *sim(x,x'')=3/13 =0.23*, and *sim(x',x'')= 4/13= 0.31*.
  id: totrans-3363
  prefs: []
  type: TYPE_NORMAL
  zh: 对三个蛋白质的相似性计算结果为 *sim(x,x')=6/12 = 0.50*，*sim(x,x'')=3/13 =0.23*，和 *sim(x',x'')=
    4/13= 0.31*。
- en: Another similar aspect is that the similarity of two identical annotations is
    1.0 and the similarity of two completely different annotations is 0.0.
  id: totrans-3364
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个相似之处是，两个相同注释的相似性为 1.0，两个完全不同注释的相似性为 0.0。
- en: Note
  id: totrans-3365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The visualization of similarity**'
  id: totrans-3366
  prefs: []
  type: TYPE_NORMAL
  zh: '**相似性的可视化**'
- en: It is usually more convenient to use a radial representation to visualize the
    similarity between features, as in the example of proteins' annotations. The distance
    *d(x,x') = 1/sim(x,x')* is visualized as the angle or cosine between two features.
    The cosine metric is commonly used in text mining.
  id: totrans-3367
  prefs: []
  type: TYPE_NORMAL
  zh: 通常使用径向表示来可视化特征之间的相似性更方便，例如在蛋白质注释的例子中。距离 *d(x,x') = 1/sim(x,x')* 被可视化成两个特征之间的角度或余弦值。余弦度量在文本挖掘中常用。
- en: In this example, the similarity is known as a kernel function in the space of
    the sequence annotation of proteins.
  id: totrans-3368
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，相似性被称为蛋白质序列注释空间中的核函数。
- en: Common discriminative kernels
  id: totrans-3369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的判别核函数
- en: 'Although the measure of similarity is very useful to understand the concept
    of a kernel function, kernels have a broader definition. A kernel *K(x, x'')*
    is a symmetric, nonnegative real function that takes two real arguments (values
    of two features). There are many different types of kernel functions, among which
    the most common are as follows:'
  id: totrans-3370
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然相似度的度量对于理解核函数的概念非常有用，但核函数有更广泛的定义。核 *K(x, x')* 是一个对称的、非负的实值函数，它接受两个实数参数（两个特征的值）。有许多不同类型的核函数，其中最常见的是以下几种：
- en: '**The linear kernel** (**dot product**): This is useful in the case of very
    high-dimensional data where problems can be expressed as a linear combination
    of the original features.'
  id: totrans-3371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性核函数**（**点积**）：这在非常高维度的数据中很有用，其中问题可以表示为原始特征的线性组合。'
- en: '**The polynomial kernel**: This extends the linear kernel for a combination
    of features that are not completely linear.'
  id: totrans-3372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式核函数**：这扩展了线性核，用于组合非完全线性的特征。'
- en: '**The radial basis function** (**RBF**): This is the most commonly applied
    kernel. It is used where the labeled or target data is noisy and requires some
    level of regularization.'
  id: totrans-3373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**径向基函数**（**RBF**）：这是最常用的核。它用于标签或目标数据有噪声且需要一定程度的正则化的场合。'
- en: '**The sigmoid kernel**: This is used in conjunction with neural networks.'
  id: totrans-3374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sigmoid 核函数**：这通常与神经网络一起使用。'
- en: '**The Laplacian kernel**: This is a variant of RBF with a higher regularization
    impact on training data.'
  id: totrans-3375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拉普拉斯核函数**：这是对 RBF 的一种变体，对训练数据有更高的正则化影响。'
- en: '**The log kernel**: This is used in image processing.'
  id: totrans-3376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对数核函数**：这在图像处理中使用。'
- en: Note
  id: totrans-3377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The RBF terminology**'
  id: totrans-3378
  prefs: []
  type: TYPE_NORMAL
  zh: '**RBF 术语**'
- en: In this presentation and the library used in its implementation, the radial
    basis function is a synonym to the Gaussian kernel function. However, RBF also
    refers to the family of exponential kernel functions that encompasses Gaussian,
    Laplacian, and exponential functions.
  id: totrans-3379
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示及其实现中使用的库中，径向基函数是高斯核函数的同义词。然而，RBF 也指包括高斯、拉普拉斯和指数函数在内的指数核函数族。
- en: The simple linear model for regression consists of the dot product of the regression
    parameters (weights) and the input data (refer to the *Ordinary least squares
    regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression
    and Regularization"), *Regression and Regularization*).
  id: totrans-3380
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的简单模型由回归参数（权重）与输入数据的点积组成（参见[第6章](part0188.xhtml#aid-5J99O2 "第6章。回归和正则化")中的*普通最小二乘回归*部分，*回归和正则化*）。
- en: 'The model is, in fact, the linear combination of weights and linear combination
    of inputs. The concept can be extended by defining a general regression model
    as the linear combination of nonlinear functions, known as basis functions (**M2**):'
  id: totrans-3381
  prefs: []
  type: TYPE_NORMAL
  zh: 模型实际上是权重和输入的线性组合。通过定义一个通用的回归模型为非线性函数的线性组合，即基函数（**M2**）的概念可以扩展：
- en: '![Common discriminative kernels](img/image01466.jpeg)'
  id: totrans-3382
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01466.jpeg)'
- en: 'The most commonly used basis functions are the power and Gaussian functions.
    The kernel function is described as the dot product of the two vectors of the
    basis function *φ(x).φ(x'')* of two features vectors *x* and *x''*. A partial
    list of kernel methods is as follows:'
  id: totrans-3383
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的基函数是幂函数和高斯函数。核函数被描述为两个特征向量 *x* 和 *x'* 的基函数向量 *φ(x).φ(x')* 的点积。以下是一些核方法的列表：
- en: Note
  id: totrans-3384
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M3: The generic kernel function is defined as:'
  id: totrans-3385
  prefs: []
  type: TYPE_NORMAL
  zh: M3：通用核函数定义为：
- en: '![Common discriminative kernels](img/image01467.jpeg)'
  id: totrans-3386
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01467.jpeg)'
- en: 'M4: The linear kernel is defined as:'
  id: totrans-3387
  prefs: []
  type: TYPE_NORMAL
  zh: M4：线性核定义为：
- en: '![Common discriminative kernels](img/image01468.jpeg)'
  id: totrans-3388
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01468.jpeg)'
- en: 'M5: The polynomial kernel with the slope *γ*, degree *n*, and constant *c*
    is defined as:'
  id: totrans-3389
  prefs: []
  type: TYPE_NORMAL
  zh: M5：具有斜率 *γ*、度数 *n* 和常数 *c* 的多项式核函数定义为：
- en: '![Common discriminative kernels](img/image01469.jpeg)'
  id: totrans-3390
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01469.jpeg)'
- en: 'M6: The sigmoid kernel with the slope *γ* and constant *c* is defined as:'
  id: totrans-3391
  prefs: []
  type: TYPE_NORMAL
  zh: M6：具有斜率 *γ* 和常数 *c* 的sigmoid核定义为：
- en: '![Common discriminative kernels](img/image01470.jpeg)'
  id: totrans-3392
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01470.jpeg)'
- en: 'M7: The radial basis function kernel with the slope *γ* is defined as:'
  id: totrans-3393
  prefs: []
  type: TYPE_NORMAL
  zh: M7：具有斜率 *γ* 的径向基函数核定义为：
- en: '![Common discriminative kernels](img/image01471.jpeg)'
  id: totrans-3394
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01471.jpeg)'
- en: 'M8: The Laplacian kernel with the slope *γ* is defined as:'
  id: totrans-3395
  prefs: []
  type: TYPE_NORMAL
  zh: M8：具有斜率 *γ* 的拉普拉斯核定义为：
- en: '![Common discriminative kernels](img/image01472.jpeg)'
  id: totrans-3396
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01472.jpeg)'
- en: 'M9: The log kernel with the degree *n* is defined as:'
  id: totrans-3397
  prefs: []
  type: TYPE_NORMAL
  zh: M9：具有度数 *n* 的对数核定义为：
- en: '![Common discriminative kernels](img/image01473.jpeg)'
  id: totrans-3398
  prefs: []
  type: TYPE_IMG
  zh: '![常见的判别核函数](img/image01473.jpeg)'
- en: 'The list of discriminative kernel functions described earlier is just a subset
    of the kernel methods'' universe. The other types of kernels include the following:'
  id: totrans-3399
  prefs: []
  type: TYPE_NORMAL
  zh: 之前描述的判别核函数列表只是核方法宇宙的一个子集。其他类型的核包括以下几种：
- en: '**Probabilistic kernels**: These are kernels derived from generative models.
    Probabilistic models such as Gaussian processes can be used as a kernel function
    [8:3].'
  id: totrans-3400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率核**：这些是从生成模型中导出的核。例如，高斯过程这样的概率模型可以用作核函数[8:3]。'
- en: '**Smoothing kernels**: This is the nonparametric formulation, averaging density
    with the nearest neighbor observations [8:4].'
  id: totrans-3401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑核**：这是非参数公式，通过最近邻观测值平均密度[8:4]。'
- en: '**Reproducible kernel Hilbert spaces**: This is the dot product of finite or
    infinite basis functions [8:5].'
  id: totrans-3402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可复现核希尔伯特空间**：这是有限或无限基函数的点积[8:5]。'
- en: The kernel functions play a very important role in support vector machines for
    nonlinear problems.
  id: totrans-3403
  prefs: []
  type: TYPE_NORMAL
  zh: 在非线性问题中，核函数在支持向量机中扮演着非常重要的角色。
- en: Kernel monadic composition
  id: totrans-3404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核单子组合
- en: The concept of a kernel function is actually derived from differential geometry
    and more specifically from manifold, which was introduced in the *Non-linear models*
    section under *Dimension reduction* in [Chapter 4](part0178.xhtml#aid-59O442 "Chapter 4. Unsupervised
    Learning"), *Unsupervised Learning*.
  id: totrans-3405
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数的概念实际上是从微分几何中推导出来的，更具体地说，是从流形中推导出来的，这在[第4章](part0178.xhtml#aid-59O442 "第4章。无监督学习")的“降维”部分下的“非线性模型”中介绍过，属于“无监督学习”。
- en: A manifold is a low dimension features space embedded in the observation space
    of higher dimension. The dot (or inner) product of two observations, known as
    the **Riemann metric,** is computed on a Euclidean tangent space.
  id: totrans-3406
  prefs: []
  type: TYPE_NORMAL
  zh: 流形是嵌入在更高维观测空间中的低维特征空间。两个观测之间的点积（或内积），称为**黎曼度量**，是在欧几里得切空间上计算的。
- en: Note
  id: totrans-3407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The heat kernel function**'
  id: totrans-3408
  prefs: []
  type: TYPE_NORMAL
  zh: '**热核函数**'
- en: The kernel function on a manifold is actually computed by solving the heat equation
    that uses the Laplace-Beltrami operator. The heat kernel is the solution of the
    heat differential equation. It associates the dot product with an exponential
    map.
  id: totrans-3409
  prefs: []
  type: TYPE_NORMAL
  zh: 流形上的核函数实际上是通过求解使用拉普拉斯-贝尔特拉米算子的热方程来计算的。热核是热微分方程的解。它将点积与指数映射关联起来。
- en: 'The kernel function is the composition of the dot product on the tangent space
    projected on the manifold using an exponential map, as shown in the following
    diagram:'
  id: totrans-3410
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数是使用指数映射在流形上投影切空间上的点积的复合，如下图所示：
- en: '![Kernel monadic composition](img/image01474.jpeg)'
  id: totrans-3411
  prefs: []
  type: TYPE_IMG
  zh: '![核单子组合](img/image01474.jpeg)'
- en: The visualization of a manifold, Riemann metric, and projection of an inner
    product
  id: totrans-3412
  prefs: []
  type: TYPE_NORMAL
  zh: 流形、黎曼度量以及内积投影的可视化
- en: 'A kernel function is the composition *g o f* of two functions:'
  id: totrans-3413
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数是两个函数的复合 *g o f*：
- en: A function *h* that implements the Riemann metric or similarity between two
    vectors *v* and *w*
  id: totrans-3414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个实现两个向量 *v* 和 *w* 之间的黎曼度量或相似度的函数 *h*
- en: A function *g* that implements the projection of the similarity *h(v, w)* to
    the manifold (exponential map)
  id: totrans-3415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个实现相似度 *h(v, w)* 投影到流形（指数映射）的函数 *g*
- en: 'The `KF` class implements the kernel function as a composition of the functions
    *g* and *h*:'
  id: totrans-3416
  prefs: []
  type: TYPE_NORMAL
  zh: '`KF` 类实现了核函数作为函数 *g* 和 *h* 的复合：'
- en: '[PRE269]'
  id: totrans-3417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE269]'
- en: The `KF` class is parameterized with a `G` type that can be converted to `Function1[Double,
    Double]`. Therefore, the computation of `metric` (dot product) requires an implicit
    conversion from `G` to `Function1` (line `1`). The `metric` is computed by zipping
    the two vectors, mapping the `h` similarity function, and summing up the resulting
    vector (line `2`).
  id: totrans-3418
  prefs: []
  type: TYPE_NORMAL
  zh: '`KF` 类使用可以转换为 `Function1[Double, Double]` 的 `G` 类型进行参数化。因此，计算 `metric`（点积）需要从
    `G` 到 `Function1` 的隐式转换（第 `1` 行）。`metric` 通过将两个向量配对，映射 `h` 相似度函数，并求和得到的向量来计算（第
    `2` 行）。'
- en: 'Let''s define the monadic composition for the `KF` class:'
  id: totrans-3419
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为 `KF` 类定义单子组合：
- en: '[PRE270]'
  id: totrans-3420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE270]'
- en: The creation of the `kfMonad` instance overrides the `map` and `flatMap` methods
    defined in the generic `_Monad` trait, as described in the *Monads* section in
    [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"), *Getting
    Started*. The implementation of the `unit` method is not essential to the monadic
    composition and it is, therefore, omitted.
  id: totrans-3421
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 `kfMonad` 实例覆盖了在 [第 1 章](part0155.xhtml#aid-4JQ761 "第 1 章。入门") 的 *Monads*
    部分中描述的通用 `_Monad` 特质中定义的 `map` 和 `flatMap` 方法。`unit` 方法的实现对于单子组合不是必要的，因此被省略。
- en: The function argument of the `map` and `flatMap` methods applies only to the
    exponential map function *g* (line `3`). The composition of two kernel functions
    *kf1 = g1 o h* and *kf2 = g2 o h* produces a kernel function *kf3 = g2 o (g1 o
    h) = (g2 o g1) o h = g3 o h*.
  id: totrans-3422
  prefs: []
  type: TYPE_NORMAL
  zh: '`map` 和 `flatMap` 方法的函数参数仅适用于指数映射函数 *g*（第 `3` 行）。两个核函数 *kf1 = g1 o h* 和 *kf2
    = g2 o h* 的组合产生核函数 *kf3 = g2 o (g1 o h) = (g2 o g1) o h = g3 o h*。'
- en: Note
  id: totrans-3423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Interpretation of kernel functions'' monadic composition**'
  id: totrans-3424
  prefs: []
  type: TYPE_NORMAL
  zh: '**核函数单子组合的解释**'
- en: The visualization of the monadic composition of kernel functions on the manifold
    is quite intuitive. The composition of two kernel functions consists of composing
    their respective projections or exponential map functions *g*. The function *g*
    is directly related to the curvature of the manifold around the data point for
    which the metric is computed. The monadic composition of the kernel functions
    attempts to adjust the exponential map to fit the curvature of the manifold.
  id: totrans-3425
  prefs: []
  type: TYPE_NORMAL
  zh: 在流形上核函数单子组合的可视化非常直观。两个核函数的组合包括组合它们各自的投影或指数映射函数 *g*。函数 *g* 与计算度量时数据点周围的流形曲率直接相关。核函数的单子组合试图调整指数映射以适应流形的曲率。
- en: 'The next step is to define an implicit class to convert a kernel function of
    the `KF` type to its monadic representation so that it can access the `map` and
    `flatMap` methods (line `4`):'
  id: totrans-3426
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义一个隐式类，将 `KF` 类型的核函数转换为它的单子表示，以便它可以访问 `map` 和 `flatMap` 方法（第 `4` 行）：
- en: '[PRE271]'
  id: totrans-3427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE271]'
- en: 'Let''s implement the `RBF` radial basis function and the polynomial kernel
    function, `Polynomial`, by defining their respective *g* and *h* functions. The
    parameterized type for the kernel function is simply `Function1[Double, Double]`:'
  id: totrans-3428
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过定义各自的 *g* 和 *h* 函数来实现 `RBF` 径向基函数和多项式核函数 `Polynomial`。核函数的参数化类型简单为 `Function1[Double,
    Double]`：
- en: '[PRE272]'
  id: totrans-3429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE272]'
- en: 'Here is an example of the composition of two kernel functions: a `kf1` kernel
    RBF with a standard deviation of `0.6` (line `5`) and a `kf2` polynomial kernel
    with a degree `3` (line `6`):'
  id: totrans-3430
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是两个核函数组合的例子：一个 `kf1` 核 RBF，标准差为 `0.6`（第 `5` 行），以及一个 `kf2` 多项式核，次数为 `3`（第 `6`
    行）：
- en: '[PRE273]'
  id: totrans-3431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE273]'
- en: Finally, the `metric` is computed on the `composed` kernel functions (line `7`).
  id: totrans-3432
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 `composed` 核函数上计算 `metric`（第 `7` 行）。
- en: Note
  id: totrans-3433
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Kernel functions in SVM**'
  id: totrans-3434
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVM 中的核函数**'
- en: Our implementation of the support vector machine uses the kernel function included
    in the LIBSVM library.
  id: totrans-3435
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对支持向量机的实现使用了包含在 LIBSVM 库中的核函数。
- en: Support vector machines
  id: totrans-3436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: A support vector machine is a linear discriminative classifier that attempts
    to maximize the margin between classes during training. This approach is similar
    to the definition of a hyperplane through the training of the logistic regression
    (refer to the *Binomial classification* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*).
    The main difference is that the support vector machine computes the optimum separating
    hyperplane between groups or classes of observations. The hyperplane is indeed
    the equation that represents the model generated through training.
  id: totrans-3437
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机是一种线性判别分类器，它在训练过程中试图最大化类别之间的间隔。这种方法与通过逻辑回归训练超平面的定义类似（参考第 6 章 *回归和正则化* 中的
    *二项式分类* 部分），*回归和正则化*）。主要区别在于支持向量机计算观察值组或类别之间的最优分隔超平面。超平面确实是代表通过训练生成的模型的方程。
- en: The quality of the SVM depends on the distance, known as margin, between the
    different classes of observations. The accuracy of the classifier increases as
    the margin increases.
  id: totrans-3438
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的质量取决于不同类别观察值之间的距离，即间隔。随着间隔的增加，分类器的准确性提高。
- en: The linear SVM
  id: totrans-3439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性支持向量机
- en: 'First, let''s apply the support vector machine to extract a linear model (classifier
    or regression) for a labeled set of observations. There are two scenarios for
    defining a linear model. The labeled observations are as follows:'
  id: totrans-3440
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将支持向量机应用于提取一组标记观察值的线性模型（分类器或回归）。定义线性模型有两种情况。标记观察值如下：
- en: They are naturally segregated in the features space (the **separable** case)
  id: totrans-3441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们在特征空间中自然地被分隔开（可分情况）
- en: They are intermingled with overlap (the **nonseparable** case)
  id: totrans-3442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们相互交织并重叠（不可分情况）
- en: It is easy to understand the concept of an optimal separating hyperplane in
    cases where the observations are naturally segregated.
  id: totrans-3443
  prefs: []
  type: TYPE_NORMAL
  zh: 当观察值自然分隔时，很容易理解最优分离超平面的概念。
- en: The separable case – the hard margin
  id: totrans-3444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可分情况 – 硬间隔
- en: The concept of separating a training set of observations with a hyperplane is
    explained in a better way with a two-dimensional *(x, y)* set of observations
    with two classes *C[1]* and *C[2]*. The label *y* has the value -1 or +1.
  id: totrans-3445
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二维 *(x, y)* 观察值集和两个类别 *C[1]* 和 *C[2]* 的二维集，以更好地解释使用超平面分隔训练集观察值的概念。标签 *y* 的值为
    -1 或 +1。
- en: 'The equation for the separating hyperplane is defined by the linear equation
    *y=w.x[T]* *+w[0]*, which sits in the midpoint between the boundary data points
    for the class *C[1] (H[1]: w.x ^T + w[0] + 1=0*) and class *C[2] (H[2]: w.x^T
    + w[0] - 1*). The planes *H[1]* and *H[2]* are the support vectors:'
  id: totrans-3446
  prefs: []
  type: TYPE_NORMAL
  zh: '分隔超平面的方程由线性方程 *y=w.x[T]* *+w[0]* 定义，它位于类别 *C[1] (H[1]: w.x ^T + w[0] + 1=0*)
    和类别 *C[2] (H[2]: w.x^T + w[0] - 1*) 的边界数据点之间。平面 *H[1]* 和 *H[2]* 是支持向量：'
- en: '![The separable case – the hard margin](img/image01475.jpeg)'
  id: totrans-3447
  prefs: []
  type: TYPE_IMG
  zh: '![可分情况 – 硬间隔](img/image01475.jpeg)'
- en: The visualization of the hard margin in the support vector machine
  id: totrans-3448
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机中硬间隔的可视化
- en: In the separable case, the support vectors fully segregate the observations
    into two distinct classes. The margin between the two support vectors is the same
    for all the observations and is known as the **hard margin**.
  id: totrans-3449
  prefs: []
  type: TYPE_NORMAL
  zh: 在可分情况下，支持向量将观察值完全分隔成两个不同的类别。两个支持向量之间的间隔对所有观察值都是相同的，称为 **硬间隔**。
- en: Note
  id: totrans-3450
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The separable case**'
  id: totrans-3451
  prefs: []
  type: TYPE_NORMAL
  zh: '**可分情况**'
- en: 'M1: The support vectors equation *w* is represented as:'
  id: totrans-3452
  prefs: []
  type: TYPE_NORMAL
  zh: M1：支持向量方程 *w* 表示为：
- en: '![The separable case – the hard margin](img/image01476.jpeg)'
  id: totrans-3453
  prefs: []
  type: TYPE_IMG
  zh: '![可分情况 – 硬间隔](img/image01476.jpeg)'
- en: 'M2: The hard margin optimization problem is given by:'
  id: totrans-3454
  prefs: []
  type: TYPE_NORMAL
  zh: M2：硬间隔优化问题如下所示：
- en: '![The separable case – the hard margin](img/image01477.jpeg)'
  id: totrans-3455
  prefs: []
  type: TYPE_IMG
  zh: '![可分情况 – 硬间隔](img/image01477.jpeg)'
- en: The nonseparable case – the soft margin
  id: totrans-3456
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不可分情况 – 软间隔
- en: 'In the nonseparable case, the support vectors cannot completely segregate observations
    through training. They merely become linear functions that penalize the few observations
    or outliers that are located outside (or beyond) their respective support vector
    *H[1]* or *H[2]*. The penalty variable *ξ*, also known as the slack variable,
    increases if the outlier is further away from the support vector:'
  id: totrans-3457
  prefs: []
  type: TYPE_NORMAL
  zh: 在不可分情况下，支持向量无法通过训练完全分隔观察值。它们仅仅变成了线性函数，惩罚位于其各自支持向量 *H[1]* 或 *H[2]* 之外（或超出）的少数观察值或异常值。如果异常值离支持向量更远，则惩罚变量
    *ξ*，也称为松弛变量，会增加：
- en: '![The nonseparable case – the soft margin](img/image01478.jpeg)'
  id: totrans-3458
  prefs: []
  type: TYPE_IMG
  zh: '![不可分情况 – 软间隔](img/image01478.jpeg)'
- en: The visualization of the hard margin in the support vector machine
  id: totrans-3459
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机中硬间隔的可视化
- en: The observations that belong to the appropriate (or own) class do not have to
    be penalized. The condition is similar to the hard margin, which means that the
    slack *ξ* is null. This technique penalizes the observations that belong to the
    class but are located beyond their support vectors; the slack *ξ* increases as
    the observations get closer to the support vector of the other class and beyond.
    The margin is then known as a soft margin because the separating hyperplane is
    enforced through a slack variable.
  id: totrans-3460
  prefs: []
  type: TYPE_NORMAL
  zh: 属于适当（或自身）类的观测值不需要被惩罚。条件与硬间隔相似，这意味着松弛*ξ*为零。这种技术惩罚属于该类但位于其支持向量之外的观测值；随着观测值接近另一类的支持向量以及更远，松弛*ξ*增加。因此，间隔被称为软间隔，因为分离超平面是通过松弛变量强制执行的。
- en: Note
  id: totrans-3461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**The nonseparable case**'
  id: totrans-3462
  prefs: []
  type: TYPE_NORMAL
  zh: '**不可分情况**'
- en: 'M3: The optimization of the soft margin for a linear SVM with *C* formulation
    is defined as:'
  id: totrans-3463
  prefs: []
  type: TYPE_NORMAL
  zh: M3：具有*C*公式的线性支持向量机软间隔的优化定义为：
- en: '![The nonseparable case – the soft margin](img/image01479.jpeg)'
  id: totrans-3464
  prefs: []
  type: TYPE_IMG
  zh: '![不可分情况 – 软间隔](img/image01479.jpeg)'
- en: Here, *C* is the penalty (or inversed regularization) factor.
  id: totrans-3465
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*C*是惩罚（或逆正则化）因子。
- en: You may wonder how the minimization of the margin error is related to the loss
    function and the penalization factor, introduced for the ridge regression (refer
    to the *Numerical optimization* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*).
    The second factor in the formula corresponds to the ubiquitous loss function.
    You will certainly be able to recognize the first term as the L2 regularization
    penalty with *λ = 1/2C*.
  id: totrans-3466
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道边缘误差最小化如何与损失函数和为岭回归引入的惩罚因子相关（参见[第6章](part0188.xhtml#aid-5J99O2 "第6章。回归和正则化")中的*数值优化*部分，*回归和正则化*）。公式中的第二个因子对应于普遍存在的损失函数。你肯定能认出第一个项是L2正则化惩罚，其中*λ
    = 1/2C*。
- en: The problem can be reformulated as the minimization of a function known as the
    **primal problem** [8:6].
  id: totrans-3467
  prefs: []
  type: TYPE_NORMAL
  zh: 问题可以重新表述为最小化一个称为**原问题**的函数[8:6]。
- en: Note
  id: totrans-3468
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: 'M4: The primal problem formulation of the support vector classifier using the
    L[2] regularization is as follows:'
  id: totrans-3469
  prefs: []
  type: TYPE_NORMAL
  zh: M4：使用L[2]正则化的支持向量机原问题表述如下：
- en: '![The nonseparable case – the soft margin](img/image01480.jpeg)'
  id: totrans-3470
  prefs: []
  type: TYPE_IMG
  zh: '![不可分情况 – 软间隔](img/image01480.jpeg)'
- en: The *C* penalty factor is the inverse of the L2 regularization factor. The loss
    function *L* is known as the **hinge loss**. The formulation of the margin using
    the *C* penalty (or cost) parameter is known as the **C-SVM** formulation. C-SVM
    is sometimes called the **C-Epsilon SVM** formulation for the nonseparable case.
  id: totrans-3471
  prefs: []
  type: TYPE_NORMAL
  zh: '*C*惩罚因子是L2正则化因子的倒数。损失函数*L*被称为**铰链损失**。使用*C*惩罚（或成本）参数的间隔表述称为**C-SVM**表述。C-SVM有时被称为非可分情况的**C-εSVM**表述。'
- en: The **υ-SVM** (or Nu-SVM) is an alternative formulation to C-SVM. The formulation
    is more descriptive than C-SVM; *υ* represents the upper bound of the training
    observations that are poorly classified and the lower bound of the observations
    on the support vectors [8:7].
  id: totrans-3472
  prefs: []
  type: TYPE_NORMAL
  zh: '**υ-SVM**（或Nu-SVM）是C-SVM的另一种表述。该表述比C-SVM更具描述性；*υ*代表训练观测值被错误分类的上限和位于支持向量上的观测值的下限[8:7]。'
- en: Note
  id: totrans-3473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: 'M5: The **ν-SVM** formulation of a linear SVM using the L2 regularization is
    defined as:'
  id: totrans-3474
  prefs: []
  type: TYPE_NORMAL
  zh: M5：使用L2正则化的线性SVM的**ν-SVM**表述定义为：
- en: '![The nonseparable case – the soft margin](img/image01481.jpeg)'
  id: totrans-3475
  prefs: []
  type: TYPE_IMG
  zh: '![不可分情况 – 软间隔](img/image01481.jpeg)'
- en: Here, *ρ* is a margin factor used as an optimization variable.
  id: totrans-3476
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*ρ*是一个作为优化变量的边缘因子。
- en: The C-SVM formulation is used throughout the chapters for the binary, one class
    support vector classifier as well as the support vector regression.
  id: totrans-3477
  prefs: []
  type: TYPE_NORMAL
  zh: C-SVM表述在章节中用于二元、单类支持向量分类器以及支持向量回归。
- en: Note
  id: totrans-3478
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Sequential Minimal Optimization**'
  id: totrans-3479
  prefs: []
  type: TYPE_NORMAL
  zh: '**顺序最小优化**'
- en: The optimization problem consists of the minimization of a quadratic objective
    function (*w²*) subject to *N* linear constraints, *N* being the number of observations.
    The time complexity of the algorithm is *O(N³* *)*. A more efficient algorithm
    known as **Sequential Minimal Optimization** (**SMO**) has been introduced to
    reduce the time complexity to *O(N²)*.
  id: totrans-3480
  prefs: []
  type: TYPE_NORMAL
  zh: 优化问题包括在 *N* 个线性约束下最小化二次目标函数 (*w²*)，其中 *N* 是观测数。算法的时间复杂度是 *O(N³)*。为了将时间复杂度降低到
    *O(N²)*，已经引入了一种更有效的算法，称为 **顺序最小优化**（**SMO**）。
- en: The nonlinear SVM
  id: totrans-3481
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非线性SVM
- en: So far, we assumed that the separating hyperplane and therefore the support
    vectors are linear functions. Unfortunately, such assumptions are not always correct
    in the real world.
  id: totrans-3482
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们假设分离超平面以及支持向量是线性函数。不幸的是，在现实世界中，这样的假设并不总是正确的。
- en: Max-margin classification
  id: totrans-3483
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大间隔分类
- en: Support vector machines are known as large or **maximum margin classifiers**.
    The objective is to maximize the margin between the support vectors with hard
    constraints for separable (similarly, soft constraints with slack variables for
    nonseparable) cases.
  id: totrans-3484
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机被称为大或 **最大间隔分类器**。目标是最大化支持向量之间的间隔，对于可分情况使用硬约束（类似地，对于不可分情况使用软约束和松弛变量）。
- en: The model parameters *{w[i]}* are rescaled during optimization to guarantee
    that the margin is at least 1\. Such algorithms are known as maximum (or large)
    margin classifiers.
  id: totrans-3485
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数 *{w[i]}* 在优化过程中进行缩放，以确保间隔至少为1。这类算法被称为最大（或大）间隔分类器。
- en: 'The problem of fitting a nonlinear model into the labeled observations using
    support vectors is not an easy task. A better alternative consists of mapping
    the problem to a new and higher dimensional space using a nonlinear transformation.
    The nonlinear separating hyperplane becomes a linear plane in the new space, as
    illustrated in the following diagram:'
  id: totrans-3486
  prefs: []
  type: TYPE_NORMAL
  zh: 使用支持向量将非线性模型拟合到标记观测值的问题并不容易。一个更好的替代方案是将问题映射到一个新的更高维空间，使用非线性变换。非线性分离超平面在新空间中成为线性平面，如下图所示：
- en: '![Max-margin classification](img/image01482.jpeg)'
  id: totrans-3487
  prefs: []
  type: TYPE_IMG
  zh: '![最大间隔分类](img/image01482.jpeg)'
- en: An illustration of the kernel trick in the SVM
  id: totrans-3488
  prefs: []
  type: TYPE_NORMAL
  zh: SVM中核技巧的示意图
- en: 'The nonlinear SVM is implemented using a basis function *ϕ* *(x)*. The formulation
    of the nonlinear C-SVM is very similar to the linear case. The only difference
    is the constraint along with the support vector, using the basis function *φ*
    (**M6**):'
  id: totrans-3489
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性SVM是通过基函数 *ϕ(x)* 实现的。非线性C-SVM的公式与线性情况非常相似。唯一的区别是约束条件和支持向量，使用基函数 *φ* （**M6**）：
- en: '![Max-margin classification](img/image01483.jpeg)'
  id: totrans-3490
  prefs: []
  type: TYPE_IMG
  zh: '![最大间隔分类](img/image01483.jpeg)'
- en: The minimization of *w^T.ϕ(x)* in the preceding equation requires the computation
    of the inner product *ϕ(x)^T.ϕ(x)*. The inner product of the basis functions is
    implemented using one of the kernel functions introduced in the first section.
    The optimization of the preceding convex problem computes the optimal hyperplane
    *w** as the kernelized linear combination of the training samples *y.* *ϕ* *(x)*
    and **Lagrange** multipliers. This formulation of the optimization problem is
    known as the **SVM dual problem**. The description of the dual problem is mentioned
    as a reference and is well beyond the scope of this book [8:8].
  id: totrans-3491
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个方程中，最小化 *w^T.ϕ(x)* 需要计算内积 *ϕ(x)^T.ϕ(x)*。基函数的内积是通过在第一节中介绍的一种核函数实现的。前一个凸问题的优化计算了最优超平面
    *w*，它是训练样本 *y* 的核化线性组合，以及 **拉格朗日**乘子。这个优化问题的表述被称为 **SVM对偶问题**。对偶问题的描述作为参考提及，并且超出了本书的范围
    [8:8]。
- en: Note
  id: totrans-3492
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M7: The optimal hyperplane for the SVM dual problem is defined as:'
  id: totrans-3493
  prefs: []
  type: TYPE_NORMAL
  zh: M7：SVM对偶问题的最优超平面定义为：
- en: '![Max-margin classification](img/image01484.jpeg)'
  id: totrans-3494
  prefs: []
  type: TYPE_IMG
  zh: '![最大间隔分类](img/image01484.jpeg)'
- en: 'M8: The hard margin formulation for the SVM dual problem is defined as:'
  id: totrans-3495
  prefs: []
  type: TYPE_NORMAL
  zh: M8：SVM对偶问题的硬间隔公式定义为：
- en: '![Max-margin classification](img/image01485.jpeg)'
  id: totrans-3496
  prefs: []
  type: TYPE_IMG
  zh: '![最大间隔分类](img/image01485.jpeg)'
- en: The kernel trick
  id: totrans-3497
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核技巧
- en: The transformation *(x,x') => K(x,x')* maps a nonlinear problem into a linear
    problem in a higher dimensional space. It is known as the **kernel trick**.
  id: totrans-3498
  prefs: []
  type: TYPE_NORMAL
  zh: 变换 *(x,x') => K(x,x')* 将非线性问题映射到更高维空间中的线性问题。它被称为 **核技巧**。
- en: 'Let''s consider, for example, the polynomial kernel defined in the first section
    with a degree *d = 2* and coefficient of *C0 = 1* in a two-dimension space. The
    polynomial kernel function of two vectors, *x = [x[1], x[2]]* and *z = [x''[1],
    x''[2]]*, is decomposed into a linear function in a 6 dimension space:'
  id: totrans-3499
  prefs: []
  type: TYPE_NORMAL
- en: '![The kernel trick](img/image01486.jpeg)'
  id: totrans-3500
  prefs: []
  type: TYPE_IMG
- en: Support vector classifiers – SVC
  id: totrans-3501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Support vector machines can be applied to classification, anomalies detection,
    and regression problems. Let's first dive into the support vector classifiers.
  id: totrans-3502
  prefs: []
  type: TYPE_NORMAL
- en: The binary SVC
  id: totrans-3503
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first classifier to be evaluated is the binary (2-class) support vector
    classifier. The implementation uses the LIBSVM library created by Chih-Chung Chang
    and Chih-Jen Lin from the National Taiwan University [8:9].
  id: totrans-3504
  prefs: []
  type: TYPE_NORMAL
- en: LIBSVM
  id: totrans-3505
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The library was originally written in C before being ported to Java. It can
    be downloaded from [http://www.csie.ntu.edu.tw/~cjlin/libsvm](http://www.csie.ntu.edu.tw/~cjlin/libsvm)
    as a `.zip` or `tar.gzip` file. The library includes the following classifier
    modes:'
  id: totrans-3506
  prefs: []
  type: TYPE_NORMAL
- en: Support vector classifiers (C-SVC, υ-SVC, and one-class SVC)
  id: totrans-3507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support vector regression (υ-SVR and ε-SVR)
  id: totrans-3508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RBF, linear, sigmoid, polynomial, and precomputed kernels
  id: totrans-3509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIBSVM has the distinct advantage of using **Sequential Minimal Optimization**
    (**SMO**), which reduces the time complexity of a training of *n* observations
    to *O(n ²)*. The LIBSVM documentation covers both the theory and implementation
    of hard and soft margins and is available at [http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf](http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf).
  id: totrans-3510
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-3511
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Why LIBSVM?**'
  id: totrans-3512
  prefs: []
  type: TYPE_NORMAL
- en: There are alternatives to the LIBSVM library for learning and experimenting
    with SVM. David Soergel from the University of Berkeley refactored and optimized
    the Java version [8:10]. Thorsten Joachims' **SVMLight** [8:11] Spark/MLlib 1.0
    includes two Scala implementations of the SVM using resilient distributed datasets
    (refer to the *Apache Spark* section in [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*). However, LIBSVM is
    the most commonly used SVM library.
  id: totrans-3513
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the different support vector classifiers and the support
    vector regression in LIBSVM is broken down into the following five Java classes:'
  id: totrans-3514
  prefs: []
  type: TYPE_NORMAL
- en: '`svm_model`: This defines the parameters of the model created during training'
  id: totrans-3515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`svm_node`: This models the element of the sparse matrix *Q*, which is used
    in the maximization of the margins'
  id: totrans-3516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`svm_parameters`: This contains the different models for support vector classifiers
    and regressions, the five kernels supported in LIBSVM with their parameters, and
    the `weights` vectors used in cross-validation'
  id: totrans-3517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`svm_problem`: This configures the input to any of the SVM algorithm (the number
    of observations, input vector data *x* as a matrix, and the vector of labels *y*)'
  id: totrans-3518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`svm`: This implements algorithms used in training, classification, and regression'
  id: totrans-3519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The library also includes template programs for training, prediction, and normalization
    of datasets.
  id: totrans-3520
  prefs: []
  type: TYPE_NORMAL
  zh: 该库还包括用于训练、预测和归一化数据集的模板程序。
- en: Note
  id: totrans-3521
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The LIBSVM Java code**'
  id: totrans-3522
  prefs: []
  type: TYPE_NORMAL
  zh: '**LIBSVM Java 代码**'
- en: The Java version of LIBSVM is a direct port of the original C code. It does
    not support generic types and is not easily configurable (the code uses switch
    statements instead of polymorphism). For all its limitations, LIBSVM is a fairly
    well-tested and robust Java library for SVMs.
  id: totrans-3523
  prefs: []
  type: TYPE_NORMAL
  zh: LIBSVM 的 Java 版本是原始 C 代码的直接移植。它不支持泛型类型，并且不易配置（代码使用 switch 语句而不是多态）。尽管有其局限性，但
    LIBSVM 是一个相当经过测试且健壮的 SVM Java 库。
- en: Let's create a Scala wrapper to the LIBSVM library to improve its flexibility
    and ease of use.
  id: totrans-3524
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个 Scala 包装器来提高 LIBSVM 库的灵活性和易用性。
- en: Design
  id: totrans-3525
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计
- en: The implementation of the support vector machine algorithm uses the design template
    for classifiers (refer to the *Design template for classifier* section in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*).
  id: totrans-3526
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机算法的实现使用了分类器的设计模板（参见 [附录 A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念") 中的 *设计模板
    for classifier* 部分，*基本概念*）。
- en: 'The key components of the implementation of a SVM are as follows:'
  id: totrans-3527
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 实现的关键组件如下：
- en: A model, `SVMModel`, of the `Model` type is initialized through training during
    the instantiation of the classifier. The model class is an adapter to the `svm_model`
    structure defined in LIBSVM.
  id: totrans-3528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分类器实例化过程中通过训练初始化 `SVMModel` 类型的模型。该模型类是 LIBSVM 中定义的 `svm_model` 结构的适配器。
- en: An `SVMAdapter` object interfaces with the internal LIBSVM data structures and
    methods.
  id: totrans-3529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVMAdapter` 对象与内部 LIBSVM 数据结构和方法进行接口。'
- en: 'The `SVM` support vector machine class is implemented as an implicit data transformation
    of the `ITransform` type. It has three parameters: the configuration wrapper of
    the `SVMConfig` type, the features/time series of the `XVSeries` type, and the
    target or labeled values, `DblVector`.'
  id: totrans-3530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVM` 支持向量机类被实现为 `ITransform` 类型的隐式数据转换。它有三个参数：`SVMConfig` 类型的配置包装器、`XVSeries`
    类型的特征/时间序列以及目标或标记值，`DblVector`。'
- en: 'The configuration (the `SVMConfig` type) consists of three distinct elements:
    `SVMExecution` that defines the execution parameters such as the maximum number
    of iterations or convergence criteria, `SVMKernel` that specifies the kernel function
    used during training, and `SVMFormulation` that defines the formula (*C*, *epsilon*,
    or *nu*) used to compute a nonseparable case for the support vector classifier
    and regression.'
  id: totrans-3531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置（`SVMConfig` 类型）由三个不同的元素组成：`SVMExecution` 定义执行参数，例如最大迭代次数或收敛标准，`SVMKernel`
    指定训练过程中使用的核函数，以及 `SVMFormulation` 定义用于计算支持向量分类器和回归的非可分情况的公式（*C*，*epsilon* 或 *nu*）。
- en: 'The key software components of the support vector machine are described in
    the following UML class diagram:'
  id: totrans-3532
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的主要软件组件在以下 UML 类图中描述：
- en: '![Design](img/image01487.jpeg)'
  id: totrans-3533
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01487.jpeg)'
- en: The UML class diagram for the support vector machine
  id: totrans-3534
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的 UML 类图
- en: The UML diagram omits the helper traits and classes such as `Monitor` or the
    Apache Commons Math components.
  id: totrans-3535
  prefs: []
  type: TYPE_NORMAL
  zh: UML 图省略了 `Monitor` 或 Apache Commons Math 组件等辅助特性和类。
- en: Configuration parameters
  id: totrans-3536
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置参数
- en: 'LIBSVM exposes a large number of parameters for the configuration and execution
    of any of the SVM algorithms. Any SVM algorithm is configured with three categories
    of parameters, which are as follows:'
  id: totrans-3537
  prefs: []
  type: TYPE_NORMAL
  zh: LIBSVM 为配置和执行任何 SVM 算法公开了大量参数。任何 SVM 算法都配置了三类参数，如下所示：
- en: Formulation (or type) of the SVM algorithms (the multiclass classifier, one-class
    classifier, regression, and so on) using the `SVMFormulation` class
  id: totrans-3538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `SVMFormulation` 类的 SVM 算法（多类分类器、单类分类器、回归等）的公式（或类型）
- en: The kernel function used in the algorithm (the RBF kernel, Sigmoid kernel, and
    so on) using the `SVMKernel` class
  id: totrans-3539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法中使用的核函数（RBF 核、Sigmoid 核等）使用 `SVMKernel` 类
- en: Training and executing parameters (the convergence criteria, number of folds
    for cross-validation, and so on) using the `SVMExecution` class
  id: totrans-3540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `SVMExecution` 类的训练和执行参数（收敛标准、交叉验证的折叠数等）
- en: The SVM formulation
  id: totrans-3541
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SVM 公式
- en: The instantiation of the configuration consists of initializing the `param`
    LIBSVM parameter by the SVM type, kernel, and the execution context selected by
    the user.
  id: totrans-3542
  prefs: []
  type: TYPE_NORMAL
  zh: 配置的实例化包括通过用户选择的 SVM 类型、核函数和执行上下文初始化 `param` LIBSVM 参数。
- en: 'Each of the SVM parameters'' case class extends the generic `SVMConfigItem`
    trait:'
  id: totrans-3543
  prefs: []
  type: TYPE_NORMAL
  zh: 每个SVM参数的案例类都扩展了通用 `SVMConfigItem` 特性：
- en: '[PRE274]'
  id: totrans-3544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE274]'
- en: The classes inherited from `SVMConfigItem` are responsible for updating the
    list of the SVM parameters, `svm_parameter`, defined in LIBSVM. The `update` method
    encapsulates the configuration of LIBSVM.
  id: totrans-3545
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `SVMConfigItem` 继承的类负责更新LIBSVM中定义的SVM参数列表 `svm_parameter`。`update` 方法封装了LIBSVM的配置。
- en: 'The formulation of the SVM algorithm by a class hierarchy with `SVMFormulation`
    as the base trait is as follows:'
  id: totrans-3546
  prefs: []
  type: TYPE_NORMAL
  zh: 以 `SVMFormulation` 作为基特性，通过类层次结构对SVM算法进行公式的定义如下：
- en: '[PRE275]'
  id: totrans-3547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE275]'
- en: 'The list of the formulation for the SVM (`C`, `nu`, and `eps` for regression)
    is completely defined and known. Therefore, the hierarchy should not be altered
    and the `SVMFormulation` trait has to be declared sealed. Here is an example of
    the SVM `CSVCFormulation` formulation class, which defines the C-SVM model:'
  id: totrans-3548
  prefs: []
  type: TYPE_NORMAL
  zh: SVM公式的列表（对于回归，`C`、`nu` 和 `eps`）完全定义且已知。因此，层次结构不应更改，并且必须声明 `SVMFormulation` 特性为密封的。以下是一个SVM
    `CSVCFormulation` 公式类的示例，它定义了C-SVM模型：
- en: '[PRE276]'
  id: totrans-3549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE276]'
- en: The other SVM `NuSVCFormulation`, `OneSVCFormulation`, and `SVRFormulation`
    formulation classes implement the υ-SVM, 1-SVM, and ε-SVM, respectively for regression
    models.
  id: totrans-3550
  prefs: []
  type: TYPE_NORMAL
  zh: 其他SVM `NuSVCFormulation`、`OneSVCFormulation` 和 `SVRFormulation` 公式类分别实现了υ-SVM、1-SVM和ε-SVM，用于回归模型。
- en: The SVM kernel function
  id: totrans-3551
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SVM核函数
- en: 'Next, you need to specify the kernel functions by defining and implementing
    the `SVMKernel` trait:'
  id: totrans-3552
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要通过定义和实现 `SVMKernel` 特性来指定核函数：
- en: '[PRE277]'
  id: totrans-3553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE277]'
- en: 'Once again, there are a limited number of kernel functions supported in LIBSVM.
    Therefore, the hierarchy of kernel functions is sealed. The following code snippet
    configures the radius basis function kernel, `RbfKernel`, as an example of the
    definition of the kernel definition class:'
  id: totrans-3554
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，LIBSVM 支持的核函数数量有限。因此，核函数的层次结构是封闭的。以下代码片段以配置半径基函数核 `RbfKernel` 为例，展示了核定义类的定义：
- en: '[PRE278]'
  id: totrans-3555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE278]'
- en: 'The fact that the LIBSVM Java byte code library is not very extensible does
    not prevent you from defining a new kernel function in the LIBSVM source code.
    For example, the Laplacian kernel can be added by performing the following steps:'
  id: totrans-3556
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LIBSVM Java字节码库的可扩展性不高，但这并不妨碍您在LIBSVM源代码中定义一个新的核函数。例如，可以通过以下步骤添加拉普拉斯核：执行以下步骤：
- en: Create a new kernel type in `svm_parameter`, such as `svm_parameter. LAPLACE
    = 5`.
  id: totrans-3557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `svm_parameter` 中创建一个新的核类型，例如 `svm_parameter.LAPLACE = 5`。
- en: Add the kernel function name to `kernel_type_table` in the `svm` class.
  id: totrans-3558
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `svm` 类中将核函数名称添加到 `kernel_type_table` 中。
- en: Add `kernel_type != svm_parameter.LAPLACE` to the `svm_check_` parameter method.
  id: totrans-3559
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `svm_check_` 参数方法中添加 `kernel_type != svm_parameter.LAPLACE`。
- en: 'Add the implementation of the kernel function to two values in `svm`: `kernel_function`
    (Java code):'
  id: totrans-3560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `svm` 中添加核函数的实现到两个值：`kernel_function`（Java代码）：
- en: '[PRE279]'
  id: totrans-3561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE279]'
- en: Add the implementation of the Laplace kernel function in the `svm.k_function`
    method by modifying the existing implementation of RBF (`distanceSqr`).
  id: totrans-3562
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过修改现有的RBF (`distanceSqr`) 实现添加拉普拉斯核函数到 `svm.k_function` 方法中。
- en: Rebuild the `libsvm.jar` file
  id: totrans-3563
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新构建 `libsvm.jar` 文件
- en: The SVM execution
  id: totrans-3564
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SVM执行
- en: 'The `SVMExecution` class defines the configuration parameters for the execution
    of the training of the model, namely the `eps` convergence factor for the optimizer
    (line `2`), the size of the cache, `cacheSize` (line `1`), and the number of folds,
    `nFolds`, used during cross-validation:'
  id: totrans-3565
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMExecution` 类定义了模型训练执行的配置参数，即优化器的 `eps` 收敛因子（第 `2` 行），缓存大小 `cacheSize`（第
    `1` 行），以及在交叉验证期间使用的折数 `nFolds`：'
- en: '[PRE280]'
  id: totrans-3566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE280]'
- en: The cross-validation is performed only if the `nFolds` value is greater than
    1.
  id: totrans-3567
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当 `nFolds` 值大于1时，才会执行交叉验证。
- en: 'We are finally ready to create the `SVMConfig` configuration class, which hides
    and manages all of the different configuration parameters:'
  id: totrans-3568
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终准备好创建 `SVMConfig` 配置类，该类隐藏和管理所有不同的配置参数：
- en: '[PRE281]'
  id: totrans-3569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE281]'
- en: The `SVMConfig` class delegates the selection of the formula to the `SVMFormulation`
    class (line `3`), selection of the kernel function to the `SVMKernel` class (line
    `4`), and the execution of parameters to the `SVMExecution` class (line `5`).
    The sequence of update calls initializes the LIBSVM list of configuration parameters.
  id: totrans-3570
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMConfig` 类将公式的选择委托给 `SVMFormulation` 类（第 `3` 行），核函数的选择委托给 `SVMKernel` 类（第
    `4` 行），参数的执行委托给 `SVMExecution` 类（第 `5` 行）。更新调用序列初始化了LIBSVM配置参数列表。'
- en: Interface to LIBSVM
  id: totrans-3571
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LIBSVM接口
- en: 'We need to create an adapter object to encapsulate the invocation to LIBSVM.
    The `SVMAdapter` object hides the LIBSVM internal data structures: `svm_model`
    and `svm_node`:'
  id: totrans-3572
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个适配器对象来封装对LIBSVM的调用。`SVMAdapter`对象隐藏了LIBSVM内部数据结构：`svm_model`和`svm_node`：
- en: '[PRE282]'
  id: totrans-3573
  prefs: []
  type: TYPE_PRE
  zh: '[PRE282]'
- en: 'The `SVMAdapter` object is a single entry point to LIBSVM for training, validating
    a SVM model, and executing predictions:'
  id: totrans-3574
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMAdapter`对象是训练、验证SVM模型和执行预测到LIBSVM的单个入口点：'
- en: '`SVMProblem` wraps the definition of the training objective or problem in LIBSVM,
    using the labels or `expected` values (line `6`)'
  id: totrans-3575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SVMProblem`将LIBSVM中训练目标或问题的定义包装起来，使用标签或`expected`值（行`6`）'
- en: '`createSVMNode` creates a new computation node for each observation `x` (line
    `7`)'
  id: totrans-3576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`createSVMNode`为每个观察值`x`创建一个新的计算节点（行`7`）'
- en: '`predictSVM` predicts the outcome of a new observation `x` given a model, `svm_model`,
    generated through training (line `8`)'
  id: totrans-3577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictSVM`根据通过训练生成的模型`svm_model`预测新观察值`x`的结果（行`8`）'
- en: '`crossValidateSVM` validates the model, `svm_model`, with the `nFold` training—validation
    sets (line `9`)'
  id: totrans-3578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crossValidateSVM`使用`nFold`训练-验证集验证模型`svm_model`（行`9`）'
- en: '`trainSVM` executes the `problem` training configuration (line `10`)'
  id: totrans-3579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainSVM`执行`problem`训练配置（行`10`）'
- en: Note
  id: totrans-3580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**svm_node**'
  id: totrans-3581
  prefs: []
  type: TYPE_NORMAL
  zh: '**svm_node**'
- en: 'The LIBSVM `svm_node` Java class is defined as a pair of indices of the feature
    in the observation array and its value:'
  id: totrans-3582
  prefs: []
  type: TYPE_NORMAL
  zh: LIBSVM的`svm_node`Java类被定义为观察数组中特征的索引及其值的对：
- en: '[PRE283]'
  id: totrans-3583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE283]'
- en: The `SVMAdapter` methods are described in the next section.
  id: totrans-3584
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMAdapter`方法将在下一节中描述。'
- en: Training
  id: totrans-3585
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: 'The model for the SVM is defined by the following two components:'
  id: totrans-3586
  prefs: []
  type: TYPE_NORMAL
  zh: SVM模型由以下两个组件定义：
- en: '`svm_model`: This is the SVM model parameters defined in LIBSVM'
  id: totrans-3587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm_model`：这是在LIBSVM中定义的SVM模型参数'
- en: '`accuracy`: This is the accuracy of the model computed during cross-validation'
  id: totrans-3588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accuracy`：这是在交叉验证期间计算的模型准确率'
- en: 'The code will be as follows:'
  id: totrans-3589
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE284]'
  id: totrans-3590
  prefs: []
  type: TYPE_PRE
  zh: '[PRE284]'
- en: The `residuals`, that is, *r = y – f(x)* are computed in the LIBSVM library.
  id: totrans-3591
  prefs: []
  type: TYPE_NORMAL
  zh: '`residuals`，即*r = y – f(x)*，在LIBSVM库中计算。'
- en: Note
  id: totrans-3592
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Accuracy in the SVM model**'
  id: totrans-3593
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVM模型中的准确率**'
- en: You may wonder why the value of the accuracy is a component of the model. The
    accuracy component of the model provides the client code with a quality metric
    associated with the model. Integrating the accuracy into the model, allows the
    user to make informed decisions in accepting or rejecting the model. The accuracy
    is stored in the model file for subsequent analysis.
  id: totrans-3594
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么准确率的值是模型的一个组件。模型的准确率组件为客户端代码提供了一个与模型相关的质量指标。将准确率集成到模型中，使用户能够在接受或拒绝模型时做出明智的决定。准确率存储在模型文件中，以供后续分析。
- en: Next, let's create the first support vector classifier for the two-class problems.
    The SVM class implements the `ITransform` monadic data transformation that implicitly
    generates a model from a training set, as described in the *Monadic data transformation*
    section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello
    World!* (line `11`).
  id: totrans-3595
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们为双分类问题创建第一个支持向量机分类器。SVM类实现了`ITransform`单调数据转换，该转换隐式地从训练集中生成一个模型，正如在[第2章](part0165.xhtml#aid-4TBCQ2
    "第2章。Hello World!")中“单调数据转换”部分所描述的，*Hello World!*（行`11`）。
- en: 'The constructor for the SVM follows the template described in the *Design template
    for immutable classifiers* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*:'
  id: totrans-3596
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的构造函数遵循[附录A](part0229.xhtml#aid-6QCGQ2 "附录A。基本概念")中“不可变分类器设计模板”部分所描述的模板，*基本概念*：
- en: '[PRE285]'
  id: totrans-3597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE285]'
- en: The implementation of the `ITransform` abstract class requires the definition
    of the output value of the predictor as a `Double` (line `12`). The `normEPS`
    is used for rounding errors in the computation of the margin (line `13`). The
    model of the `SVMModel` type is generated through training by the `SVM` constructor
    (line `14`). The last four methods are used to compute the parameters of the `accuracy`
    model (line `15`), the mean square of errors, `mse`, (line `16`), and the `margin`
    (line `17`).
  id: totrans-3598
  prefs: []
  type: TYPE_NORMAL
  zh: '`ITransform`抽象类的实现需要将预测器的输出值定义为`Double`（行`12`）。`normEPS`用于计算边界的舍入误差（行`13`）。`SVMModel`类型的模型通过`SVM`构造函数通过训练生成（行`14`）。最后四个方法用于计算`accuracy`模型的参数（行`15`）、均方误差`mse`（行`16`）和`margin`（行`17`）。'
- en: 'Let''s take a look at the training method, `train`:'
  id: totrans-3599
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看训练方法，`train`：
- en: '[PRE286]'
  id: totrans-3600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE286]'
- en: 'The `train` method creates `SVMProblem` that provides LIBSVM with the training
    components (line `18`). The purpose of the `SVMProblem` class is to manage the
    definition of training parameters implemented in LIBSVM, as follows:'
  id: totrans-3601
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法创建`SVMProblem`，为LIBSVM提供训练组件（第`18`行）。`SVMProblem`类的作用是管理LIBSVM中实现的训练参数的定义，如下所示：'
- en: '[PRE287]'
  id: totrans-3602
  prefs: []
  type: TYPE_PRE
  zh: '[PRE287]'
- en: The arguments of the `SVMProblem` constructor, the number of observations, and
    the labels or expected values are used to initialize the corresponding `svm_problem`
    data structure in LIBSVM (line `21`). The `update` method maps each observation,
    which is defined as an array of `svm_node` to the problem (line `22`).
  id: totrans-3603
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVMProblem`构造函数的参数、观察数和标签或期望值用于在LIBSVM中初始化相应的`svm_problem`数据结构（第`21`行）。`update`方法将每个观察值（定义为`svm_node`数组）映射到问题（第`22`行）。'
- en: 'The `createSVMNode` method creates an array of `svm_node` from an observation.
    A `svm_node` in LIBSVM is the pair of the `j` index of a feature in an observation
    (line `23`) and its value, `y` (line `24`):'
  id: totrans-3604
  prefs: []
  type: TYPE_NORMAL
  zh: '`createSVMNode`方法从一个观察值创建一个`svm_node`数组。在LIBSVM中，`svm_node`是一个观察值中特征`j`的索引（第`23`行）及其值，`y`（第`24`行）的配对：'
- en: '[PRE288]'
  id: totrans-3605
  prefs: []
  type: TYPE_PRE
  zh: '[PRE288]'
- en: 'The mapping between an observation and a LIBSVM node is illustrated in the
    following diagram:'
  id: totrans-3606
  prefs: []
  type: TYPE_NORMAL
  zh: 观察与LIBSVM节点之间的映射在以下图中说明：
- en: '![Training](img/image01488.jpeg)'
  id: totrans-3607
  prefs: []
  type: TYPE_IMG
  zh: '![训练](img/image01488.jpeg)'
- en: Indexing of observations using LIBSVM
  id: totrans-3608
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LIBSVM对观察值进行索引
- en: 'The `trainSVM` method pushes the training request with a well-defined problem
    and configuration parameters to LIBSVM by invoking the `svm_train` method (line
    `26`):'
  id: totrans-3609
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainSVM`方法通过调用`svm_train`方法，将具有明确定义的问题和配置参数的训练请求推送到LIBSVM（第`26`行）：'
- en: '[PRE289]'
  id: totrans-3610
  prefs: []
  type: TYPE_PRE
  zh: '[PRE289]'
- en: 'The accuracy is the ratio of the true positive plus the true negative over
    the size of the test sample (refer to the *Key quality metrics* section in [Chapter
    2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*). It is
    computed through cross-validation only if the number of folds initialized in the
    `SVMExecution` configuration class is greater than 1\. Practically, the accuracy
    is computed by invoking the cross-validation method, `svm_cross_validation`, in
    the LIBSVM package, and then computing the ratio of the number of predicted values
    that match the labels over the total number of observations:'
  id: totrans-3611
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是真实正例加上真实负例与测试样本大小的比率（参考[第2章](part0165.xhtml#aid-4TBCQ2 "第2章。Hello World!")中的*关键质量指标*部分，*Hello
    World!*）。只有在`SVMExecution`配置类中初始化的折数大于1时，才会通过交叉验证来计算。实际上，准确率是通过调用LIBSVM包中的交叉验证方法`svm_cross_validation`来计算的，然后计算预测值与标签匹配的数量与观察总数之比：
- en: '[PRE290]'
  id: totrans-3612
  prefs: []
  type: TYPE_PRE
  zh: '[PRE290]'
- en: 'The call to the `crossValidateSVM` method of `SVMAdapter` forwards the configuration
    and execution of the cross validation with `config.nFolds` (line `27`):'
  id: totrans-3613
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`SVMAdapter`的`crossValidateSVM`方法将配置和执行交叉验证的`config.nFolds`（第`27`行）：
- en: '[PRE291]'
  id: totrans-3614
  prefs: []
  type: TYPE_PRE
  zh: '[PRE291]'
- en: The Scala `filter` weeds out the observations that were poorly predicted (line
    `28`). This minimalist implementation is good enough to start exploring the support
    vector classifier.
  id: totrans-3615
  prefs: []
  type: TYPE_NORMAL
  zh: Scala的`filter`过滤掉预测不良的观察值（第`28`行）。这种最小化实现足以开始探索支持向量分类器。
- en: Classification
  id: totrans-3616
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: 'The implementation of the `|>` classification method for the `SVM` class follows
    the same pattern as the other classifiers. It invokes the `predictSVM` method
    in `SVMAdapter` that forwards the request to LIBSVM (line `29`):'
  id: totrans-3617
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVM`类的`|>`分类方法实现遵循与其他分类器相同的模式。它调用`SVMAdapter`中的`predictSVM`方法，将请求转发给LIBSVM（第`29`行）：'
- en: '[PRE292]'
  id: totrans-3618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE292]'
- en: C-penalty and margin
  id: totrans-3619
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C惩罚和边缘
- en: The first evaluation consists of understanding the impact of the penalty factor
    *C* on the margin in the generation of the classes. Let's implement the computation
    of the margin. The margin is defined as *2/|w|* and implemented as a method of
    the `SVM` class, as follows:-
  id: totrans-3620
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次评估包括理解惩罚因子*C*对生成类边缘的影响。让我们实现边缘的计算。边缘定义为*2/|w|*，并在`SVM`类中实现为一个方法，如下所示：-
- en: '[PRE293]'
  id: totrans-3621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE293]'
- en: The first instruction computes the sum of the squares, `wNorm`, of the residuals
    *r = y – f(x|w)*. The margin is ultimately computed if the sum of squares is significant
    enough to avoid rounding errors.
  id: totrans-3622
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条指令计算残差*r = y – f(x|w)*的平方和，`wNorm`。如果平方和足够大以避免舍入误差，则最终计算边缘。
- en: 'The margin is evaluated using an artificially generated time series and labeled
    data. First, we define the method to evaluate the margin for a specific value
    of the penalty (inversed regularization coefficient) factor *C*:'
  id: totrans-3623
  prefs: []
  type: TYPE_NORMAL
  zh: 使用人工生成的时间序列和标记数据评估边缘。首先，我们定义评估特定惩罚（逆正则化系数）因子*C*的边缘的方法：
- en: '[PRE294]'
  id: totrans-3624
  prefs: []
  type: TYPE_PRE
  zh: '[PRE294]'
- en: 'The `evalMargin` method uses the `CACHE_SIZE`, `EPS`, and `NFOLDS` execution
    parameters. The execution displays the value of the margin for different values
    of *C* (line `30`). The method is invoked iteratively to evaluate the impact of
    the penalty factor on the margin extracted from the training of the model. The
    test uses a synthetic time series to highlight the relation between *C* and the
    margin. The synthetic time series created by the `generate` method consists of
    two training sets of an equal size, *N*:'
  id: totrans-3625
  prefs: []
  type: TYPE_NORMAL
  zh: '`evalMargin` 方法使用 `CACHE_SIZE`、`EPS` 和 `NFOLDS` 执行参数。执行显示不同 *C* 值的边缘值（行 `30`）。该方法通过迭代调用以评估惩罚因子对从模型训练中提取的边缘的影响。测试使用合成时间序列来突出
    *C* 与边缘之间的关系。由 `generate` 方法创建的合成时间序列由两个大小相等的训练集 *N* 组成：'
- en: Data points generated as *y = x(1 + r/5)* for the label 1, *r* being a randomly
    generated number over the range [0,1] (line `31`)
  id: totrans-3626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为标签 1 生成的数据点 *y = x(1 + r/5)*，其中 *r* 是在 [0,1] 范围内随机生成的数字（行 `31`）
- en: A randomly generated data point *y = r* for the label -1 (line `32`)
  id: totrans-3627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为标签 -1 随机生成的数据点 *y = r*（行 `32`）
- en: 'Consider the following code:'
  id: totrans-3628
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码：
- en: '[PRE295]'
  id: totrans-3629
  prefs: []
  type: TYPE_PRE
  zh: '[PRE295]'
- en: 'The `evalMargin` method is executed for different values of *C* ranging from
    0 to 5:'
  id: totrans-3630
  prefs: []
  type: TYPE_NORMAL
  zh: 对 *C* 从 0 到 5 的不同值执行 `evalMargin` 方法：
- en: '[PRE296]'
  id: totrans-3631
  prefs: []
  type: TYPE_PRE
  zh: '[PRE296]'
- en: Note
  id: totrans-3632
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**val versus final val**'
  id: totrans-3633
  prefs: []
  type: TYPE_NORMAL
  zh: '**值与最终值**'
- en: 'There is a difference between a val and a final val. A nonfinal value can be
    overridden in a subclass. Overriding a final value produces a compiler error,
    as follows:'
  id: totrans-3634
  prefs: []
  type: TYPE_NORMAL
  zh: 最终值和非最终值之间有区别。非最终值可以在子类中被覆盖。覆盖最终值会产生编译错误，如下所示：
- en: '[PRE297]'
  id: totrans-3635
  prefs: []
  type: TYPE_PRE
  zh: '[PRE297]'
- en: 'The following chart illustrates the relation between the penalty or cost factor
    *C* and the margin:'
  id: totrans-3636
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了惩罚或成本因子 *C* 与边缘之间的关系：
- en: '![C-penalty and margin](img/image01489.jpeg)'
  id: totrans-3637
  prefs: []
  type: TYPE_IMG
  zh: '![C-penalty and margin](img/image01489.jpeg)'
- en: The margin value versus the C-penalty factor for a support vector classifier
  id: totrans-3638
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量分类器的边缘值与 *C* 惩罚因子之间的关系
- en: As expected, the value of the margin decreases as the penalty term *C* increases.
    The *C* penalty factor is related to the L [2] regularization factor *λ* as *C
    ~ 1/λ*. A model with a large value of *C* has a high variance and a low bias,
    while a small value of *C* will produce lower variance and a higher bias.
  id: totrans-3639
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，随着惩罚项 *C* 的增加，边缘值会减小。*C* 惩罚因子与 L [2] 正则化因子 *λ* 相关，关系为 *C ~ 1/λ*。具有较大 *C*
    值的模型具有高方差和低偏差，而较小的 *C* 值将产生较低的方差和较高的偏差。
- en: Note
  id: totrans-3640
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Optimizing C penalty**'
  id: totrans-3641
  prefs: []
  type: TYPE_NORMAL
  zh: '**优化 *C* 惩罚**'
- en: 'The optimal value for *C* is usually evaluated through cross-validation, by
    varying *C* in incremental powers of 2: 2n, 2n+1, … [8:12].'
  id: totrans-3642
  prefs: []
  type: TYPE_NORMAL
  zh: '*C* 的最佳值通常通过交叉验证来评估，通过将 *C* 以 2 的增量幂变化：2n，2n+1，… [8:12]。'
- en: Kernel evaluation
  id: totrans-3643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核函数评估
- en: 'The next test consists of comparing the impact of the kernel function on the
    accuracy of the prediction. Once again, a synthetic time series is generated to
    highlight the contribution of each kernel. The test code uses the runtime prediction
    or classification method, `|>`, to evaluate the different kernel functions. Let''s
    create a method to evaluate and compare these kernel functions. All we need is
    the following (line `33`):'
  id: totrans-3644
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个测试是对比核函数对预测准确性的影响。再次，生成一个合成时间序列来突出每个核的贡献。测试代码使用运行时预测或分类方法 `|>` 来评估不同的核函数。让我们创建一个评估和比较这些核函数的方法。我们需要的只是以下内容（行
    `33`）：
- en: An `xt` training set of the `Vector[DblArray]` type
  id: totrans-3645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Vector[DblArray]` 类型的 `xt` 训练集'
- en: A test set, `test`, of the `Vector[DblArray]` type
  id: totrans-3646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Vector[DblArray]` 类型的测试集 `test`'
- en: A set of `labels` for the training set that takes the value 0 or 1
  id: totrans-3647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集的一组 `labels`，其值为 0 或 1
- en: A `kF` kernel function
  id: totrans-3648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kF` 核函数'
- en: 'Consider the following code:'
  id: totrans-3649
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码：
- en: '[PRE298]'
  id: totrans-3650
  prefs: []
  type: TYPE_PRE
  zh: '[PRE298]'
- en: The `config` configuration of the SVM uses the *C* penalty factor 1, the C-formulation,
    and the default execution environment (line `34`). The predictive `pfnSvc` partial
    function (line `35`) is used to compute the predictive values for the test set.
    Finally, the `evalKernel` method counts the number of successes for which the
    predictive values match the labeled or expected values. The accuracy is computed
    as the ratio of the successful prediction over the size of the test sample (line
    `36`).
  id: totrans-3651
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 的 `config` 配置使用 *C* 惩罚因子 1，C 公式，以及默认执行环境（行 `34`）。预测的 `pfnSvc` 部分函数（行 `35`）用于计算测试集的预测值。最后，`evalKernel`
    方法计算预测值与标记或预期值匹配的成功次数。准确率是成功预测与测试样本大小的比率（行 `36`）。
- en: 'In order to compare the different kernels, let''s generate three datasets of
    the size 2N for a binomial classification using the pseudo-random `genData` data
    generation method:'
  id: totrans-3652
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较不同的核函数，让我们使用伪随机 `genData` 数据生成方法生成三个大小为2N的二项分类数据集：
- en: '[PRE299]'
  id: totrans-3653
  prefs: []
  type: TYPE_PRE
  zh: '[PRE299]'
- en: 'The random value is computed through a transformation *f(x) = variance*x =
    mean* (line `37`). The training and test sets consist of the aggregate of two
    classes of data points:'
  id: totrans-3654
  prefs: []
  type: TYPE_NORMAL
  zh: 随机值通过变换 *f(x) = variance*x = mean* (行 `37`) 来计算。训练集和测试集由两类数据点的总和组成：
- en: Random data points with the variance `a` and mean `b` associated with the label
    0.0
  id: totrans-3655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与标签 0.0 相关的具有方差 `a` 和均值 `b` 的随机数据点
- en: Random data points with the variance `a` and mean `1-b` associated with the
    label 1.0
  id: totrans-3656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与标签 1.0 相关的具有方差 `a` 和均值 `1-b` 的随机数据点
- en: 'Consider the following code for the training set:'
  id: totrans-3657
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码用于训练集：
- en: '[PRE300]'
  id: totrans-3658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE300]'
- en: The `a` and `b` parameters are selected from two groups of training data points
    with various degrees of separation to illustrate the separating hyperplane.
  id: totrans-3659
  prefs: []
  type: TYPE_NORMAL
  zh: '`a` 和 `b` 参数是从具有不同分离程度的两组训练数据点中选择，以说明分离超平面。'
- en: 'The following chart describes the high margin; the first training set generated
    with the parameters *a = 0.6* and *b = 0.3* illustrates the highly separable classes
    with a clean and distinct hyperplane:'
  id: totrans-3660
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了高边缘；使用参数 *a = 0.6* 和 *b = 0.3* 生成的第一个训练集展示了高度可分离的类别，具有干净且明显的超平面：
- en: '![Kernel evaluation](img/image01490.jpeg)'
  id: totrans-3661
  prefs: []
  type: TYPE_IMG
  zh: '![内核评估](img/image01490.jpeg)'
- en: The scatter plot for training and testing sets with a = 0.6 and b = 0.3
  id: totrans-3662
  prefs: []
  type: TYPE_NORMAL
  zh: 当a = 0.6和b = 0.3时的训练集和测试集散点图
- en: 'The following chart describes the medium margin; the parameters *a = 0.8* and
    *b = 0.3* generate two groups of observations with some overlap:'
  id: totrans-3663
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了中等边缘；参数 *a = 0.8* 和 *b = 0.3* 生成两组具有一些重叠的观察值：
- en: '![Kernel evaluation](img/image01491.jpeg)'
  id: totrans-3664
  prefs: []
  type: TYPE_IMG
  zh: '![内核评估](img/image01491.jpeg)'
- en: The scatter plot for training and testing sets with a = 0.8 and b = 0.3
  id: totrans-3665
  prefs: []
  type: TYPE_NORMAL
  zh: 当a = 0.8和b = 0.3时的训练集和测试集散点图
- en: 'The following chart describes the low margin; the two groups of observations
    in this last training set are generated with *a = 1.4* and *b = 0.3* and show
    a significant overlap:'
  id: totrans-3666
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了低边缘；这个最后训练集中的两组观察值是用 *a = 1.4* 和 *b = 0.3* 生成的，并显示出显著的重叠：
- en: '![Kernel evaluation](img/image01492.jpeg)'
  id: totrans-3667
  prefs: []
  type: TYPE_IMG
  zh: '![内核评估](img/image01492.jpeg)'
- en: The scatter plot for training and testing sets with a = 1.4 and b = 0.3
  id: totrans-3668
  prefs: []
  type: TYPE_NORMAL
  zh: 当a = 1.4和b = 0.3时的训练集和测试集散点图
- en: 'The test set is generated in a similar fashion as the training set, as they
    are extracted from the same data source:'
  id: totrans-3669
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集以与训练集类似的方式生成，因为它们是从相同的数据源提取的：
- en: '[PRE301]'
  id: totrans-3670
  prefs: []
  type: TYPE_PRE
  zh: '[PRE301]'
- en: 'The parameters for each of the four kernel functions are arbitrary selected
    from textbooks (line `38`). The `evalKernel` method defined earlier is applied
    to the three training sets: the high margin (*a = 1.4*), medium margin (*a = 0.8*),
    and low margin (*a = 0.6*) with each of the four kernels (RBF, sigmoid, linear,
    and polynomial). The accuracy is assessed by counting the number of observations
    correctly classified for all of the classes for each invocation of the predictor,
    `|>`:'
  id: totrans-3671
  prefs: []
  type: TYPE_NORMAL
  zh: 每个四个核函数的参数都是从教科书中任意选择的（行 `38`）。之前定义的 `evalKernel` 方法应用于三个训练集：高边缘 (*a = 1.4*)、中等边缘
    (*a = 0.8*) 和低边缘 (*a = 0.6*)，每个都使用四个核（RBF、sigmoid、线性和多项式）。通过计算预测器每次调用中对所有类别的正确分类的观察数来评估准确性，`|>`：
- en: '![Kernel evaluation](img/image01493.jpeg)'
  id: totrans-3672
  prefs: []
  type: TYPE_IMG
  zh: '![内核评估](img/image01493.jpeg)'
- en: A comparative chart of kernel functions using synthetic data
  id: totrans-3673
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合成数据的核函数比较图
- en: 'Although the different kernel functions do not differ in terms of the impact
    on the accuracy of the classifier, you can observe that the RBF and polynomial
    kernels produce results that are slightly more accurate. As expected, the accuracy
    decreases as the margin decreases. A decreasing margin indicates that the cases
    are not easily separable, affecting the accuracy of the classifier:'
  id: totrans-3674
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不同的核函数在影响分类器准确性的方面没有差异，但你可以观察到 RBF 和多项式核产生的结果略为准确。正如预期的那样，随着边缘的减小，准确性降低。减小的边缘表示案例不易分离，这会影响分类器的准确性：
- en: '![Kernel evaluation](img/image01494.jpeg)'
  id: totrans-3675
  prefs: []
  type: TYPE_IMG
  zh: '![内核评估](img/image01494.jpeg)'
- en: The impact of the margin value on the accuracy of RBF and Sigmoid kernel functions
  id: totrans-3676
  prefs: []
  type: TYPE_NORMAL
  zh: RBF 和 Sigmoid 核函数的边缘值对准确性的影响
- en: Note
  id: totrans-3677
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**A test case design**'
  id: totrans-3678
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试用例设计**'
- en: The test to compare the different kernel methods is highly dependent on the
    distribution or mixture of data in the training and test sets. The synthetic generation
    of data in this test case is used for illustrating the margin between classes
    of observations. Real-world datasets may produce different results.
  id: totrans-3679
  prefs: []
  type: TYPE_NORMAL
  zh: 比较不同核方法的测试高度依赖于训练集和测试集中数据的分布或混合。在这个测试案例中，使用合成数据来展示观察值类之间的边界。现实世界的数据集可能会产生不同的结果。
- en: 'In summary, there are four steps required to create a SVC-based model:'
  id: totrans-3680
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，创建基于SVC的模型需要四个步骤：
- en: Select a features set.
  id: totrans-3681
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个特征集。
- en: Select the C-penalty (inverse regularization).
  id: totrans-3682
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择C-惩罚（逆正则化）。
- en: Select the kernel function.
  id: totrans-3683
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择核函数。
- en: Tune the kernel parameters.
  id: totrans-3684
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整核参数。
- en: As mentioned earlier, this test case relies on synthetic data to illustrate
    the concept of the margin and compare kernel methods. Let's use the support vector
    classifier for a real-world financial application.
  id: totrans-3685
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这个测试案例依赖于合成数据来展示边界概念和比较核方法。让我们使用支持向量分类器来展示现实世界的金融应用。
- en: Applications in risk analysis
  id: totrans-3686
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险分析中的应用
- en: The purpose of the test case is to evaluate the risk for a company to curtail
    or eliminate its quarterly or yearly dividend. The features selected are financial
    metrics relevant to a company's ability to generate a cash flow and pay out its
    dividends over the long term.
  id: totrans-3687
  prefs: []
  type: TYPE_NORMAL
  zh: 测试案例的目的是评估公司削减或消除其季度或年度股息的风险。所选特征是反映公司长期产生现金流和支付股息能力的财务指标。
- en: 'We need to select any subset of the following financial technical analysis
    metrics (refer to [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*):'
  id: totrans-3688
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择以下财务技术分析指标中的任何子集（参考[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")，*基本概念*）：
- en: Relative change in stock prices over the last 12 months
  id: totrans-3689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去12个月股票价格的相对变化
- en: Long-term debt-equity ratio
  id: totrans-3690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长期债务权益比率
- en: Dividend coverage ratio
  id: totrans-3691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股息覆盖率比率
- en: Annual dividend yield
  id: totrans-3692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年度股息收益率
- en: Operating profit margin
  id: totrans-3693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 营业利润率
- en: Short interest (ratio of shares shorted over the float)
  id: totrans-3694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空头（已售出股份与流通股份的比例）
- en: Cash per share-share price ratio
  id: totrans-3695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每股现金-股价比率
- en: Earnings per share trend
  id: totrans-3696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每股收益趋势
- en: 'The earnings trend has the following values:'
  id: totrans-3697
  prefs: []
  type: TYPE_NORMAL
  zh: 收益趋势有以下值：
- en: -2 if earnings per share decline by more than 15 percent over the last 12 months.
  id: totrans-3698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果过去12个月内每股收益下降超过15%，则-2
- en: -1 if earnings per share decline between 5 percent and 15 percent.
  id: totrans-3699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1 如果每股收益下降在5%到15%之间。
- en: 0 if earnings per share is maintained within 5 percent.
  id: totrans-3700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果每股收益保持在5%以内，则0
- en: +1 if earnings per share increase between 5 percent and 15 percent.
  id: totrans-3701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果每股收益在5%到15%之间增加，则+1。
- en: +2 if earnings per share increase by more than 15 percent. The values are normalized
    with values 0 and 1.
  id: totrans-3702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果每股收益增加超过15%，则+2。这些值用0和1进行归一化。
- en: 'The labels or expected output (dividend changes) is categorized as follows:'
  id: totrans-3703
  prefs: []
  type: TYPE_NORMAL
  zh: 标签或预期输出（股息变化）按以下方式分类：
- en: -1 if the dividend is cut by more than 5 percent
  id: totrans-3704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果股息削减超过5%，则-1
- en: 0 if the dividend is maintained within 5 percent
  id: totrans-3705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果股息保持在5%以内，则0
- en: +1 if the dividend is increased by more than 5 percent
  id: totrans-3706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果股息增加超过5%，则+1
- en: 'Let''s combine two of these three labels *{-1, 0, 1}* to generate two classes
    for the binary SVC:'
  id: totrans-3707
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这三个标签中的两个 *{-1, 0, 1}* 结合起来，为二元SVC生成两个类别：
- en: Class C1 = stable or decreasing dividends and class C2 = increasing dividends—training
    set A
  id: totrans-3708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C1类 = 稳定或下降的股息和C2类 = 增加的股息——训练集A
- en: Class C1 = decreasing dividends and class C2 = stable or increasing dividends—training
    set B
  id: totrans-3709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C1类 = 下降的股息和C2类 = 稳定或增加的股息——训练集B
- en: 'The different tests are performed with a fixed set of `C` and `GAMMA` configuration
    parameters and a 2-fold validation configuration:'
  id: totrans-3710
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一组固定的 `C` 和 `GAMMA` 配置参数以及2折验证配置进行不同的测试：
- en: '[PRE302]'
  id: totrans-3711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE302]'
- en: 'The first step is to define the `extractor` (which is the list of fields to
    be retrieved from the `dividends2.csv` file) (line `39`). The `pfnSrc` partial
    function generated by the `DataSource` transformation class (line `40`) converts
    the input file into a set of typed fields (line `41`). An observation is an array
    of fields. The `obs` sequence of observations is generated from the input fields
    by transposing the matrix observations `x` features (line `42`):'
  id: totrans-3712
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义 `extractor`（即从 `dividends2.csv` 文件中检索的字段列表）（行 `39`）。由 `DataSource` 转换类生成的
    `pfnSrc` 部分函数（行 `40`）将输入文件转换为一系列类型字段（行 `41`）。一个观察值是一个字段数组。通过转置矩阵观察值 `x` 特征生成 `obs`
    观察值序列（行 `42`）：
- en: '[PRE303]'
  id: totrans-3713
  prefs: []
  type: TYPE_PRE
  zh: '[PRE303]'
- en: The test computes the model parameters and the accuracy from the cross-validation
    during the instantiation of the SVM.
  id: totrans-3714
  prefs: []
  type: TYPE_NORMAL
  zh: 测试在SVM实例化的过程中计算模型参数和交叉验证的准确性。
- en: Note
  id: totrans-3715
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**LIBSVM scaling**'
  id: totrans-3716
  prefs: []
  type: TYPE_NORMAL
  zh: '**LIBSVM缩放**'
- en: LIBSVM supports feature normalization known as scaling, prior to training. The
    main advantage of scaling is to avoid attributes in greater numeric ranges, dominating
    those in smaller numeric ranges. Another advantage is to avoid numerical difficulties
    during the calculation. In our examples, we use the normalization method of the
    `normalize` time series. Therefore, the scaling flag in LIBSVM is disabled.
  id: totrans-3717
  prefs: []
  type: TYPE_NORMAL
  zh: LIBSVM支持在训练之前进行特征归一化，称为缩放。缩放的主要优势是避免更大数值范围的属性支配那些数值范围较小的属性。另一个优势是避免计算过程中的数值困难。在我们的示例中，我们使用`normalize`时间序列的归一化方法。因此，LIBSVM中的缩放标志被禁用。
- en: 'The test is repeated with a different set of features and consists of comparing
    the accuracy of the support vector classifier for different features sets. The
    features sets are selected from the content of the `.csv` file by assembling the
    extractor with different configurations, as follows:'
  id: totrans-3718
  prefs: []
  type: TYPE_NORMAL
  zh: 测试重复使用不同的特征集，并包括比较不同特征集的支持向量分类器的准确性。特征集是通过使用不同配置的提取器从`.csv`文件的内容中选择的，如下所示：
- en: '[PRE304]'
  id: totrans-3719
  prefs: []
  type: TYPE_PRE
  zh: '[PRE304]'
- en: 'Let''s take a look at the following graph:'
  id: totrans-3720
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下以下图表：
- en: '![Applications in risk analysis](img/image01495.jpeg)'
  id: totrans-3721
  prefs: []
  type: TYPE_IMG
  zh: '![风险分析应用](img/image01495.jpeg)'
- en: A comparative study of trading strategies using the binary SVC
  id: totrans-3722
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二元SVC进行交易策略比较研究
- en: The test demonstrates that the selection of the proper features set is the most
    critical step in applying the support vector machine, and any other model for
    that matter, to classification problems. In this particular case, the accuracy
    is also affected by the small size of the training set. The increase in the number
    of features also reduces the contribution of each specific feature to the loss
    function.
  id: totrans-3723
  prefs: []
  type: TYPE_NORMAL
  zh: 测试表明，选择合适的特征集是应用支持向量机（以及任何其他模型）到分类问题中最关键的步骤。在这个特定案例中，准确性也受到训练集规模较小的 影响。特征数量的增加也减少了每个特定特征对损失函数的贡献。
- en: Note
  id: totrans-3724
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The N-fold cross-validation**'
  id: totrans-3725
  prefs: []
  type: TYPE_NORMAL
  zh: '**N折交叉验证**'
- en: The cross-validation in this test example uses only two folds because the number
    of observations is small, and you want to make sure that any class contains at
    least a few observations.
  id: totrans-3726
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个测试示例中，交叉验证只使用两个折，因为观察的数量很小，并且你想要确保任何类别至少包含几个观察值。
- en: 'The same process is repeated for the test B whose purpose is to classify companies
    with decreasing dividends and companies with stable or increasing dividends, as
    shown in the following graph:'
  id: totrans-3727
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试B，重复相同的过程，其目的是对减少分配的公司和稳定或增加分配的公司进行分类，如下面的图所示：
- en: '![Applications in risk analysis](img/image01496.jpeg)'
  id: totrans-3728
  prefs: []
  type: TYPE_IMG
  zh: '![风险分析应用](img/image01496.jpeg)'
- en: A comparative study of trading strategies using the binary SVC
  id: totrans-3729
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二元SVC进行交易策略比较研究
- en: The difference in terms of accuracy of prediction between the first three features
    set and the last two features set in the preceding graph is more pronounced in
    test A than test B. In both the tests, the `eps` feature (earning per share) trend
    improves the accuracy of the classification. It is a particularly good predictor
    for companies with increasing dividends.
  id: totrans-3730
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个图中，第一个三个特征集和最后两个特征集在预测准确性方面的差异在测试A中比测试B中更为明显。在这两个测试中，`eps`特征（每股收益）的趋势提高了分类的准确性。它是对增加分配的公司特别好的预测器。
- en: The problem of predicting the distribution (or not) dividends can be restated
    as evaluating the risk of a company to dramatically reduce its dividends.
  id: totrans-3731
  prefs: []
  type: TYPE_NORMAL
  zh: 预测（或不）分配的分布问题可以重新表述为评估公司大幅减少其分配的风险。
- en: What is the risk if a company eliminates its dividend altogether? Such a scenario
    is rare, and these cases are actually outliers. A one-class support vector classifier
    can be used to detect outliers or anomalies [8:13].
  id: totrans-3732
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一家公司完全取消其分配，风险是什么？这种情况很少见，这些案例实际上是异常值。可以使用单类支持向量分类器来检测异常值或异常[8:13]。
- en: Anomaly detection with one-class SVC
  id: totrans-3733
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用单类SVC进行异常检测
- en: 'The design of the one-class SVC is an extension of the binary SVC. The main
    difference is that a single class contains most of the baseline (or normal) observations.
    A reference point, known as the SVC origin, replaces the second class. The outliers
    (or abnormal) observations reside beyond (or outside) the support vector of the
    single class:'
  id: totrans-3734
  prefs: []
  type: TYPE_NORMAL
  zh: 单类支持向量机（SVC）的设计是二类SVC的扩展。主要区别在于单个类别包含了大部分基线（或正常）观测值。一个称为SVC原点的参考点取代了第二类。异常（或异常）观测值位于单个类别的支持向量之外（或之外）：
- en: '![Anomaly detection with one-class SVC](img/image01497.jpeg)'
  id: totrans-3735
  prefs: []
  type: TYPE_IMG
  zh: '![使用单类SVC进行异常检测](img/image01497.jpeg)'
- en: The visualization of the one-class SVC
  id: totrans-3736
  prefs: []
  type: TYPE_NORMAL
  zh: 单类SVC的可视化
- en: The outlier observations have a labeled value of -1, while the remaining training
    sets are labeled +1\. In order to create a relevant test, we add four more companies
    that have drastically cut their dividends (ticker symbols WLT, RGS, MDC, NOK,
    and GM). The dataset includes the stock prices and financial metrics recorded
    prior to the cut in dividends.
  id: totrans-3737
  prefs: []
  type: TYPE_NORMAL
  zh: 异常观测值有一个标记值为-1，而剩余的训练集被标记为+1。为了创建一个相关的测试，我们添加了四家大幅削减股息的公司（股票代码WLT、RGS、MDC、NOK和GM）。数据集包括在削减股息之前的股票价格和财务指标。
- en: 'The implementation of this test case is very similar to the binary SVC driver
    code, except for the following:'
  id: totrans-3738
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试案例的实现与二类SVC驱动代码非常相似，除了以下方面：
- en: The classifier uses the Nu-SVM formulation, `OneSVFormulation`
  id: totrans-3739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器使用Nu-SVM公式，`OneSVFormulation`
- en: The labeled data is generated by assigning -1 to companies that have eliminated
    their dividends and +1 for all other companies
  id: totrans-3740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记数据是通过将-1分配给取消股息的公司，将+1分配给所有其他公司生成的
- en: 'The test is executed against the `resources/data/chap8/dividends2.csv` dataset.
    First, we need to define the formulation for the one-class SVM:'
  id: totrans-3741
  prefs: []
  type: TYPE_NORMAL
  zh: 测试是在`resources/data/chap8/dividends2.csv`数据集上执行的。首先，我们需要定义单类SVM的公式：
- en: '[PRE305]'
  id: totrans-3742
  prefs: []
  type: TYPE_PRE
  zh: '[PRE305]'
- en: 'The test code is similar to the execution code for the binomial SVC. The only
    difference is the definition of the output labels; -1 for companies eliminating
    dividends and +1 for all other companies:'
  id: totrans-3743
  prefs: []
  type: TYPE_NORMAL
  zh: 测试代码与二类SVC执行代码类似。唯一的区别是输出标签的定义；取消股息的公司为-1，其他所有公司为+1：
- en: '[PRE306]'
  id: totrans-3744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE306]'
- en: The labels or expected data is generated by applying a binary filter to the
    last `dividendTrend` field (line `43`). The formulation in the configuration has
    the `OneSVCFormulation` type (line `44`).
  id: totrans-3745
  prefs: []
  type: TYPE_NORMAL
  zh: 标签或预期数据是通过应用二进制过滤器到最后的`dividendTrend`字段（行`43`）生成的。配置中的公式具有`OneSVCFormulation`类型（行`44`）。
- en: The model is generated with the accuracy of 0.821\. This level of accuracy should
    not be a surprise; the outliers (companies that eliminated their dividends) are
    added to the original dividend `.csv` file. These outliers differ significantly
    from the baseline observations (companies who have reduced, maintained, or increased
    their dividends) in the original input file.
  id: totrans-3746
  prefs: []
  type: TYPE_NORMAL
  zh: 模型以0.821的准确率生成。这种准确率水平不应令人惊讶；异常值（取消股息的公司）被添加到原始股息`.csv`文件中。这些异常值与原始输入文件中的基线观测值（减少、维持或增加股息的公司）有显著差异。
- en: In cases where the labeled observations are available, the one-class support
    vector machine is an excellent alternative to clustering techniques.
  id: totrans-3747
  prefs: []
  type: TYPE_NORMAL
  zh: 在有标记观测值的情况下，单类支持向量机是聚类技术的优秀替代品。
- en: Note
  id: totrans-3748
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**The definition of an anomaly**'
  id: totrans-3749
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常的定义**'
- en: The results generated by a one-class support vector classifier depend heavily
    on the subjective definition of an outlier. The test case assumes that the companies
    that eliminate their dividends have unique characteristics that set them apart
    and are different even from companies who have cut, maintained, or increased their
    dividends. There is no guarantee that this assumption is indeed always valid.
  id: totrans-3750
  prefs: []
  type: TYPE_NORMAL
  zh: 单类支持向量分类器生成的结果在很大程度上取决于对异常的主观定义。测试案例假设取消股息的公司具有独特的特征，使其与众不同，甚至与削减、维持或增加股息的公司也不同。不能保证这个假设确实总是有效的。
- en: Support vector regression
  id: totrans-3751
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量回归
- en: 'Most of the applications using support vector machines are related to classification.
    However, the same technique can be applied to regression problems. Luckily, as
    with classification, LIBSVM supports two formulations for support vector regression:'
  id: totrans-3752
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数使用支持向量机的应用都与分类相关。然而，同样的技术也可以应用于回归问题。幸运的是，与分类一样，LIBSVM支持两种支持向量回归公式：
- en: ∈-VR (sometimes called C-SVR)
  id: totrans-3753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∈-VR（有时称为C-SVR）
- en: υ-SVR
  id: totrans-3754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: υ-SVR
- en: For the sake of consistency with the two previous cases, the following test
    uses the ∈ (or *C*) formulation of the support vector regression.
  id: totrans-3755
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与前两个案例保持一致性，以下测试使用支持向量回归的 ∈（或 *C*）公式。
- en: An overview
  id: totrans-3756
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: The SVR introduces the concept of **error insensitive zone** and insensitive
    error, *ε*. The insensitive zone defines a range of values around the predictive
    values, *y(x)*. The penalization component *C* does not affect the data point
    *{x[i],y[i]}* that belongs to the insensitive zone [8:14].
  id: totrans-3757
  prefs: []
  type: TYPE_NORMAL
  zh: SVR 引入了 **误差不敏感区** 和不敏感误差 *ε* 的概念。不敏感区定义了预测值 *y(x)* 附近的值范围。惩罚成分 *C* 不影响属于不敏感区
    [8:14] 的数据点 *{x[i],y[i]}*。
- en: The following diagram illustrates the concept of an error insensitive zone using
    a single variable feature *x* and an output *y*. In the case of a single variable
    feature, the error insensitive zone is a band of width *2ε* (*ε* is known as the
    insensitive error). The insensitive error plays a similar role to the margin in
    the SVC.
  id: totrans-3758
  prefs: []
  type: TYPE_NORMAL
  zh: 下图使用单个变量特征 *x* 和输出 *y* 阐述了误差不敏感区的概念。在单变量特征的情况下，误差不敏感区是一个宽度为 *2ε* 的带（*ε* 被称为不敏感误差）。不敏感误差在
    SVC 中扮演着与边缘相似的角色。
- en: '![An overview](img/image01498.jpeg)'
  id: totrans-3759
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01498.jpeg)'
- en: The visualization of the support vector regression and insensitive error
  id: totrans-3760
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量回归和不敏感误差的可视化
- en: For the mathematically inclined, the maximization of the margin for nonlinear
    models introduces a pair of slack variables. As you may remember, the C-support
    vector classifiers use a single slack variable. The preceding diagram illustrates
    the minimization formula.
  id: totrans-3761
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数学倾向者，非线性模型的边缘最大化引入了一对松弛变量。如您所记得，C-支持向量分类器使用单个松弛变量。前面的图展示了最小化公式。
- en: Note
  id: totrans-3762
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'M9: The ε-SVR formulation is defined as:'
  id: totrans-3763
  prefs: []
  type: TYPE_NORMAL
  zh: M9：ε-SVR 公式定义为：
- en: '![An overview](img/image01499.jpeg)'
  id: totrans-3764
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01499.jpeg)'
- en: Here, *ε* is the insensitive error function.
  id: totrans-3765
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*ε* 是不敏感误差函数。
- en: 'M10: The ε-SVR regression equation is given by:'
  id: totrans-3766
  prefs: []
  type: TYPE_NORMAL
  zh: M10：ε-SVR 回归方程如下：
- en: '![An overview](img/image01500.jpeg)'
  id: totrans-3767
  prefs: []
  type: TYPE_IMG
  zh: '![概述](img/image01500.jpeg)'
- en: Let's reuse the `SVM` class to evaluate the capability of the SVR, compared
    to the linear regression (refer to the *Ordinary least squares regression* section
    in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization*).
  id: totrans-3768
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重用 `SVM` 类来评估 SVR 的能力，与线性回归相比（参考第 6 章 [普通最小二乘回归](part0188.xhtml#aid-5J99O2
    "第 6 章。回归和正则化")中的 *普通最小二乘回归* 部分，*回归和正则化*）。
- en: SVR versus linear regression
  id: totrans-3769
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SVR与线性回归的比较
- en: This test consists of reusing the example on single-variate linear regression
    (refer to the *One-variate linear regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*).
    The purpose is to compare the output of the linear regression with the output
    of the SVR for predicting the value of a stock price or an index. We select the
    S&P 500 exchange traded fund, SPY, which is a proxy for the S&P 500 index.
  id: totrans-3770
  prefs: []
  type: TYPE_NORMAL
  zh: 本测试包括重用单变量线性回归的示例（参考第 6 章 [单变量线性回归](part0188.xhtml#aid-5J99O2 "第 6 章。回归和正则化")中的
    *单变量线性回归* 部分，*回归和正则化*）。目的是比较线性回归的输出与 SVR 的输出，以预测股价或指数的值。我们选择了标准普尔 500 交易所交易基金，SPY，它是标准普尔
    500 指数的代理。
- en: 'The model consists of the following:'
  id: totrans-3771
  prefs: []
  type: TYPE_NORMAL
  zh: 模型由以下内容组成：
- en: 'One labeled output: SPY-adjusted daily closing price'
  id: totrans-3772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标记的输出：SPY 调整后的每日收盘价
- en: 'One single variable feature set: the index of the trading session (or index
    of the values SPY)'
  id: totrans-3773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个变量特征集：交易时段的索引（或 SPY 的值索引）
- en: 'The implementation follows a familiar pattern:'
  id: totrans-3774
  prefs: []
  type: TYPE_NORMAL
  zh: 实现遵循熟悉的模式：
- en: Define the configuration parameters for the SVR (the `C` cost/penalty function,
    `GAMMA` coefficient for the RBF kernel, `EPS` for the convergence criteria, and
    `EPSILON` for the regression insensitive error).
  id: totrans-3775
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 SVR 的配置参数（`C` 成本/惩罚函数，RBF 内核的 `GAMMA` 系数，`EPS` 用于收敛标准，以及 `EPSILON` 用于回归不敏感误差）。
- en: Extract the labeled data (the SPY `price`) from the data source (`DataSource`),
    which is the Yahoo financials CSV-formatted data file.
  id: totrans-3776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据源（`DataSource`）中提取标记数据（SPY 的 `price`），数据源是 Yahoo 财经 CSV 格式的数据文件。
- en: Create the linear regression, `SingleLinearRegression`, with the index of the
    trading session as the single variable feature and the SPY-adjusted closing price
    as the labeled output.
  id: totrans-3777
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建线性回归，`SingleLinearRegression`，以交易时段的索引作为单一变量特征，以 SPY 调整后的收盘价作为标记的输出。
- en: Create the observations as a time series of indices, `xt`.
  id: totrans-3778
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将观测值创建为时间序列索引，`xt`。
- en: Instantiate the SVR with the index of trading session as features and the SPY-adjusted
    closing price as the labeled output.
  id: totrans-3779
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用交易会话的索引作为特征，将SPY调整后的收盘价作为标记输出实例化SVR。
- en: Run the prediction methods for both SVR and the linear regression and compare
    the results of the linear regression and SVR, `collect`.
  id: totrans-3780
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行SVR和线性回归的预测方法，并比较线性回归和SVR的结果，`collect`。
- en: 'The code will be as follows:'
  id: totrans-3781
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE307]'
  id: totrans-3782
  prefs: []
  type: TYPE_PRE
  zh: '[PRE307]'
- en: 'The formulation in the configuration has the `SVRFormulation` type (line `45`).
    The `DataSource` class extracts the price of the SPY ETF. The `getLabeledData`
    method generates the `xt` input features and the `y` labels (or expected values)
    (line `46`):'
  id: totrans-3783
  prefs: []
  type: TYPE_NORMAL
  zh: 配置中的公式具有`SVRFormulation`类型（第`45`行）。`DataSource`类提取SPY ETF的价格。`getLabeledData`方法生成`xt`输入特征和`y`标签（或预期值）（第`46`行）：
- en: '[PRE308]'
  id: totrans-3784
  prefs: []
  type: TYPE_PRE
  zh: '[PRE308]'
- en: The single variate linear regression, `SingleLinearRegression`, is instantiated
    using the `price` input and `y` labels as inputs (line `47`).
  id: totrans-3785
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量线性回归`SingleLinearRegression`使用`price`输入和`y`标签作为输入（第`47`行）进行实例化。
- en: 'Finally, the `collect` method executes the two `pfSvr` and `pfLinr` regression
    partial functions:'
  id: totrans-3786
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`collect`方法执行了两个`pfSvr`和`pfLinr`回归部分函数：
- en: '[PRE309]'
  id: totrans-3787
  prefs: []
  type: TYPE_PRE
  zh: '[PRE309]'
- en: Note
  id: totrans-3788
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**isDefinedAt**'
  id: totrans-3789
  prefs: []
  type: TYPE_NORMAL
  zh: '**isDefinedAt**'
- en: It is a good practice to validate whether a partial function is defined for
    a specific value of the argument or not. This preemptive approach allows the developer
    to select an alternative method or a full function. It is an efficient alternative
    to catch a `MathErr` exception.
  id: totrans-3790
  prefs: []
  type: TYPE_NORMAL
  zh: 验证一个部分函数是否为特定参数值定义是一个好的实践。这种预防性方法允许开发者选择一个替代方法或完整函数。这是捕获`MathErr`异常的有效替代方案。
- en: The results are displayed in the following graph, which are generated using
    the JFreeChart library. The code to plot the data is omitted because it is not
    essential to the understanding of the application.
  id: totrans-3791
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在下图中，这些图是用JFreeChart库生成的。绘制数据的代码被省略，因为它对于理解应用程序不是必要的。
- en: '![SVR versus linear regression](img/image01501.jpeg)'
  id: totrans-3792
  prefs: []
  type: TYPE_IMG
  zh: '![SVR与线性回归对比](img/image01501.jpeg)'
- en: A comparative plot of linear regression and SVR
  id: totrans-3793
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归和SVR的比较图
- en: The support vector regression provides a more accurate prediction than the linear
    regression model. You can also observe that the L[2] regularization term of the
    SVR penalizes the data points (the SPY price) with a high deviation from the mean
    of the price. A lower value of *C* will increase the L[2]-norm penalty factor
    as *λ =1/C*.
  id: totrans-3794
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量回归比线性回归模型提供更准确的预测。你还可以观察到SVR的L[2]正则化项对价格均值有较大偏差的数据点（SPY价格）进行惩罚。*C*的值越低，L[2]-范数惩罚因子*λ
    =1/C*就越大。
- en: Note
  id: totrans-3795
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**SVR and L[2]** **regularization**'
  id: totrans-3796
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVR和L[2]** **正则化**'
- en: You are invited to run the use case with a different value of *C* to quantify
    the impact of the L[2] regularization on the predictive values of the SVR.
  id: totrans-3797
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎您尝试使用不同的*C*值来量化L[2]正则化对SVR预测值的影响。
- en: There is no need to compare SVR with the logistic regression, as the logistic
    regression is a classifier. However, the SVM is related to the logistic regression;
    the hinge loss in the SVM is similar to the loss in the logistic regression [8:15].
  id: totrans-3798
  prefs: []
  type: TYPE_NORMAL
  zh: 没有必要将SVR与逻辑回归进行比较，因为逻辑回归是一个分类器。然而，SVM与逻辑回归相关；SVM中的hinge损失与逻辑回归中的损失相似[8:15]。
- en: Performance considerations
  id: totrans-3799
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能考虑
- en: 'You may have already observed that the training of a model for the support
    vector regression on a large dataset is time consuming. The performance of the
    support vector machine depends on the type of optimizer (for example, a sequential
    minimal optimization) selected to maximize the margin during training:'
  id: totrans-3800
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经观察到，在大型数据集上对支持向量回归模型进行训练是耗时的。支持向量机的性能取决于在训练期间选择的优化器类型（例如，序列最小优化）以最大化边缘：
- en: A linear model (a SVM without kernel) has an asymptotic time complexity *O(N)*
    for training *N* labeled observations.
  id: totrans-3801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个线性模型（没有核的SVM）在训练*N*个标记观察值时具有渐近时间复杂度*O(N)*。
- en: Nonlinear models rely on kernel methods formulated as a quadratic programming
    problem with an asymptotic time complexity of *O(N³)*
  id: totrans-3802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非线性模型依赖于核方法，这些方法被表述为具有渐近时间复杂度*O(N³)*的二次规划问题。
- en: An algorithm that uses sequential minimal optimization techniques, such as index
    caching or elimination of null values (as in LIBSVM), has an asymptotic time complexity
    of *O(N²)* with the worst case scenario (quadratic optimization) of *O(N³)*
  id: totrans-3803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用序列最小优化技术（如索引缓存或消除空值，如LIBSVM）的算法具有渐近时间复杂度*O(N²)*，最坏情况（二次优化）为*O(N³)*。
- en: Sparse problems for very large training sets (*N > 10,000*) also have an asymptotic
    time of *O(N²)*
  id: totrans-3804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于非常大的训练集（*N > 10,000*）的稀疏问题也有*O(N²)*的渐近时间复杂度
- en: The time and space complexity of the kernelized support vector machine has been
    receiving a great deal of attention [8:16] [8:17].
  id: totrans-3805
  prefs: []
  type: TYPE_NORMAL
  zh: 核化支持向量机的时间和空间复杂度已经引起了极大的关注[8:16] [8:17]。
- en: Summary
  id: totrans-3806
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: This concludes our investigation of kernel and support vector machines. Support
    vector machines have become a robust alternative to logistic regression and neural
    networks for extracting discriminative models from large training sets.
  id: totrans-3807
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着我们对核和支持向量机的调查结束。支持向量机已成为从大型训练集中提取判别模型的一种稳健替代方案，优于逻辑回归和神经网络。
- en: Apart from the unavoidable references to the mathematical foundation of maximum
    margin classifiers, such as SVMs, you should have developed a basic understanding
    of the power and complexity of the tuning and configuration parameters of the
    different variants of SVMs.
  id: totrans-3808
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不可避免地引用最大边缘分类器的数学基础，如SVMs之外，你还应该对SVMs不同变体的调整和配置参数的强大功能和复杂性有一个基本的了解。
- en: As with other discriminative models, the selection of the optimization method
    for SVMs has a critical impact not only on the quality of the model, but also
    on the performance (time complexity) of the training and cross-validation process.
  id: totrans-3809
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他判别模型一样，SVMs的优化方法选择不仅对模型的质量有重大影响，而且对训练和交叉验证过程的表现（时间复杂度）也有重大影响。
- en: The next chapter will describe the third most commonly used discriminative supervised
    model—artificial neural networks.
  id: totrans-3810
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将描述第三种最常用的判别监督模型——人工神经网络。
- en: Chapter 9. Artificial Neural Networks
  id: totrans-3811
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 人工神经网络
- en: The popularity of neural networks surged in the 90s. They were seen as the silver
    bullet to a vast number of problems. At its core, a neural network is a nonlinear
    statistical model that leverages the logistic regression to create a nonlinear
    distributed model. The concept of artificial neural networks is rooted in biology,
    with the desire to simulate key functions of the brain and replicate its structure
    in terms of neurons, activation, and synapses.
  id: totrans-3812
  prefs: []
  type: TYPE_NORMAL
  zh: 20世纪90年代，神经网络的人气激增。它们被视为解决大量问题的银弹。从核心来看，神经网络是一个非线性统计模型，它利用逻辑回归来创建非线性分布式模型。人工神经网络的概念源于生物学，目的是模拟大脑的关键功能，并在神经元、激活和突触方面复制其结构。
- en: 'In this chapter, you will move beyond the hype and learn the following topics:'
  id: totrans-3813
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将超越炒作，学习以下主题：
- en: The concepts and elements of the **multilayer perceptron** (**MLP**)
  id: totrans-3814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多层感知器**（**MLP**）的概念和元素'
- en: How to train a neural network using error backpropagation
  id: totrans-3815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用误差反向传播训练神经网络
- en: The evaluation and tuning of MLP configuration parameters
  id: totrans-3816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估和调整MLP配置参数
- en: A full Scala implementation of the MLP classifier
  id: totrans-3817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLP分类器的完整Scala实现
- en: How to apply MLP to extract correlation models for currency exchange rates
  id: totrans-3818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将MLP应用于提取货币汇率的相关模型
- en: A brief introduction to **convolutional neural network** (**CNN**)
  id: totrans-3819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**）简介'
- en: Feed-forward neural networks
  id: totrans-3820
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前馈神经网络
- en: The idea behind artificial neural networks was to build mathematical and computational
    models of the natural neural network in the brain. After all, the brain is a very
    powerful information processing engine that surpasses computers in domains, such
    as learning, inductive reasoning, prediction and vision, and speech recognition.
  id: totrans-3821
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络背后的想法是构建大脑中自然神经网络的数学和计算模型。毕竟，大脑是一个非常强大的信息处理引擎，在诸如学习、归纳推理、预测和视觉、语音识别等领域超越了计算机。
- en: The biological background
  id: totrans-3822
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生物背景
- en: 'In biology, a neural network is composed of groups of neurons interconnected
    through synapses [9:1], as shown in the following diagram:'
  id: totrans-3823
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物学中，神经网络由通过突触相互连接的神经元群组成[9:1]，如下面的图所示：
- en: '![The biological background](img/image01502.jpeg)'
  id: totrans-3824
  prefs: []
  type: TYPE_IMG
  zh: '![生物背景](img/image01502.jpeg)'
- en: The visualization of biological neurons and synapses
  id: totrans-3825
  prefs: []
  type: TYPE_NORMAL
  zh: 生物神经元和突触的可视化
- en: Neuroscientists have been especially interested in understanding how billions
    of neurons in the brain can interact to provide human beings with parallel processing
    capabilities. The 60s saw a new field of study emerging, known as **connectionism**.
    Connectionism marries cognitive psychology, artificial intelligence, and neuroscience.
    The goal was to create a model for mental phenomena. Although there are many forms
    of connectionism, the neural network models have become the most popular and the
    most taught of all connectionism models [9:2].
  id: totrans-3826
  prefs: []
  type: TYPE_NORMAL
  zh: 神经科学家特别感兴趣的是了解大脑中数十亿个神经元如何相互作用，为人类提供并行处理能力。20世纪60年代出现了一个新的研究领域，称为**联结主义**。联结主义将认知心理学、人工智能和神经科学结合起来。目标是创建一个心理现象的模型。尽管联结主义有多种形式，但神经网络模型已成为所有联结主义模型中最受欢迎和最常教授的
    [9:2]。
- en: 'Biological neurons communicate with electrical charges known as **stimuli**.
    This network of neurons can be represented as a simple schematic, as follows:'
  id: totrans-3827
  prefs: []
  type: TYPE_NORMAL
  zh: 生物神经元通过称为**刺激**的电能进行交流。这个神经元网络可以用以下简单的示意图表示：
- en: '![The biological background](img/image01503.jpeg)'
  id: totrans-3828
  prefs: []
  type: TYPE_IMG
  zh: '![生物背景](img/image01503.jpeg)'
- en: The representation of neuron layers, connections, and synapses
  id: totrans-3829
  prefs: []
  type: TYPE_NORMAL
  zh: 神经层、连接和突触的表示
- en: This representation categorizes groups of neurons as layers. The terminology
    used to describe the natural neural networks has a corresponding nomenclature
    for the artificial neural network.
  id: totrans-3830
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示法将神经元群分类为层。用于描述自然神经网络的术语在人工神经网络中也有相应的命名法。
- en: '| The biological neural network | The artificial neuron network |'
  id: totrans-3831
  prefs: []
  type: TYPE_TB
  zh: '| 生物神经网络 | 人工神经网络 |'
- en: '| --- | --- |'
  id: totrans-3832
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Axon | Connection |'
  id: totrans-3833
  prefs: []
  type: TYPE_TB
  zh: '| 轴突 | 连接 |'
- en: '| Dendrite | Connection |'
  id: totrans-3834
  prefs: []
  type: TYPE_TB
  zh: '| 树突 | 连接 |'
- en: '| Synapse | Weight |'
  id: totrans-3835
  prefs: []
  type: TYPE_TB
  zh: '| 突触 | 权重 |'
- en: '| Potential | Weighted sum |'
  id: totrans-3836
  prefs: []
  type: TYPE_TB
  zh: '| 电势 | 加权求和 |'
- en: '| Threshold | Bias weight |'
  id: totrans-3837
  prefs: []
  type: TYPE_TB
  zh: '| 阈值 | 偏置权重 |'
- en: '| Signal, Stimulus | Activation |'
  id: totrans-3838
  prefs: []
  type: TYPE_TB
  zh: '| 信号、刺激 | 激活 |'
- en: '| Group of neurons | Layer of neurons |'
  id: totrans-3839
  prefs: []
  type: TYPE_TB
  zh: '| 神经元群 | 神经元层 |'
- en: 'In the biological world, stimuli do not propagate in any specific direction
    between neurons. An artificial neural network can have the same degree of freedom.
    The most commonly used artificial neural networks by data scientists have a predefined
    direction: from the input layer to output layers. These neural networks are known
    as a **feed-forward neural network** (**FFNN**).'
  id: totrans-3840
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物世界中，刺激在神经元之间不沿任何特定方向传播。人工神经网络可以具有相同的自由度。数据科学家最常用的人工神经网络有一个预定义的方向：从输入层到输出层。这些神经网络被称为**前馈神经网络**（**FFNN**）。
- en: Mathematical background
  id: totrans-3841
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学背景
- en: In the previous chapter, you learned that support vector machines have the ability
    to formulate the training of a model as a nonlinear optimization for which the
    objective function is convex. A convex objective function is fairly straightforward
    to implement. The drawback is that the kernelization of the SVM may result in
    a large number of basis functions (or model dimensions). Refer to the *The kernel
    trick* section under *Support vector machines* in [Chapter 8](part0200.xhtml#aid-5UNGG2
    "Chapter 8. Kernel Models and Support Vector Machines"), *Kernel Models and Support
    Vector Machines*. One solution is to reduce the number of basis functions through
    parameterization, so these functions can adapt to different training sets. Such
    an approach can be modeled as a FFNN, known as the multilayer perceptron [9:3].
  id: totrans-3842
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你了解到支持向量机有能力将模型的训练表述为非线性优化，其目标函数是凸的。凸目标函数相对容易实现。缺点是SVM的核化可能会导致大量的基函数（或模型维度）。请参阅[第8章](part0200.xhtml#aid-5UNGG2
    "第8章。核模型和支持向量机")下的*核技巧*部分，*核模型和支持向量机*。一种解决方案是通过参数化减少基函数的数量，这样这些函数可以适应不同的训练集。这种方法可以建模为FFNN，称为多层感知器
    [9:3]。
- en: 'The linear regression can be visualized as a simple connectivity model using
    neurons and synapses, as follows:'
  id: totrans-3843
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归可以可视化为一个简单的使用神经元和突触的连接模型，如下所示：
- en: '![Mathematical background](img/image01504.jpeg)'
  id: totrans-3844
  prefs: []
  type: TYPE_IMG
  zh: '![数学背景](img/image01504.jpeg)'
- en: A two-layer neural network
  id: totrans-3845
  prefs: []
  type: TYPE_NORMAL
  zh: 二层神经网络
- en: The feature *x[0]=+1* is known as the **bias input** (or the bias element),
    which corresponds to the intercept in the classic linear regression.
  id: totrans-3846
  prefs: []
  type: TYPE_NORMAL
  zh: 特征 *x[0]=+1* 被称为**偏置输入**（或偏置元素），它对应于经典线性回归中的截距。
- en: 'As with support vector machines, linear regression is appropriate for observations
    that can be linearly separable. The real world is usually driven by a nonlinear
    phenomenon. Therefore, the logistic regression is naturally used to compute the
    output of the perceptron. For a set of input variable *x = {x[i]}[0,n]* and the
    weights *w={w[i]}[1,n]*, the output *y* is computed as follows (**M1**):'
  id: totrans-3847
  prefs: []
  type: TYPE_NORMAL
  zh: 与支持向量机一样，线性回归适用于可以线性分离的观测值。现实世界通常由非线性现象驱动。因此，逻辑回归自然被用来计算感知器的输出。对于一组输入变量 *x =
    {x[i]}[0,n]* 和权重 *w={w[i]}[1,n]*，输出 *y* 的计算如下（**M1**）：
- en: '![Mathematical background](img/image01505.jpeg)'
  id: totrans-3848
  prefs: []
  type: TYPE_IMG
  zh: '![数学背景](img/image01505.jpeg)'
- en: A FFNN can be regarded as a stack of layers of logistic regression with the
    output layer as a linear regression.
  id: totrans-3849
  prefs: []
  type: TYPE_NORMAL
  zh: FFNN可以被视为堆叠了具有线性回归输出层的逻辑回归层。
- en: The value of the variables in each hidden layer is computed as the sigmoid of
    the dot product of the connection weights and the output of the previous layer.
    Although interesting, the theory behind artificial neural networks is beyond the
    scope of this book [9:4].
  id: totrans-3850
  prefs: []
  type: TYPE_NORMAL
  zh: 每个隐藏层中变量的值是通过连接权重和前一层的输出的点积的Sigmoid函数来计算的。尽管很有趣，但人工神经网络背后的理论超出了本书的范围[9:4]。
- en: The multilayer perceptron
  id: totrans-3851
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多层感知器
- en: The perceptron is a basic processing element that performs a binary classification
    by mapping a scalar or vector to a binary (or **XOR**) value *{true, false}* or
    *{-1, +1}*. The original perceptron algorithm was defined as a single layer of
    neurons for which each value *x[i]* of the feature vector is processed in parallel
    and generates a single output *y*. The perceptron was later extended to encompass
    the concept of an activation function.
  id: totrans-3852
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是一个基本的处理单元，通过将标量或向量映射到二元（或**XOR**）值 *{true, false}* 或 *{-1, +1}* 来执行二元分类。原始的感知器算法被定义为单层神经元，其中特征向量的每个值
    *x[i]* 都并行处理并生成单个输出 *y*。感知器后来扩展到包括激活函数的概念。
- en: The single layer perceptrons are limited to process a single linear combination
    of weights and input values. Scientists found out that adding intermediate layers
    between the input and output layers enable them to solve more complex classification
    problems. These intermediate layers are known as **hidden layers** because they
    interface only with other perceptrons. Hidden nodes can be accessed only through
    the input layer.
  id: totrans-3853
  prefs: []
  type: TYPE_NORMAL
  zh: 单层感知器仅限于处理单个权重的线性组合和输入值。科学家发现，在输入层和输出层之间添加中间层使他们能够解决更复杂的分类问题。这些中间层被称为**隐藏层**，因为它们只与其他感知器接口。隐藏节点只能通过输入层访问。
- en: 'From now on, we will use a three-layered perceptron to investigate and illustrate
    the properties of neural networks, as shown here:'
  id: totrans-3854
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将使用三层感知器来研究和说明神经网络的特征，如下所示：
- en: '![The multilayer perceptron](img/image01506.jpeg)'
  id: totrans-3855
  prefs: []
  type: TYPE_IMG
  zh: '![多层感知器](img/image01506.jpeg)'
- en: A three-layered perceptron
  id: totrans-3856
  prefs: []
  type: TYPE_NORMAL
  zh: 三层感知器
- en: 'The three-layered perceptron requires two sets of weights: *w[ij]* to process
    the output of the input layer to the hidden layer and *v[ij]* between the hidden
    layer and the output layer. The intercept value *w[0]*, in both linear and logistic
    regression, is represented with *+1* in the visualization of the neural network
    (*w[0].1+ w[1].x[1]+w[2].x[2]+ …*).'
  id: totrans-3857
  prefs: []
  type: TYPE_NORMAL
  zh: 三层感知器需要两组权重：*w[ij]* 用于处理输入层到隐藏层的输出，*v[ij]* 在隐藏层和输出层之间。在线性回归和逻辑回归中，截距值 *w[0]*
    在神经网络的可视化中表示为 *+1*（*w[0].1+ w[1].x[1]+w[2].x[2]+ …*）。
- en: Note
  id: totrans-3858
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**A FFNN without a hidden layer**'
  id: totrans-3859
  prefs: []
  type: TYPE_NORMAL
  zh: '**无隐藏层的FFNN**'
- en: A FFNN without a hidden layer is similar to a linear statistical model. The
    only transformation or connection between the input and output layer is actually
    a linear regression. A linear regression is a more efficient alternative to the
    FFNN without a hidden layer.
  id: totrans-3860
  prefs: []
  type: TYPE_NORMAL
  zh: 无隐藏层的FFNN类似于线性统计模型。输入层和输出层之间唯一的转换或连接实际上是一个线性回归。线性回归是无隐藏层FFNN的一个更有效的替代方案。
- en: 'The description of the MLP components and their implementations rely on the
    following stages:'
  id: totrans-3861
  prefs: []
  type: TYPE_NORMAL
  zh: MLP组件及其实现的描述依赖于以下阶段：
- en: An overview of the software design.
  id: totrans-3862
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 软件设计的概述。
- en: A description of the MLP model components.
  id: totrans-3863
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MLP模型组件的描述。
- en: The implementation of the four-step training cycle.
  id: totrans-3864
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 四步训练周期的实现。
- en: The definition and implementation of the training strategy and the resulting
    classifier.
  id: totrans-3865
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练策略的定义和实现以及由此产生的分类器。
- en: Note
  id: totrans-3866
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Terminology**'
  id: totrans-3867
  prefs: []
  type: TYPE_NORMAL
  zh: '**术语**'
- en: Artificial neural networks encompass a large variety of learning algorithms,
    the multilayer perceptron being one of them. Perceptrons are indeed components
    of a neural network organized as the input, output, and hidden layers. This chapter
    is dedicated to the multilayer perceptron with hidden layers. The terms "neural
    network" and "multilayer perceptron" are used interchangeably.
  id: totrans-3868
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络包含大量学习算法，多层感知器是其中之一。感知器确实是按照输入、输出和隐藏层组织起来的神经网络组件。本章专门讨论具有隐藏层的多层感知器。术语“神经网络”和“多层感知器”可以互换使用。
- en: The activation function
  id: totrans-3869
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数
- en: 'The perceptron is represented as a linear combination of weights *w[i]* and
    input values *x[i]* processed by the output unit activation function *h*, as shown
    here (**M2**):'
  id: totrans-3870
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器被表示为权重*w[i]*和输入值*x[i]*通过输出单元激活函数*h*的线性组合，如下所示（**M2**）：
- en: '![The activation function](img/image01507.jpeg)'
  id: totrans-3871
  prefs: []
  type: TYPE_IMG
  zh: '![激活函数](img/image01507.jpeg)'
- en: 'The output activation function *h* has to be continuous and differentiable
    for a range of value of the weights. It takes different forms depending on the
    problems to be solved, as mentioned here:'
  id: totrans-3872
  prefs: []
  type: TYPE_NORMAL
  zh: 输出激活函数*h*必须对于权重的一定范围内的值是连续且可微分的。它根据要解决的问题采取不同的形式，如下所述：
- en: An identity for the output layer (linear formula) of the regression mode
  id: totrans-3873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归模式的输出层（线性公式）的恒等式
- en: The sigmoid *σ* for hidden layers and output layers of the binomial classifier
  id: totrans-3874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二项式分类器的隐藏层和输出层的sigmoid *σ*
- en: Softmax for the multinomial classification
  id: totrans-3875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式分类的softmax
- en: The hyperbolic tangent, *tanh*, for the classification using zero mean
  id: totrans-3876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双曲正切*tanh*用于使用零均值的分类
- en: The softmax formula is described in *Step 1 – input forward propagation* under
    *Training epoch*.
  id: totrans-3877
  prefs: []
  type: TYPE_NORMAL
  zh: 软max公式在**训练周期**下的**步骤1 - 输入前向传播**中描述。
- en: The network topology
  id: totrans-3878
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络拓扑
- en: 'The output layers and hidden layers have a computational capability (dot product
    of weights, inputs, and activation functions). The input layer does not transform
    data. An n-layer neural network is a network with *n* computational layers. Its
    architecture consists of the following components:'
  id: totrans-3879
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层和隐藏层具有计算能力（权重、输入和激活函数的点积）。输入层不转换数据。一个n层神经网络是一个具有*n*计算层的网络。其架构由以下组件组成：
- en: one input layer
  id: totrans-3880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输入层
- en: '*n-1* hidden layer'
  id: totrans-3881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n-1*隐藏层'
- en: one output layer
  id: totrans-3882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输出层
- en: A **fully connected neural network** has all its input nodes connected to hidden
    layer neurons. Networks are characterized as **partially connected neural networks**
    if one or more of their input variables are not processed. This chapter deals
    with a fully connected neural network.
  id: totrans-3883
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**全连接神经网络**的所有输入节点都连接到隐藏层神经元。如果一个或多个输入变量没有被处理，网络被定义为**部分连接神经网络**。本章讨论的是全连接神经网络。
- en: Note
  id: totrans-3884
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Partially connected networks**'
  id: totrans-3885
  prefs: []
  type: TYPE_NORMAL
  zh: '**部分连接网络**'
- en: Partially connected networks are not as complex as they seem. They can be generated
    from fully connected networks by setting some of the weights to zero.
  id: totrans-3886
  prefs: []
  type: TYPE_NORMAL
  zh: 部分连接网络并不像看起来那么复杂。它们可以通过将一些权重设置为零从全连接网络生成。
- en: 'The structure of the output layer is highly dependent on the type of problems
    (regression or classification) you need to solve, also known as the operating
    mode of the multilayer perceptron. The type of problem at hand defines the number
    of output nodes [9:5]. Consider the following examples:'
  id: totrans-3887
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层的结构高度依赖于需要解决的问题的类型（回归或分类），也称为多层感知器的操作模式。当前问题的类型定义了输出节点的数量[9:5]。考虑以下示例：
- en: A one-variate regression has one output node whose value is a real number [0,
    1]
  id: totrans-3888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个一元回归有一个输出节点，其值是一个实数[0, 1]
- en: A multivariate regression with *n* variables has *n* real output nodes
  id: totrans-3889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有*n*个变量的多元回归有*n*个实数输出节点
- en: A binary classification has one binary output node *{0, 1}* or *{-1, +1}*
  id: totrans-3890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二元分类有一个二元输出节点*{0, 1}*或*{-1, +1}*
- en: A multinomial or K-class classification has *K* binary output nodes
  id: totrans-3891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式或K类分类有*K*个二元输出节点
- en: Design
  id: totrans-3892
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计
- en: 'The implementation of the MLP classifier follows the same pattern as previous
    classifiers (refer to the *Design template for immutable classifiers* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*):'
  id: totrans-3893
  prefs: []
  type: TYPE_NORMAL
  zh: MLP分类器的实现遵循与先前分类器相同的模式（参考[附录A](part0229.xhtml#aid-6QCGQ2 "附录 A. 基本概念")中的*不可变分类器设计模板*部分，*基本概念*）：
- en: An `MLPNetwork` connectionist network is composed of a layer of neurons of the
    `MLPLayer` type, connected by synapses of the `MLPSynapse` type contained by a
    connector of the `MLPConnection` type.
  id: totrans-3894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`MLPNetwork`连接主义网络由`MLPLayer`类型的神经元层组成，这些神经元通过`MLPConnection`类型的连接器中的`MLPSynapse`类型的突触连接。
- en: All of the configuration parameters are encapsulated into a single `MLPConfig`
    configuration class.
  id: totrans-3895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有配置参数都被封装到一个单一的`MLPConfig`配置类中。
- en: A model, `MLPModel`, consists of a sequence of connection synapses.
  id: totrans-3896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模型，`MLPModel`，由一系列连接突触组成。
- en: The `MLP` multilayer perceptron class is implemented as a data transformation,
    `ITransform`, for which the model is automatically extracted from a training set
    with labels.
  id: totrans-3897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLP`多层感知器类被实现为一个数据转换`ITransform`，模型会自动从带有标签的训练集中提取。'
- en: 'The `MLP` multilayer perceptron class takes four parameters: a configuration,
    a features set or time series of the `XVSeries` type, a labeled dataset of the
    `XVSeries` type, and an activation function of the `Function1[Double, Double]`
    type.'
  id: totrans-3898
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLP`多层感知器类接受四个参数：一个配置、一个`XVSeries`类型的特征集或时间序列、一个带有标签的`XVSeries`类型的数据集以及一个`Function1[Double,
    Double]`类型的激活函数。'
- en: 'The software components of the multilayer perceptron are described in the following
    UML class diagram:'
  id: totrans-3899
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器的软件组件在以下UML类图中描述：
- en: .
  id: totrans-3900
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: '![Design](img/image01508.jpeg)'
  id: totrans-3901
  prefs: []
  type: TYPE_IMG
  zh: '![设计](img/image01508.jpeg)'
- en: A UML class diagram for the multilayer perceptron
  id: totrans-3902
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器的UML类图
- en: The class diagram is a convenient navigation map used to understand the role
    and relation of the Scala classes used to build an MLP. Let's start with the implementation
    of the MLP network and its components. The UML diagram omits the helper traits
    or classes such as `Monitor` or the Apache Commons Math components.
  id: totrans-3903
  prefs: []
  type: TYPE_NORMAL
  zh: 类图是一个方便的导航图，用于理解构建MLP所使用的Scala类的角色和关系。让我们从MLP网络及其组件的实现开始。UML图省略了`Monitor`或Apache
    Commons Math组件等辅助特性和类。
- en: Configuration
  id: totrans-3904
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: 'The `MLPConfig` configuration of the multilayer perceptron consists of the
    definition of the network configuration with its hidden layers, the learning and
    training parameters, and the activation function:'
  id: totrans-3905
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器的`MLPConfig`配置包括定义网络配置及其隐藏层、学习和训练参数以及激活函数：
- en: '[PRE310]'
  id: totrans-3906
  prefs: []
  type: TYPE_PRE
  zh: '[PRE310]'
- en: 'For the sake of readability, the name of the configuration parameters matches
    the symbols defined in the mathematical formulation (line `1`):'
  id: totrans-3907
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可读性，配置参数的名称与数学公式中定义的符号相匹配（行`1`）：
- en: '`alpha`: This is the momentum factor *α* that smoothes the computation of the
    gradient of the weights for online training. The momentum factor is used in the
    mathematical expression **M10** in *Step 2 – error backpropagation* under *Training
    epoch*.'
  id: totrans-3908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`: 这是用于在线训练中平滑权重梯度计算的动量因子*α*。动量因子在*第二步 - 错误反向传播*下的*训练周期*中的数学表达式**M10**中使用。'
- en: '`eta`: This is the learning rate *η* used in the gradient descent. The gradient
    descent updates the weights or parameters of a model by the quantity, *eta.(predicted
    – expected).input,* as described in the mathematical formulation **M9** in *Step
    2 – error backpropagation* section under *The training epoch*. The gradient descent
    was introduced in *Let''s kick the tires* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*.'
  id: totrans-3909
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta`: 这是梯度下降中使用的学习率*η*。梯度下降通过数量*eta.(predicted – expected).input*更新模型的权重或参数，如数学公式**M9**在*第二步
    - 错误反向传播*部分下*训练周期*中所述。梯度下降在[第一章](part0155.xhtml#aid-4JQ761 "第一章。入门")的*Let''s kick
    the tires*中介绍，*入门*。'
- en: '`numEpochs`: This is the maximum number of epochs (or cycles or episodes) allowed
    for training the neural network. An epoch is the execution of the error backpropagation
    across the entire observation set.'
  id: totrans-3910
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numEpochs`: 这是允许训练神经网络的最多周期数（或循环或剧集）。一个周期是在整个观察集上执行错误反向传播的执行。'
- en: '`eps`: This is the convergence criteria used as an exit condition for the training
    of the neural network when *error < eps*.'
  id: totrans-3911
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eps`: 这是在神经网络训练过程中用作退出条件的收敛标准，当*error < eps*时。'
- en: '`activation`: This is the activation function used for nonlinear regression
    applied to hidden layers. The default function is the sigmoid (or the hyperbolic
    tangent) introduced for the logistic regression (refer to the *Logistic function*
    section in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization*).'
  id: totrans-3912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`激活函数`: 这是用于非线性回归并应用于隐藏层的激活函数。默认函数是用于逻辑回归的sigmoid函数（或双曲正切函数）（参考[第6章](part0188.xhtml#aid-5J99O2
    "第6章。回归和正则化")中的*逻辑函数*部分，*回归和正则化*）。'
- en: Network components
  id: totrans-3913
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络组件
- en: The training and classification of an MLP model relies on the network architecture.
    The `MLPNetwork` class is responsible for creating and managing the different
    components and the topology of the network, that is layers, synapses, and connections.
  id: totrans-3914
  prefs: []
  type: TYPE_NORMAL
  zh: MLP模型的训练和分类依赖于网络架构。`MLPNetwork`类负责创建和管理网络的不同组件及其拓扑，即层、突触和连接。
- en: The network topology
  id: totrans-3915
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络拓扑
- en: 'The instantiation of the `MLPNetwork` class requires a minimum set of two parameters
    with an instance of the model as an optional third argument (line `2`):'
  id: totrans-3916
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化`MLPNetwork`类需要一个最小参数集，包括一个模型实例，以及一个可选的第三个参数（行`2`）：
- en: An MLP execution configuration, `config`, introduced in the previous section
  id: totrans-3917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上一节中引入的MLP执行配置，`config`
- en: 'A `topology` defined as an array of the number of nodes for each layer: input,
    hidden, and output layers.'
  id: totrans-3918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义为每层节点数的数组：输入层、隐藏层和输出层。
- en: A `model` with the `Option[MLPModel]` type if it has already been generated
    through training, or `None` otherwise
  id: totrans-3919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果已经通过训练生成，则具有`Option[MLPModel]`类型的`model`，否则为`None`
- en: An implicit reference to the operating `mode` of the MLP
  id: totrans-3920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对MLP操作`模式`的隐式引用
- en: 'The code is as follows:'
  id: totrans-3921
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE311]'
  id: totrans-3922
  prefs: []
  type: TYPE_PRE
  zh: '[PRE311]'
- en: 'A MLP network has the following components, which are derived from the topology
    array:'
  id: totrans-3923
  prefs: []
  type: TYPE_NORMAL
  zh: MLP网络具有以下组件，这些组件来自拓扑数组：
- en: Multiple `layers` of the `MLPLayers` class (line `3`)
  id: totrans-3924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLPLayers`类的多个`层`（行`3`）'
- en: Multiple `connections` of the `MLPConnection` class (line `4`)
  id: totrans-3925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLPConnection`类的多个`连接`（行`4`）'
- en: The topology is defined as an array of number of nodes per layer, starting with
    the input nodes. The array indices follow the forward path within the network.
    The size of the input layer is automatically generated from the observations as
    the size of the features vector. The size of the output layer is automatically
    extracted from the size of the output vector (line `3`).
  id: totrans-3926
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑定义为从输入节点开始的每层的节点数数组。数组索引遵循网络中的前向路径。输入层的大小自动从特征向量的大小生成。输出层的大小自动从输出向量的大小提取（行`3`）。
- en: The constructor for `MLPNetwork` creates a sequence of layers by assigning and
    ordering an `MLPLayer` instance to each entry in the topology (line `3`). The
    constructor creates *number of layers – 1* interlayer connections of the `MLPConnection`
    type (line `4`). The `zipWithShift1` method of the `XTSeries` object zips a time
    series with its duplicated shift by one element.
  id: totrans-3927
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLPNetwork`的构造函数通过将`MLPLayer`实例分配并排序到拓扑中的每个条目来创建一系列层（行`3`）。构造函数创建了`层数 - 1`个`MLPConnection`类型的层间连接（行`4`）。`XTSeries`对象的`zipWithShift1`方法将时间序列与其重复移位一个元素的时间序列进行连接。'
- en: The `trainEpoch` method (line `5`) implements the training of this network for
    a single pass of the entire set of observations (refer to the *Putting it all
    together* section under *The training epoch*). The `getModel` method retrieves
    the model (synapses) generated through training of the MLP (line `6`). The `predict`
    method computes the output value generated from the network using the forward
    propagation algorithm (line `7`).
  id: totrans-3928
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainEpoch`方法（行`5`）实现了对整个观察集的单次遍历的网络训练（参考*训练周期*下的*整合一切*部分）。`getModel`方法检索通过训练MLP生成的模型（突触）（行`6`）。`predict`方法使用前向传播算法计算网络生成的输出值（行`7`）。'
- en: 'The following diagram visualizes the interaction between the different components
    of a model: `MLPLayer`, `MLPConnection`, and `MLPSynapse`:'
  id: totrans-3929
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了模型不同组件之间的交互：`MLPLayer`、`MLPConnection`和`MLPSynapse`：
- en: '![The network topology](img/image01509.jpeg)'
  id: totrans-3930
  prefs: []
  type: TYPE_IMG
  zh: '![网络拓扑](img/image01509.jpeg)'
- en: Core components of the MLP Network
  id: totrans-3931
  prefs: []
  type: TYPE_NORMAL
  zh: MLP网络的核心组件
- en: Input and hidden layers
  id: totrans-3932
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入层和隐藏层
- en: 'First, let''s start with the definition of the `MLPLayer` layer class, which
    is completely specified by its position (or rank) `id` in the network and the
    number of nodes, `numNodes`, it contains:'
  id: totrans-3933
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从`MLPLayer`层类的定义开始，该类完全由其在网络中的位置（或排名）`id`以及它包含的节点数，`numNodes`来指定：
- en: '[PRE312]'
  id: totrans-3934
  prefs: []
  type: TYPE_PRE
  zh: '[PRE312]'
- en: The `id` parameter is the order of the layer (0 for input, 1 for the first hidden
    layer, and *n – 1* for the output layer) in the network. The `numNodes` value
    is the number of elements or nodes, including the bias element, in this layer.
    The `activation` function is the last argument of the layer given a user-defined
    mode or objective (line `8`). The operating `mode` has to be provided implicitly
    prior to the instantiation of a layer (line `9`).
  id: totrans-3935
  prefs: []
  type: TYPE_NORMAL
  zh: '`id`参数是层在网络中的顺序（输入层为0，第一个隐藏层为1，输出层为*n – 1*）。`numNodes`值是此层中元素或节点的数量，包括偏置元素。`activation`函数是层给出的用户定义模式或目标的最后一个参数（行`8`）。操作`mode`必须在实例化层之前隐式提供（行`9`）。'
- en: The `output` vector for the layer is an uninitialized array of values updated
    during the forward propagation. It initializes the bias value with the value 1.0
    (line `9`). The matrix of difference of weights, `deltaMatrix`, associated with
    the output vector (line `10`) is updated using the error backpropagation algorithm,
    as described in the *Step 2 – error back propagation* section under *The training
    epoch*. The `setOutput` method initializes the output values for the output and
    hidden layers during the backpropagation of the error on the output of the network
    (*expected – predicted*) values (line `11`).
  id: totrans-3936
  prefs: []
  type: TYPE_NORMAL
  zh: 层的`output`向量是一个未初始化的值数组，在正向传播过程中更新。它使用值1.0初始化偏置值（行`9`）。与输出向量相关的权重差矩阵`deltaMatrix`（行`10`）使用错误反向传播算法更新，如*训练周期*下的*步骤
    2 – 错误反向传播*部分所述。`setOutput`方法在反向传播错误到网络的输出（*预期 – 预测*）值时初始化输出和隐藏层的输出值（行`11`）。
- en: The `activate` method invokes the activation method (*tanh*, *sigmoid*, …) defined
    in the configuration (line `12`).
  id: totrans-3937
  prefs: []
  type: TYPE_NORMAL
  zh: '`activate`方法调用配置中定义的激活方法（*tanh*，*sigmoid*等）（行`12`）。'
- en: The `delta` method computes the correction to be applied to each weight or synapses,
    as described in the *Step 2 – error back propagation* section under *The training
    epoch* (line `13`).
  id: totrans-3938
  prefs: []
  type: TYPE_NORMAL
  zh: '`delta`方法计算应用于每个权重或突触的校正，如*训练周期*下的*步骤 2 – 错误反向传播*部分所述（行`13`）。'
- en: 'The `setInput` method initializes the `output` values for the nodes of the
    input and hidden layers, except the bias element, with the value `x` (line `14`).
    The method is invoked during the forward propagation of input values:'
  id: totrans-3939
  prefs: []
  type: TYPE_NORMAL
  zh: '`setInput`方法使用值`x`初始化输入和隐藏层的节点`output`值，除了偏置元素。该方法在输入值的正向传播过程中被调用（行`14`）。'
- en: '[PRE313]'
  id: totrans-3940
  prefs: []
  type: TYPE_PRE
  zh: '[PRE313]'
- en: The methods of the `MLPLayer` class for the input and hidden layers are overridden
    for the output layer of the `MLPOutLayer` type.
  id: totrans-3941
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLPLayer`类的方法对于输入和隐藏层被重写以适用于`MLPOutLayer`类型的输出层。'
- en: The output layer
  id: totrans-3942
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出层
- en: 'Contrary to the hidden layers, the output layer does not have either an activation
    function or a bias element. The `MLPOutLayer` class has the following arguments:
    the order `id` in the network (as the last layer of the network) and the number,
    `numNodes`, of the output or nodes (line `15`):'
  id: totrans-3943
  prefs: []
  type: TYPE_NORMAL
  zh: 与隐藏层相反，输出层既没有激活函数也没有偏置元素。`MLPOutLayer`类有以下参数：网络中的顺序`id`（作为网络的最后一层）和输出或节点的数量`numNodes`（行`15`）：
- en: '[PRE314]'
  id: totrans-3944
  prefs: []
  type: TYPE_PRE
  zh: '[PRE314]'
- en: The `numNonBias` method returns the actual number of output values from the
    network. The implementation of the `delta` method is described in the *Step 2
    – error back propagation* section under *The training epoch*.
  id: totrans-3945
  prefs: []
  type: TYPE_NORMAL
  zh: '`numNonBias`方法返回网络的实际输出值数量。`delta`方法的实现如*训练周期*下的*步骤 2 – 错误反向传播*部分所述。'
- en: Synapses
  id: totrans-3946
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 突触
- en: 'A synapse is defined as a pair of real (a floating point) values:'
  id: totrans-3947
  prefs: []
  type: TYPE_NORMAL
  zh: 突触被定义为两个实数（浮点数）值的对：
- en: The weight *w[ij]* of the connection from the neuron *i* of the previous layer
    to the neuron *j*
  id: totrans-3948
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从前一层的神经元*i*到神经元*j*的连接的权重*w[ij]*
- en: The weights' adjustment (or gradient of weights) *∆w[ij]*
  id: totrans-3949
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重调整（或权重梯度）*∆w[ij]*
- en: 'Its type is defined as `MLPSynapse`, as shown here:'
  id: totrans-3950
  prefs: []
  type: TYPE_NORMAL
  zh: 它的类型被定义为`MLPSynapse`，如下所示：
- en: '[PRE315]'
  id: totrans-3951
  prefs: []
  type: TYPE_PRE
  zh: '[PRE315]'
- en: Connections
  id: totrans-3952
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接
- en: 'The connections are instantiated by selecting two consecutive layers of an
    index *n* (with respect to *n + 1*) as a source (with respect to destination).
    A connection between two consecutive layers implements the matrix of synapses
    as the *(w[ij]* *, ∆w[ij])* pairs. The `MLPConnection` instance is created with
    the following parameters (line `16`):'
  id: totrans-3953
  prefs: []
  type: TYPE_NORMAL
  zh: 连接通过选择索引*n*的两个连续层（相对于*n + 1*）作为源（相对于目标）来实例化。两个连续层之间的连接实现了突触矩阵，作为*(w[ij]* *,
    ∆w[ij])*对。`MLPConnection`实例使用以下参数创建（行`16`）：
- en: Configuration parameters, `config`
  id: totrans-3954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置参数，`config`
- en: The source layer, sometimes known as the ingress layer, `src`
  id: totrans-3955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源层，有时也称为入口层，`src`
- en: The `dst` destination (or egress) layer
  id: totrans-3956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dst`目标（或出口）层'
- en: A reference to the `model` if it has already been generated through training
    or `None` if the model has not been trained
  id: totrans-3957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型已经通过训练生成，则引用`model`，如果没有训练，则为`None`
- en: An implicitly defined operating `mode` or objective `mode`
  id: totrans-3958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐式定义的操作`模式`或目标`模式`
- en: 'The `MLPConnection` class is defined as follows:'
  id: totrans-3959
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLPConnection`类定义如下：'
- en: '[PRE316]'
  id: totrans-3960
  prefs: []
  type: TYPE_PRE
  zh: '[PRE316]'
- en: The last step in the initialization of the MLP algorithm is the selection of
    the initial (usually random) values of the weights (synapse) (line `17`).
  id: totrans-3961
  prefs: []
  type: TYPE_NORMAL
  zh: MLP算法初始化的最后一步是选择权重（突触）的初始值（通常是随机的）（行`17`）。
- en: The `MLPConnection` methods implement the forward propagation of weights' computation
    for this `connectionForwardPropagation` connection (line `18`) and the backward
    propagation of the delta error during training `connectionBackpropagation` (line
    `19`). These methods are described in the next section related to the training
    of the MLP model.
  id: totrans-3962
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLPConnection`方法实现了`connectionForwardPropagation`连接的权重计算的前向传播（行`18`）和训练期间的delta误差的反向传播`connectionBackpropagation`（行`19`）。这些方法在下一节中描述，该节与MLP模型的训练相关。'
- en: The initialization weights
  id: totrans-3963
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 权重的初始化
- en: The initialization values for the weights depends is domain specific. Some problems
    require a very small range, less than *1e-3*, while others use the probability
    space *[0, 1]*. The initial values have an impact on the number of epochs required
    to converge toward an optimal set of weights [9:6].
  id: totrans-3964
  prefs: []
  type: TYPE_NORMAL
  zh: 权重的初始化值取决于特定领域。一些问题需要一个非常小的范围，小于*1e-3*，而其他问题则使用概率空间*[0, 1]*。初始值会影响收敛到最优权重集所需的epoch数量[9:6]。
- en: 'Our implementation relies on the sigmoid activation function and uses the range
    *[0, BETA/sqrt(numOutputs + 1)]* (line `20`). However, the user can select a different
    range for random values, such as *[-r, +r]* for the *tanh* activation function.
    The weight of the bias is obviously defined as *w[0]* *=+1*, and its weight adjustment
    is initialized as *∆w[0] = 0*, as shown here (line `20`):'
  id: totrans-3965
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现依赖于sigmoid激活函数，并使用范围*[0, BETA/sqrt(numOutputs + 1)]*（行`20`）。然而，用户可以选择不同的随机值范围，例如*tanh*激活函数的*[-r,
    +r]*。偏置的权重显然定义为*w[0]* *=+1*，其权重调整初始化为*∆w[0] = 0*，如下所示（行`20`）：
- en: '[PRE317]'
  id: totrans-3966
  prefs: []
  type: TYPE_PRE
  zh: '[PRE317]'
- en: The connection derives its weights or synapses from a model (line `21`) if it
    has already been created through training.
  id: totrans-3967
  prefs: []
  type: TYPE_NORMAL
  zh: 如果连接已经通过训练创建，则其权重或突触来自模型（行`21`）。
- en: The model
  id: totrans-3968
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: 'The `MLPNetwork` class defines the topological model of the multilayer perceptron.
    The weights or synapses are the attributes of the model of the `MLPModel` type
    generated through training:'
  id: totrans-3969
  prefs: []
  type: TYPE_NORMAL
  zh: '`MLPNetwork`类定义了多层感知器的拓扑模型。权重或突触是多层感知器模型`MLPModel`类型的属性，通过训练生成：'
- en: '[PRE318]'
  id: totrans-3970
  prefs: []
  type: TYPE_PRE
  zh: '[PRE318]'
- en: The model can be stored in a simple key-value pair JSON, CVS, or sequence file.
  id: totrans-3971
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以存储在简单的键值对JSON、CVS或序列文件中。
- en: Note
  id: totrans-3972
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: '**Encapsulation and the model factory**'
  id: totrans-3973
  prefs: []
  type: TYPE_NORMAL
  zh: '**封装和模型工厂**'
- en: 'The network components: connections, layers, and synapses are implemented as
    top-level classes for the sake of clarity. However, there is no need for the model
    to expose its inner workings to the client code. These components should be declared
    as an inner class to the model. A factory design pattern would be perfectly appropriate
    to instantiate an `MLPNetwork` instance dynamically [9:7].'
  id: totrans-3974
  prefs: []
  type: TYPE_NORMAL
  zh: 网络组件：连接、层和突触被实现为清晰起见的顶级类。然而，模型不需要将其内部工作暴露给客户端代码。这些组件应声明为模型的内部类。工厂设计模式非常适合动态实例化`MLPNetwork`实例[9:7]。
- en: Once initialized, the MLP model is ready to be trained using a combination of
    forward propagation, output error back propagation, and iterative adjustment of
    weights and gradients of weights.
  id: totrans-3975
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦初始化，MLP模型就准备好使用前向传播、输出误差反向传播和权重及权重梯度的迭代调整组合进行训练。
- en: Problem types (modes)
  id: totrans-3976
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题类型（模式）
- en: 'There are three distinct types of problems or operating modes associated with
    the multilayer perceptron:'
  id: totrans-3977
  prefs: []
  type: TYPE_NORMAL
  zh: 与多层感知器相关联的有三种不同类型的问题或操作模式：
- en: '**The binomial classification** (binary) with two classes and one output'
  id: totrans-3978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二项式分类**（二元）具有两个类别和一个输出'
- en: '**The multinomial classification** (multiclass) with *n* classes and output'
  id: totrans-3979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式分类**（多类别）具有*n*个类别和输出'
- en: '**Regression**'
  id: totrans-3980
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**'
- en: 'Each operating mode has distinctive error, hidden layer, and output layer activation
    functions, as illustrated in the following table:'
  id: totrans-3981
  prefs: []
  type: TYPE_NORMAL
  zh: 每种操作模式都有独特的错误、隐藏层和输出层激活函数，如下表所示：
- en: '| Operating modes | Error function | Hidden layer activation function | Output
    layer activation function |'
  id: totrans-3982
  prefs: []
  type: TYPE_TB
  zh: '| 操作模式 | 错误函数 | 隐藏层激活函数 | 输出层激活函数 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-3983
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Binomial classification | Cross-entropy | Sigmoid | Sigmoid |'
  id: totrans-3984
  prefs: []
  type: TYPE_TB
  zh: '| 二项式分类 | 交叉熵 | Sigmoid | Sigmoid |'
- en: '| Multinomial classification | Sum of squares error or mean squared error |
    Sigmoid | Softmax |'
  id: totrans-3985
  prefs: []
  type: TYPE_TB
  zh: '| 多项式分类 | 平方误差和或均方误差 | Sigmoid | Softmax |'
- en: '| Regression | Sum of squares error or mean squared error | Sigmoid | Linear
    |'
  id: totrans-3986
  prefs: []
  type: TYPE_TB
  zh: '| 回归 | 平方误差和或均方误差 | Sigmoid | 线性 |'
- en: '*A table for operating modes of the multilayer perceptron*'
  id: totrans-3987
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*多层感知器的操作模式表*'
- en: The cross-entropy is described by the mathematical expressions **M6** and **M7**
    and the softmax uses the formula **M8** in the *Step 1 – input forward propagation*
    section under *The training epoch*.
  id: totrans-3988
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵由数学表达式**M6**和**M7**描述，而softmax在**训练周期**下的**步骤1 – 输入前向传播**中使用公式**M8**。
- en: Online training versus batch training
  id: totrans-3989
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线训练与批量训练
- en: 'One important issue is to find a strategy to conduct the training of a time
    series as an ordered sequence of data. There are two strategies to create an MLP
    model for a time series:'
  id: totrans-3990
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的问题是找到一种策略来按有序数据序列进行时间序列的训练。有两种策略可以创建用于时间序列的MLP模型：
- en: '**Batch training**: The entire time series is processed at once as a single
    input to the neural network. The weights (synapses) are updated at each epoch
    using the sum of the squared errors on the output of the time series. The training
    exits once the sum of the squared errors meets the convergence criteria.'
  id: totrans-3991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量训练**：整个时间序列一次作为单个输入处理到神经网络中。在每个周期使用时间序列输出的平方误差总和更新权重（突触）。一旦平方误差总和满足收敛标准，训练就会退出。'
- en: '**Online training**: The observations are fed to the neural network one at
    a time. Once the time series has been processed, the total of the sum of the squared
    errors (`sse`) for the time series for all the observations are computed. If the
    exit condition is not met, the observations are reprocessed by the network.![Online
    training versus batch training](img/image01510.jpeg)'
  id: totrans-3992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线训练**：一次将观测值输入到神经网络中。一旦处理完时间序列，就会计算所有观测值的时间序列平方误差总和（`sse`）。如果未满足退出条件，观测值将被网络重新处理。![在线训练与批量训练](img/image01510.jpeg)'
- en: An illustration on online and batch training
  id: totrans-3993
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在线和批量训练的示意图
- en: An online training is faster than batch training because the convergence criterion
    has to be met for each data point, possibly resulting in a smaller number of epochs
    [9:12]. Techniques such as the momentum factor, which is described earlier, or
    any adaptive learning scheme improves the performance and accuracy of the online
    training methodology.
  id: totrans-3994
  prefs: []
  type: TYPE_NORMAL
  zh: 在线训练比批量训练快，因为每个数据点都必须满足收敛标准，这可能导致更少的周期数 [9:12]。如前所述的动量因子或任何自适应学习方案可以提高在线训练方法的表现和准确性。
- en: The online training strategy is applied to all the test cases of this chapter.
  id: totrans-3995
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有测试案例都应用了在线训练策略。
- en: The training epoch
  id: totrans-3996
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练周期
- en: 'The training of the model processes the training observations iteratively multiple
    times. A training cycle or iteration is known as an **epoch**. The order of observations
    is shuffled for each epoch. The three steps of the training cycle are as follows:'
  id: totrans-3997
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的训练通过迭代多次处理训练观测值。一个训练周期或迭代被称为**周期**。每个周期观测值的顺序都会被打乱。训练周期的三个步骤如下：
- en: Forward the propagation of the input value for a specific epoch.
  id: totrans-3998
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入值的前向传播推进到特定周期。
- en: Computation and backpropagation of the output error.
  id: totrans-3999
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出错误的计算和反向传播。
- en: Evaluate the convergence criteria and exit if the criteria is met.
  id: totrans-4000
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估收敛标准，如果满足标准则退出。
- en: The computation of the network weights during training can use the difference
    between labeled data and actual output for each layer. But this solution is not
    feasible because the output of the hidden layers is actually unknown. The solution
    is to propagate the error on the output values (predicted values) backward to
    the input layer through the hidden layers, if an error is defined.
  id: totrans-4001
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程中网络权重的计算可以使用每个层的标签数据和实际输出的差异。但这种方法不可行，因为隐藏层的输出实际上是未知的。解决方案是将输出值（预测值）上的错误反向传播到输入层，通过隐藏层，如果定义了错误。
- en: 'The three steps of the training cycle or training epoch are summarized in the
    following diagram:'
  id: totrans-4002
  prefs: []
  type: TYPE_NORMAL
  zh: 训练周期或训练周期的三个步骤总结如下图所示：
- en: '![The training epoch](img/image01511.jpeg)'
  id: totrans-4003
  prefs: []
  type: TYPE_IMG
  zh: '![训练周期](img/image01511.jpeg)'
- en: An iterative implementation of the training for MLP
  id: totrans-4004
  prefs: []
  type: TYPE_NORMAL
  zh: MLP训练的迭代实现
- en: 'Let''s apply the three steps of a training epoch in the `trainEpoch` method
    of the `MLPNetwork` class using a simple `foreach` Scala higher order function,
    as shown here:'
  id: totrans-4005
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `MLPNetwork` 类的 `trainEpoch` 方法中使用简单的 Scala 高阶函数 `foreach` 应用训练周期的三个步骤，如下所示：
- en: '[PRE319]'
  id: totrans-4006
  prefs: []
  type: TYPE_PRE
  zh: '[PRE319]'
- en: 'You can certainly recognize the first two stages of the training cycle: the
    forward propagation of the input and the backpropagation of the error of the online
    training of a single epoch.'
  id: totrans-4007
  prefs: []
  type: TYPE_NORMAL
  zh: 你当然可以识别出训练周期的前两个阶段：输入的前向传播和单个周期的在线训练错误的反向传播。
- en: The execution of the training of the network for one epoch, `trainEpoch`, initializes
    the input layer with observations, `x` (line `22`). The input values are propagated
    through the network by invoking `connectionForwardPropagation` for each connection
    (line `23`). The `delta` error is initialized from the values in the output layer
    and the expected values, `y` (line `24`).
  id: totrans-4008
  prefs: []
  type: TYPE_NORMAL
  zh: 网络在一个周期 `trainEpoch` 中的训练执行，初始化输入层为观察值 `x`（第 22 行）。通过调用每个连接的 `connectionForwardPropagation`
    方法（第 23 行），将输入值通过网络传播。`delta` 错误从输出层和期望值 `y`（第 24 行）的值初始化。
- en: The training method iterates through the connections backward to propagate the
    error through each connection by invoking the `connectionBackpropagation` method
    on the backward iterator, `bckIterator` (line `25`). Finally, the training method
    returns the cumulative error, mean square error, or cross entropy, according to
    the operating mode (line `26`).
  id: totrans-4009
  prefs: []
  type: TYPE_NORMAL
  zh: 训练方法通过在反向迭代器 `bckIterator` 上调用 `connectionBackpropagation` 方法反向遍历连接，以通过每个连接传播错误。最后，根据操作模式（第
    26 行），训练方法返回累积错误、均方误差或交叉熵。
- en: This approach is not that different than the beta (or backward) pass in the
    hidden Markov model, which was covered in the *Beta – the backward pass* section
    in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"),
    *Sequential Data Models*.
  id: totrans-4010
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法与隐藏马尔可夫模型中的 beta（或反向）传递没有太大区别，这在第 7 章 *Beta – 反向传递* 节中有所介绍，该节在 *序列数据模型*
    中。
- en: 'Let''s take a look at the implementation of the forward and backward propagation
    algorithm for each type of connection:'
  id: totrans-4011
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每种类型连接的前向和反向传播算法的实现：
- en: An input or hidden layer to a hidden layer
  id: totrans-4012
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输入层或隐藏层到隐藏层
- en: A hidden layer to an output layer
  id: totrans-4013
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个隐藏层到输出层
- en: Step 1 – input forward propagation
  id: totrans-4014
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 1 – 输入前向传播
- en: As mentioned earlier, the output values of a hidden layer are computed as the
    sigmoid or hyperbolic tangent of the dot product of the weights *w[ij]* and the
    input values *x[i]*.
  id: totrans-4015
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，隐藏层的输出值是计算为权重 *w[ij]* 和输入值 *x[i]* 的点积的 sigmoid 或双曲正切。
- en: 'In the following diagram, the MLP algorithm computes the linear product of
    the weights *w[ij]* and input *x[i]* for the hidden layer. The product is then
    processed by the activation function *σ* (the sigmoid or hyperbolic tangent).
    The output values *z[j]* are then combined with the weights *v[ij]* of the output
    layer that doesn''t have an activation function:'
  id: totrans-4016
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，MLP 算法计算隐藏层的权重 *w[ij]* 和输入 *x[i]* 的线性乘积。然后，该乘积通过激活函数 *σ*（sigmoid 或双曲正切）进行处理。输出值
    *z[j]* 然后与输出层没有激活函数的权重 *v[ij]* 结合：
- en: '![Step 1 – input forward propagation](img/image01512.jpeg)'
  id: totrans-4017
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 1 – 输入前向传播](img/image01512.jpeg)'
- en: The distribution of weights in MLP hidden and output layers
  id: totrans-4018
  prefs: []
  type: TYPE_NORMAL
  zh: MLP隐藏层和输出层中权重的分布
- en: The mathematical formulation of the output of a neuron *j* is defined as a composition
    of the activation function and the dot product of the weights *w[ij]* and input
    values *x[i]*.
  id: totrans-4019
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元 *j* 输出的数学公式定义为激活函数和权重 *w[ij]* 与输入值 *x[i]* 的点积的组合。
- en: Note
  id: totrans-4020
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M3: The computation (or prediction) of the output layer from the output values
    *z[j]* of the preceding hidden layer and the weights *vkj* is defined as:'
  id: totrans-4021
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 1 – input forward propagation](img/image01513.jpeg)'
  id: totrans-4022
  prefs: []
  type: TYPE_IMG
- en: 'M4: The estimation of the output values for a binary classification with an
    activation function *σ* is defined as:'
  id: totrans-4023
  prefs: []
  type: TYPE_NORMAL
- en: '![Step 1 – input forward propagation](img/image01514.jpeg)'
  id: totrans-4024
  prefs: []
  type: TYPE_IMG
- en: As seen in the network architecture section, the output values for the multinomial
    (or multiclass) classification with more than two classes are normalized using
    an exponential function, as described in the following *Softmax* section.
  id: totrans-4025
  prefs: []
  type: TYPE_NORMAL
- en: The computational flow
  id: totrans-4026
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The computation of the output values *y* from the input *x* is known as the
    input forward propagation. For the sake of simplicity, we represent the forward
    propagation between layers with the following block diagram:'
  id: totrans-4027
  prefs: []
  type: TYPE_NORMAL
- en: '![The computational flow](img/image01515.jpeg)'
  id: totrans-4028
  prefs: []
  type: TYPE_IMG
- en: A computation model of the input forward propagation
  id: totrans-4029
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram conveniently illustrates a computational model for the
    input forward propagation, as the programmatic relation between the source and
    destination layers and their connectivity. The input *x* is propagated forward
    through each connection.
  id: totrans-4030
  prefs: []
  type: TYPE_NORMAL
- en: The `connectionForwardPropagation` method computes the dot product of the weights
    and the input values and applies the activation function, in the case of hidden
    layers, for each connection. Therefore, it is a member of the `MLPConnection`
    class.
  id: totrans-4031
  prefs: []
  type: TYPE_NORMAL
- en: 'The forward propagation of input values across the entire network is managed
    by the MLP algorithm itself. The forward propagation of the input value is used
    in the classification or prediction *y = f(x)*. It depends on the value weights
    *w[ij]* and *v[ij]* that need to be estimated through training. As you may have
    guessed, the weights define the model of a neural network similar to the regression
    models. Let''s take a look at the `connectionForwardPropagation` method of the
    `MLPConnection` class:'
  id: totrans-4032
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE320]'
  id: totrans-4033
  prefs: []
  type: TYPE_PRE
  zh: '[PRE320]'
- en: The first step is to compute the linear inner (or dot) product (refer to the
    *Time series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing*) of the output, `_output`, of the current
    source layer for this connection and the synapses (weights) (line `27`). The activation
    function is computed by applying the `activate` method of the destination layer
    to the dot product (line `28`). Finally, the computed value, `_output`, is used
    to initialize the output for the destination layer (line `29`).
  id: totrans-4034
  prefs: []
  type: TYPE_NORMAL
- en: Error functions
  id: totrans-4035
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As mentioned in the *Problem types (modes)* section, there are two approaches
    to compute the error or loss on the output values:'
  id: totrans-4036
  prefs: []
  type: TYPE_NORMAL
- en: The sum of the squared errors between expected and predicted output values,
    as defined in the **M5** mathematical expression
  id: totrans-4037
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-entropy of expected and predicted values described in the **M6** and **M7**
    mathematical formulas
  id: totrans-4038
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4039
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M5: The sum of the squared errors *ε* and mean square error for predicted values
    *~y* and expected values *y* are defined as:'
  id: totrans-4040
  prefs: []
  type: TYPE_NORMAL
- en: '![Error functions](img/image01516.jpeg)'
  id: totrans-4041
  prefs: []
  type: TYPE_IMG
- en: 'M6: Cross entropy for a single output value *y* is defined as:'
  id: totrans-4042
  prefs: []
  type: TYPE_NORMAL
- en: '![Error functions](img/image01517.jpeg)'
  id: totrans-4043
  prefs: []
  type: TYPE_IMG
- en: 'M7: Cross entropy for a multivariable output vector *y* is defined as:'
  id: totrans-4044
  prefs: []
  type: TYPE_NORMAL
- en: '![Error functions](img/image01518.jpeg)'
  id: totrans-4045
  prefs: []
  type: TYPE_IMG
- en: The sum of squared errors and mean squared error functions have been described
    in the *Time series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*.
  id: totrans-4046
  prefs: []
  type: TYPE_NORMAL
- en: 'The `crossEntropy` method of the `XTSeries` object for a single variable is
    implemented as follows:'
  id: totrans-4047
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE321]'
  id: totrans-4048
  prefs: []
  type: TYPE_PRE
  zh: '[PRE321]'
- en: 'The computation of the cross entropy for multiple variable features as a signature
    is similar to the single variable case:'
  id: totrans-4049
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE322]'
  id: totrans-4050
  prefs: []
  type: TYPE_PRE
  zh: '[PRE322]'
- en: Operating modes
  id: totrans-4051
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the *network architecture* section, you learned that the structure of the
    output layer depends on the type of problems that need to be resolved, also known
    as operating modes. Let''s encapsulate the different operating modes (binomial,
    multinomial classification, and regression) into a class hierarchy, implementing
    the `MLPMode` trait. The `MLPMode` trait has two methods that is specific to the
    type of the problem:'
  id: totrans-4052
  prefs: []
  type: TYPE_NORMAL
- en: '`apply`: This is the transformation applied to the output values'
  id: totrans-4053
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`error`: This is the computation of the cumulative error for the entire observation
    set'
  id: totrans-4054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code will be as follows:'
  id: totrans-4055
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE323]'
  id: totrans-4056
  prefs: []
  type: TYPE_PRE
  zh: '[PRE323]'
- en: The `apply` method applies a transformation to the output layer, as described
    in the last column of the operating modes table (line `30`). The `error` function
    computes the cumulative error or loss in the output layer for all the observations,
    as described in the first column of the operating modes table (line `31`).
  id: totrans-4057
  prefs: []
  type: TYPE_NORMAL
- en: 'The transformation in the output layer of the `MLPBinClassifier` binomial (two-class)
    classifier consists of applying the `sigmoid` function to each `output` value
    (line `32`). The cumulative error is computed as the cross entropy of the expected
    output, labels, and the predicted output (line `33`):'
  id: totrans-4058
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE324]'
  id: totrans-4059
  prefs: []
  type: TYPE_PRE
  zh: '[PRE324]'
- en: 'The regression mode for the multilayer perceptron is defined according to the
    operating modes table in the *Problem types (modes)* section:'
  id: totrans-4060
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE325]'
  id: totrans-4061
  prefs: []
  type: TYPE_PRE
  zh: '[PRE325]'
- en: 'The multinomial classifier mode is defined by the `MLPMultiClassifier` class.
    It uses the `softmax` method to boost the `output` with the highest value, as
    shown in the following code:'
  id: totrans-4062
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE326]'
  id: totrans-4063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE326]'
- en: The `softmax` method is applied to the actual `output` value, not the bias.
    Therefore, the first node *y(0) = +1* has to be dropped before applying the `softmax`
    normalization.
  id: totrans-4064
  prefs: []
  type: TYPE_NORMAL
- en: Softmax
  id: totrans-4065
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the case of a classification problem with *K* classes (*K > 2*), the output
    has to be converted into a probability *[0, 1]*. For problems that require a large
    number of classes, there is a need to boost the output *y[k]* with the highest
    value (or probability). This process is known as **exponential normalization**
    or softmax [9:8].
  id: totrans-4066
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4067
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M8: The softmax formula for the multinomial (*K > 2*) classification is as
    follows:'
  id: totrans-4068
  prefs: []
  type: TYPE_NORMAL
- en: '![Softmax](img/image01519.jpeg)'
  id: totrans-4069
  prefs: []
  type: TYPE_IMG
- en: 'Here is the simple implementation of the `softmax` method of the `MLPMultiClassifier`
    class:'
  id: totrans-4070
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE327]'
  id: totrans-4071
  prefs: []
  type: TYPE_PRE
  zh: '[PRE327]'
- en: The `softmax` method implements the **M8** mathematical expression. First, the
    method computes the `expY` exponential values of the output values (line `34`).
    The exponentially transformed outputs are then normalized by their sum, `expYSum`,
    (line `35`) to generate the array of the `softmaxValues` output (line `36`). Once
    again, there is no need to update the bias element *y(0)*.
  id: totrans-4072
  prefs: []
  type: TYPE_NORMAL
- en: The second step in the training phase is to define and initialize the matrix
    of delta error values to be back propagated between layers from the output layer
    back to the input layer.
  id: totrans-4073
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – error backpropagation
  id: totrans-4074
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The error backpropagation is an algorithm that estimates the error for the hidden
    layer in order to compute the change in weights of the network. It takes the sum
    of squared errors of the output as the input.
  id: totrans-4075
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4076
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The convention for computing the cumulative error**'
  id: totrans-4077
  prefs: []
  type: TYPE_NORMAL
- en: Some authors refer to the backpropagation as a training methodology for an MLP,
    which applies the gradient descent to the output error defined as either the sum
    of squared errors, or the mean squared error for multinomial classification or
    regression. In this chapter, we keep the narrower definition of the backpropagation
    as the backward computation of the sum of squared errors.
  id: totrans-4078
  prefs: []
  type: TYPE_NORMAL
- en: Weights' adjustment
  id: totrans-4079
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The connection weights *∆v* and *∆w* are adjusted by computing the sum of the
    derivatives of the error, over the weights scaled with a learning factor. The
    gradient of weights are then used to compute the error of the output of the source
    layer [9:9].
  id: totrans-4080
  prefs: []
  type: TYPE_NORMAL
- en: The simplest algorithm to update the weights is the gradient descent [9:10].
    The batch gradient descent was introduced in *Let's kick the tires* in [Chapter
    1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"), *Getting Started*.
  id: totrans-4081
  prefs: []
  type: TYPE_NORMAL
- en: The gradient descent is a very simple and robust algorithm. However, it can
    be slower in converging toward a global minimum than the conjugate gradient or
    the quasi-Newton method (refer to the *Summary of optimization techniques* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*).
  id: totrans-4082
  prefs: []
  type: TYPE_NORMAL
- en: There are several methods available to speed up the convergence of the gradient
    descent toward a minimum, such as the momentum factor and adaptive learning coefficient
    [9:11].
  id: totrans-4083
  prefs: []
  type: TYPE_NORMAL
- en: Large variations of the weights during training increase the number of epochs
    required for the model (connection weights) to converge. This is particularly
    true for a training strategy known as online training. The training strategies
    are discussed in the next section. The momentum factor α is used for the remaining
    section of the chapter.
  id: totrans-4084
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4085
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M9: The learning rate'
  id: totrans-4086
  prefs: []
  type: TYPE_NORMAL
- en: 'The computation of neural network weights using the gradient descent is as
    follows:'
  id: totrans-4087
  prefs: []
  type: TYPE_NORMAL
- en: '![Weights'' adjustment](img/image01520.jpeg)'
  id: totrans-4088
  prefs: []
  type: TYPE_IMG
- en: 'M10: The learning rate and momentum factor'
  id: totrans-4089
  prefs: []
  type: TYPE_NORMAL
- en: 'The computation of neural network weights using the gradient descent method
    with the momentum coefficient *α* is as follows:'
  id: totrans-4090
  prefs: []
  type: TYPE_NORMAL
- en: '![Weights'' adjustment](img/image01521.jpeg)'
  id: totrans-4091
  prefs: []
  type: TYPE_IMG
- en: The simplest version of the gradient descent algorithm (**M9**) is selected
    by simply setting the momentum factor *α* to zero in the generic (**M10**) mathematical
    expression.
  id: totrans-4092
  prefs: []
  type: TYPE_NORMAL
- en: The error propagation
  id: totrans-4093
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The objective of the training of a perceptron is to minimize the loss or cumulative
    error for all the input observations as either the sum of squared errors or the
    cross entropy as computed at the output layer. The error *ε[k]* for each output
    neuron *y[k]* is computed as the difference between a predicted output value and
    label output value. The error cannot be computed on output values of the hidden
    layers *z[j]* because the label values for those layers are unknown:'
  id: totrans-4094
  prefs: []
  type: TYPE_NORMAL
- en: '![The error propagation](img/image01522.jpeg)'
  id: totrans-4095
  prefs: []
  type: TYPE_IMG
- en: An illustration of the back-propagation algorithm
  id: totrans-4096
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the sum of squared errors, the partial derivative of the cumulative
    error over each weight of the output layer is computed as the composition of the
    derivative of the square function and the derivative of the dot product of weights
    and the input *z*.
  id: totrans-4097
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned earlier, the computation of the partial derivative of the error
    over the weights of the hidden layer is a bit tricky. Fortunately, the mathematical
    expression for the partial derivative can be written as the product of three partial
    derivatives:'
  id: totrans-4098
  prefs: []
  type: TYPE_NORMAL
- en: The derivative of the cumulative error *ε* over the output value *y[k]*
  id: totrans-4099
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The derivative of the output value *yk* over the hidden value *z[j]*, knowing
    that the derivative of a sigmoid *σ* is *σ(1 - σ)*
  id: totrans-4100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The derivative of the output of the hidden layer *z[j]* over the weights *w[ij]*
  id: totrans-4101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The decomposition of the partial derivative produces the following formulas
    for updating the synapses' weights for the output and hidden neurons by propagating
    the error (or loss) *ε*.
  id: totrans-4102
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Output weights'' adjustment**'
  id: totrans-4104
  prefs: []
  type: TYPE_NORMAL
- en: 'M11: The computation of delta *δ* and weight adjustment *∆v* for the output
    layer with the predicted value *~y* and expected value *y*, and output *z* of
    the hidden layer is as follows:'
  id: totrans-4105
  prefs: []
  type: TYPE_NORMAL
- en: '![The error propagation](img/image01523.jpeg)'
  id: totrans-4106
  prefs: []
  type: TYPE_IMG
- en: '**Hidden weights'' adjustment**'
  id: totrans-4107
  prefs: []
  type: TYPE_NORMAL
- en: 'M12: The computation of delta *δ* and weight adjustment *∆w* for the hidden
    layer with the predicted value *~y* and expected value *y*, output *z* of the
    hidden layer, and the input value *x* is as follows:'
  id: totrans-4108
  prefs: []
  type: TYPE_NORMAL
- en: '![The error propagation](img/image01524.jpeg)'
  id: totrans-4109
  prefs: []
  type: TYPE_IMG
- en: 'The matrix *δ[ij]* is defined by the `delta` matrix in the `Delta` class. It
    contains the basic parameters to be passed between layers, traversing the network
    from the output layer back to the input layer. The parameters are as follows:'
  id: totrans-4110
  prefs: []
  type: TYPE_NORMAL
- en: Initial `loss` or error computed at the output layer
  id: totrans-4111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix of the `delta` values from the current connection
  id: totrans-4112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weights or `synapses` of the downstream connection (or connection between the
    destination layer and the following layer)
  id: totrans-4113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code will be as follows:'
  id: totrans-4114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE328]'
  id: totrans-4115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE328]'
- en: 'The first instance of the `Delta` class is generated for the output layer using
    the expected values *y*, then propagated to the preceding hidden layer in the
    `MLPNetwork.trainEpoch` method (line `24`):'
  id: totrans-4116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE329]'
  id: totrans-4117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE329]'
- en: 'The **M11** mathematical expression is implemented by the `delta` method of
    the `MLPOutLayer` class:'
  id: totrans-4118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE330]'
  id: totrans-4119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE330]'
- en: The method generates the matrix of delta values associated with the output layer
    (line `34`). The **M11** formula is actually implemented by the fold over the
    `srcOut` output value (line `35`). The new delta instances are returned to the
    `trainEpoch` method of `MLPNetwork` and backpropagated to the preceding hidden
    layer (line `36`).
  id: totrans-4120
  prefs: []
  type: TYPE_NORMAL
- en: 'The `delta` method of the `MLPLayer` class implements the **M12** mathematical
    expression:'
  id: totrans-4121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE331]'
  id: totrans-4122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE331]'
- en: The implementation of the `delta` method is similar to the `MLPOutLayer.delta`
    method. It extracts the weights `v` from the output layer through transposition
    (line `37`). The values of the delta matrix in the hidden connection is computed
    by applying the **M12** formula (line `38`). The new delta instance is returned
    to the `trainEpoch` method (line `39`) to be propagated to the preceding hidden
    layer if one exists.
  id: totrans-4123
  prefs: []
  type: TYPE_NORMAL
- en: The computational model
  id: totrans-4124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The computational model for the error backpropagation algorithm is very similar
    to the forward propagation of the input. The main difference is that the propagation
    of *δ* (delta) is performed from the output layer to the input layer. The following
    diagram illustrates the computational model of the backpropagation in the case
    of two hidden layers *z[s]* and *z[t]*:'
  id: totrans-4125
  prefs: []
  type: TYPE_NORMAL
- en: '![The computational model](img/image01525.jpeg)'
  id: totrans-4126
  prefs: []
  type: TYPE_IMG
- en: An illustration of the backpropagation of the delta error
  id: totrans-4127
  prefs: []
  type: TYPE_NORMAL
- en: The `connectionBackPropagation` method propagates the error back from the output
    layer or one of the hidden layers to the preceding layer. It is a member of the
    `MLPConnection` class. The backpropagation of the output error across the entire
    network is managed by the `MLP` class.
  id: totrans-4128
  prefs: []
  type: TYPE_NORMAL
- en: 'It implements the two set of equations where `synapses(j)(i)._1` are the weights
    *w[ji]*, `dst.delta` is the vector of the error derivative in the destination
    layer, and `src.delta` is the error derivative of the output in the source layer,
    as shown here:'
  id: totrans-4129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE332]'
  id: totrans-4130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE332]'
- en: The `connectionBackPropagation` method takes `delta` associated with the destination
    (output) layer as an argument (line `40`). The output layer is the last layer
    of the network, and therefore, the synapses for the following connection is defined
    as an empty matrix of length zero (line `41`). The method computes the new `delta`
    matrix for the hidden layer using the `delta.loss` error and output from the source
    layer, `src.output` (line `42`). The weights (synapses) are updated using the
    gradient descent with the momentum factor as in the **M10** mathematical expression
    (line `43`).
  id: totrans-4131
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The adjustable learning rate**'
  id: totrans-4133
  prefs: []
  type: TYPE_NORMAL
- en: The computation of the new weights of a connection for each new epoch can be
    further improved by making the learning adjustable.
  id: totrans-4134
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – exit condition
  id: totrans-4135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The convergence criterion consists of evaluating the cumulative error (or loss)
    relevant to the operating mode (or problem) against a predefined `eps` convergence.
    The cumulative error is computed using either the sum of squares error formula
    (**M5**) or the cross-entropy formula (**M6** and **M7**). An alternative approach
    is to compute the difference of the cumulative error between two consecutive epochs
    and apply the `eps` convergence criteria as the exit condition.
  id: totrans-4136
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-4137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `MLP` class is defined as a data transformation of the `ITransform` type
    using a model implicitly generated from a training set, `xt`, as described in
    the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!* (line `44`).
  id: totrans-4138
  prefs: []
  type: TYPE_NORMAL
- en: 'The MLP algorithm takes the following parameters:'
  id: totrans-4139
  prefs: []
  type: TYPE_NORMAL
- en: '`config`: This is the configuration of the algorithm'
  id: totrans-4140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hidden`: This is an array of the size of the hidden layers if any'
  id: totrans-4141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`xt`: This is the time series of features used to train the model'
  id: totrans-4142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expected`: This is the labeled output values for training purpose'
  id: totrans-4143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mode`: This is the implicit operating mode or objective of the algorithm'
  id: totrans-4144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`f`: This is the implicit conversion from feature from type `T` to `Double`'
  id: totrans-4145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `V` type of the output of the prediction or classification method `|>`
    of this implicit transform is `DblArray` (line `45`):'
  id: totrans-4146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE333]'
  id: totrans-4147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE333]'
- en: 'The topology is created from the `xt` input variables, the `expected` values,
    and the configuration of `hidden` layers, if any (line `46`). The generation of
    the topology from parameters of the `MLPNetwork` class is illustrated in the following
    diagram:'
  id: totrans-4148
  prefs: []
  type: TYPE_NORMAL
- en: '![Putting it all together](img/image01526.jpeg)'
  id: totrans-4149
  prefs: []
  type: TYPE_IMG
- en: Topology encoding for multi-layer perceptrons
  id: totrans-4150
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, the `topology` of a neural network with three input variables:
    one output variable and two hidden layers of three neurons each is specified as
    `Array[Int](4, 3, 3, 1)`. The model is generated through training by invoking
    the `train` method (line `47`). Finally, the `|>` operator of the `ITransform`
    trait is used for classification, prediction, or regression, depending on the
    selected operating mode (line `48`).'
  id: totrans-4151
  prefs: []
  type: TYPE_NORMAL
- en: Training and classification
  id: totrans-4152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the training cycle or epoch is defined, it is merely a matter of defining
    and implementing a strategy to create a model using a sequence of data or time
    series.
  id: totrans-4153
  prefs: []
  type: TYPE_NORMAL
- en: Regularization
  id: totrans-4154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two approaches to find the most appropriate network architecture
    for a given classification or regression problem, which are follows:'
  id: totrans-4155
  prefs: []
  type: TYPE_NORMAL
- en: '**Destructive tuning**: Starting with a large network, and then removing nodes,
    synapses, and hidden layers that have no impact on the sum of squared errors'
  id: totrans-4156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Constructive tuning**: Starting with a small network, and then incrementally
    adding the nodes, synapses, and hidden layers that reduce the output error'
  id: totrans-4157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The destructive tuning strategy removes the synapses by zeroing out their weights.
    This is commonly accomplished using regularization.
  id: totrans-4158
  prefs: []
  type: TYPE_NORMAL
- en: You have seen that regularization is a powerful technique to address overfitting
    in the case of the linear and logistic regression in the *Ridge regression* section
    in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression and Regularization"),
    *Regression and Regularization*. Neural networks can benefit from adding a regularization
    term to the sum of squared errors. The larger the regularization factor is, the
    more likely some weights will be reduced to zero, thus reducing the scale of the
    network [9:13].
  id: totrans-4159
  prefs: []
  type: TYPE_NORMAL
- en: The model generation
  id: totrans-4160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `MLPModel` instance is created (trained) during the instantiation of the
    multilayer perceptron. The constructor iterates through the training cycles (or
    epochs) over all the data points of the `xt` time series, until the cumulative
    is smaller than the `eps` convergence criteria, as shown in the following code:'
  id: totrans-4161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE334]'
  id: totrans-4162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE334]'
- en: The `train` method instantiates an MLP network using the configuration and `topology`
    as the input (line `48`). The method executes multiple epochs until either the
    gradient descent with a momentum converges or the maximum number of allowed iterations
    is reached (line `50`). At each epoch, the method shuffles the input values and
    labels using the Fisher-Yates algorithm, invokes the `MLPNetwork.trainEpoch` method,
    and computes the `cumulErr` cumulative error (line `51`). This particular implementation
    compares the value of the cumulative error against the `eps` convergence criteria
    as the exit condition (line `52`).
  id: totrans-4163
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Tail recursive training of MLP**'
  id: totrans-4165
  prefs: []
  type: TYPE_NORMAL
- en: The training of the multilayer is implemented as an iterative process. It can
    be easily substituted with a tail recursion using weights and the cumulative error
    as the argument of the recursion.
  id: totrans-4166
  prefs: []
  type: TYPE_NORMAL
- en: Lazy views are used to reduce the unnecessary creation of objects (line `49`).
  id: totrans-4167
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The exit condition**'
  id: totrans-4169
  prefs: []
  type: TYPE_NORMAL
- en: In this implementation, the training initializes the model as `None` if it does
    not converge before the maximum number of epochs are reached. An alternative would
    be to generate a model even in the case of nonconvergence and add an accuracy
    metric to the model, as in our implementation of the support vector machine (refer
    to the *Training* section under *Support vector classifiers – SVC* in [Chapter
    8](part0200.xhtml#aid-5UNGG2 "Chapter 8. Kernel Models and Support Vector Machines"),
    *Kernel Models and Support Vector Machines*).
  id: totrans-4170
  prefs: []
  type: TYPE_NORMAL
- en: Once the model is created during the instantiation of the multilayer perceptron,
    it is available to predict or classify the class of a new observation.
  id: totrans-4171
  prefs: []
  type: TYPE_NORMAL
- en: The Fast Fisher-Yates shuffle
  id: totrans-4172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The *Step 5 – implementing the classifier* section under *Let''s kick the tires*
    in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting Started"), *Getting
    Started*, describes a home grown shuffling algorithm as an alternative to the
    `scala.util.Random.shuffle` method of the Scala standard library. This section
    describes an alternative shuffling mechanism known as the Fisher-Yates shuffling
    algorithm:'
  id: totrans-4173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE335]'
  id: totrans-4174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE335]'
- en: The Fisher-Yates algorithm creates an ordered sequence of integers (line `55`),
    and swaps each integer with another integer, randomly selected from the remaining
    of the initial sequences (line `52`). This implementation is particularly fast
    because the integers are swapped in place using the bit operator, also known as
    **bitwise swap** (line `54`).
  id: totrans-4175
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Tail recursive implementation of Fisher-Yates**'
  id: totrans-4177
  prefs: []
  type: TYPE_NORMAL
- en: The Fisher-Yates shuffling algorithm can be implemented using a tail recursion
    instead of an iteration.
  id: totrans-4178
  prefs: []
  type: TYPE_NORMAL
- en: Prediction
  id: totrans-4179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `|>` data transformation implements the runtime classification/prediction.
    It returns the predicted value that is normalized as a probability if the model
    was successfully trained and `None` otherwise. The methods invoke the forward
    prediction function of `MLPNetwork` (line `53`):'
  id: totrans-4180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE336]'
  id: totrans-4181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE336]'
- en: 'The `predict` method of `MLPNetwork` computes the output values from an input
    `x` using the forward propagation as follows:'
  id: totrans-4182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE337]'
  id: totrans-4183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE337]'
- en: Model fitness
  id: totrans-4184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The fitness of a model measures how well the model fits the training set. A
    model with a high-degree of fitness will likely overfit. The `fit` fitness method
    computes the mean squared errors of the predicted values against the labels (or
    expected values) of the training set. The method returns the percentage of observations
    for which the prediction value is correct, using the higher order `count` method:'
  id: totrans-4185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE338]'
  id: totrans-4186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE338]'
- en: Note
  id: totrans-4187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Model fitness versus accuracy**'
  id: totrans-4188
  prefs: []
  type: TYPE_NORMAL
- en: The fitness of a model against the training set reflects the degree the model
    fit the training set. The computation of the fitness does not involve a validation
    set. Quality parameters such as accuracy, precision, or recall measures the reliability
    or quality of the model against a validation set.
  id: totrans-4189
  prefs: []
  type: TYPE_NORMAL
- en: Our `MLP` class is now ready to tackle some classification challenges.
  id: totrans-4190
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  id: totrans-4191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before applying our multilayer perceptron to understand fluctuations in the
    currency market exchanges, let's get acquainted with some of the key learning
    parameters introduced in the first section.
  id: totrans-4192
  prefs: []
  type: TYPE_NORMAL
- en: The execution profile
  id: totrans-4193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's take a look at the convergence of the training of the multiple layer perceptron.
    The monitor trait (refer to the *Monitor* section under *Utility classes* in the
    [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic Concepts*)
    collects and displays some execution parameters. We select to extract the profile
    for the convergence of the multiple layer perceptron using the difference of the
    backpropagation errors between two consecutive episodes (or epochs).
  id: totrans-4194
  prefs: []
  type: TYPE_NORMAL
- en: 'The test profiles the convergence of the MLP using a learning rate of *η =
    0.03* and a momentum factor of *α = 0.3* for a multilayer perceptron with two
    input values: one hidden layer with three nodes and one output value. The test
    relies on synthetically generated random values:'
  id: totrans-4195
  prefs: []
  type: TYPE_NORMAL
- en: '![The execution profile](img/image01527.jpeg)'
  id: totrans-4196
  prefs: []
  type: TYPE_IMG
- en: The execution profile for the cumulative error for MLP
  id: totrans-4197
  prefs: []
  type: TYPE_NORMAL
- en: Impact of the learning rate
  id: totrans-4198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The purpose of the first exercise is to evaluate the impact of the learning
    rate *η* on the convergence of the training epoch, as measured by the cumulative
    error of all output variables. The observations `xt` (with respect to the labeled
    output `yt`) are synthetically generated using several noisy patterns such as
    `f1` (line `57`) and `f2` functions (line `58`), as follows:'
  id: totrans-4199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE339]'
  id: totrans-4200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE339]'
- en: The input values, `xt`, are synthetically generated by the `f1` function for
    half of the dataset and by the `f2` function for the other half (line `59`). The
    data generator for the expected values `yt` assigns the label 0.0 for the input
    values generated with the `f1` function and 1.0 for the input values created with
    `f2` (line `60`).
  id: totrans-4201
  prefs: []
  type: TYPE_NORMAL
- en: 'The test is run with a sample of size `TEST_SIZE` data points over a maximum
    of `NUM_EPOCHS` epochs, a single hidden layer of `HIDDENS.head` neurons with no
    `softmax` transformation, and the following MLP parameters:'
  id: totrans-4202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE340]'
  id: totrans-4203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE340]'
- en: The `testEta` method generates the profile or errors given different values
    of `eta`.
  id: totrans-4204
  prefs: []
  type: TYPE_NORMAL
- en: The operating `mode` has to be implicitly defined prior to the instantiation
    of the `MLP` class (line `61`). It is set as a binomial classifier of the `MLPBinClassifier`
    type. The execution profile data is collected by the `counters` method of the
    `Monitor` trait (line `62`) (refer to the *Monitor* section under *Utility classes*
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*).
  id: totrans-4205
  prefs: []
  type: TYPE_NORMAL
- en: 'The driver code for evaluating the impact of the learning rate on the convergence
    of the multilayer perceptron is quite simple:'
  id: totrans-4206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE341]'
  id: totrans-4207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE341]'
- en: 'The profile is created with the JFreeChart library and displayed in the following
    chart:'
  id: totrans-4208
  prefs: []
  type: TYPE_NORMAL
- en: '![Impact of the learning rate](img/image01528.jpeg)'
  id: totrans-4209
  prefs: []
  type: TYPE_IMG
- en: The impact of the learning rate on the MLP training
  id: totrans-4210
  prefs: []
  type: TYPE_NORMAL
- en: The chart illustrates that the MLP model training converges a lot faster with
    a larger value of learning rate. You need to keep in mind, however, that a very
    steep learning rate may lock the training process into a local minimum for the
    cumulative error, generating weights with lesser accuracy. The same configuration
    parameters are used to evaluate the impact of the momentum factor on the convergence
    of the gradient descent algorithm.
  id: totrans-4211
  prefs: []
  type: TYPE_NORMAL
- en: The impact of the momentum factor
  id: totrans-4212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's quantify the impact of the momentum factor *α* on the convergence of the
    training process toward an optimal model (synapse weights). The testing code is
    very similar to the evaluation of the impact of the learning rate.
  id: totrans-4213
  prefs: []
  type: TYPE_NORMAL
- en: 'The cumulative error for the entire time series is plotted in the following
    graph:'
  id: totrans-4214
  prefs: []
  type: TYPE_NORMAL
- en: '![The impact of the momentum factor](img/image01529.jpeg)'
  id: totrans-4215
  prefs: []
  type: TYPE_IMG
- en: The impact of the momentum factor on the MLP training
  id: totrans-4216
  prefs: []
  type: TYPE_NORMAL
- en: The preceding graph shows that the rate of the mean square error decreases as
    the momentum factor increases. In other words, the momentum factor has a positive
    although limited impact on the convergence of the gradient descent.
  id: totrans-4217
  prefs: []
  type: TYPE_NORMAL
- en: The impact of the number of hidden layers
  id: totrans-4218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s consider a multilayer perceptron with two hidden layers (7 and 3 neurons).
    The execution profile for the training shows that the cumulative error of the
    output converges abruptly after several epochs for which the descent gradient
    failed to find a direction:'
  id: totrans-4219
  prefs: []
  type: TYPE_NORMAL
- en: '![The impact of the number of hidden layers](img/image01530.jpeg)'
  id: totrans-4220
  prefs: []
  type: TYPE_IMG
- en: The execution profile of training of an MLP with two hidden layers
  id: totrans-4221
  prefs: []
  type: TYPE_NORMAL
- en: Let's apply our newfound knowledge regarding neural networks and the classification
    of variables that impact the exchange rate of a certain currency.
  id: totrans-4222
  prefs: []
  type: TYPE_NORMAL
- en: Test case
  id: totrans-4223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neural networks have been used in financial applications from risk management
    in mortgage applications and hedging strategies for commodities pricing, to predictive
    modeling of the financial markets [9:14].
  id: totrans-4224
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective of the test case is to understand the correlation factors between
    the exchange rate of some currencies, the spot price of gold, and the S&P 500
    index. For this exercise, we will use the following **exchange-traded funds**
    (**ETFs**) as proxies for the exchange rate of currencies:'
  id: totrans-4225
  prefs: []
  type: TYPE_NORMAL
- en: '**FXA**: This is the rate of an Australian dollar in US dollar'
  id: totrans-4226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FXB**: This is the rate of a British pound in US dollar'
  id: totrans-4227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FXE**: This is the rate of an Euro in US dollar'
  id: totrans-4228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FXC**: This is the rate of a Canadian dollar in US dollar'
  id: totrans-4229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FXF**: This is the rate of a Swiss franc in US dollar'
  id: totrans-4230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**FXY**: This is the rate of a Japanese yen in US dollar'
  id: totrans-4231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CYB**: This is the rate of a Chinese yuan in US dollar'
  id: totrans-4232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SPY**: This is the S&P 500 index'
  id: totrans-4233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GLD**: This is the price of gold in US dollar'
  id: totrans-4234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Practically, the problem to solve is to extract one or more regressive models
    that link one ETFs *y* with a basket of other ETFs *{x[i]} y=f(x[i])*. For example,
    is there a relation between the exchange rate of the Japanese yen (FXY) and a
    combination of the spot price for gold (GLD), exchange rate of the Euro in US
    dollar (FXE), the exchange rate of the Australian dollar in US dollar (FXA), and
    so on? If so, the regression *f* will be defined as *FXY = f (GLD, FXE, FXA)*.
  id: totrans-4235
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two charts visualize the fluctuation between currencies over
    a period of two and a half years. The first chart displays an initial group of
    potentially correlated ETFs:'
  id: totrans-4236
  prefs: []
  type: TYPE_NORMAL
- en: '![Test case](img/image01531.jpeg)'
  id: totrans-4237
  prefs: []
  type: TYPE_IMG
- en: An example of correlated currency-based ETFs
  id: totrans-4238
  prefs: []
  type: TYPE_NORMAL
- en: 'The second chart displays another group of currency-related ETFs that shares
    a similar price action behavior. Neural networks do not provide any analytical
    representation of their internal reasoning; therefore, a *visual* correlation
    can be extremely useful to novice engineers to validate their models:'
  id: totrans-4239
  prefs: []
  type: TYPE_NORMAL
- en: '![Test case](img/image01532.jpeg)'
  id: totrans-4240
  prefs: []
  type: TYPE_IMG
- en: An example of correlated currency-based ETFs
  id: totrans-4241
  prefs: []
  type: TYPE_NORMAL
- en: A very simple approach for finding any correlation between the movement of the
    currency exchange rates and the gold spot price is to select one ticker symbol
    as the target and a subset of other currency-based ETFs as features.
  id: totrans-4242
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the following problem: finding the correlation between the
    price of FXE and a range of currencies FXB, CYB, FXA, and FXC, as illustrated
    in the following diagram:'
  id: totrans-4243
  prefs: []
  type: TYPE_NORMAL
- en: '![Test case](img/image01533.jpeg)'
  id: totrans-4244
  prefs: []
  type: TYPE_IMG
- en: The mechanism to generate features from ticker symbols
  id: totrans-4245
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  id: totrans-4246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is to define the configuration parameter for the MLP classifier,
    as follows:'
  id: totrans-4247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE342]'
  id: totrans-4248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE342]'
- en: Besides the learning parameters, the network is initialized with multiple topology
    configurations (line `59`).
  id: totrans-4249
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create the search space of the prices of all the ETFs used in
    the analysis:'
  id: totrans-4250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE343]'
  id: totrans-4251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE343]'
- en: 'The purpose of the test is to evaluate and compare seven different portfolios
    or studies (line `60`). The closing prices of all the ETFs over a period of 3
    years are extracted from the Google Financial tables, using the `GoogleFinancials`
    extractor for a basket of ETFs (line `61`):'
  id: totrans-4252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE344]'
  id: totrans-4253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE344]'
- en: 'The next step consists of implementing the mechanism to extract the target
    and the features from a basket of ETFs or studies introduced in the previous paragraph.
    Let''s consider the following study as the list of ETF ticker symbols:'
  id: totrans-4254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE345]'
  id: totrans-4255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE345]'
- en: 'The first element of the study, `FXE`, is the labeled output; the remaining
    three elements are observed features. For this study, the network architecture
    has three input variables (`FXF`, `FXB`, and `CYB`) and one output variable, `FXE`:'
  id: totrans-4256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE346]'
  id: totrans-4257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE346]'
- en: The set of observations, `obs`, is built using an index (line `62`). By convention,
    the first observation is selected as the label data and the remaining studies
    as the features for training. As the observations are loaded as an array of time
    series, the time features of the series is computed using `transpose` (line `63`).
    The single `target` output variable has to be converted into a matrix before transposition
    (line `64`).
  id: totrans-4258
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, the model is built through instantiation of the `MLP` class:'
  id: totrans-4259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE347]'
  id: totrans-4260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE347]'
- en: The objective or operating `mode` is implicitly defined as an MLP binary classifier,
    `MLPBinClassifier` (line `65`). The `MLP.fit` method is defined in the *Training
    and classification* section.
  id: totrans-4261
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation of models
  id: totrans-4262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The test consists of evaluating six different models to determine which ones
    provide the most reliable correlation. It is critical to ensure that the result
    is somewhat independent of the architecture of the neural network. Different architectures
    are evaluated as part of the test.
  id: totrans-4263
  prefs: []
  type: TYPE_NORMAL
- en: 'The following charts compare the models for two architectures:'
  id: totrans-4264
  prefs: []
  type: TYPE_NORMAL
- en: Two hidden layers with four nodes each
  id: totrans-4265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three hidden layers with eight (with respect to five and six) nodes
  id: totrans-4266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This first chart visualizes the fitness of the six regression models with an
    architecture consisting of a variable number of inputs (2, 7): one output variable
    and two hidden layers of four nodes each. The features (ETF symbols) are listed
    on the left-hand side of the arrow **=>** along the *y* axis. The symbol on the
    right-hand side of the arrow is the expected output value:'
  id: totrans-4267
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation of models](img/image01534.jpeg)'
  id: totrans-4268
  prefs: []
  type: TYPE_IMG
- en: The accuracy of MLP with two hidden layers of four nodes each
  id: totrans-4269
  prefs: []
  type: TYPE_NORMAL
- en: 'The following chart displays the fitness of the six regression models for an
    architecture with three hidden layers of eight, five, and six nodes, respectively:'
  id: totrans-4270
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation of models](img/image01535.jpeg)'
  id: totrans-4271
  prefs: []
  type: TYPE_IMG
- en: The accuracy of MLP with three hidden layers with 8, 5, and 6 nodes, respectively
  id: totrans-4272
  prefs: []
  type: TYPE_NORMAL
- en: 'The two network architectures shared a lot of similarity; in both cases, the
    fittest regression models are as follows:'
  id: totrans-4273
  prefs: []
  type: TYPE_NORMAL
- en: '*FXE = f (FXA, SPY, GLD, FXB, FXF, FXD, FXY, CYB)*'
  id: totrans-4274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*FXE = g (FXC, GLD, FXA, FXY, FXB)*'
  id: totrans-4275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*FXE = h (FXF, FXB, CYB)*'
  id: totrans-4276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, the prediction of the Canadian dollar to US dollar's exchange
    rate (FXC) using the exchange rate for the Japanese yen (FXY) and the Australian
    dollar (FXA) is poor with both the configurations.
  id: totrans-4277
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The empirical evaluation**'
  id: totrans-4279
  prefs: []
  type: TYPE_NORMAL
- en: These empirical tests use a simple accuracy metric. A formal comparison of the
    regression models will systematically analyze every combination of input and output
    variables. The evaluation will also compute the precision, the recall, and the
    F1 score for each of those models (refer to the *Key quality metrics* section
    under *Validation* in the *Assessing a model* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*).
  id: totrans-4280
  prefs: []
  type: TYPE_NORMAL
- en: Impact of the hidden layers' architecture
  id: totrans-4281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next test consists of evaluating the impact of the hidden layer(s) of configuration
    on the accuracy of three models: *FXF, FXB, CYB => FXE*, *FCX, GLD, FXA =>FXY*,
    and *FXC, GLD, FXA, FXY, FXB => FXE*. For this test, the accuracy is computed
    by selecting a subset of the training data as a test sample, for the sake of convenience.
    The objective of the test is to compare different network architectures using
    some metrics, and not to estimate the absolute accuracy of each model.'
  id: totrans-4282
  prefs: []
  type: TYPE_NORMAL
- en: 'The four network configurations are as follows:'
  id: totrans-4283
  prefs: []
  type: TYPE_NORMAL
- en: A single hidden layer with four nodes
  id: totrans-4284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two hidden layers with four nodes each
  id: totrans-4285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two hidden layers with seven nodes each
  id: totrans-4286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three hidden layers with eight, five, and six nodes
  id: totrans-4287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following graph:'
  id: totrans-4288
  prefs: []
  type: TYPE_NORMAL
- en: '![Impact of the hidden layers'' architecture](img/image01536.jpeg)'
  id: totrans-4289
  prefs: []
  type: TYPE_IMG
- en: The impact of the hidden layers' architecture on the MLP accuracy
  id: totrans-4290
  prefs: []
  type: TYPE_NORMAL
- en: The complex neural network architecture with two or more hidden layers generates
    weights with similar accuracy. The four-node single hidden layer architecture
    generates the highest accuracy. The computation of the accuracy using a formal
    cross-validation technique would generate a lower accuracy number.
  id: totrans-4291
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we take a look at the impact of the complexity of the network on the
    duration of the training, as shown in the following graph:'
  id: totrans-4292
  prefs: []
  type: TYPE_NORMAL
- en: '![Impact of the hidden layers'' architecture](img/image01537.jpeg)'
  id: totrans-4293
  prefs: []
  type: TYPE_IMG
- en: The impact of the hidden layers' architecture on the duration of training
  id: totrans-4294
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, the time complexity increases significantly with the number
    of hidden layers and number of nodes.
  id: totrans-4295
  prefs: []
  type: TYPE_NORMAL
- en: Convolution neural networks
  id: totrans-4296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section is provided as a brief introduction to convolution neural networks
    without the Scala implementation.
  id: totrans-4297
  prefs: []
  type: TYPE_NORMAL
- en: So far, the layers of perceptrons were organized as a fully connected network.
    It is clear that the number of synapses or weights increases significantly as
    the number and size of hidden layers increases. For instance, a network for a
    features set of dimension 6, 3 hidden layers of 64 nodes each, and one output
    value requires *7*64 + 2*65*64 + 65*1 = 8833* weights!
  id: totrans-4298
  prefs: []
  type: TYPE_NORMAL
- en: Applications such as image or character recognition require very large features
    set, making training a fully connected layered perceptron very computational intensive.
    Moreover, these applications need to convey spatial information such as the proximity
    of pixels as part of the features vector.
  id: totrans-4299
  prefs: []
  type: TYPE_NORMAL
- en: A recent approach, known as **convolution neural networks**, consists of limiting
    the number of nodes in the hidden layers a input node is connected to. In other
    words, the methodology leverages spatial localization to reduce the complexity
    of connectivity between the input and the hidden layer [9:15]. The subset of input
    nodes connected to a single neuron in the hidden layer is known as the **local
    receptive fields**.
  id: totrans-4300
  prefs: []
  type: TYPE_NORMAL
- en: Local receptive fields
  id: totrans-4301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The neuron of the hidden layer learns from the local receptive fields or subimage
    of *n by n* pixels, each of those pixels being an input value. The next local
    receptive field, which is shifted by one pixel in any direction, is connected
    to the next neuron in the first hidden layer. The first hidden layer is known
    as the **convolution layer**. An illustration of the mapping between the input
    (image) and the first hidden layer (convolution layer) is as follows:'
  id: totrans-4302
  prefs: []
  type: TYPE_NORMAL
- en: '![Local receptive fields](img/image01538.jpeg)'
  id: totrans-4303
  prefs: []
  type: TYPE_IMG
- en: The generation of a convolution layer from an image
  id: totrans-4304
  prefs: []
  type: TYPE_NORMAL
- en: It would make sense that each *n by n* local receptive field has a bias element
    (+1) that connects to the hidden neuron. However, the extra complexity does not
    lead to a more accurate model, and therefore, the bias is shared across the neurons
    of the convolution layer.
  id: totrans-4305
  prefs: []
  type: TYPE_NORMAL
- en: Sharing of weights
  id: totrans-4306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The local receptive fields representing a small section of the image are generated
    by shifting the fields by one pixel (up, down, left, or right). Therefore, the
    weights associated with the local receptive fields are also shared across the
    neurons in the hidden layer. As a matter of fact, the same feature such as an
    image color or edge can be detected in many pixels across the image. The maps
    between the input features and neurons in the hidden layer, known as **features
    maps**, share weights across the convolution layer. The output is computed using
    the activation function.
  id: totrans-4307
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Tanh versus the sigmoid activation**'
  id: totrans-4309
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid is predominately used in the examples related to the multilayer
    perceptron as the activation function for the hidden layer. The hyperbolic tangent
    function is commonly used for convolution networks.
  id: totrans-4310
  prefs: []
  type: TYPE_NORMAL
- en: Convolution layers
  id: totrans-4311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The output computed from the features maps is expressed as a convolution that
    is similar to the convolution used in a discrete Fourier transformed-based filter
    (refer to **M11** mathematical expression in the *DFT-based filtering* section
    under *Fourier analysis* in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data
    Preprocessing"), *Data Preprocessing*). The activation function that computes
    the output in the hidden layer has to be modified to take into account the local
    receptive fields.
  id: totrans-4312
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The activation of a convolution neural network**'
  id: totrans-4314
  prefs: []
  type: TYPE_NORMAL
- en: 'M13: The output value *z[j]* for a shared bias *w[0]*, an activation function
    *σ*, a local receptive field of *n by n* pixels, input values *x[ij]* *,* and
    weights *wuv* associated with a features map is given by:'
  id: totrans-4315
  prefs: []
  type: TYPE_NORMAL
- en: '![Convolution layers](img/image01539.jpeg)'
  id: totrans-4316
  prefs: []
  type: TYPE_IMG
- en: The next step in building the neural network would be to use the output of the
    convolution layer to a full connected hidden layer. However, the features maps
    in the convolution layer are usually similar so that they can be reduced to a
    smaller set of outputs using an intermediate layer known as subsampling layer
    [9:16].
  id: totrans-4317
  prefs: []
  type: TYPE_NORMAL
- en: Subsampling layers
  id: totrans-4318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each features map in the convolution layer is reduced or condensed into a smaller
    features map. The layer composed of these smaller features map is known as the
    subsampling layer. The purpose of the sampling is to reduce the sensitivity of
    the weights to any minute changes in the image between adjacent pixels. The sharing
    of weights reduces the sensitivity to any nonsignificant changes in the image:'
  id: totrans-4319
  prefs: []
  type: TYPE_NORMAL
- en: '![Subsampling layers](img/image01540.jpeg)'
  id: totrans-4320
  prefs: []
  type: TYPE_IMG
- en: The connectivity between features map from a convolution to a subsampling layer
  id: totrans-4321
  prefs: []
  type: TYPE_NORMAL
- en: The subsampling layer is sometimes referred to as the **pooling layer**.
  id: totrans-4322
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-4323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last layer of the convolution neural network is the fully connected hidden
    layer and output layer, subjected to the same transformative formulas as the traditional
    multilayer perceptron. The output values can be computed using a linear product
    or a `softmax` function:'
  id: totrans-4324
  prefs: []
  type: TYPE_NORMAL
- en: '![Putting it all together](img/image01541.jpeg)'
  id: totrans-4325
  prefs: []
  type: TYPE_IMG
- en: An overview of a convolution neural network
  id: totrans-4326
  prefs: []
  type: TYPE_NORMAL
- en: The error backpropagation algorithm described in the *Step 2 – error back propagation*
    section has to be modified to support the features map [9:17].
  id: totrans-4327
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The architecture of convolution networks**'
  id: totrans-4329
  prefs: []
  type: TYPE_NORMAL
- en: Deep convolution neural networks have multiple sequences of convolution layers
    and subsampling layers and may have more than one fully connection hidden layer.
  id: totrans-4330
  prefs: []
  type: TYPE_NORMAL
- en: Benefits and limitations
  id: totrans-4331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The advantages and disadvantages of neural networks depend on which other machine
    learning methods they are compared to. However, neural-network-based classifiers,
    particularly the multilayer perceptron using the error backpropagation, have some
    obvious advantages, which are as follows:'
  id: totrans-4332
  prefs: []
  type: TYPE_NORMAL
- en: The mathematical foundation of a neural network does not require expertise in
    dynamic programming or linear algebra, beyond the basic gradient descent algorithm.
  id: totrans-4333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A neural network can perform tasks that a linear algorithm cannot.
  id: totrans-4334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An MLP is usually reliable for highly dynamic and nonlinear processes. Contrary
    to the support vector machines, they do not require us to increase the problem
    dimension through kernelization.
  id: totrans-4335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An MLP does not make any assumption on linearity, variable independence, or
    normality.
  id: totrans-4336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution of training of an MLP lends itself to concurrent processing quite
    well for online training. In most architecture, the algorithm can continue even
    if a node in the network fails (refer to the *Apache Spark* section in [Chapter
    12](part0223.xhtml#aid-6KLDE1 "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*).
  id: totrans-4337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, as with any machine learning algorithm, neural networks have their
    detractors. The most documented limitations are as follows:'
  id: totrans-4338
  prefs: []
  type: TYPE_NORMAL
- en: MLP models are black boxes for which the association between features and classes
    may not be easily described and understood.
  id: totrans-4339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An MLP requires a lengthy training process, especially using the batch training
    strategy. For example, a two-layer network has a time complexity (number of multiplications)
    of *O(n.m.p.N.e)* for *n* input variables, *m* hidden neurons, *p* output values,
    *N* observations, and *e* epochs. It is not uncommon that a solution emerges after
    thousands of epochs. The online training strategy using a momentum factor tends
    to converge faster and requires a smaller number of epochs than the batch process.
  id: totrans-4340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning the configuration parameters, such as optimization of the learning rate
    and momentum factors, selection of the most appropriate activation method, and
    the cumulative error formula can turn into a lengthy process.
  id: totrans-4341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating the minimum size of the training set required to generate an accurate
    model and limiting the computation time is not obvious.
  id: totrans-4342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A neural network cannot be incrementally retrained. Any new labeled data requires
    the execution of several training epochs.
  id: totrans-4343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Other types of neural networks**'
  id: totrans-4345
  prefs: []
  type: TYPE_NORMAL
- en: This chapter covers the multilayer perceptron and introduces the concept of
    a convolution neural network. There are many more types of neural networks, such
    as recurrent networks and mixture density networks.
  id: totrans-4346
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-4347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This concludes not only the journey inside the multilayer perceptron, but also
    the introduction of the supervised learning algorithms. In this chapter, you learned:'
  id: totrans-4348
  prefs: []
  type: TYPE_NORMAL
- en: The components and architecture of artificial neural networks
  id: totrans-4349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The stages of the training cycle (or epoch) for the backpropagation multilayer
    perceptron
  id: totrans-4350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to implement an MLP from the ground up in Scala
  id: totrans-4351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numerous configuration parameters and options available to create the MLP
    classification or regression model.
  id: totrans-4352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To evaluate the impact of the learning rate and the gradient descent momentum
    factor on the convergence of the training process.
  id: totrans-4353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to apply a multilayer perceptron to the financial analysis of the fluctuation
    of currencies
  id: totrans-4354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the convolution neural network
  id: totrans-4355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next chapter will introduce the concept of genetic algorithms with a complete
    implementation in Scala. Although, strictly speaking, genetic algorithms do not
    belong to the family of machine learning algorithms, they play a crucial role
    in the optimization of nonlinear, nondifferentiable problems, and the selection
    of strong classifiers within ensembles.
  id: totrans-4356
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 10. Genetic Algorithms
  id: totrans-4357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduces the concept of evolutionary computing. Algorithms derived
    from the theory of evolution are particularly efficient in solving large combinatorial
    or **NP problems**. Evolutionary computing has been pioneered by John Holland
    [10:1] and David Goldberg [10:2]. Their findings should be of interest to anyone
    eager to learn about the foundation of **genetic algorithms** (**GA**) and **artificial
    life**.
  id: totrans-4358
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  id: totrans-4359
  prefs: []
  type: TYPE_NORMAL
- en: The origin of evolutionary computing
  id: totrans-4360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The theoretical foundation of genetic algorithms
  id: totrans-4361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and limitations of genetic algorithms
  id: totrans-4362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From a practical perspective, you will learn how to:'
  id: totrans-4363
  prefs: []
  type: TYPE_NORMAL
- en: Apply genetic algorithms to leverage technical analysis of market price and
    volume movement to predict future returns
  id: totrans-4364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate or estimate the search space
  id: totrans-4365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encode solutions in the binary format using either hierarchical or flat addressing
  id: totrans-4366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tune some of the genetic operators
  id: totrans-4367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create and evaluate fitness functions
  id: totrans-4368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evolution
  id: totrans-4369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **theory of evolution**, enunciated by Charles Darwin, describes the morphological
    adaptation of living organisms [10:3].
  id: totrans-4370
  prefs: []
  type: TYPE_NORMAL
- en: The origin
  id: totrans-4371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Darwinian** process consists of optimizing the morphology of organisms
    to adapt to the harshest environments—hydrodynamic optimization for fishes, aerodynamic
    for birds, or stealth skills for predators. The following diagram shows a gene:'
  id: totrans-4372
  prefs: []
  type: TYPE_NORMAL
- en: '![The origin](img/image01542.jpeg)'
  id: totrans-4373
  prefs: []
  type: TYPE_IMG
- en: The **population** of organisms varies over time. The number of individuals
    within a population changes, sometimes dramatically. These variations are usually
    associated with the abundance or lack of predators and prey as well as the changing
    environment. Only the fittest organisms within the population can survive over
    time by adapting quickly to sudden changes in living environments and new constraints.
  id: totrans-4374
  prefs: []
  type: TYPE_NORMAL
- en: NP problems
  id: totrans-4375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NP stands for nondeterministic polynomial time. The NP problems'' concept relates
    to the theory of computation and more precisely, time and space complexity. The
    categories of NP problems are as follows:'
  id: totrans-4376
  prefs: []
  type: TYPE_NORMAL
- en: '**P-problems** (or P decision problems): For these problems, the resolution
    on a deterministic Turing machine (computer) takes a deterministic polynomial
    time.'
  id: totrans-4377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NP problems**: These problems can be resolved in a polynomial time on nondeterministic
    machines.'
  id: totrans-4378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NP-complete problems**: These are NP-hard problems that are reduced to NP
    problems for which the solution takes a deterministic polynomial time. These types
    of problems may be difficult to solve but their solutions can be validated.'
  id: totrans-4379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NP-hard problems**: These problems have solutions that may not be found in
    polynomial time.![NP problems](img/image01543.jpeg)'
  id: totrans-4380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The categorization of NP problems using computational complexity
  id: totrans-4381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Problems such as the traveling salesman, floor shop scheduling, the computation
    of a graph K-minimum spanning tree, map coloring, or cyclic ordering have a search
    execution time that is a nondeterministic polynomial, ranging from *n!* to *2[n]*
    for a population of *n* elements [10:4].
  id: totrans-4382
  prefs: []
  type: TYPE_NORMAL
- en: NP problems cannot always be solved using analytical methods because of the
    computation overhead—even in the case of a model, it relies on differentiable
    functions. Genetic algorithms were invented by John Holland in the 1970s, and
    they derived their properties from the theory of evolution of Darwin to tackle
    NP and NP-complete problems.
  id: totrans-4383
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary computing
  id: totrans-4384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A living organism consists of cells that contain identical chromosomes. **Chromosomes**
    are strands of **DNA** and serve as a model for the whole organism. A chromosome
    consists of **genes** that are blocks of DNA and encode a specific protein.
  id: totrans-4385
  prefs: []
  type: TYPE_NORMAL
- en: '**Recombination** (or crossover) is the first stage of reproduction. Genes
    from parents generate the whole new chromosome (**offspring**) that can be mutated.
    During mutation, one or more elements, also known as individual bases of the DNA
    strand or chromosomes, are changed. These changes are mainly caused by errors
    that occur when the genes from parents are being passed on to their offspring.
    The success of an organism in its life measures its fitness [10:5].'
  id: totrans-4386
  prefs: []
  type: TYPE_NORMAL
- en: Genetic algorithms use reproduction to evolve a population of possible solutions
    to a problem.
  id: totrans-4387
  prefs: []
  type: TYPE_NORMAL
- en: Genetic algorithms and machine learning
  id: totrans-4388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The practical purpose of a genetic algorithm as an optimization technique is
    to solve problems by finding the most relevant or fittest solution among a set
    or group of solutions. Genetic algorithms have many applications in machine learning,
    which are as follows:'
  id: totrans-4389
  prefs: []
  type: TYPE_NORMAL
- en: '**Discrete model parameters**: Genetic algorithms are particularly effective
    in finding the set of discrete parameters that maximizes the log likelihood. For
    example, the colorization of a black and white movie relies on a large but finite
    set of transformations from shades of grey to the RGB color scheme. The search
    space is composed of the different transformations and the objective function
    is the quality of the colorized version of the movie.'
  id: totrans-4390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reinforcement learning**: Systems that select the most appropriate rules
    or policies to match a given dataset rely on genetic algorithms to evolve the
    set of rules over time. The search space or population is the set of candidate
    rules, and the objective function is the credit or reward for an action triggered
    by these rules (refer to [Chapter 11](part0220.xhtml#aid-6HPRO2 "Chapter 11. Reinforcement
    Learning"), *Reinforcement Learning*).'
  id: totrans-4391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The neural network architecture**: A genetic algorithm drives the evaluation
    of different configurations of networks. The search space consists of different
    combinations of hidden layers and the size of those layers. The fitness or objective
    function is the sum of the squared errors.'
  id: totrans-4392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ensemble learning** [10:6]: A genetic algorithm can weed out the weak learners
    among a set of classifiers in order to improve the quality of the prediction.'
  id: totrans-4393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Genetic algorithm components
  id: totrans-4394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Genetic algorithms have the following three components:'
  id: totrans-4395
  prefs: []
  type: TYPE_NORMAL
- en: '**Genetic encoding** (**and decoding**): This is the conversion of a solution
    candidate and its components into the binary format (an array of bits or a string
    of `0` and `1` characters)'
  id: totrans-4396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Genetic operations**: This is the application of a set of operators to extract
    the best (most genetically fit) candidates (chromosomes)'
  id: totrans-4397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Genetic fitness functions**: This is the evaluation of the fittest candidate
    using an objective function'
  id: totrans-4398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encodings and the fitness function are problem dependent. Genetic operators
    are not.
  id: totrans-4399
  prefs: []
  type: TYPE_NORMAL
- en: Encoding
  id: totrans-4400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's consider the optimization problem in machine learning that consists of
    maximizing the log likelihood or minimizing the loss function. The goal is to
    compute the parameters or weights, *w={w[i]}*, that minimize or maximize a function
    *f(w)*. In the case of a nonlinear model, variables may depend on other variables,
    which make the optimization problem particularly challenging.
  id: totrans-4401
  prefs: []
  type: TYPE_NORMAL
- en: Value encoding
  id: totrans-4402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The genetic algorithm manipulates variables as bits or bit strings. The conversion
    of a variable into a bit string is known as encoding. In the case where the variable
    is continuous, the conversion is known as **quantization** or **discretization**.
    Each type of variable has a unique encoding scheme, as follows:'
  id: totrans-4403
  prefs: []
  type: TYPE_NORMAL
- en: 'Boolean values are easily encoded with 1 bit: 0 for false and 1 for true.'
  id: totrans-4404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous variables are quantized or discretized in a fashion similar to the
    conversion of an analog to a digital signal. Let's consider the function with
    a maximum **max** (similarly **min** for minimum) over a range of values, encoded
    with *n = 16* bits:![Value encoding](img/image01544.jpeg)
  id: totrans-4405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An illustration of quantization of a continuous variable y = f(x)
  id: totrans-4406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The step size of the discretization is computed as (M1):'
  id: totrans-4407
  prefs: []
  type: TYPE_NORMAL
- en: '![Value encoding](img/image01545.jpeg)'
  id: totrans-4408
  prefs: []
  type: TYPE_IMG
- en: The step size of the quantization of the *sine y = sin(x)* in 16 bits is 1.524e-5.
  id: totrans-4409
  prefs: []
  type: TYPE_NORMAL
- en: 'Discrete or categorical variables are a bit more challenging to encode to bits.
    At a minimum, all the discrete values have to be accounted for. However, there
    is no guarantee that the number of variables will coincide with the bits boundary:'
  id: totrans-4410
  prefs: []
  type: TYPE_NORMAL
- en: '![Value encoding](img/image01546.jpeg)'
  id: totrans-4411
  prefs: []
  type: TYPE_IMG
- en: Padding for base 2 representation of values
  id: totrans-4412
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the next exponent, *n+1*, defines the minimum number of bits
    required to represent the set of values: *n = log2(m).toInt + 1*. A discrete variable
    with 19 values requires 5 bits. The remaining bits are set to an arbitrary value
    (0, NaN, and so on) depending on the problem. This procedure is known as **padding**.'
  id: totrans-4413
  prefs: []
  type: TYPE_NORMAL
- en: Encoding is as much art as it is science. For each encoding function, you need
    a decoding function to convert the bits representation back to actual values.
  id: totrans-4414
  prefs: []
  type: TYPE_NORMAL
- en: Predicate encoding
  id: totrans-4415
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A predicate for a variable *x* is a relation defined as a *x operator [target]*;
    for instance, *unit cost < [9$]*, *temperature = [82F]*, or *Movie rating is [3
    stars]*.
  id: totrans-4416
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest encoding scheme for predicates is as follows:'
  id: totrans-4417
  prefs: []
  type: TYPE_NORMAL
- en: '**Variables** are encoded as a category or type (for example, temperature,
    barometric pressure, and so on) because there are a finite number of variables
    in any model'
  id: totrans-4418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operators** are encoded as discrete types'
  id: totrans-4419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Values** are encoded as either discrete or continuous values'
  id: totrans-4420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4421
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Encoding format for predicates**'
  id: totrans-4422
  prefs: []
  type: TYPE_NORMAL
- en: There are many approaches for encoding a predicate in a bits string. For instance,
    the format *{operator, left-operand,* and *right-operand}* is useful because it
    allows you to encode a binary tree. The entire rule, *IF predicate THEN action*,
    can be encoded with the action being represented as a discrete or categorical
    value.
  id: totrans-4423
  prefs: []
  type: TYPE_NORMAL
- en: Solution encoding
  id: totrans-4424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The solution encoding approach describes the solution to a problem as an unordered
    sequence of predicates. Let''s consider the following rule:'
  id: totrans-4425
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE348]'
  id: totrans-4426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE348]'
- en: 'In this example, the search space is defined by two levels:'
  id: totrans-4427
  prefs: []
  type: TYPE_NORMAL
- en: Boolean operators (for example, AND) and predicates
  id: totrans-4428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each predicate is defined as a tuple (a variable, operator, target value)
  id: totrans-4429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The tree representation for the search space is shown in the following diagram:'
  id: totrans-4430
  prefs: []
  type: TYPE_NORMAL
- en: '![Solution encoding](img/image01547.jpeg)'
  id: totrans-4431
  prefs: []
  type: TYPE_IMG
- en: A graph representation of encoded rules
  id: totrans-4432
  prefs: []
  type: TYPE_NORMAL
- en: 'The bits string representation is decoded back to its original format for further
    computation:'
  id: totrans-4433
  prefs: []
  type: TYPE_NORMAL
- en: '![Solution encoding](img/image01548.jpeg)'
  id: totrans-4434
  prefs: []
  type: TYPE_IMG
- en: Encoding, alteration, and decoding of predicates
  id: totrans-4435
  prefs: []
  type: TYPE_NORMAL
- en: The encoding scheme
  id: totrans-4436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two approaches to encode such a candidate solution or chain of predicates:'
  id: totrans-4437
  prefs: []
  type: TYPE_NORMAL
- en: Flat coding of a chromosome
  id: totrans-4438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hierarchical coding of a chromosome as a composition of genes
  id: totrans-4439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flat encoding
  id: totrans-4440
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The flat encoding approach consists of encoding the set of predicates into
    a single chromosome (bits string), representing a specific solution candidate
    to the optimization problem. The identity of the predicates is not preserved:'
  id: totrans-4441
  prefs: []
  type: TYPE_NORMAL
- en: '![Flat encoding](img/image01549.jpeg)'
  id: totrans-4442
  prefs: []
  type: TYPE_IMG
- en: Flat addressing schema for chromosomes
  id: totrans-4443
  prefs: []
  type: TYPE_NORMAL
- en: 'A genetic operator manipulates the bits of the chromosome regardless of whether
    the bits refer to a particular predicate:'
  id: totrans-4444
  prefs: []
  type: TYPE_NORMAL
- en: '![Flat encoding](img/image01550.jpeg)'
  id: totrans-4445
  prefs: []
  type: TYPE_IMG
- en: Chromosome encoding with flat addressing
  id: totrans-4446
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchical encoding
  id: totrans-4447
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this configuration, the characteristic of each predicate is preserved during
    the encoding process. Each predicate is converted into a gene represented by a
    bit string. The genes are aggregated to form the chromosome. An extra field is
    added to the bits string or chromosome for the selection of the gene. This extra
    field consists of the index or the address of the gene:'
  id: totrans-4448
  prefs: []
  type: TYPE_NORMAL
- en: '![Hierarchical encoding](img/image01551.jpeg)'
  id: totrans-4449
  prefs: []
  type: TYPE_IMG
- en: Hierarchical addressing schema for chromosomes
  id: totrans-4450
  prefs: []
  type: TYPE_NORMAL
- en: 'A generic operator selects the predicate it needs to first manipulate. Once
    the target gene is selected, the operator updates the bits string associated with
    the gene, as follows:'
  id: totrans-4451
  prefs: []
  type: TYPE_NORMAL
- en: '![Hierarchical encoding](img/image01552.jpeg)'
  id: totrans-4452
  prefs: []
  type: TYPE_IMG
- en: Chromosome encoding with flat addressing
  id: totrans-4453
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to define the genetic operators that manipulate or update the
    bits string representing either a chromosome or individual genes.
  id: totrans-4454
  prefs: []
  type: TYPE_NORMAL
- en: Genetic operators
  id: totrans-4455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The implementation of the reproduction cycle attempts to replicate the natural
    reproduction process [10:7]. The reproduction cycle that controls the population
    of chromosomes consists of three genetic operators:'
  id: totrans-4456
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection**: This operator ranks chromosomes according to a fitness function
    or criteria. It eliminates the weakest or less-fit chromosomes and controls the
    population growth.'
  id: totrans-4457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crossover**: This operator pairs chromosomes to generate offspring chromosomes.
    These offspring chromosomes are added to the population along with their parent
    chromosomes.'
  id: totrans-4458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mutation**: This operator introduces a minor alteration in the genetic code
    (bits string representation) to prevent the successive reproduction cycles from
    electing the same fittest chromosome. In optimization terms, this operator reduces
    the risk of the genetic algorithm converging quickly toward a local maximum or
    minimum.'
  id: totrans-4459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The transposition operator**'
  id: totrans-4461
  prefs: []
  type: TYPE_NORMAL
- en: Some implementations of genetic algorithms use a fourth operator, genetic transposition,
    in case the fitness function cannot be very well defined and the initial population
    is very large. Although additional genetic operators could potentially reduce
    the odds of finding a local maximum or minimum, the inability to describe the
    fitness criteria or the search space is a sure sign that a genetic algorithm may
    not be the most suitable tool.
  id: totrans-4462
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram gives an overview of the genetic algorithm workflow:'
  id: totrans-4463
  prefs: []
  type: TYPE_NORMAL
- en: '![Genetic operators](img/image01553.jpeg)'
  id: totrans-4464
  prefs: []
  type: TYPE_IMG
- en: A basic workflow for the execution of genetic algorithms
  id: totrans-4465
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4466
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Initialization**'
  id: totrans-4467
  prefs: []
  type: TYPE_NORMAL
- en: The initialization of the search space (a set of potential solutions to a problem)
    in any optimization procedure is challenging and genetic algorithms are no exception.
    In the absence of biases or heuristics, the reproduction initializes the population
    with randomly generated chromosomes. However, it is worth the effort to extract
    the characteristics of a population. Any well-founded bias introduced during initialization
    facilitates the convergence of the reproduction process.
  id: totrans-4468
  prefs: []
  type: TYPE_NORMAL
- en: Each of these genetic operators has at least one configurable parameter that
    has to be estimated and/or tuned. Moreover, you will likely need to experiment
    with different fitness functions and encoding schemes in order to increase your
    odds of finding a fittest solution (or chromosome).
  id: totrans-4469
  prefs: []
  type: TYPE_NORMAL
- en: Selection
  id: totrans-4470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The purpose of the genetic selection phase is to evaluate, rank, and weed out
    the chromosomes (that is, the solution candidates) that are not a good fit for
    the problem. The selection procedure relies on a fitness function to score and
    rank candidate solutions through their chromosomal representation. It is a common
    practice to constrain the growth of the population of chromosomes by setting a
    limit to the size of the population.
  id: totrans-4471
  prefs: []
  type: TYPE_NORMAL
- en: There are several methodologies to implement the selection process from scaled
    relative fitness, Holland roulette wheel, and tournament selection to rank-based
    selection [10:8].
  id: totrans-4472
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Relative fitness degradation**'
  id: totrans-4474
  prefs: []
  type: TYPE_NORMAL
- en: As the initial population of chromosomes evolves, the chromosomes tend to get
    more and more similar to each other. This phenomenon is a healthy sign that the
    population is actually converging. However, for some problems, you may need to
    scale or magnify the relative fitness to preserve a meaningful difference in the
    fitness score between the chromosomes [10:9].
  id: totrans-4475
  prefs: []
  type: TYPE_NORMAL
- en: The following implementation relies on rank-based selection.
  id: totrans-4476
  prefs: []
  type: TYPE_NORMAL
- en: 'The selection process consists of the following steps:'
  id: totrans-4477
  prefs: []
  type: TYPE_NORMAL
- en: Apply the fitness function to each chromosome *j* in the population *f[j]*.
  id: totrans-4478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the total fitness score for the entire population *∑f[j]*.
  id: totrans-4479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Normalize the fitness score of each chromosome by the sum of the fitness scores
    of all the chromosomes *f[j] = f[i]/Σf[j]*.
  id: totrans-4480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sort the chromosomes by their descending fitness score *f[j] < f[j-1]*.
  id: totrans-4481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the cumulative fitness score for each chromosome *j f[j] = f[j] + ∑f[k]*.
  id: totrans-4482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate the selection probability (for the rank-based formula) as a random
    value *p ε [0,1]*.
  id: totrans-4483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eliminate the chromosome *k* that has a low unfitness score *f[k] < p* or high
    fitness cost *f[k]* *> p*.
  id: totrans-4484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reduce the size of the population if it exceeds the maximum allowed number of
    chromosomes.
  id: totrans-4485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4486
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Natural selection**'
  id: totrans-4487
  prefs: []
  type: TYPE_NORMAL
- en: You should not be surprised by the need to control the size of the population
    of chromosomes. After all, nature does not allow any species to grow beyond a
    certain point in order to avoid depleting natural resources. The predator-prey
    process modeled by the **Lotka-Volterra** equation [10:10] keeps the population
    of each species in check.
  id: totrans-4488
  prefs: []
  type: TYPE_NORMAL
- en: Crossover
  id: totrans-4489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The purpose of the genetic crossover is to expand the current population of
    chromosomes in order to intensify the competition among the solution candidates.
    The crossover phase consists of reprogramming chromosomes from one generation
    to the next. There are many different variations of crossover techniques. The
    algorithm for the evolution of the population of chromosomes is independent of
    the crossover technique. Therefore, the case study uses the simpler one-point
    crossover. The crossover swaps sections of the two-parent chromosomes to produce
    two offspring chromosomes, as illustrated in the following diagram:'
  id: totrans-4490
  prefs: []
  type: TYPE_NORMAL
- en: '![Crossover](img/image01554.jpeg)'
  id: totrans-4491
  prefs: []
  type: TYPE_IMG
- en: A chromosome's crossover operation
  id: totrans-4492
  prefs: []
  type: TYPE_NORMAL
- en: 'An important element in the crossover phase is selecting and pairing of parent
    chromosomes. There are different approaches for selecting and pairing the parent
    chromosomes that are the most suitable for reproduction:'
  id: totrans-4493
  prefs: []
  type: TYPE_NORMAL
- en: Selecting only the *n* fittest chromosomes for reproduction
  id: totrans-4494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pairing chromosomes ordered by their fitness (or unfitness) value
  id: totrans-4495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pairing the fittest chromosome with the least-fit chromosome, the second fittest
    chromosome with the second least-fit chromosome, and so on
  id: totrans-4496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a common practice to rely on a specific optimization problem to select
    the most appropriate selection method as it is highly domain dependent.
  id: totrans-4497
  prefs: []
  type: TYPE_NORMAL
- en: 'The crossover phase that uses hierarchical addressing as the encoding scheme
    consists of the following steps:'
  id: totrans-4498
  prefs: []
  type: TYPE_NORMAL
- en: Extract pairs of chromosomes from the population.
  id: totrans-4499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a random probability *p* *ϵ* *[0,1]*.
  id: totrans-4500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the index *r[i]* of the gene for which the crossover is applied as *r[i]*
    *= p.num_genes*, where *num_genes* are the number of genes in a chromosome.
  id: totrans-4501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the index of the bit in the selected gene for which the crossover is
    applied as *x[i]* *= p.gene_length*, where *gene_length* is the number of bits
    in the gene.
  id: totrans-4502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate two offspring chromosomes by interchanging strands between parents.
  id: totrans-4503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the two offspring chromosomes to the population.
  id: totrans-4504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4505
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Preserving parent chromosomes**'
  id: totrans-4506
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder why the parents are not removed from the population once the
    offspring chromosomes are created. This is because there is no guarantee that
    any of the offspring chromosomes are a better fit.
  id: totrans-4507
  prefs: []
  type: TYPE_NORMAL
- en: Mutation
  id: totrans-4508
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The objective of genetic mutation is to prevent the reproduction cycle from
    converging toward a local optimum by introducing a pseudo-random alteration to
    the genetic material. The mutation procedure inserts a small variation in a chromosome
    to maintain some level of diversity between generations. The methodology consists
    of flipping one bit in the bits string representation of the chromosome, as illustrated
    in the following diagram:'
  id: totrans-4509
  prefs: []
  type: TYPE_NORMAL
- en: '![Mutation](img/image01555.jpeg)'
  id: totrans-4510
  prefs: []
  type: TYPE_IMG
- en: A chromosome's mutation operation
  id: totrans-4511
  prefs: []
  type: TYPE_NORMAL
- en: 'The mutation is the simplest of the three phases in the reproduction process.
    In the case of hierarchical addressing, the steps are as follows:'
  id: totrans-4512
  prefs: []
  type: TYPE_NORMAL
- en: Select the chromosome to be mutated.
  id: totrans-4513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a random probability *p* *ϵ**[0,1]*.
  id: totrans-4514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the index *m[i]* of the gene to be mutated using the formula *m[i]*
    *= p.num_genes*.
  id: totrans-4515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the index of the bit in the gene to be mutated *x[i]* *= p.genes_length*.
  id: totrans-4516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform a flip XOR operation on the selected bit.
  id: totrans-4517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4518
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The tuning issue**'
  id: totrans-4519
  prefs: []
  type: TYPE_NORMAL
- en: The tuning of a genetic algorithm can be a daunting task. A plan including a
    systematic design experiment for measuring the impact of the encoding, fitness
    function, crossover, and mutation ratio is necessary to avoid lengthy evaluation
    and self-doubt.
  id: totrans-4520
  prefs: []
  type: TYPE_NORMAL
- en: The fitness score
  id: totrans-4521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The fitness function is the centerpiece of the selection process. There are
    three categories of fitness functions, which are as follows:'
  id: totrans-4522
  prefs: []
  type: TYPE_NORMAL
- en: '**The fixed fitness function**: In this function, the computation of the fitness
    value does not vary during the reproduction process'
  id: totrans-4523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The evolutionary fitness function**: In this function, the computation of
    the fitness value morphs between each selection according to predefined criteria'
  id: totrans-4524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An approximate fitness function**: In this function, the fitness value cannot
    be computed directly using an analytical formula [10:11]'
  id: totrans-4525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our implementation of the genetic algorithm uses a fixed fitness function.
  id: totrans-4526
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  id: totrans-4527
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the genetic operators are independent of the problem to
    be solved. Let's implement all the components of the reproduction cycle. The fitness
    function and the encoding scheme are highly domain specific.
  id: totrans-4528
  prefs: []
  type: TYPE_NORMAL
- en: 'In accordance with the principles of object-oriented programming, the software
    architecture defines the genetic operators using a top-down approach: starting
    with the population, then each chromosome, and down to each gene.'
  id: totrans-4529
  prefs: []
  type: TYPE_NORMAL
- en: Software design
  id: totrans-4530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The implementation of the genetic algorithm uses a design that is similar to
    the template for classifiers (refer to the *Design template for classifier* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*).
  id: totrans-4531
  prefs: []
  type: TYPE_NORMAL
- en: 'The key components of the implementation of the genetic algorithm are as follows:'
  id: totrans-4532
  prefs: []
  type: TYPE_NORMAL
- en: The `Population` class defines the current set of solution candidates or chromosomes.
  id: totrans-4533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `GASolver` class implements the GA solver and has two components: a configuration
    object of the `GAConfig` type and the initial population. This class implements
    an explicit monadic data transformation of the `ETransform` type.'
  id: totrans-4534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `GAConfig` configuration class consists of the GA execution and reproduction
    configuration parameters.
  id: totrans-4535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The reproduction (of the `Reproduction` type) controls the reproduction cycle
    between consecutive generations of chromosomes through the `mate` method.
  id: totrans-4536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `GAMonitor` monitoring trait tracks the progress of the optimization and
    evaluates the exit condition for each reproduction cycle.
  id: totrans-4537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following UML class diagram describes the relation between the different
    components of the genetic algorithm:'
  id: totrans-4538
  prefs: []
  type: TYPE_NORMAL
- en: '![Software design](img/image01556.jpeg)'
  id: totrans-4539
  prefs: []
  type: TYPE_IMG
- en: The UML class diagram of genetic algorithm components
  id: totrans-4540
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with defining the key classes that control the genetic algorithm.
  id: totrans-4541
  prefs: []
  type: TYPE_NORMAL
- en: Key components
  id: totrans-4542
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Population` parameterized class (with the `Gene` subtype) contains the
    set or pool of chromosomes. A population contains chromosomes that are a sequence
    or list of elements of the type inherited from `Gene`. A `Pool` is a mutable array
    used in order to avoid excessive duplication of the `Chromosome` instances associated
    with immutable collections.
  id: totrans-4543
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4544
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The case for mutability**'
  id: totrans-4545
  prefs: []
  type: TYPE_NORMAL
- en: It is a good Scala programming practice to stay away from mutable collections.
    However, in this case, the number of chromosomes can be very large. Most implementations
    of genetic algorithms update the population potentially three times per reproduction
    cycle, generating a large number of objects and taxing the Java garbage collector.
  id: totrans-4546
  prefs: []
  type: TYPE_NORMAL
- en: Population
  id: totrans-4547
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Population` class takes two arguments:'
  id: totrans-4548
  prefs: []
  type: TYPE_NORMAL
- en: '`limit`: This is the maximum size of the population'
  id: totrans-4549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`chromosomes`: This is the pool of chromosomes that define the current population'
  id: totrans-4550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A reproduction cycle executes the following sequence of three genetic operators
    on a population: `select` for the selection across all the chromosomes of the
    population (line `1`), `+-` for crossover of all the chromosomes (line `2`), and
    `^` for the mutation of each chromosome (line `3`). Consider the following code:'
  id: totrans-4551
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE349]'
  id: totrans-4552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE349]'
- en: The `limit` value specifies the maximum size of the population during optimization.
    It defines the hard limit or constraints on the population growth.
  id: totrans-4553
  prefs: []
  type: TYPE_NORMAL
- en: Chromosomes
  id: totrans-4554
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The chromosome is the second level of containment in the genotype hierarchy.
    The `Chromosome` class takes a list of genes as parameter (code). The signature
    of the crossover and mutation methods, `+-` and `^`, are similar to their implementation
    in the `Population` class except for the fact that the crossover and mutable parameters
    are passed as indices relative to the list of genes and each gene. The section
    dedicated to the genetic crossover describes the `GeneticIndices` class:'
  id: totrans-4555
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE350]'
  id: totrans-4556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE350]'
- en: The algorithm assigns the (un)fitting score or a `cost` value to each chromosome
    to enable the ranking of chromosomes in the population, and ultimately, the selection
    of the fittest chromosomes (line `4`).
  id: totrans-4557
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4558
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Fitness versus cost**'
  id: totrans-4559
  prefs: []
  type: TYPE_NORMAL
- en: The machine learning algorithms use the loss function or its variant as an objective
    function to be minimized. This implementation of the GA uses `cost` scores in
    order to be consistent with the concept of the minimization of the cost, loss,
    or penalty function.
  id: totrans-4560
  prefs: []
  type: TYPE_NORMAL
- en: Genes
  id: totrans-4561
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, the reproduction process executes the genetic operators on each gene:'
  id: totrans-4562
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE351]'
  id: totrans-4563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE351]'
- en: 'The `Gene` class takes three arguments and two implicit parameters, which are
    as follows:'
  id: totrans-4564
  prefs: []
  type: TYPE_NORMAL
- en: '`id`: This is the identifier of the gene. It is usually the name of the variable
    represented by the gene.'
  id: totrans-4565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target`: This is the target value or threshold to be converted or discretized
    into a bit string.'
  id: totrans-4566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`op`: This is the operator that is applied to the target value.'
  id: totrans-4567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`quantize`: This is the `quantization` or `discretization` class that converts
    a double value to an integer to be converted into bits and vice versa (line `5`).'
  id: totrans-4568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`encoding`: This is the encoding or bits layout of the gene as a pair of values
    and operators.'
  id: totrans-4569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `apply` method encodes a pair of value and operator into a bit set (line
    `6`). An `unapply` method is the reverse operation of `apply`. In this case, it
    decodes a bit set into a pair of value and operator (line `7`).
  id: totrans-4570
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4571
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**unapply()**'
  id: totrans-4572
  prefs: []
  type: TYPE_NORMAL
- en: The `unapply` method reverses the state transition performed by the `apply`
    method. For example, if the `apply` method populates a collection, the `unapply`
    method clears the collection from its elements.
  id: totrans-4573
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of the crossover (line `8`) and mutation (line `9`) operators
    on a gene is similar to the operations on the container chromosome.
  id: totrans-4574
  prefs: []
  type: TYPE_NORMAL
- en: 'The quantization is implemented as a case class:'
  id: totrans-4575
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE352]'
  id: totrans-4576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE352]'
- en: The first `toInt` function converts a real value to an integer and `toDouble`
    converts the integer back to a real value. The `discretization` and `inverse`
    functions are encapsulated into a class to reduce the risk of inconsistency between
    the two opposite conversion functions.
  id: totrans-4577
  prefs: []
  type: TYPE_NORMAL
- en: The instantiation of a gene converts the predicate representation into a bit
    string (bits of the `java.util.BitSet` type) using the quantization function,
    `Quantization.toInt`.
  id: totrans-4578
  prefs: []
  type: TYPE_NORMAL
- en: 'The layout of a gene is defined by the `Encoding` class as follows:'
  id: totrans-4579
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE353]'
  id: totrans-4580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE353]'
- en: The `Encoding` class specifies the bits layout of the gene as a number of bits,
    `nValueBits`, to encode the value and the number of bits, `nOpBits`, to encode
    the operator. The class defines the `rValue` range for the value and the `rOp`
    range for the operator. The client code has to be supplied to the implicit instance
    of the `Encoding` class.
  id: totrans-4581
  prefs: []
  type: TYPE_NORMAL
- en: 'The bit set, `bitset`, of the gene (encoding) is implemented by using the `apply`
    method:'
  id: totrans-4582
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE354]'
  id: totrans-4583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE354]'
- en: The bits layout of the gene is created using `java.util.BitSet`. The `op` operator
    is encoded first through its identifier, `id` (line `10`). The `value` is quantized
    by invoking the `toInt` method and then encoded (line `11`).
  id: totrans-4584
  prefs: []
  type: TYPE_NORMAL
- en: 'The `unapply` method decodes the gene from a bit set or bit string to a pair
    of values and operators. The method uses the quantization instance to cover bits
    into values and a `convert` auxiliary function that is described along with its
    implementation in the source code, accompanying the book (line `12`):'
  id: totrans-4585
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE355]'
  id: totrans-4586
  prefs: []
  type: TYPE_PRE
  zh: '[PRE355]'
- en: 'The `Operator` trait defines the signature of any operator. Each domain-specific
    problem requires a unique set of operations: Boolean, numeric, or string manipulation:'
  id: totrans-4587
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE356]'
  id: totrans-4588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE356]'
- en: 'The preceding operator has two methods: an identifier `id` and an `apply` method
    that converts an index to an operator.'
  id: totrans-4589
  prefs: []
  type: TYPE_NORMAL
- en: Selection
  id: totrans-4590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first genetic operator of the reproduction cycle is the selection process.
    The `select` method of the `Population` class implements the steps of the selection
    phase to the population of chromosomes in the most efficient manner, as follows:'
  id: totrans-4591
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE357]'
  id: totrans-4592
  prefs: []
  type: TYPE_PRE
  zh: '[PRE357]'
- en: 'The `select` method computes the `cumul` cumulative sum of the `cost` (line
    `13`) for the entire population. It normalizes the cost of each chromosome (line
    `14`), orders the population by decreasing the value (line `15`), and applies
    a `cutOff` soft limit function on the population growth (line `16`). The next
    step reduces the size of the population to the lowest of the two limits: the hard
    limit, `limit`, or the soft limit, `cutOffSize`. Finally, the existing chromosomes
    are cleared (line `17`) and updated with the next generation (line `18`).'
  id: totrans-4593
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4594
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Even population size**'
  id: totrans-4595
  prefs: []
  type: TYPE_NORMAL
- en: The next phase in the reproduction cycle is the crossover, which requires the
    pairing of parent chromosomes. It makes sense to pad the population so that its
    size is an even integer.
  id: totrans-4596
  prefs: []
  type: TYPE_NORMAL
- en: The `score` scoring function takes a chromosome as a parameter and returns the
    `cost` value for this chromosome.
  id: totrans-4597
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the population growth
  id: totrans-4598
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The natural selection process controls or manages the growth of the population
    of species. The genetic algorithm uses the following two mechanisms:'
  id: totrans-4599
  prefs: []
  type: TYPE_NORMAL
- en: The absolute maximum size of the population (the hard limit).
  id: totrans-4600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The incentive to reduce the population as the optimization progresses (the soft
    limit). This incentive (or penalty) on the population growth is defined by the
    `cutOff` value used during selection (the `select` method).
  id: totrans-4601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `cutoff` value is computed using a `softLimit` user-defined function of
    the `Int => Double` type, which is provided as a configuration parameter (`softLimit(cycle:
    Int) => a.cycle +b`).'
  id: totrans-4602
  prefs: []
  type: TYPE_NORMAL
- en: The GA configuration
  id: totrans-4603
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The four configurations and tuning parameters required by the genetic algorithm
    are as follows:'
  id: totrans-4604
  prefs: []
  type: TYPE_NORMAL
- en: '`xOver`: This is the crossover ratio (or probability) and has a value in the
    interval [0, 1]'
  id: totrans-4605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mu`: This is the mutation ratio'
  id: totrans-4606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxCycles`: This is the maximum number of reproduction cycles'
  id: totrans-4607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`softLimit`: This is the soft constraint on the population growth'
  id: totrans-4608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following code:'
  id: totrans-4609
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE358]'
  id: totrans-4610
  prefs: []
  type: TYPE_PRE
  zh: '[PRE358]'
- en: Crossover
  id: totrans-4611
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier, the genetic crossover operator couples two chromosomes
    to generate two offspring chromosomes that compete with all the other chromosomes
    in the population, including their own parents, in the selection phase of the
    next reproduction cycle.
  id: totrans-4612
  prefs: []
  type: TYPE_NORMAL
- en: Population
  id: totrans-4613
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We use the `+-` notation as the implementation of the crossover operator in
    Scala. There are several options to select pairs of chromosomes for crossover.
    This implementation ranks the chromosomes by their *fitness* (or inverse `cost`)
    value and then divides the population into two halves. Finally, it pairs the chromosomes
    of identical rank from each half, as illustrated in the following diagram:'
  id: totrans-4614
  prefs: []
  type: TYPE_NORMAL
- en: '![Population](img/image01557.jpeg)'
  id: totrans-4615
  prefs: []
  type: TYPE_IMG
- en: Pairing of chromosomes within a population prior to crossover
  id: totrans-4616
  prefs: []
  type: TYPE_NORMAL
- en: 'The crossover implementation, `+-`, selects the parent chromosome candidates
    for crossover using the pairing scheme described earlier. Consider the following
    code:'
  id: totrans-4617
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE359]'
  id: totrans-4618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE359]'
- en: This method splits the population into two subpopulations of equal size (line
    `19`) and applies the Scala `zip` and `unzip` methods to generate the set of pairs
    of offspring chromosomes (line `20`). The `+-` crossover operator is applied to
    each chromosome pair to produce an array of pairs of `offSprings` (line `21`).
    Finally, the `crossover` method adds offspring chromosomes to the existing population
    (line `22`). The `xOver` crossover value is a probability randomly generated over
    the interval [`config.xOver`, 1].
  id: totrans-4619
  prefs: []
  type: TYPE_NORMAL
- en: 'The `GeneticIndices` case class defines two indices of the bit whenever a crossover
    or a mutation occurs. The first `chOpIdx` index is the absolute index of the bit
    affected by the genetic operation in the chromosome (line `23`). The second `geneOpIdx`
    index is the index of the bit within the gene subjected to crossover or mutation
    (line `24`):'
  id: totrans-4620
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE360]'
  id: totrans-4621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE360]'
- en: 'The `geneticIndices` method computes the relative indices of the crossover
    bit in the chromosomes and genes:'
  id: totrans-4622
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE361]'
  id: totrans-4623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE361]'
- en: The first `chIdx` indexer is the index or rank of the gene within the chromosome
    to be affected by the genetic operator (line `25`). The second `gIdx` indexer
    is the relative index of the bit within the gene (line `26`).
  id: totrans-4624
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a chromosome composed of 2 genes with 63 bits/elements each,
    as illustrated in the following diagram:'
  id: totrans-4625
  prefs: []
  type: TYPE_NORMAL
- en: '![Population](img/image01558.jpeg)'
  id: totrans-4626
  prefs: []
  type: TYPE_IMG
- en: 'The `geneticIndices` method computes the following:'
  id: totrans-4627
  prefs: []
  type: TYPE_NORMAL
- en: The `chIdx` index of the gene within the chromosome and the `gIdx` index of
    the bit within the gene
  id: totrans-4628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The genetic operator selects the gene of the `chIdx` index (that is the second
    gene) to be altered
  id: totrans-4629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The genetic operator alters the chromosome at the bit of the `gIdx` index (that
    is *chIdx*64 + gIdx*)
  id: totrans-4630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chromosomes
  id: totrans-4631
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we need to define the `Chromosome` class, which takes a list of genes,
    `code`, (for genetic code) as the parameter:'
  id: totrans-4632
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE362]'
  id: totrans-4633
  prefs: []
  type: TYPE_PRE
  zh: '[PRE362]'
- en: The cost (or unfitness) of a chromosome is initialized as a random value between
    `QUANT` and `2*QUANT` (line `27`). The genetic `+-` crossover operator generates
    a pair of two offspring chromosomes (line `28`). The genetic `^` mutation operator
    creates a slightly modified (1 or 2 bits) clone of this chromosome (line `29`).
    The `/=` method normalizes the cost of the chromosome (line `30`). The `decode`
    method converts the gene to a logic predicate or rule using an implicit conversion,
    `d`, between a gene and its subclass (line `31`).
  id: totrans-4634
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4635
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Cost initialization**'
  id: totrans-4636
  prefs: []
  type: TYPE_NORMAL
- en: There is no absolute rule to initialize the cost of the chromosomes from an
    initial population. However, it is recommended that you differentiate a chromosome
    using nonzero random values with a large range as their cost.
  id: totrans-4637
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the crossover for a pair of chromosomes using hierarchical
    encoding follows two steps:'
  id: totrans-4638
  prefs: []
  type: TYPE_NORMAL
- en: Find the gene on each chromosome that corresponds to the `indices.chOpIdx` crossover
    index and then swap the remaining genes.
  id: totrans-4639
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split and splice the gene crossover at `xoverIdx`.
  id: totrans-4640
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Consider the following code:'
  id: totrans-4641
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE363]'
  id: totrans-4642
  prefs: []
  type: TYPE_PRE
  zh: '[PRE363]'
- en: 'The crossover method computes the index `xoverIdx` of the bit that defines
    the crossover in each parent chromosome (line `32`). The `this.code(xoverIdx)`
    and `that.code(xoverIdx)` genes are swapped and spliced by the `spliceGene` method
    to generate a spliced gene (line `33`):'
  id: totrans-4643
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE364]'
  id: totrans-4644
  prefs: []
  type: TYPE_PRE
  zh: '[PRE364]'
- en: The offspring chromosomes are gathered by collating the first `xOverIdx` genes
    of the parent chromosome, the crossover gene, and the remaining genes of the other
    parent (line `34`). The method returns the pair of offspring chromosomes (line
    `35`).
  id: totrans-4645
  prefs: []
  type: TYPE_NORMAL
- en: Genes
  id: totrans-4646
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The crossover is applied to a gene using the `+-` method of the `Gene` class.
    The exchange of bits between the `this` and `that` genes uses the `BitSet` Java
    class to rearrange the bits after the permutation:'
  id: totrans-4647
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE365]'
  id: totrans-4648
  prefs: []
  type: TYPE_PRE
  zh: '[PRE365]'
- en: The bits of the gene are cloned (line `36`) and then spliced by exchanging their
    bits along with the `indices.geneOpIdx` crossover point (line `37`). The `cloneBits`
    function duplicates a bit string, which is then converted into a (target value,
    operator) tuple using the `decode` method (line `38`). We omit these two methods
    because they are not critical to the understanding of the algorithm.
  id: totrans-4649
  prefs: []
  type: TYPE_NORMAL
- en: Mutation
  id: totrans-4650
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mutation of the population uses the same algorithmic approach as the crossover
    operation.
  id: totrans-4651
  prefs: []
  type: TYPE_NORMAL
- en: Population
  id: totrans-4652
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `^` mutation operator invokes the same operator for all the chromosomes
    in the population and then adds the mutated chromosomes to the existing population,
    so that they can compete with the original chromosomes. We use the `^` notation
    to define the mutation operator to remind you that the mutation is implemented
    by flipping one bit:'
  id: totrans-4653
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE366]'
  id: totrans-4654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE366]'
- en: The `prob` mutation parameter is used to compute the absolute index of the mutating
    gene, `geneticIndices(prob)`.
  id: totrans-4655
  prefs: []
  type: TYPE_NORMAL
- en: Chromosomes
  id: totrans-4656
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The implementation of the `^` mutation operator on a chromosome consists of
    mutating the gene of the `indices.chOpIdx` index (line `39`) and then updating
    the list of genes in the chromosome (line `40`). The method returns a new chromosome
    (line `41`) that will compete with the original chromosome:'
  id: totrans-4657
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE367]'
  id: totrans-4658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE367]'
- en: Genes
  id: totrans-4659
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, the mutation operator flips (XOR) the bit at the `indices.geneOpIdx`
    index:'
  id: totrans-4660
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE368]'
  id: totrans-4661
  prefs: []
  type: TYPE_PRE
  zh: '[PRE368]'
- en: The `^` method mutates the cloned bit string, `clonedBits`, (line `42`) by flipping
    the bit at the `indices.geneOpIdx` index (line `43`). It decodes and converts
    the mutated bit string by converting it into a (target value, operator) tuple
    (line `44`). The last step creates a new gene from the target-operator tuple (line
    `45`).
  id: totrans-4662
  prefs: []
  type: TYPE_NORMAL
- en: Reproduction
  id: totrans-4663
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s wrap the reproduction cycle into a `Reproduction` class that uses the
    scoring function, `score`:'
  id: totrans-4664
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE369]'
  id: totrans-4665
  prefs: []
  type: TYPE_PRE
  zh: '[PRE369]'
- en: 'The `mate` reproduction function implements the sequence or workflow of the
    three genetic operators: `select` for the selection, `+-` (xover) for the crossover,
    and `^` (mu) for the mutation:'
  id: totrans-4666
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE370]'
  id: totrans-4667
  prefs: []
  type: TYPE_PRE
  zh: '[PRE370]'
- en: 'The `mate` method returns false (that is, the reproduction cycle aborts) if
    the population size is less than 3 (line `46`). The chromosomes in the current
    population are ranked by the increasing cost. The chromosomes with the high cost
    or low fitness are discarded to comply with the soft limit, `softLimit`, on the
    population growth (line `47`). The randomly generated probability is used as an
    input to the crossover operation on the entire remaining population (line `48`)
    and as an input to the mutation of the remaining population (line `49`):'
  id: totrans-4668
  prefs: []
  type: TYPE_NORMAL
- en: '![Reproduction](img/image01559.jpeg)'
  id: totrans-4669
  prefs: []
  type: TYPE_IMG
- en: An illustration of the linear and quadratic soft limit for the population growth
  id: totrans-4670
  prefs: []
  type: TYPE_NORMAL
- en: Solver
  id: totrans-4671
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `GASolver` class manages the reproduction cycles and the population of chromosomes.
    The solver is defined as a data transformation of the `ETransform` type using
    an explicit configuration of the `GAConfig` type, as described in the *Monadic
    data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!* (line `50`).
  id: totrans-4672
  prefs: []
  type: TYPE_NORMAL
- en: The `GASolver` class implements the `GAMonitor` trait to monitor the population
    diversity, manage the reproduction cycle, and control the convergence of the optimizer
    (line `51`).
  id: totrans-4673
  prefs: []
  type: TYPE_NORMAL
- en: 'The genetic algorithm-based solver has the following three arguments:'
  id: totrans-4674
  prefs: []
  type: TYPE_NORMAL
- en: '`config`: This is the configuration of the execution of the genetic algorithm'
  id: totrans-4675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score`: This is the scoring function of a chromosome'
  id: totrans-4676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tracker`: This is the optional tracking function to initialize the monitoring
    function of `GAMonitor`'
  id: totrans-4677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code will be as follows:'
  id: totrans-4678
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE371]'
  id: totrans-4679
  prefs: []
  type: TYPE_PRE
  zh: '[PRE371]'
- en: This explicit data transformation has to initialize the `U` type of an input
    element (line `52`) and the `V` type of an output element (line `53`) for the
    prediction or optimization method, `|>`. The optimizer takes an initial population
    as the input and generates a very small population of the fittest chromosomes
    from which the best solution is extracted (line `55`).
  id: totrans-4680
  prefs: []
  type: TYPE_NORMAL
- en: The population is generated by the `|>` method `( => Population[T])` that takes
    the constructor of the `Population` class as an argument (line `54`).
  id: totrans-4681
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s briefly take a look at the `GAMonitor` monitoring trait assigned to
    the genetic algorithm. The trait has the following two attributes:'
  id: totrans-4682
  prefs: []
  type: TYPE_NORMAL
- en: '`monitor`: This is an abstract value to be initialized by classes that implement
    this trait (line `55`).'
  id: totrans-4683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`state`: This is the current state of the execution of the genetic algorithm.
    The initial state of the genetic algorithm is `GA_NOT_RUNNING` (line `56`).'
  id: totrans-4684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code will be as follows:'
  id: totrans-4685
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE372]'
  id: totrans-4686
  prefs: []
  type: TYPE_PRE
  zh: '[PRE372]'
- en: The `state` of the genetic algorithm can only be updated in the `|>` method
    through an instance of the `GAMonitor` class. (line `55`).
  id: totrans-4687
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a subset of the possible state of the execution of the genetic algorithm:'
  id: totrans-4688
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE373]'
  id: totrans-4689
  prefs: []
  type: TYPE_PRE
  zh: '[PRE373]'
- en: The solver invokes the `isComplete` method to test the convergence of the optimizer
    at each reproduction cycle (line `58`).
  id: totrans-4690
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options for estimating that the reproducing cycle is converging:'
  id: totrans-4691
  prefs: []
  type: TYPE_NORMAL
- en: '**Greedy**: In this approach, the objective is to check whether the *n* fittest
    chromosomes have not changed in the last *m* reproduction cycles'
  id: totrans-4692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function**: This approach is similar to the convergence criteria for
    the training of supervised learning'
  id: totrans-4693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s consider the following implementation of the genetic algorithm solver:'
  id: totrans-4694
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE374]'
  id: totrans-4695
  prefs: []
  type: TYPE_PRE
  zh: '[PRE374]'
- en: The optimizing method initializes the state of execution (line `59`) and the
    components of the `reproduction` cycle (line `60`). The reproduction cycle (or
    an epoch) is implemented as a tail recursion that tests whether the last reproduction
    cycle has failed or whether the optimization has converged toward a solution (line
    `61`). Finally, the remaining fittest chromosomes are reordered by invoking the
    `select` method of the `Population` class (line `62`).
  id: totrans-4696
  prefs: []
  type: TYPE_NORMAL
- en: GA for trading strategies
  id: totrans-4697
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's apply our expertise in genetic algorithms to evaluate different strategies
    to trade securities using trading signals. Knowledge in trading strategies is
    not required to understand the implementation of a GA. However, you may want to
    get familiar with the foundation and terminology of technical analysis of securities
    and financial markets, as described briefly in the *Technical analysis* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*.
  id: totrans-4698
  prefs: []
  type: TYPE_NORMAL
- en: The problem is to find the best trading strategy to predict the increase or
    decrease of the price of a security given a set of trading signals. A trading
    strategy is defined as a set of trading signals *ts[j]* that are triggered or
    fired when a variable *x = {x[j]}*, derived from financial metrics such as the
    price of the security or the daily or weekly trading volume, either exceeds or
    equals or is below a predefined target value *α[j]* (refer to the *Trading signals
    and strategy* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic
    Concepts"), *Basic Concepts*).
  id: totrans-4699
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of variables that can be derived from price and volume can be very
    large. Even the most seasoned financial professionals face two challenges, which
    are as follows:'
  id: totrans-4700
  prefs: []
  type: TYPE_NORMAL
- en: Selecting a minimal set of trading signals that are relevant to a given dataset
    (minimize a cost or unfitness function)
  id: totrans-4701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turning those trading signals with heuristics derived from personal experience
    and expertise
  id: totrans-4702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4703
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Alternative to GA**'
  id: totrans-4704
  prefs: []
  type: TYPE_NORMAL
- en: The problem described earlier can certainly be solved using one of the machine
    learning algorithms introduced in the previous chapters. It is just a matter of
    defining a training set and formulating the problem as minimizing the loss function
    between the predictor and the training score.
  id: totrans-4705
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the trading classes with their counterpart in the
    genetic world:'
  id: totrans-4706
  prefs: []
  type: TYPE_NORMAL
- en: '| Generic classes | Corresponding securities trading classes |'
  id: totrans-4707
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-4708
  prefs: []
  type: TYPE_TB
- en: '| Operator | `SOperator` |'
  id: totrans-4709
  prefs: []
  type: TYPE_TB
- en: '| Gene | `Signal` |'
  id: totrans-4710
  prefs: []
  type: TYPE_TB
- en: '| Chromosome | `Strategy` |'
  id: totrans-4711
  prefs: []
  type: TYPE_TB
- en: '| Population | `StrategiesFactory` |'
  id: totrans-4712
  prefs: []
  type: TYPE_TB
- en: Definition of trading strategies
  id: totrans-4713
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A chromosome is the genetic encoding of a trading strategy. A factory class,
    `StrategyFactory`, assembles the components of a trading strategy: operators,
    unfitness function, and signals'
  id: totrans-4714
  prefs: []
  type: TYPE_NORMAL
- en: Trading operators
  id: totrans-4715
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s extend the `Operator` trait with the `SOperator` class to define the
    operations that we need to trigger the signals. The `SOperator` instance has a
    single parameter: its identifier, `_id`. The class overrides the `id()` method
    to retrieve the ID (similarly, the class overrides the `apply` method to convert
    an ID into an `SOperator` instance):'
  id: totrans-4716
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE375]'
  id: totrans-4717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE375]'
- en: 'The operators used by trading signals are the logical operators: < (`LESS_THAN`),
    > (`GREATER_THAN`), and = (`EQUAL`), as follows:'
  id: totrans-4718
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE376]'
  id: totrans-4719
  prefs: []
  type: TYPE_PRE
  zh: '[PRE376]'
- en: 'Each operator of the `SOperator` type is associated with a scoring function
    by the `operatorFuncMap` map. The scoring function computes the cost (or unfitness)
    of the signal against a real value or a time series:'
  id: totrans-4720
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE377]'
  id: totrans-4721
  prefs: []
  type: TYPE_PRE
  zh: '[PRE377]'
- en: The `select` method of `Population` computes the `cost` value of a signal by
    quantifying the truthfulness of the predicate. For instance, the unfitness value
    for a trading signal, *x > 10*, is penalized as *5 – 10 = -5* for *x = 5* and
    credited as *14 – 10 = 4* if *x = 14*. In this case, the unfitness value is similar
    to the cost or loss in a discriminative machine learning algorithm.
  id: totrans-4722
  prefs: []
  type: TYPE_NORMAL
- en: The cost function
  id: totrans-4723
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s consider the following trading strategy defined as a set of two signals
    to predict the sudden relative decrease *Δp* of the price of a security:'
  id: totrans-4724
  prefs: []
  type: TYPE_NORMAL
- en: Relative volume *v[m]* with a condition *v[m] < α*
  id: totrans-4725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relative volatility *v[l]* with the condition *v[l] > β*
  id: totrans-4726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following graphs:'
  id: totrans-4727
  prefs: []
  type: TYPE_NORMAL
- en: '![The cost function](img/image01560.jpeg)'
  id: totrans-4728
  prefs: []
  type: TYPE_IMG
- en: A chart of the price, relative volume, and relative volatility of a security
  id: totrans-4729
  prefs: []
  type: TYPE_NORMAL
- en: 'As the goal is to model a sudden crash in the stock price, we should reward
    the trading strategies that predict the steep decrease in the stock price and
    penalize the strategies that work well only with a small decrease or increase
    in the stock price. In the case of the trading strategy with two signals, relative
    volume *v[m]* and relative volatility *v[l]*, *n* trading sessions, the cost or
    unfitness function *C*, and given a relative variation of the stock price and
    a penalization *w = -Δp (M2)*:'
  id: totrans-4730
  prefs: []
  type: TYPE_NORMAL
- en: '![The cost function](img/image01561.jpeg)'
  id: totrans-4731
  prefs: []
  type: TYPE_IMG
- en: Trading signals
  id: totrans-4732
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s subclass the `Gene` class to define the trading signal of the `Signal`
    type as follows:'
  id: totrans-4733
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE378]'
  id: totrans-4734
  prefs: []
  type: TYPE_PRE
  zh: '[PRE378]'
- en: 'The `Signal` class requires the following arguments:'
  id: totrans-4735
  prefs: []
  type: TYPE_NORMAL
- en: An identifier `id` for the feature
  id: totrans-4736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `target` value
  id: totrans-4737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An `op` operator
  id: totrans-4738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An `xt` time series of the `DblVector` type
  id: totrans-4739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The optional `weights` associated with each data point of the time series, `xt`
  id: totrans-4740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implicit quantization instance, `quantize`
  id: totrans-4741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An implicit `encoding` scheme
  id: totrans-4742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The main purpose of the `Signal` class is to compute its `score` as a chromosome.
    The chromosome updates its `cost` by summing the score or weighted score of the
    signals it contains. The score of the trading signal is simply the summation of
    the penalty or truthfulness of the signal for each entry of the time series, `ts`:'
  id: totrans-4743
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE379]'
  id: totrans-4744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE379]'
- en: Trading strategies
  id: totrans-4745
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A trading strategy is an unordered list of trading signals. It makes sense
    to create a factory class to generate the trading strategies. The `StrategyFactory`
    class creates strategies of the `List[Signal]` type from an existing pool of signals
    of the subtype, `Gene`:'
  id: totrans-4746
  prefs: []
  type: TYPE_NORMAL
- en: '![Trading strategies](img/image01562.jpeg)'
  id: totrans-4747
  prefs: []
  type: TYPE_IMG
- en: A factory pattern for trading signals
  id: totrans-4748
  prefs: []
  type: TYPE_NORMAL
- en: 'The `StrategyFactory` class has two arguments: the number of signals, `nSignals`,
    in a trading strategy and the implicit `Quantization` and `Encoding` instances
    (line `63`):'
  id: totrans-4749
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE380]'
  id: totrans-4750
  prefs: []
  type: TYPE_PRE
  zh: '[PRE380]'
- en: 'The `+=` method takes five arguments: the identifier `id`, the `target` value,
    the `op` operation to qualify the class as `Gene`, the `xt` times series for scoring
    the signals, and the `weights` associated with the overall cost function. The
    `StrategyFactory` class generates all possible sequences of signals as trading
    strategies as lazy values to avoid unnecessary regeneration of the pool on demand
    (line `64`), as follows:'
  id: totrans-4751
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE381]'
  id: totrans-4752
  prefs: []
  type: TYPE_PRE
  zh: '[PRE381]'
- en: 'The implementation of the `strategies` value creates a pool of signals `Pool`
    (line `65`) by converting the list of signals to `treeset` (line `66`). It breaks
    down the tree set into unique subtrees of `nSignals` nodes each. It instantiates
    a `subsetsIterator` iterator to traverse the sequence of subtrees (line `67`)
    and converts them into a list (line `68`) as arguments of the new chromosome (trading
    strategy) (line `69`). The procedure to order the signals, `orderedSignals,` in
    the tree set has to be implicitly defined (line `70`) as `val orderedSignals =
    Ordering.by((signal: Signal) => signal.id)`.'
  id: totrans-4753
  prefs: []
  type: TYPE_NORMAL
- en: Trading signal encoding
  id: totrans-4754
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The encoding of trading predicates is the most critical element of the genetic
    algorithm. In our example, we encode a predicate as a tuple (target value, operator).
    Let''s consider the simple predicate *volatility > 0.62*. The discretization converts
    the value 0.62 into 32 bits for the instance and a 2-bit representation for the
    operator:'
  id: totrans-4755
  prefs: []
  type: TYPE_NORMAL
- en: '![Trading signal encoding](img/image01563.jpeg)'
  id: totrans-4756
  prefs: []
  type: TYPE_IMG
- en: 'Encoding of the trading signal: volatility > 0.62'
  id: totrans-4757
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4758
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**IEEE-732 encoding**'
  id: totrans-4759
  prefs: []
  type: TYPE_NORMAL
- en: 'The threshold value for predicates is converted into an integer (the `Int`
    type or `Long`). The IEEE-732 binary representation of floating point values makes
    the bit addressing required to apply genetic operators quite challenging. A simple
    conversion consists of the following:'
  id: totrans-4760
  prefs: []
  type: TYPE_NORMAL
- en: '`encoding e: (x: Double) => (x*100000).toInt`'
  id: totrans-4761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoding d: (x: Int) => x*1e-5`'
  id: totrans-4762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All values are normalized, so there is no risk of overflowing the 32-bit representation.
  id: totrans-4763
  prefs: []
  type: TYPE_NORMAL
- en: A test case
  id: totrans-4764
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The goal is to evaluate which trading strategy was the most relevant (fittest)
    during the crash of the stock market in fall 2008\. Let''s consider the stock
    price of one of the financial institutions, Goldman Sachs, as a proxy of the sudden
    market decline:'
  id: totrans-4765
  prefs: []
  type: TYPE_NORMAL
- en: '![A test case](img/image01564.jpeg)'
  id: totrans-4766
  prefs: []
  type: TYPE_IMG
- en: A sudden decrease in Goldman-Sachs stock price in Sept – Nov 2008
  id: totrans-4767
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the variation of the price of the stock between two consecutive trading
    sessions (`dPrice`), the model uses the following parameters (or trading signals):'
  id: totrans-4768
  prefs: []
  type: TYPE_NORMAL
- en: '`dVolume`: This is the relative variation of the volume between two consecutive
    trading sessions'
  id: totrans-4769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dVolatility`: This is the relative variation of volatility between two consecutive
    trading sessions'
  id: totrans-4770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`volatility`: This is the relative volatility within a trading session'
  id: totrans-4771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vPrice`: This is the relative difference of the stock opening and closing
    price'
  id: totrans-4772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The naming convention for the trading data and metrics is described in the *Trading
    data* section under *Technical analysis* in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*.
  id: totrans-4773
  prefs: []
  type: TYPE_NORMAL
- en: 'The execution of the genetic algorithm requires the following steps:'
  id: totrans-4774
  prefs: []
  type: TYPE_NORMAL
- en: Extraction of model parameters or variables.
  id: totrans-4775
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generation of the initial population of trading strategies.
  id: totrans-4776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting up the GA configuration parameters with the maximum number of reproduction
    cycles allowed, the crossover and mutation ratio, and the soft limit function
    for the population growth.
  id: totrans-4777
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instantiating the GA algorithm with the scoring/unfitness function.
  id: totrans-4778
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extracting the fittest trading strategy that can best explain the sharp decline
    in the price of Goldman Sachs stocks.
  id: totrans-4779
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating trading strategies
  id: totrans-4780
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The input to the genetic algorithm is the population of trading strategies.
    Each strategy consists of the combination of three trading signals and each trading
    signal is a tuple (signal ID, operator, and target value).
  id: totrans-4781
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to extract the model parameters as illustrated for the variation
    of the stock price volume, volatility, and relative volatility between two consecutive
    trading sessions (line `71`):'
  id: totrans-4782
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE382]'
  id: totrans-4783
  prefs: []
  type: TYPE_PRE
  zh: '[PRE382]'
- en: 'The purpose is to generate the initial population of strategies that compete
    to become relevant to the decline of the price of stocks of Goldman Sachs. The
    initial population of trading strategies is generated by creating a combination
    from four trading signals weighted by the variation in the stock price: *∆(volume)
    > 1.1*, *∆(volatility) > 1.3*, *∆(close-open) < 0.8*, and *volatility > 0.9*.'
  id: totrans-4784
  prefs: []
  type: TYPE_NORMAL
- en: 'The `delta` method computes the variation of a trading variable between consecutive
    trading sessions. It invokes the `XTSeries.zipWithShift` method, which was introduced
    in the *Time series in Scala* section in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*:'
  id: totrans-4785
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE383]'
  id: totrans-4786
  prefs: []
  type: TYPE_PRE
  zh: '[PRE383]'
- en: 'The trading strategies are generated by the `StrategyFactory` class introduced
    in the previous section (line `73`). The `weights` for the trading strategies
    are computed as the `dPrice` difference of the price of the stock between two
    consecutive trading sessions (line `74`). The option of unweighted trading strategies
    is selected by replacing the `weights` by the average price variation as follows:'
  id: totrans-4787
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE384]'
  id: totrans-4788
  prefs: []
  type: TYPE_PRE
  zh: '[PRE384]'
- en: 'The generation of the initial population of trading strategies is illustrated
    in the following diagram:'
  id: totrans-4789
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating trading strategies](img/image01565.jpeg)'
  id: totrans-4790
  prefs: []
  type: TYPE_IMG
- en: A design for the generation of the initial population of trading strategies
  id: totrans-4791
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the optimizer
  id: totrans-4792
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The configuration parameters for the execution of the genetic algorithm is
    categorized as follows:'
  id: totrans-4793
  prefs: []
  type: TYPE_NORMAL
- en: Tuning parameters such as crossover, mutation ratio, or soft limit on the population
    growth
  id: totrans-4794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data representation parameters such as quantization and encoding
  id: totrans-4795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A scoring scheme
  id: totrans-4796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The four configuration parameters for the GA are the maximum number of reproduction
    cycles (`MAX_CYCLES`) allowed in the execution, the crossover (`XOVER`), the mutation
    ratio (`MU`), and the soft limit function (`softLimit`) to control the population
    growth. The soft limit is implemented as a linearly decreasing function of the
    number of cycles (`n`) to retrain the growth of the population as the execution
    of the genetic algorithm progresses:'
  id: totrans-4797
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE385]'
  id: totrans-4798
  prefs: []
  type: TYPE_PRE
  zh: '[PRE385]'
- en: 'The trading strategies are converted into chromosomes through `encoding` (line
    `75`). A `digitize` quantization scheme has to be implicitly defined in order
    to encode the target value in each trading signal (line `76`):'
  id: totrans-4799
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE386]'
  id: totrans-4800
  prefs: []
  type: TYPE_PRE
  zh: '[PRE386]'
- en: 'The `scoring` function computes the `cost` or unfitness of a trading strategy
    (chromosome) by applying the `score` function to each of the three trading signals
    (genes) it contains (line `77`):'
  id: totrans-4801
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE387]'
  id: totrans-4802
  prefs: []
  type: TYPE_PRE
  zh: '[PRE387]'
- en: Finding the best trading strategy
  id: totrans-4803
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The trading `strategies` generated by the factory in the `createStrategies`
    method are fed to the genetic algorithm as the `initial` population (line `79`).
    The upper `limit` to the population growth is set at eight times the size of the
    initial population (line `78`):'
  id: totrans-4804
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE388]'
  id: totrans-4805
  prefs: []
  type: TYPE_PRE
  zh: '[PRE388]'
- en: The configuration, `config` (line `80`), the scoring function, and optionally
    a tracker function are all that you need to create and execute the `solver` genetic
    algorithm (line `81`). The partial function generated by the `|>` operator transforms
    the `initial` population of trading strategies into the two `fittest` strategies
    (line `82`).
  id: totrans-4806
  prefs: []
  type: TYPE_NORMAL
- en: The documented source code for the monitoring function, tracker, and miscellaneous
    methods is available online.
  id: totrans-4807
  prefs: []
  type: TYPE_NORMAL
- en: Tests
  id: totrans-4808
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The cost function *C* (or unfitness) score of each trading strategy are weighted
    for the rate of decline of the price of the Goldman Sachs stock. Let''s run the
    following two tests:'
  id: totrans-4809
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation of the configuration of the genetic algorithm with the score weighted
    by the price variation
  id: totrans-4810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation of the genetic algorithm with an unweighted scoring function
  id: totrans-4811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The weighted score
  id: totrans-4812
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The score is weighted by the variation of the price of the stock GS. The test
    uses three different sets of crossover and mutation ratios: (0.6, 0.2), (0.3,
    0.1), and (0.2, 0.6). The best trading strategy for each scenario is as follows:'
  id: totrans-4813
  prefs: []
  type: TYPE_NORMAL
- en: '**0.6-0.2**: *change < 0.82 dVolume > 1.17 volatility > 1.35 cost= 0.0 fitness:
    1.0E10*'
  id: totrans-4814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**0.3-0.1**: *change < 0.42 dVolume > 1.61 volatility > 1.08 cost= 59.18 fitness:
    0.016*'
  id: totrans-4815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**0.2-0.6**: *change < 0.87 dVolume < 8.17 volatility > 3.91 cost= 301.3 fitness:
    0.003*'
  id: totrans-4816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The fittest trading strategy for each case does not differ much from the initial
    population for one or several of the following reasons:'
  id: totrans-4817
  prefs: []
  type: TYPE_NORMAL
- en: The initial guess for the trading signals was good
  id: totrans-4818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the initial population is too small to generate genetic diversity
  id: totrans-4819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The test does not take into account the rate of decline of the stock price
  id: totrans-4820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution of the genetic algorithm with *cross-over = 0.2* and *mutation
    = 0.6* produces a trading strategy that is inconsistent with the first two cases.
    One possible explanation is the fact that the crossover is applied always to the
    first of the three genes, forcing the optimizer to converge toward a local minimum.
  id: totrans-4821
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine the behavior of the genetic algorithm during execution. We are
    particularly interested in the convergence of the average chromosome unfitness
    score. The average chromosome unfitness is the ratio of the total unfitness score
    for the population over the size of the population. Let''s take a look at the
    following graph:'
  id: totrans-4822
  prefs: []
  type: TYPE_NORMAL
- en: '![The weighted score](img/image01566.jpeg)'
  id: totrans-4823
  prefs: []
  type: TYPE_IMG
- en: The convergence of a genetic algorithm for the crossover ratio 0.2 and mutation
    0.6 with a weighted score
  id: totrans-4824
  prefs: []
  type: TYPE_NORMAL
- en: 'The GA converges quite quickly and then stabilizes. The size of the population
    increases through crossover and mutation operations until it reaches the maximum
    of 256 trading strategies. The soft limit or constraint on the population size
    kicks in after 23 trading cycles. The test is run again with different values
    of crossover and mutation ratios, as shown in the following graph:'
  id: totrans-4825
  prefs: []
  type: TYPE_NORMAL
- en: '![The weighted score](img/image01567.jpeg)'
  id: totrans-4826
  prefs: []
  type: TYPE_IMG
- en: The impact of the crossover and mutation ratio on the convergence of a genetic
    algorithm with a weighted score
  id: totrans-4827
  prefs: []
  type: TYPE_NORMAL
- en: The profile of the execution of the genetic algorithm is not overly affected
    by the different values of crossover and mutation ratios. The chromosome unfitness
    score for the high crossover ratio (0.6) oscillates as the execution progresses.
    In some cases, the unfitness score between chromosomes is so small that the GA
    recycles the same few trading strategies.
  id: totrans-4828
  prefs: []
  type: TYPE_NORMAL
- en: The quick decline in the unfitness of the chromosomes is consistent with the
    fact that some of the fittest strategies were part of the initial population.
    It should, however, raise some concerns that the GA locked on a local minimum
    early on.
  id: totrans-4829
  prefs: []
  type: TYPE_NORMAL
- en: The unweighted score
  id: totrans-4830
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The execution of a test that is similar to the previous one with the unweighted
    trading strategies (trading strategies that use the average price variation) scoring
    formula produces some interesting results, as shown in the following graph:'
  id: totrans-4831
  prefs: []
  type: TYPE_NORMAL
- en: '![The unweighted score](img/image01568.jpeg)'
  id: totrans-4832
  prefs: []
  type: TYPE_IMG
- en: The convergence of a genetic algorithm for the crossover ratio 0.4 and mutation
    0.4 with an unweighted score
  id: totrans-4833
  prefs: []
  type: TYPE_NORMAL
- en: The profile for the size of the population is similar to the test using weighted
    scoring. However, the chromosome average cost pattern is somewhat linear. The
    unweighted (or averaging) adds the rate of decline of the stock price to the score
    (cost).
  id: totrans-4834
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4835
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The complexity of a scoring function**'
  id: totrans-4836
  prefs: []
  type: TYPE_NORMAL
- en: 'The complexity of the scoring (or computation of the cost) formula increases
    the odds of the genetic algorithm not converging properly. The possible solutions
    to the convergence problem are as follows:'
  id: totrans-4837
  prefs: []
  type: TYPE_NORMAL
- en: Make the weighting function additive (less complex)
  id: totrans-4838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase the size and diversity of the initial population
  id: totrans-4839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and risks of genetic algorithms
  id: totrans-4840
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, it should be clear that genetic algorithms provide scientists with a powerful
    toolbox with which to optimize problems that:'
  id: totrans-4841
  prefs: []
  type: TYPE_NORMAL
- en: Are poorly understood.
  id: totrans-4842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: May have more than one good enough solution.
  id: totrans-4843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have discrete, discontinuous, and nondifferentiable functions.
  id: totrans-4844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be easily integrated with the rules engine and knowledge bases (for example,
    learning classifiers systems).
  id: totrans-4845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not require deep domain knowledge. The genetic algorithm generates new solution
    candidates through genetic operators. The initial population does not have to
    contain the fittest solution.
  id: totrans-4846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not require knowledge of numerical methods such as the **Newton-Raphson**,
    **conjugate gradient**, or **BFGS** as optimization techniques, which frighten
    those with little inclination for mathematics.
  id: totrans-4847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, evolutionary computation is not suitable for problems for which:'
  id: totrans-4848
  prefs: []
  type: TYPE_NORMAL
- en: A fitness function cannot be clearly defined
  id: totrans-4849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the global (absolute) minimum or maximum is essential to the problem
  id: totrans-4850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution time has to be predictable
  id: totrans-4851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The solution has to be provided in real time or pseudo-real time (streaming
    data)
  id: totrans-4852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-4853
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Are you hooked on evolutionary computation, genetic algorithms in particular,
    and their benefits, limitations as well as some of the common pitfalls? If the
    answer is yes, then you may find learning classifier systems, introduced in the
    next chapter, fascinating. This chapter dealt with the following topics:'
  id: totrans-4854
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts in evolutionary computing
  id: totrans-4855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key components and operators of genetic operators
  id: totrans-4856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pitfalls in defining a fitness or unfitness score using a financial trading
    strategy as a backdrop
  id: totrans-4857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenge of encoding predicates in the case of trading strategies
  id: totrans-4858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advantages and risks of genetic algorithms
  id: totrans-4859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The process for building a genetic algorithm forecasting tool from the bottom
    up
  id: totrans-4860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The genetic algorithm is an important element of a special class of reinforcement
    learning, which is introduced in the *Learning classifier systems* section in
    the next chapter.
  id: totrans-4861
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 11. Reinforcement Learning
  id: totrans-4862
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter presents the concept of **reinforcement learning**, which is widely
    used in gaming and robotics. The second part of this chapter is dedicated to **learning
    classifier systems**, which combine reinforcement learning techniques with evolutionary
    computing introduced in the previous chapter. Learning classifiers are an interesting
    breed of algorithms that are not commonly included in literature dedicated to
    machine learning. I highly recommend that you to read the seminal book on reinforcement
    learning by R. Sutton and A. Barto [11:1] if you are interested to know about
    the origin, purpose, and scientific foundation of reinforcement learning.
  id: totrans-4863
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn the following topics:'
  id: totrans-4864
  prefs: []
  type: TYPE_NORMAL
- en: Basic concepts behind reinforcement learning
  id: totrans-4865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A detailed implementation of the Q-learning algorithm
  id: totrans-4866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A simple approach to manage and balance an investment portfolio using reinforcement
    learning
  id: totrans-4867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to learning classifier systems
  id: totrans-4868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A simple implementation of extended learning classifiers
  id: totrans-4869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The section on **learning classifier systems** (**LCS**) is mainly informative
    and does not include a test case.
  id: totrans-4870
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  id: totrans-4871
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The need of an alternative to traditional learning techniques arose with the
    design of the first autonomous systems.
  id: totrans-4872
  prefs: []
  type: TYPE_NORMAL
- en: The problem
  id: totrans-4873
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Autonomous systems** are semi-independent systems that perform tasks with
    a high degree of autonomy. Autonomous systems touch every facet of our life, from
    robots and self-driving cars to drones. Autonomous devices react to the environment
    in which they operate. The reaction or action requires the knowledge of not only
    the current state of the environment but also the previous state(s).'
  id: totrans-4874
  prefs: []
  type: TYPE_NORMAL
- en: 'Autonomous systems have specific characteristics that challenge traditional
    methodologies of machine learning, as listed here:'
  id: totrans-4875
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous systems have poorly defined domain knowledge because of the sheer
    number of possible combinations of states.
  id: totrans-4876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Traditional nonsequential supervised learning is not a practical option because
    of the following:'
  id: totrans-4877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training consumes significant computational resources, which are not always
    available on small autonomous devices
  id: totrans-4878
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Some learning algorithms are not suitable for real-time prediction
  id: totrans-4879
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The models do not capture the sequential nature of the data feed
  id: totrans-4880
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequential data models such as hidden Markov models require training sets to
    compute the emission and state transition matrices (as explained in *The hidden
    Markov model* section in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential
    Data Models"), *Sequential Data Models*), which are not always available. However,
    a reinforcement learning algorithm benefits from a hidden Markov model if some
    of the states are unknown. These algorithms are known as behavioral hidden Markov
    models [11:2].
  id: totrans-4881
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Genetic algorithms are an option if the search space can be constrained heuristically.
    However, genetic algorithms have unpredictable response time, which makes them
    impractical for real-time processing.
  id: totrans-4882
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A solution – Q-learning
  id: totrans-4883
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Reinforcement learning is an algorithmic approach to understanding and ultimately
    automating goal-based decision making. Reinforcement learning is also known as
    control learning. It differs from both supervised and unsupervised learning techniques
    from the knowledge acquisition standpoint: **autonomous**, automated systems,
    or devices learn from direct and real-time interaction with their environment.
    There are numerous practical applications of reinforcement learning from robotics,
    navigation agents, drones, adaptive process control, game playing, and online
    learning, to scheduling and routing problems.'
  id: totrans-4884
  prefs: []
  type: TYPE_NORMAL
- en: Terminology
  id: totrans-4885
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Reinforcement learning introduces new terminologies as listed here, which are
    quite different from that of older machine learning techniques:'
  id: totrans-4886
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment**: This is any system that has states and mechanisms to transition
    between states. For example, the environment for a robot is the landscape or facility
    it operates.'
  id: totrans-4887
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agent**: This is an automated system that interacts with the environment.'
  id: totrans-4888
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**State**: The state of the environment or system is the set of variables or
    features that fully describe the environment.'
  id: totrans-4889
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Goal or absorbing state or terminal state**: This is the state that provides
    a higher discounted cumulative reward than any other state. A high cumulative
    reward prevents the best policy from being dependent on the initial state during
    training.'
  id: totrans-4890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Action**: This defines the transition between states. The agent is responsible
    for performing or at least recommending an action. Upon execution of the action,
    the agent collects a reward (or punishment) from the environment.'
  id: totrans-4891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Policy**: This defines the action to be selected and executed for any state
    of the environment.'
  id: totrans-4892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Best policy**: This is the policy generated through training. It defines
    the model in Q-learning and is constantly updated with any new episode.'
  id: totrans-4893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reward**: This quantifies the positive or negative interaction of the agent
    with the environment. Rewards are essentially the training set for the learning
    engine.'
  id: totrans-4894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Episode**: This defines the number of steps necessary to reach the goal state
    from an initial state. Episodes are also known as trials.'
  id: totrans-4895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizon**: This is the number of future steps or actions used in the maximization
    of the reward. The horizon can be infinite, in which case the future rewards are
    discounted in order for the value of the policy to converge.'
  id: totrans-4896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concepts
  id: totrans-4897
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The key component in reinforcement learning is a **decision-making agent**
    that reacts to its environment by selecting and executing the best course of actions
    and being rewarded or penalized for it [11:3]. You can visualize these agents
    as robots navigating through an unfamiliar terrain or a maze. Robots use reinforcement
    learning as part of their reasoning process after all. The following diagram gives
    the overview architecture of the reinforcement learning agent:'
  id: totrans-4898
  prefs: []
  type: TYPE_NORMAL
- en: '![Concepts](img/image01569.jpeg)'
  id: totrans-4899
  prefs: []
  type: TYPE_IMG
- en: The four state transitions of reinforcement learning
  id: totrans-4900
  prefs: []
  type: TYPE_NORMAL
- en: The agent collects the state of the environment, selects, and then executes
    the most appropriate action. The environment responds to the action by changing
    its state and rewarding or punishing the agent for the action.
  id: totrans-4901
  prefs: []
  type: TYPE_NORMAL
- en: 'The four steps of an episode or learning cycle are as follows:'
  id: totrans-4902
  prefs: []
  type: TYPE_NORMAL
- en: The learning agent retrieves or is notified of a new state of the environment.
  id: totrans-4903
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agent evaluates and selects the action that may provide the highest reward.
  id: totrans-4904
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agent executes the action.
  id: totrans-4905
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agent collects the reward or penalty and applies it to calibrate the learning
    algorithm.
  id: totrans-4906
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-4907
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reinforcement versus supervision**'
  id: totrans-4908
  prefs: []
  type: TYPE_NORMAL
- en: The training process in reinforcement learning rewards features that maximize
    a value or return. Supervised learning rewards features that meet a predefined
    labeled value. Supervised learning can be regarded as forced learning.
  id: totrans-4909
  prefs: []
  type: TYPE_NORMAL
- en: The action of the agent modifies the state of the system, which in turn notifies
    the agent of the new operational condition. Although not every action will trigger
    a change in the state of the environment, the agent collects the reward or penalty
    nevertheless. At its core, the agent has to design and execute a sequence of actions
    to reach its goal. This sequence of actions is modeled using the ubiquitous Markov
    decision process (refer to the *Markov decision processes* section in [Chapter
    7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"), *Sequential
    Data Models*).
  id: totrans-4910
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4911
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Dummy actions**'
  id: totrans-4912
  prefs: []
  type: TYPE_NORMAL
- en: It is important to design the agent so that actions may not automatically trigger
    a new state of the environment. It is easy to think about a scenario in which
    the agent triggers an action just to evaluate its reward without affecting the
    environment significantly.
  id: totrans-4913
  prefs: []
  type: TYPE_NORMAL
- en: A good metaphor for such a scenario is the *rollback* of the action. However,
    not all environments support such a *dummy* action, and the agent may have to
    run Monte-Carlo simulations to try out an action.
  id: totrans-4914
  prefs: []
  type: TYPE_NORMAL
- en: Value of a policy
  id: totrans-4915
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reinforcement learning is particularly suited to problems for which long-term
    rewards can be balanced against short-term rewards. A policy enforces the trade-off
    between short-term and long-term rewards. It guides the behavior of the agent
    by mapping the state of the environment to its actions. Each policy is evaluated
    through a variable known as the **value of a policy**.
  id: totrans-4916
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the value of a policy is the sum of all the rewards collected as
    a result of the sequence of actions taken by the agent. In practice, an action
    over the policy farther in the future obviously has a lesser impact than the next
    action from a state *S[t]* to a state *S[t+1]*. In other words, the impact of
    future actions on the current state has to be discounted by a factor, known as
    the *discount coefficient for future rewards* < 1.
  id: totrans-4917
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4918
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Transition and rewards matrices**'
  id: totrans-4919
  prefs: []
  type: TYPE_NORMAL
- en: The transition and emission matrices have been introduced in the *The hidden
    Markov model* section in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential
    Data Models"), *Sequential Data Models*.
  id: totrans-4920
  prefs: []
  type: TYPE_NORMAL
- en: The optimum policy *π** is the agent's sequence of actions that maximizes the
    future reward discounted to the current time.
  id: totrans-4921
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table introduces the mathematical notation of each component
    of reinforcement learning:'
  id: totrans-4922
  prefs: []
  type: TYPE_NORMAL
- en: '| Notation | Description |'
  id: totrans-4923
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-4924
  prefs: []
  type: TYPE_TB
- en: '| *S = {s[i]}* | These are the states of the environment |'
  id: totrans-4925
  prefs: []
  type: TYPE_TB
- en: '| *A = {a[i]}* | These are the actions on the environment |'
  id: totrans-4926
  prefs: []
  type: TYPE_TB
- en: '| *Π[t] = p(a[t] &#124; s[t])* | This is the policy (or strategy) of the agent
    |'
  id: totrans-4927
  prefs: []
  type: TYPE_TB
- en: '| *V^π(s[t])* | This is the value of the policy at a state |'
  id: totrans-4928
  prefs: []
  type: TYPE_TB
- en: '| *pt =p(s[t+1] &#124; s[t],a[t])* | These are the state transition probabilities
    from the state *st* to the state *s[t+1]* |'
  id: totrans-4929
  prefs: []
  type: TYPE_TB
- en: '| *r[t]= p(r[t+1] &#124; s[t],s[t+1],a[t])* | This is the reward of an action
    *a[t]* for a state *s[t]* |'
  id: totrans-4930
  prefs: []
  type: TYPE_TB
- en: '| *R[t]* | This is the expected discounted long-term return |'
  id: totrans-4931
  prefs: []
  type: TYPE_TB
- en: '| *γ* | This is the coefficient to discount the future rewards |'
  id: totrans-4932
  prefs: []
  type: TYPE_TB
- en: The purpose is to compute the maximum expected reward *R[t]* from any starting
    state *s[k]* as the sum of all discounted rewards to reach the current state *s[t]*.
    The value *V^π* of a policy *π* at the state *s[t]* is the maximum expected reward
    *R[t]* given the state *s[t]*.
  id: totrans-4933
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4934
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M1: The cumulative reward *R[t]* and value function *V^π(st)* for the state
    *st* given a policy *π* and a discount rate *γ* is defined as:'
  id: totrans-4935
  prefs: []
  type: TYPE_NORMAL
- en: '![Value of a policy](img/image01570.jpeg)'
  id: totrans-4936
  prefs: []
  type: TYPE_IMG
- en: The Bellman optimality equations
  id: totrans-4937
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The problem of finding the optimal policies is indeed a nonlinear optimization
    problem whose solution is iterative (dynamic programming). The expression of the
    value function *V^π* of a policy *π* can be formulated using the Markovian state
    transition probabilities *p[t]*.
  id: totrans-4938
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4939
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M2: The value function *V^π(s[t])* for a state *st* and future state *s[k]*
    with a reward *r[k]* using the transition probability *p[k]*, given a policy *π*
    and a discount rate *γ* is defined as:'
  id: totrans-4940
  prefs: []
  type: TYPE_NORMAL
- en: '![The Bellman optimality equations](img/image01571.jpeg)'
  id: totrans-4941
  prefs: []
  type: TYPE_IMG
- en: '*V*(s[t])* is the optimal value of the state *st* across all the policies.
    The equations are known as the Bellman optimality equations.'
  id: totrans-4942
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4943
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The curse of dimensionality**'
  id: totrans-4944
  prefs: []
  type: TYPE_NORMAL
- en: The number of states for a high-dimension problem (large-feature vector) becomes
    quickly unsolvable. A workaround is to approximate the value function and reduce
    the number of states by sampling. The application test case introduces a very
    simple approximation function.
  id: totrans-4945
  prefs: []
  type: TYPE_NORMAL
- en: If the environment model, state, action, and rewards, as well as transition
    between states, are completely defined, the reinforcement learning technique is
    known as model-based learning. In this case, there is no need to explore a new
    sequence of actions or state transitions. Model-based learning is similar to playing
    a board game in which all combinations of steps that are necessary to win are
    completely known.
  id: totrans-4946
  prefs: []
  type: TYPE_NORMAL
- en: However, most practical applications using sequential data do not have a complete,
    definitive model. Learning techniques that do not depend on a fully defined and
    available model are known as model-free techniques. These techniques require exploration
    to find the best policy for any given state. The remaining sections in this chapter
    deal with model-free learning techniques, and more specifically, the temporal
    difference algorithm.
  id: totrans-4947
  prefs: []
  type: TYPE_NORMAL
- en: Temporal difference for model-free learning
  id: totrans-4948
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Temporal difference** is a model-free learning technique that samples the
    environment. It is a commonly used approach to solve the Bellman equations iteratively.
    The absence of a model requires a discovery or **exploration** of the environment.
    The simplest form of exploration is to use the value of the next state and the
    reward defined from the action to update the value of the current state, as described
    in the following diagram:'
  id: totrans-4949
  prefs: []
  type: TYPE_NORMAL
- en: '![Temporal difference for model-free learning](img/image01572.jpeg)'
  id: totrans-4950
  prefs: []
  type: TYPE_IMG
- en: An illustration of the temporal difference algorithm
  id: totrans-4951
  prefs: []
  type: TYPE_NORMAL
- en: 'The iterative feedback loop used to adjust the value action on the state plays
    a role similar to the backpropagation of errors in artificial neural networks
    or minimization of the loss function in supervised learning. The adjustment algorithm
    has to:'
  id: totrans-4952
  prefs: []
  type: TYPE_NORMAL
- en: Discount the estimate value of the next state using the discount rate *γ*
  id: totrans-4953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strike a balance between the impact of the current state and the next state
    on updating the value at time *t* using the learning rate *α*
  id: totrans-4954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The iterative formulation of the first Bellman equation predicts *V^π(st)*,
    the value function of state *st* from the value function of the next state *s[t+1]*.
    The difference between the predicted value and the actual value is known as the
    temporal difference error abbreviated as *δt*.
  id: totrans-4955
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4956
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M3: The formula for tabular temporal difference *δ[t]* for a value function
    *V(s[t])* at state *s[t]*, a learning rate *α*, a reward *r[t]*, and a discount
    rate *γ* is defined as:'
  id: totrans-4957
  prefs: []
  type: TYPE_NORMAL
- en: '![Temporal difference for model-free learning](img/image01573.jpeg)'
  id: totrans-4958
  prefs: []
  type: TYPE_IMG
- en: An alternative to evaluating a policy using the value of the state *V^π(s[t])*
    is to use the value of taking an action on a state *s[t]* known as the value of
    action (or action-value) *Q^π(s[t], a[t])*.
  id: totrans-4959
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4960
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M4: The definition of the value *Q* of action at a state *st* as the expectation
    of a reward *R[t]* for an action *a[t]* on a state *s[t]* is defined as:'
  id: totrans-4961
  prefs: []
  type: TYPE_NORMAL
- en: '![Temporal difference for model-free learning](img/image01574.jpeg)'
  id: totrans-4962
  prefs: []
  type: TYPE_IMG
- en: 'There are two methods to implement the temporal difference algorithm:'
  id: totrans-4963
  prefs: []
  type: TYPE_NORMAL
- en: '**On-policy**: This is the value for the next best action that uses the policy'
  id: totrans-4964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Off-policy**: This is the value for the next best action that does not use
    the policy'
  id: totrans-4965
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s consider the temporal difference algorithm using an off-policy method
    and its most commonly used implementation: Q-learning.'
  id: totrans-4966
  prefs: []
  type: TYPE_NORMAL
- en: Action-value iterative update
  id: totrans-4967
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Q-learning is a model-free learning technique using an off-policy method. It
    optimizes the action-selection policy by learning an action-value function. Like
    any machine learning technique that relies on convex optimization, the Q-learning
    algorithm iterates through actions and states using the quality function, as described
    in the following mathematical formulation.
  id: totrans-4968
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm predicts and discounts the optimum value of action *max{Q[t]}*
    for the current state *st* and action *at* on the environment to transition to
    the state *s[t+1]*.
  id: totrans-4969
  prefs: []
  type: TYPE_NORMAL
- en: Similar to genetic algorithms that reuse the population of chromosomes in the
    previous reproduction cycle to produce offspring, the Q-learning technique strikes
    a balance between the new value of the quality function *Q[t+1]* and the old value
    *Q[t]* using the learning rate *α*. Q-learning applies temporal difference techniques
    to the Bellman equation for an off-policy methodology.
  id: totrans-4970
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4971
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'M5: The Q-learning action-value updating formula for a given policy *π*, set
    of states *{s[t]}*, a set of actions *{a[t]}* associated with each state *s[t]*,
    a learning rate *α*, and a discount rate *γ* is given by:'
  id: totrans-4972
  prefs: []
  type: TYPE_NORMAL
- en: '![Action-value iterative update](img/image01575.jpeg)'
  id: totrans-4973
  prefs: []
  type: TYPE_IMG
- en: A value 1 for the learning rate *α* discards the previous state, while a value
    0 discards learning
  id: totrans-4974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A value 1 for the discount rate *γ* uses long-term rewards only, while a value
    0 uses the short-term reward only
  id: totrans-4975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Q-learning estimates the cumulative reward discounted for future actions.
  id: totrans-4976
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-4977
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Q-learning as reinforcement learning**'
  id: totrans-4978
  prefs: []
  type: TYPE_NORMAL
- en: Q-learning qualifies as a reinforcement learning technique because it does not
    strictly require labeled data and training. Moreover, the Q-value does not have
    to be a continuous, differentiable function.
  id: totrans-4979
  prefs: []
  type: TYPE_NORMAL
- en: Let's apply our hard-earned knowledge of reinforcement learning to management
    and optimization of a portfolio of exchange-traded funds.
  id: totrans-4980
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  id: totrans-4981
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's implement the Q-learning algorithm in Scala.
  id: totrans-4982
  prefs: []
  type: TYPE_NORMAL
- en: Software design
  id: totrans-4983
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The key components of the implementation of the Q-learning algorithm are defined
    as follows:'
  id: totrans-4984
  prefs: []
  type: TYPE_NORMAL
- en: The `QLearning` class implements training and prediction methods. It defines
    a data transformation of the `ETransform` type using an explicit configuration
    of the `QLConfig` type.
  id: totrans-4985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `QLSpace` class has two components: a sequence of states of the `QLState`
    type and the identifier `id` of one or more goal states within the sequence.'
  id: totrans-4986
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A state, `QLState`, contains a sequence of `QLAction` instances used in its
    transition to another state and a reference to the object or `instance` for which
    the state is to be evaluated and predicted.
  id: totrans-4987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An indexed state, `QLIndexedState`, indexes a state in the search toward the
    goal state.
  id: totrans-4988
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An optional `constraint` function that limits the scope of the search for the
    next most rewarding action from the current state.
  id: totrans-4989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model of the `QLModel` type is generated through training. It contains the
    best policy and the accuracy for a model.
  id: totrans-4990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the key components of the Q-learning algorithm:'
  id: totrans-4991
  prefs: []
  type: TYPE_NORMAL
- en: '![Software design](img/image01576.jpeg)'
  id: totrans-4992
  prefs: []
  type: TYPE_IMG
- en: The UML components diagram of the Q-learning algorithm
  id: totrans-4993
  prefs: []
  type: TYPE_NORMAL
- en: The states and actions
  id: totrans-4994
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `QLAction` class specifies the transition of one state with a `from` identifier
    to another state with the `to` identifier, as shown here:'
  id: totrans-4995
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE389]'
  id: totrans-4996
  prefs: []
  type: TYPE_PRE
  zh: '[PRE389]'
- en: 'Actions have a *Q* value (or action-value), a reward, and a probability. The
    implementation defines these three values in three separate matrices: *Q* for
    the action values, *R* for rewards, and *P* for probabilities, in order to stay
    consistent with the mathematical formulation.'
  id: totrans-4997
  prefs: []
  type: TYPE_NORMAL
- en: 'A state of the `QLState` type is fully defined by its identifier, `id`, the
    list of `actions` to transition to some other states, and a `prop` property of
    the parameterized type, as shown in the following code:'
  id: totrans-4998
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE390]'
  id: totrans-4999
  prefs: []
  type: TYPE_PRE
  zh: '[PRE390]'
- en: The state might not have any actions. This is usually the case of the goal or
    absorbing state. In this case, the list is empty. The parameterized `instance`
    is a reference to the object for which the state is computed.
  id: totrans-5000
  prefs: []
  type: TYPE_NORMAL
- en: The next step consists of creating the graph or search space.
  id: totrans-5001
  prefs: []
  type: TYPE_NORMAL
- en: The search space
  id: totrans-5002
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The search space is the container responsible for any sequence of states. The
    `QLSpace` class takes the following parameters:'
  id: totrans-5003
  prefs: []
  type: TYPE_NORMAL
- en: The sequence of all the possible `states`
  id: totrans-5004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ID of one or several states that have been selected as `goals`
  id: totrans-5005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5006
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Why multiple goals?**'
  id: totrans-5007
  prefs: []
  type: TYPE_NORMAL
- en: There is absolutely no requirement that a state space must have a single goal.
    You can describe a solution to a problem as reaching a threshold or meeting one
    of the several conditions. Each condition can be defined as a state goal.
  id: totrans-5008
  prefs: []
  type: TYPE_NORMAL
- en: 'The `QLSpace` class is implemented as follows:'
  id: totrans-5009
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE391]'
  id: totrans-5010
  prefs: []
  type: TYPE_PRE
  zh: '[PRE391]'
- en: The constructor of the `QLSpace` class generates a map, `statesMap`. It retrieves
    the state using its `id` value (line `1`) and the array of goals, `goalStates`
    (line `2`). Furthermore, the `maxQ` method computes the maximum action-value,
    `maxQ`, for a state given a policy (line `3`). The implementation of the `maxQ`
    method is described in the next section.
  id: totrans-5011
  prefs: []
  type: TYPE_NORMAL
- en: 'The `init` method selects an initial state for training episodes (line `4`).
    The state is randomly selected if the `state0` argument is invalid:'
  id: totrans-5012
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE392]'
  id: totrans-5013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE392]'
- en: Finally, the `nextStates` method retrieves the list of states resulting from
    the execution of all the actions associated with the `st` state (line `5`).
  id: totrans-5014
  prefs: []
  type: TYPE_NORMAL
- en: 'The `QLSpace` search space is actually created by the `apply` factory method
    defined in the `QLSpace` companion object, as shown here:'
  id: totrans-5015
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE393]'
  id: totrans-5016
  prefs: []
  type: TYPE_PRE
  zh: '[PRE393]'
- en: The `apply` method creates a list of states using the `instances` set, the `goals`,
    and the `constraints` constraining function as inputs (line `6`). Each state creates
    its list of `actions`. The actions are generated from this state to any other
    states (line `7`).
  id: totrans-5017
  prefs: []
  type: TYPE_NORMAL
- en: 'The search space of states is illustrated in the following diagram:'
  id: totrans-5018
  prefs: []
  type: TYPE_NORMAL
- en: '![The search space](img/image01577.jpeg)'
  id: totrans-5019
  prefs: []
  type: TYPE_IMG
- en: The state transition matrix with QLData (Q-value, reward, and probability)
  id: totrans-5020
  prefs: []
  type: TYPE_NORMAL
- en: The `constraints` function limits the scope of the actions that can be triggered
    from any given state, as illustrated in the preceding diagram.
  id: totrans-5021
  prefs: []
  type: TYPE_NORMAL
- en: The policy and action-value
  id: totrans-5022
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each action has an action-value, a reward, and a potentially probability. The
    probability variable is introduced to simply model the hindrance or adverse condition
    for an action to be executed. If the action does not have any external constraint,
    the probability is 1\. If the action is not allowed, the probability is 0.
  id: totrans-5023
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5024
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Dissociating a policy from states**'
  id: totrans-5025
  prefs: []
  type: TYPE_NORMAL
- en: The action and states are the edges and vertices of the search space or search
    graph. The policy defined by the action-values, rewards, and probabilities is
    completely dissociated from the graph. The Q-learning algorithm initializes the
    reward matrix and updates the action-value matrix independently of the structure
    of the graph.
  id: totrans-5026
  prefs: []
  type: TYPE_NORMAL
- en: 'The `QLData` class is a container for three values: `reward`, `probability`,
    and a `value` variable for the Q-value, as shown here:'
  id: totrans-5027
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE394]'
  id: totrans-5028
  prefs: []
  type: TYPE_PRE
  zh: '[PRE394]'
- en: Note
  id: totrans-5029
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reward and punishment**'
  id: totrans-5030
  prefs: []
  type: TYPE_NORMAL
- en: The probability in the `QLData` class represents the hindrance or difficulty
    to reach one state from another state. Nothing prevents you from using the probability
    as a negative reward or punishment. However, its proper definition is to create
    a soft constraint of a state transition for a small subset of a state. For most
    applications, the overwhelming majority of state transitions have a probability
    of 1.0, and therefore, rely on the reward to guide the search toward the goal.
  id: totrans-5031
  prefs: []
  type: TYPE_NORMAL
- en: The `estimate` method adjusts the Q-value, `value`, with the probability to
    reflect any external condition that can impede the action.
  id: totrans-5032
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5033
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Mutable data**'
  id: totrans-5034
  prefs: []
  type: TYPE_NORMAL
- en: You might wonder why the `QLData` class defines a value as a variable instead
    of a value as recommended by the best Scala coding practices [11:4]. The reason
    being that an instance of an immutable class can be created for each action or
    state transition that requires you to update the `value` variable.
  id: totrans-5035
  prefs: []
  type: TYPE_NORMAL
- en: The training of the Q-learning model entails iterating across several episodes,
    each episode being defined as a multiple iteration. For instance, the training
    of a model with 400 states for 10 episodes of 100 iterations can potentially create
    160 million instances of `QLData`. Although not quite elegant, mutability reduces
    the load on the JVM garbage collector.
  id: totrans-5036
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s create a simple schema or class, `QLInput`, to initialize the
    reward and probability associated with each action as follows:'
  id: totrans-5037
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE395]'
  id: totrans-5038
  prefs: []
  type: TYPE_PRE
  zh: '[PRE395]'
- en: The first two arguments are the identifiers for the `from` source state and
    the `to` target state for this specific action. The last two arguments are the
    `reward`, collected at the completion of the action, and its `probability`. There
    is no need to provide an entire matrix. Actions have a reward of 1 and a probability
    of 1 by default. You only need to create an input for actions that have either
    a higher reward or a lower probability.
  id: totrans-5039
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of states and a sequence of input define the policy of the `QLPolicy`
    type. It is merely a data container, as shown here:'
  id: totrans-5040
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE396]'
  id: totrans-5041
  prefs: []
  type: TYPE_PRE
  zh: '[PRE396]'
- en: The number of states, `numStates`, is the square root of the number of elements
    of the initial input matrix, `input` (line `8`). The constructor initializes the
    `qlData` matrix of the `QLData` type with the input data, `reward`, and `probability`
    (line `9`). The `QLPolicy` class defines the shortcut methods to update (line
    `10`) and retrieve (line `11`) the `value`, the `estimate` (line `12`), the `reward`
    (line `13`), and the `probability` (line `14`).
  id: totrans-5042
  prefs: []
  type: TYPE_NORMAL
- en: The Q-learning components
  id: totrans-5043
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `QLearning` class encapsulates the Q-learning algorithm, and more specifically,
    the action-value updating equation. It is a data transformation of the `ETransform`
    type with an explicit configuration of the `QLConfig` type (line `16`) (refer
    to the *Monadic data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2
    "Chapter 2. Hello World!"), *Hello World!*):'
  id: totrans-5044
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE397]'
  id: totrans-5045
  prefs: []
  type: TYPE_PRE
  zh: '[PRE397]'
- en: 'The constructor takes the following parameters (line `15`):'
  id: totrans-5046
  prefs: []
  type: TYPE_NORMAL
- en: '`config`: This is the configuration of the algorithm'
  id: totrans-5047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qlSpace`: This is the search space'
  id: totrans-5048
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qlPolicy`: This is the policy'
  id: totrans-5049
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `model` is generated or trained during the instantiation of the class (refer
    to the *Design template for classifier* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*) (line `19`). The Q-learning algorithm
    is implemented as an explicit data transformation; therefore, the `U` type of
    the input element and the `V` type of the output element to the `|>` predictor
    are initialized as `QLState` (lines `17` and `18`).
  id: totrans-5050
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration of the Q-learning algorithm, `QLConfig`, specifies the learning
    rate, `alpha`, the discount rate, `gamma`, the maximum number of states (or length)
    of an episode, `episodeLength`, the number of episodes (or epochs) used in training,
    `numEpisodes`, and the minimum coverage, `minCoverage`, required to select the
    best policy as follows:'
  id: totrans-5051
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE398]'
  id: totrans-5052
  prefs: []
  type: TYPE_PRE
  zh: '[PRE398]'
- en: 'The `QLearning` class has two constructors defined in its companion object
    that initializes the policy either from an input matrix of states or from a function
    that compute the reward and probabilities:'
  id: totrans-5053
  prefs: []
  type: TYPE_NORMAL
- en: The client code specifies the `input` function to initialize the state of the
    Q-learning algorithm from the input data
  id: totrans-5054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The client code specifies the functions to generate the `reward` and `probability`
    for each action or state transition
  id: totrans-5055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first constructor for the `QLearning` class passes the initialization of
    states `=> Seq[QLInput]`, the sequence of references of `instances` associated
    with the states, and the `constraints` scope constraining function as an argument,
    besides the configuration and the goals (line `20`):'
  id: totrans-5056
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE399]'
  id: totrans-5057
  prefs: []
  type: TYPE_PRE
  zh: '[PRE399]'
- en: 'The second constructor passes the input data, `xt` (line `21`), the `reward`
    function (line `22`), and the `probability` function (line `23`) as well as the
    sequence of references of `instances` associated with the states and the `constraints`
    scope constraining function as arguments:'
  id: totrans-5058
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE400]'
  id: totrans-5059
  prefs: []
  type: TYPE_PRE
  zh: '[PRE400]'
- en: The reward and probability matrices are used to initialize the `input` state
    (line `24`).
  id: totrans-5060
  prefs: []
  type: TYPE_NORMAL
- en: The Q-learning training
  id: totrans-5061
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s take a look at the computation of the best policy during training. First,
    we need to define a `QLModel` model class with the `bestPolicy` optimum policy
    (or path) and its `coverage` as parameters:'
  id: totrans-5062
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE401]'
  id: totrans-5063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE401]'
- en: 'The creation of `model` consists of executing multiple episodes to extract
    the best policy. The training is executed in the `train` method: Each episode
    starts with a randomly selected state, as shown in the following code:'
  id: totrans-5064
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE402]'
  id: totrans-5065
  prefs: []
  type: TYPE_PRE
  zh: '[PRE402]'
- en: The `train` method iterates through the generation of the best policy starting
    from a randomly selected state `config.numEpisodes` times (line `25`). The state
    `coverage` is calculated as the percentage of times the search ends with the goal
    state (line `26`). The training succeeds only if the coverage exceeds a threshold
    value, `config.minAccuracy`, specified in the configuration.
  id: totrans-5066
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5067
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The quality of the model**'
  id: totrans-5068
  prefs: []
  type: TYPE_NORMAL
- en: The implementation uses the accuracy to measure the quality of the model or
    best policy. The F1 measure (refer to the *Assessing a model* section in [Chapter
    2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*), is not
    appropriate because there are no false positives.
  id: totrans-5069
  prefs: []
  type: TYPE_NORMAL
- en: 'The `train(state0: Int)` method does the heavy lifting at each episode (or
    epoch). It triggers the search by selecting either the `state0` initial state
    or a `r` random generator with a new seed, if `state0` is < 0, as shown in the
    following code:'
  id: totrans-5070
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE403]'
  id: totrans-5071
  prefs: []
  type: TYPE_PRE
  zh: '[PRE403]'
- en: 'The `QLIndexedState` utility class keeps track of the `state` at a specific
    iteration, `iter`, within an episode or epoch:'
  id: totrans-5072
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE404]'
  id: totrans-5073
  prefs: []
  type: TYPE_PRE
  zh: '[PRE404]'
- en: The implementation of `search` for the goal state(s) from a `state0` predefined
    or random is a textbook implementation of the Scala tail recursion. Either the
    recursive search ends if there are no more states to consider (line `28`) or the
    goal state is reached (line `29`).
  id: totrans-5074
  prefs: []
  type: TYPE_NORMAL
- en: Tail recursion to the rescue
  id: totrans-5075
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Tail recursion is a very effective construct to apply an operation to every
    item of a collection [11:5]. It optimizes the management of the function stack
    frame during the recursion. The annotation triggers a validation of the condition
    necessary for the compiler to optimize the function calls, as shown here:'
  id: totrans-5076
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE405]'
  id: totrans-5077
  prefs: []
  type: TYPE_PRE
  zh: '[PRE405]'
- en: Let's dive into the implementation for the *Q* action-value updating equation.
    The `search` method implements the **M5** mathematical expression for each recursion.
  id: totrans-5078
  prefs: []
  type: TYPE_NORMAL
- en: 'The recursion uses the `QLIndexedState` utility class (state, iteration number
    in the episode) as an argument. First, the recursion invokes the `nextStates`
    method of `QLSpace` (line `30`) to retrieve all the states associated with the
    `st` current state through its actions, as shown here:'
  id: totrans-5079
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE406]'
  id: totrans-5080
  prefs: []
  type: TYPE_PRE
  zh: '[PRE406]'
- en: The search completes and returns the current `state` if the length of the episode
    (maximum number of states visited) is reached or the `goal` is reached or there
    is no further state to transition to (line `31`). Otherwise, the recursion computes
    the state to which the transition generates the higher reward `R` from the current
    policy (line `32`). The recursion returns the state with the highest reward if
    it is one of the goal states (line `33`). The method retrieves the current `q`
    action-value (line `34`) and `r` reward matrices from the policy, and then applies
    the equation to update the action-value (line `35`). The method updates the action-value
    `Q` with the new value `nq` (line `36`).
  id: totrans-5081
  prefs: []
  type: TYPE_NORMAL
- en: 'The action-value updating equation requires the computation of the maximum
    action-value associated with the current state, which is performed by the `maxQ`
    method of the `QLSpace` class:'
  id: totrans-5082
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE407]'
  id: totrans-5083
  prefs: []
  type: TYPE_PRE
  zh: '[PRE407]'
- en: The `maxQ` method filters out the current state (line `37`) and then extracts
    the best state, which maximizes the policy (line `38`).
  id: totrans-5084
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5085
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reachable goal**'
  id: totrans-5086
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm does not require the goal state to be reached for every episode.
    After all, there is no guarantee that the goal will be reached from any randomly
    selected state. It is a constraint on the algorithm to follow a positive gradient
    of the rewards when transitioning between states within an episode. The goal of
    the training is to compute the best possible policy or sequence of states from
    any given initial state. You are responsible for validating the model or best
    policy extracted from the training set, independent from the fact that the goal
    state is reached for every episode.
  id: totrans-5087
  prefs: []
  type: TYPE_NORMAL
- en: The validation
  id: totrans-5088
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A commercial application may require multiple types of validation mechanisms
    regarding the states transition, reward, probability, and Q-value matrices.
  id: totrans-5089
  prefs: []
  type: TYPE_NORMAL
- en: 'One critical validation is to verify that the user-defined `constraints` function
    does not create a dead end in the search or training of Q-learning. The `constraints`
    function establishes the list of states that can be accessed from a given state
    through actions. If the constraints are too tight, some of the possible search
    paths may not reach the goal state. Here is a simple validation of the `constraints`
    function:'
  id: totrans-5090
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE408]'
  id: totrans-5091
  prefs: []
  type: TYPE_PRE
  zh: '[PRE408]'
- en: The prediction
  id: totrans-5092
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The last functionality of the `QLearning` class is the prediction using the
    model created during training. The `|>` method predicts the optimum state transition
    (or action) from a given state, `state0`:'
  id: totrans-5093
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE409]'
  id: totrans-5094
  prefs: []
  type: TYPE_PRE
  zh: '[PRE409]'
- en: 'The `|>` data transformation returns itself if the `state0` input state is
    the goal (line `39`) or computes the best outcome, `nextState`, (line `40`) using
    another tail recursion, as follows:'
  id: totrans-5095
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE410]'
  id: totrans-5096
  prefs: []
  type: TYPE_PRE
  zh: '[PRE410]'
- en: 'The `nextState` method executes the following sequence of invocations:'
  id: totrans-5097
  prefs: []
  type: TYPE_NORMAL
- en: Retrieve the eligible states that can be transitioned to from the current state,
    `iSt.state` (line `41`).
  id: totrans-5098
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return the states if there are no more states or if the method does not converge
    within the maximum number of allowed iterations, `config.episodeLength` (line
    `42`).
  id: totrans-5099
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extracts the state, `qState`, with the most rewarding policy (line `43`).
  id: totrans-5100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the `iSt.iter` iteration counter (line `44`).
  id: totrans-5101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The exit condition**'
  id: totrans-5103
  prefs: []
  type: TYPE_NORMAL
- en: The prediction ends when no more states are available or the maximum number
    of iterations within the episode is exceeded. You can define a more sophisticated
    exit condition. The challenge is that there is no explicit error or loss variable/function
    that can be used except the temporal difference error.
  id: totrans-5104
  prefs: []
  type: TYPE_NORMAL
- en: The `|>` prediction method returns either the best possible state or `None`
    if the model cannot be created during training.
  id: totrans-5105
  prefs: []
  type: TYPE_NORMAL
- en: Option trading using Q-learning
  id: totrans-5106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Q-learning algorithm is used in many financial and market trading applications
    [11:6]. Let's consider the problem of computing the best strategy to trade certain
    types of options given some market conditions and trading data.
  id: totrans-5107
  prefs: []
  type: TYPE_NORMAL
- en: The **Chicago Board Options Exchange** (**CBOE**) offers an excellent online
    tutorial on options [11:7]. An option is a contract that gives the buyer the right
    but not the obligation to buy or sell an underlying asset at a specific price
    on or before a certain date (refer to the *Options trading* section under *Finances
    101* in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"),
    *Basic Concepts*.) There are several option pricing models, the Black-Scholes
    stochastic partial differential equations being the most recognized [11:8].
  id: totrans-5108
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of the exercise is to predict the price of an option on a security
    for *N* days in the future according to the current set of observed features derived
    from the time to expiration, price of the security, and volatility. Let''s focus
    on the call options of a given security, IBM. The following chart plots the daily
    price of the IBM stock and its derivative call option for May 2014 with a strike
    price of $190:'
  id: totrans-5109
  prefs: []
  type: TYPE_NORMAL
- en: '![Option trading using Q-learning](img/image01578.jpeg)'
  id: totrans-5110
  prefs: []
  type: TYPE_IMG
- en: The IBM stock and Call $190 May 2014 pricing in May-Oct 2013
  id: totrans-5111
  prefs: []
  type: TYPE_NORMAL
- en: 'The price of an option depends on the following parameters:'
  id: totrans-5112
  prefs: []
  type: TYPE_NORMAL
- en: Time to expiration of the option (time decay)
  id: totrans-5113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The price of the underlying security
  id: totrans-5114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The volatility of returns of the underlying asset
  id: totrans-5115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pricing model usually does not take into account the variation in trading
    volume of the underlying security. Therefore, it would be quite interesting to
    include it in our model. Let''s define the state of an option using the following
    four normalized features:'
  id: totrans-5116
  prefs: []
  type: TYPE_NORMAL
- en: '**Time decay** (`timeToExp`): This is the time to expiration once normalized
    over [0, 1].'
  id: totrans-5117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relative volatility** (`volatility`): This is the relative variation of the
    price of the underlying security within a trading session. It is different from
    the more complex volatility of returns defined in the Black-Scholes model, for
    example.'
  id: totrans-5118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volatility relative to volume** (`vltyByVol`): This is the relative volatility
    of the price of the security adjusted for its trading volume.'
  id: totrans-5119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relative difference between the current price and strike price** (`priceToStrike`):
    This measures the ratio of the difference between price and strike price to the
    strike price.'
  id: totrans-5120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following graph shows the four normalized features for the IBM option strategy:'
  id: totrans-5121
  prefs: []
  type: TYPE_NORMAL
- en: '![Option trading using Q-learning](img/image01579.jpeg)'
  id: totrans-5122
  prefs: []
  type: TYPE_IMG
- en: Normalized relative stock price volatility, volatility relative to trading volume,
    and price relative to strike price for the IBM stock
  id: totrans-5123
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the option trading strategy using Q-learning consists
    of the following steps:'
  id: totrans-5124
  prefs: []
  type: TYPE_NORMAL
- en: Describing the property of an option
  id: totrans-5125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining the function approximation
  id: totrans-5126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specifying the constraints on the state transition
  id: totrans-5127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The OptionProperty class
  id: totrans-5128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's select *N = 2* as the number of days in the future for our prediction.
    Any longer-term prediction is quite unreliable because it falls outside the constraint
    of the discrete Markov model. Therefore, the price of the option two days in the
    future is the value of the reward—profit or loss.
  id: totrans-5129
  prefs: []
  type: TYPE_NORMAL
- en: 'The `OptionProperty` class encapsulates the four attributes of an option (line
    `45`) as follows:'
  id: totrans-5130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE411]'
  id: totrans-5131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE411]'
- en: Note
  id: totrans-5132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**A modular design**'
  id: totrans-5133
  prefs: []
  type: TYPE_NORMAL
- en: The implementation avoids subclassing the `QLState` class to define the features
    of our option pricing model. The state of the option is a parameterized `prop`
    parameter for the state class.
  id: totrans-5134
  prefs: []
  type: TYPE_NORMAL
- en: The OptionModel class
  id: totrans-5135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `OptionModel` class is a container and a factory for the properties of
    the option. It creates the list of `propsList` option properties by accessing
    the data source of the four features introduced earlier. It takes the following
    parameters:'
  id: totrans-5136
  prefs: []
  type: TYPE_NORMAL
- en: The symbol of the security.
  id: totrans-5137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The strike price for the `strikePrice` option.
  id: totrans-5138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The source of data, `src`.
  id: totrans-5139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum time decay or time to expiration, `minTDecay`. Out-of-the-money
    options expire worthless and in-the-money options have very different price behavior
    as they get closer to the expiration date (refer to the *Options trading* section
    in the [Appendix A](part0229.xhtml#aid-6QCGQ2 "Appendix A. Basic Concepts"), *Basic
    Concepts*). Therefore, the last `minTDecay` trading sessions prior to the expiration
    date are not used in the training of the model.
  id: totrans-5140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of steps (or buckets), `nSteps`. It is used in approximating the
    values of each feature. For instance, an approximation of four steps creates four
    buckets [0, 25], [25, 50], [50, 75], and [75, 100].
  id: totrans-5141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The implementation of the `OptionModel` class is as follows:'
  id: totrans-5142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE412]'
  id: totrans-5143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE412]'
- en: The factory uses the `zipWithIndex` Scala method to represent the index of the
    trading sessions (line `46`). All feature values are normalized over the interval
    [0, 1], including the time decay (or time to expiration) of the `normDecay` option
    (line `47`). The instantiation of the `OptionModel` class generates a list of
    `OptionProperty` elements if the constructor succeeds (line `48`), an empty list
    otherwise.
  id: totrans-5144
  prefs: []
  type: TYPE_NORMAL
- en: Quantization
  id: totrans-5145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The four properties of the option are continuous values, normalized as a probability
    [0, 1]. The states in the Q-learning algorithm are discrete and require a quantization
    or categorization known as a **function approximation**; although a function approximation
    scheme can be quite elaborate [11:9]. Let''s settle for a simple linear categorization,
    as illustrated in the following diagram:'
  id: totrans-5146
  prefs: []
  type: TYPE_NORMAL
- en: '![Quantization](img/image01580.jpeg)'
  id: totrans-5147
  prefs: []
  type: TYPE_IMG
- en: Quantization of the state of a traded option
  id: totrans-5148
  prefs: []
  type: TYPE_NORMAL
- en: The function approximation defines the number of states. In this example, a
    function approximation that converts a normalized value into three intervals or
    buckets generates *3⁴ = 81* states or potentially *3⁸-3⁴* *= 6480* actions! The
    maximum number of states for *l* buckets function approximation and *n* features
    is *l^n* with a maximum number of *l^(2n)-l^n* actions.
  id: totrans-5149
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Quantization or function approximation guidelines**'
  id: totrans-5151
  prefs: []
  type: TYPE_NORMAL
- en: 'The design of the function to approximate the state of options has to address
    the following two conflicting requirements:'
  id: totrans-5152
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy demands a fine-grained approximation
  id: totrans-5153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited computation resources restrict the number of states, and therefore,
    level of approximation
  id: totrans-5154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `quantize` method of the `OptionModel` class converts the normalized value
    of each option property of features into an array of bucket indices. It returns
    a map of profit and loss for each bucket keyed on the array of bucket indices,
    as shown in the following code:'
  id: totrans-5155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE413]'
  id: totrans-5156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE413]'
- en: The method creates a `mapper` instance to index the array of buckets (line `49`).
    An `acc` accumulator of the `NumericAccumulator` type extends `Map[Int, (Int,
    Double)]` and computes the tuple (number of occurrences of features on each buckets
    and the sum of increase or decrease of the option price) (line `50`). The `toArrayInt`
    method converts the value of each option property (`timeToExp`, `volatility`,
    and so on) into the index of the appropriate bucket (line `51`). The array of
    indices is then encoded (line `52`) to generate the `id` or index of a state.
    The method updates the accumulator with the number of occurrences and the total
    profit and loss for a trading session for the option (line `53`). It finally computes
    the reward on each action by averaging the profit and loss on each bucket (line
    `54`).
  id: totrans-5157
  prefs: []
  type: TYPE_NORMAL
- en: A view is used in the generation of the list of `OptionProperty` to avoid unnecessary
    object creation.
  id: totrans-5158
  prefs: []
  type: TYPE_NORMAL
- en: The source code for the `toArrayInt` and `encode` methods and `NumericAccumulator`
    is documented and available online.
  id: totrans-5159
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-5160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The final piece of the puzzle is the code that configures and executes the
    Q-learning algorithm on one or several options on a security, IBM:'
  id: totrans-5161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE414]'
  id: totrans-5162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE414]'
- en: 'The preceding implementation creates the Q-learning model with the following
    steps:'
  id: totrans-5163
  prefs: []
  type: TYPE_NORMAL
- en: Extract the historical prices for the IBM stock by instantiating a data source,
    `src` (line `55`).
  id: totrans-5164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an `option` model (line `56`).
  id: totrans-5165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract the historical prices `oPrices` for option call $190 May 2014 (line
    `57`).
  id: totrans-5166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the model, `_model`, with a `goalStr` predefined goal (line `58`).
  id: totrans-5167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  id: totrans-5168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE415]'
  id: totrans-5169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE415]'
- en: 'Let''s take a look at the `createModel` method that takes the option pricing
    model, `option,` and the historical prices for `oPrice` options as arguments:'
  id: totrans-5170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE416]'
  id: totrans-5171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE416]'
- en: The method quantizes the option prices map, `oPrices` (line `59`), extracts
    the historical option prices, `qPrice` (line `60`), computes the profit as the
    difference in the price of the option between two consecutive trading sessions
    (line `61`), and computes the index, `maxProfitIndex,` of the trading session
    with the highest profile (line `62`). The state with the `maxProfitIndex` index
    is selected as the goal.
  id: totrans-5172
  prefs: []
  type: TYPE_NORMAL
- en: The input matrix is automatically generated using the `reward` and `probability`
    functions. The `reward` function rewards the state transition proportionally to
    the profit (line `63`). The `probability` function punishes the state transition
    for which the loss *y – x* is greater than *0.3*x* by setting the probability
    value to `0` (line `64`).
  id: totrans-5173
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Initialization of rewards and probabilities**'
  id: totrans-5175
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the reward and probability matrices are automatically generated
    through two functions. An alternative approach consists of initializing these
    two matrices using either historical data or educated guesses.
  id: totrans-5176
  prefs: []
  type: TYPE_NORMAL
- en: The `validateConstraints` method of the `QLearning` companion object validates
    the `neighbors` constraints function, as described in the *The validation* section
    (line `65`).
  id: totrans-5177
  prefs: []
  type: TYPE_NORMAL
- en: The last two steps consists of creating a configuration, `config,` for the Q-learning
    algorithm (line `66`) and training the model by instantiating the `QLearning`
    class with the appropriate parameters, including the `neighbors` method that defines
    the neighboring states for any given state (line `67`). The `neighbors` method
    is described in the documented source code available online.
  id: totrans-5178
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The anti-goal state**'
  id: totrans-5180
  prefs: []
  type: TYPE_NORMAL
- en: The goal state is the state with the highest assigned reward. It is a heuristic
    to reward a strategy for a good performance. However, it is conceivable and possible
    to define an anti-goal state with the highest assigned penalty or the lowest assigned
    reward to guide the search away from some condition.
  id: totrans-5181
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  id: totrans-5182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides the function approximation, the size of the training set has an impact
    on the number of states. A well-distributed or large training set provides at
    least one value for each bucket created by the approximation. In this case, the
    training set is quite small and only 34 out of 81 buckets have actual values.
    As result, the number of states is 34\. The initialization of the Q-learning model
    generates the following reward matrix:'
  id: totrans-5183
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/image01581.jpeg)'
  id: totrans-5184
  prefs: []
  type: TYPE_IMG
- en: The reward matrix for the option-pricing Q-learning strategy
  id: totrans-5185
  prefs: []
  type: TYPE_NORMAL
- en: The graph visualizes the distribution of the rewards computed from the profit
    and loss of the option. The *xy* plane represents the actions between states.
    The states' IDs are listed on *x* and *y* axes. The *z* axis measures the actual
    value of the reward associated with each action.
  id: totrans-5186
  prefs: []
  type: TYPE_NORMAL
- en: The reward reflects the fluctuation in the price of the option. The price of
    an option has a higher volatility than the price of the underlying security.
  id: totrans-5187
  prefs: []
  type: TYPE_NORMAL
- en: 'The *xy* reward matrix *R* is rather highly distributed. Therefore, we select
    a small value for the learning rate *0.2* to reduce the impact of the previous
    state on the new state. The value for the discount rate *0.7* accommodates the
    fact that the number of states is limited. There is no reason to compute the future
    discounted reward using a long sequence of states. The training of the policies
    generates the following action-value matrix *Q* of 34 states by 34 states after
    the first episode:'
  id: totrans-5188
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/image01582.jpeg)'
  id: totrans-5189
  prefs: []
  type: TYPE_IMG
- en: The Q action-value matrix for the first episode (epoch)
  id: totrans-5190
  prefs: []
  type: TYPE_NORMAL
- en: 'The distribution of the action-values between states at the end of the first
    episode reflects the distribution of the reward across state-to-state action.
    The first episode consists of a sequence of nine states from an initial randomly
    selected state to the goal state. The action-value map is compared to the map
    generated after 20 episodes in the following graph:'
  id: totrans-5191
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/image01583.jpeg)'
  id: totrans-5192
  prefs: []
  type: TYPE_IMG
- en: The Q Action-Value matrix for the last episode (epoch)
  id: totrans-5193
  prefs: []
  type: TYPE_NORMAL
- en: 'The action-value map at the end of the last episode shows some clear patterns.
    Most of the rewarding actions transition from a large number of states (*X* axis)
    to a smaller number of states (*Y* axis). The chart illustrates the following
    issues with the small training sample:'
  id: totrans-5194
  prefs: []
  type: TYPE_NORMAL
- en: The small size of the training set forces us to use an approximate representation
    of each feature. The purpose is to increase the odds that most buckets have, that
    is, at least one data point.
  id: totrans-5195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, a loose function approximation or quantization tends to group quite
    different states into the same bucket.
  id: totrans-5196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bucket with a very low number can potentially mischaracterize one property
    or feature of a state.
  id: totrans-5197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next test is to display the profile of the log of the Q-value (`QLData.value`)
    as the recursive search (or training) progress for different episodes or epochs.
    The test uses a learning rate *α = 0.1* and a discount rate *γ = 0.9*.
  id: totrans-5198
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/image01584.jpeg)'
  id: totrans-5199
  prefs: []
  type: TYPE_IMG
- en: The profile of the log (Q-Value) for different epochs during Q-learning training
  id: totrans-5200
  prefs: []
  type: TYPE_NORMAL
- en: The preceding chart illustrates the fact that the Q-value for each profile is
    independent of the order of the epochs during training. However, the length of
    the profile (or number of iterations to reach the goal state) depends on the initial
    state, which is selected randomly, in this example.
  id: totrans-5201
  prefs: []
  type: TYPE_NORMAL
- en: 'The last test consists of evaluating the impact of the learning rate and discount
    rate on the coverage of the training:'
  id: totrans-5202
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluation](img/image01585.jpeg)'
  id: totrans-5203
  prefs: []
  type: TYPE_IMG
- en: Training coverage versus learning rate and discount rate
  id: totrans-5204
  prefs: []
  type: TYPE_NORMAL
- en: The coverage (percentage of an episode or epoch for which the goal state is
    reached) decreases as the learning rate increases. The result confirms the general
    rule of using learning rate < 0.2\. The similar test to evaluate the impact of
    the discount rate on the coverage is inconclusive.
  id: totrans-5205
  prefs: []
  type: TYPE_NORMAL
- en: Pros and cons of reinforcement learning
  id: totrans-5206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Reinforcement learning algorithms are ideal for the following problems:'
  id: totrans-5207
  prefs: []
  type: TYPE_NORMAL
- en: Online learning
  id: totrans-5208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training data is small or nonexistent
  id: totrans-5209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A model is nonexistent or poorly defined
  id: totrans-5210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computation resources are limited
  id: totrans-5211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, these techniques perform poorly in the following cases:'
  id: totrans-5212
  prefs: []
  type: TYPE_NORMAL
- en: The search space (number of possible actions) is large because the maintenance
    of the states, action graph, and rewards matrix becomes challenging
  id: totrans-5213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution is not always predictable in terms of scalability and performance
  id: totrans-5214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning classifier systems
  id: totrans-5215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: J. Holland introduced the concept of **learning classifier systems** (**LCS**)
    more than 30 years ago as an extension to evolutionary computing [11:10].
  id: totrans-5216
  prefs: []
  type: TYPE_NORMAL
- en: Learning classifier systems are a kind of rule-based system with general mechanisms
    for processing rules in parallel, for adaptive generation of new rules, and for
    testing the effectiveness of new rules.
  id: totrans-5217
  prefs: []
  type: TYPE_NORMAL
- en: However, the concept started to get the attention of computer scientists only
    a few years ago, with the introduction of several variants of the original concept,
    including **extended learning classifiers** (**XCS**). Learning classifier systems
    are interesting because they combine rules, reinforcement learning, and genetic
    algorithms.
  id: totrans-5218
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Disclaimer**'
  id: totrans-5220
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of the extended learning classifier is presented for informational
    purposes only. Validating XCS against a known and labeled population of rules
    is a very significant endeavor. The source code snippet is presented only to illustrate
    the different components of the XCS algorithm.
  id: totrans-5221
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to LCS
  id: totrans-5222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Learning classifier systems merge the concepts of reinforcement learning, rule-based
    policies, and evolutionary computing. This unique class of learning algorithms
    represents the merger of the following research fields [11:11]:'
  id: totrans-5223
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  id: totrans-5224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Genetic algorithms and evolutionary computing
  id: totrans-5225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervised learning
  id: totrans-5226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule-based knowledge encoding
  id: totrans-5227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following diagram:'
  id: totrans-5228
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction to LCS](img/image01586.jpeg)'
  id: totrans-5229
  prefs: []
  type: TYPE_IMG
- en: A diagram of the scientific disciplines required for learning classifier systems
  id: totrans-5230
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning classifier systems are an example of **complex adaptive systems**.
    A learning classifier system has the following four components:'
  id: totrans-5231
  prefs: []
  type: TYPE_NORMAL
- en: '**A population of classifiers or rules**: This evolves over time. In some cases,
    a domain expert creates a primitive set of rules (core knowledge). In other cases,
    the rules are randomly generated prior to the execution of the learning classifier
    system.'
  id: totrans-5232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A genetic algorithm-based discovery engine**: This generates new classifiers
    or rules from the existing population. This component is also known as the **rules
    discovery module**. The rules rely on the same pattern of evolution of organisms
    introduced in the previous chapter. The rules are encoded as strings or bit strings
    to represent a condition (predicate) and action.'
  id: totrans-5233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A performance or evaluation function**: This measures the positive or negative
    impact of the actions from the fittest classifiers or policies.'
  id: totrans-5234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A reinforcement learning component**: This rewards or punishes the classifiers
    that contribute to the action, as seen in the previous section. The rules that
    contribute to an action that improves the performance of the system are rewarded,
    while those that degrade the performance of the system are punished. This component
    is also known as the credit assignment module.'
  id: totrans-5235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why LCS?
  id: totrans-5236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Learning classifier systems are particularly appropriate to problems in which
    the environment is constantly changing and are the combinations of a learning
    strategy and an evolutionary approach to build and maintain a knowledge base [11:12].
  id: totrans-5237
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning methods alone can be effective on large datasets, but they
    require either a significant amount of labeled data or a reduced set of features
    to avoid overfitting. Such constraints may not be practical in the case of ever-changing
    environments.
  id: totrans-5238
  prefs: []
  type: TYPE_NORMAL
- en: 'The last 20 years have seen the introduction of many variants of learning classifier
    systems that belong to the following two categories:'
  id: totrans-5239
  prefs: []
  type: TYPE_NORMAL
- en: Systems for which accuracy is computed from the correct predictions and that
    apply the discovery to a subset of those correct classes. They incorporate elements
    of supervised learning to constrain the population of classifiers. These systems
    are known to follow the **Pittsburgh approach**.
  id: totrans-5240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Systems that explore all the classifiers and apply rule accuracy to the genetic
    selection of the rules. Each individual classifier is a rule. These systems are
    known to follow the **Michigan approach**.
  id: totrans-5241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of this section is dedicated to the second type of learning classifiers—more
    specifically, extended learning classifier systems. In a context of LCS, the term
    *classifier* refers to the predicate or rule generated by the system. From this
    point on, the term *rule* replaces the term *classifier* to avoid confusion with
    the more common definition of classification.
  id: totrans-5242
  prefs: []
  type: TYPE_NORMAL
- en: Terminology
  id: totrans-5243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Each domain of research has its own terminology and LCS is no exception. The
    terminology of LCS consists of the following terms:'
  id: totrans-5244
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment**: These are the environment variables in the context of reinforcement
    learning.'
  id: totrans-5245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agent**: An agent used in reinforcement learning.'
  id: totrans-5246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predicate**: A clause or fact using the format, *variable-operator-value*,
    and usually implemented as (operator, variable value); for example, *Temperature-exceeds-87F*
    or *(''Temperature'', 87F)*, *Hard drive–failed* or *(''Status hard drive'', FAILED)*,
    and so on. It is encoded as a gene in order to be processed by the genetic algorithm.'
  id: totrans-5247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compound predicate**: This is the composition of several predicates and Boolean
    logic operators, which is usually implemented as a logical tree (for example,
    *((predicate1 AND predicate2) OR predicate3* is implemented as *OR (AND (predicated
    1, predicate 2), predicate3)*. It uses a chromosome representation.'
  id: totrans-5248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Action**: This is a mechanism that alters the environment by modifying the
    value of one or several of its parameters using a format *(type of action, target)*;
    for example, *change thermostat settings*, *replace hard drive*, and so on.'
  id: totrans-5249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule**: This is a formal first-order logic formula using the format *IF compound
    predicate THEN sequence of action*; for example, *IF gold price < $1140 THEN sell
    stock of oil and gas producing companies*.'
  id: totrans-5250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classifier**: This is a rule in the context of an LCS.'
  id: totrans-5251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule fitness or score**: This is identical to the definition of the fitness
    or score in the genetic algorithm. In the context of an LCS, it is the probability
    of a rule to be invoked and fired in response to the change in environment.'
  id: totrans-5252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensors**: These are environment variables monitored by an agent; for example,
    the temperature and hard drive status.'
  id: totrans-5253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input data stream**: This is the flow of data generated by sensors. It is
    usually associated with online training.'
  id: totrans-5254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule matching**: This is a mechanism to match a predicate or compound predicate
    with a sensor.'
  id: totrans-5255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Covering**: This is the process of creating new rules to match a new condition
    (sensor) in the environment. It generates the rules by either using a random generator
    or mutating existing rules.'
  id: totrans-5256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictor**: This is an algorithm to find the action with the maximum number
    of occurrences within a set of matching rules.'
  id: totrans-5257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extended learning classifier systems
  id: totrans-5258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to reinforcement learning, the XCS algorithm has an **exploration**
    phase and an **exploitation** phase. The exploitation process consists of leveraging
    the existing rules to influence the target environment in a profitable or rewarding
    manner:'
  id: totrans-5259
  prefs: []
  type: TYPE_NORMAL
- en: '![Extended learning classifier systems](img/image01587.jpeg)'
  id: totrans-5260
  prefs: []
  type: TYPE_IMG
- en: The exploitation component of the XCS algorithm
  id: totrans-5261
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list describes each numbered block:'
  id: totrans-5262
  prefs: []
  type: TYPE_NORMAL
- en: Sensors acquire new data or events from the system.
  id: totrans-5263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rules for which the condition matches the input event are extracted from the
    current population.
  id: totrans-5264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A new rule is created if no match is found in the existing population. This
    process is known as covering.
  id: totrans-5265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The chosen rules are ranked by their fitness values, and the rules with the
    highest predicted outcome are used to trigger the action.
  id: totrans-5266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The purpose of exploration components is to increase the rule base as a population
    of the chromosomes that encode these rules.
  id: totrans-5267
  prefs: []
  type: TYPE_NORMAL
- en: '![Extended learning classifier systems](img/image01588.jpeg)'
  id: totrans-5268
  prefs: []
  type: TYPE_IMG
- en: Exploration components of the XCS algorithm
  id: totrans-5269
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list describes each numbered block of the block diagram:'
  id: totrans-5270
  prefs: []
  type: TYPE_NORMAL
- en: Once the action is performed, the system rewards the rules for which the action
    has been executed. The reinforcement learning module assigns credit to these rules.
  id: totrans-5271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rewards are used to update the rule fitness, applying evolutionary constraints
    to the existing population.
  id: totrans-5272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The genetic algorithm updates the existing population of classifiers/rules using
    operators such as crossover and mutation.
  id: totrans-5273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: XCS components
  id: totrans-5274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section describes the key classes of the XCS. The implementation leverages
    the existing design of the genetic algorithm and the reinforcement learning. It
    is easier to understand the inner workings of the XCS algorithm with a concrete
    application.
  id: totrans-5275
  prefs: []
  type: TYPE_NORMAL
- en: Application to portfolio management
  id: totrans-5276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Portfolio management and trading have benefited from the application of extended
    learning classifiers [11:13]. The use case is the management of a portfolio of
    exchange-traded funds in an ever-changing financial environment. Contrary to stocks,
    exchange-traded funds are representative of an industry-specific group of stocks
    or the financial market at large. Therefore, the price of these ETFs is affected
    by the following macroeconomic changes:'
  id: totrans-5277
  prefs: []
  type: TYPE_NORMAL
- en: Gross domestic product
  id: totrans-5278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inflation
  id: totrans-5279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geopolitical events
  id: totrans-5280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interest rates
  id: totrans-5281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's select the value of the 10-year Treasury yield as a proxy for the macroeconomic
    conditions, for the sake of simplicity.
  id: totrans-5282
  prefs: []
  type: TYPE_NORMAL
- en: 'The portfolio has to be constantly adjusted in response to any specific change
    in the environment or market condition that affects the total value of the portfolio,
    and this can be done by referring to the following table:'
  id: totrans-5283
  prefs: []
  type: TYPE_NORMAL
- en: '| XCS component | Portfolio management |'
  id: totrans-5284
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-5285
  prefs: []
  type: TYPE_TB
- en: '| Environment | This is the portfolio of securities defined by its composition,
    total value, and the yield of the 10-year Treasury bond |'
  id: totrans-5286
  prefs: []
  type: TYPE_TB
- en: '| Action | This is the change in the composition of the portfolio |'
  id: totrans-5287
  prefs: []
  type: TYPE_TB
- en: '| Reward | This is the profit and loss of the total value of the portfolio
    |'
  id: totrans-5288
  prefs: []
  type: TYPE_TB
- en: '| Input data stream | This is the feed of the stock and bond price quotation
    |'
  id: totrans-5289
  prefs: []
  type: TYPE_TB
- en: '| Sensor | This is the trading information regarding securities in the portfolio
    such as price, volume, volatility, yield, and the yield of the-10 year Treasury
    bond |'
  id: totrans-5290
  prefs: []
  type: TYPE_TB
- en: '| Predicate | This is the change in the composition of the portfolio |'
  id: totrans-5291
  prefs: []
  type: TYPE_TB
- en: '| Action | This rebalances a portfolio by buying and selling securities |'
  id: totrans-5292
  prefs: []
  type: TYPE_TB
- en: '| Rule | This is the association of trading data with the rebalancing of a
    portfolio |'
  id: totrans-5293
  prefs: []
  type: TYPE_TB
- en: The first step is to create an initial set of rules regarding the portfolio.
    This initial set can be created randomly, like the initial population of a genetic
    algorithm or defined by a domain expert.
  id: totrans-5294
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The XCS initial population**'
  id: totrans-5296
  prefs: []
  type: TYPE_NORMAL
- en: Rules or classifiers are defined and/or refined through evolution. Therefore,
    there is no absolute requirement for the domain expert to set up a comprehensive
    knowledge base. In fact, rules can be randomly generated at the start of the training
    phase. However, seeding the XCS initial population with a few relevant rules improves
    the odds of having the algorithm converge quickly.
  id: totrans-5297
  prefs: []
  type: TYPE_NORMAL
- en: 'You are invited to initialize the population of rules with as many relevant
    and financially sound trading rules as possible. Over time, the execution of the
    XCS algorithm will confirm whether or not the initial rules are indeed appropriate.
    The following diagram describes the application of the XCS algorithm to the composition
    of a portfolio of ETFs, such as VWO, TLT, IWC, and so on, with the following components:'
  id: totrans-5298
  prefs: []
  type: TYPE_NORMAL
- en: The population of trading rules
  id: totrans-5299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An algorithm to match rules and compute the prediction
  id: totrans-5300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An algorithm to extract the actions sets
  id: totrans-5301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Q-learning module to assign a credit or reward to the selected rules
  id: totrans-5302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The genetic algorithm to evolve the population of rules
  id: totrans-5303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following diagram:'
  id: totrans-5304
  prefs: []
  type: TYPE_NORMAL
- en: '![Application to portfolio management](img/image01589.jpeg)'
  id: totrans-5305
  prefs: []
  type: TYPE_IMG
- en: An overview of the XCS algorithm to optimize the portfolio allocation
  id: totrans-5306
  prefs: []
  type: TYPE_NORMAL
- en: The agent responds to the change in the allocation of ETFs in the portfolio
    by matching one of the existing rules.
  id: totrans-5307
  prefs: []
  type: TYPE_NORMAL
- en: Let's build the XCS agent from the ground.
  id: totrans-5308
  prefs: []
  type: TYPE_NORMAL
- en: The XCS core data
  id: totrans-5309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three types of data that are manipulated by the XCS agent:'
  id: totrans-5310
  prefs: []
  type: TYPE_NORMAL
- en: '`Signal`: This is the trading signal.'
  id: totrans-5311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`XcsAction`: This is the action on the environment. It subclasses a `Gene`
    defined in the genetic algorithm.'
  id: totrans-5312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`XcsSensor`: This is the sensor or data from the environment.'
  id: totrans-5313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Gene` class was introduced for the evaluation of the genetic algorithm
    in the *Trading signals* section in [Chapter 10](part0213.xhtml#aid-6B47Q1 "Chapter 10. Genetic
    Algorithms"), *Genetic Algorithms*. The agent creates, modifies, and deletes actions.
    It makes sense to define these actions as mutable genes, as follows:'
  id: totrans-5314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE417]'
  id: totrans-5315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE417]'
- en: 'The quantization and encoding of the `XCSAction` into a `Gene` has to be explicitly
    declared (line `1`). The `XcsAction` class has the identifier of the `sensorId`
    sensor and the target value as parameters. For example, the action to increase
    the number of shares of ETF, VWO in the portfolio to 80 is defined as follows:'
  id: totrans-5316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE418]'
  id: totrans-5317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE418]'
- en: The only type of action allowed in this scheme is setting a value using the
    `EQUAL` operator. You can create actions that support other operators such as
    `+=` used to increase an existing value. These operators need to implement the
    operator trait, as explained in the *Trading operators* section in [Chapter 10](part0213.xhtml#aid-6B47Q1
    "Chapter 10. Genetic Algorithms"), *Genetic Algorithms*.
  id: totrans-5318
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `XcsSensor` class encapsulates the `sensorId` identifier for the
    variable and `value` of the sensor, as shown here:'
  id: totrans-5319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE419]'
  id: totrans-5320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE419]'
- en: Note
  id: totrans-5321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Setters and getters**'
  id: totrans-5322
  prefs: []
  type: TYPE_NORMAL
- en: In this simplistic scenario, the sensors retrieve a new value from an environment
    variable. The action sets a new value to an environment variable. You can think
    of a sensor as a get method of an environment class and an action as a set method
    with variable/sensor ID and value as arguments.
  id: totrans-5323
  prefs: []
  type: TYPE_NORMAL
- en: XCS rules
  id: totrans-5324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next step consists of defining a rule of the `XcsRule` type as a pair of
    two genes: a `signal` and an `action`, as shown in the following code:'
  id: totrans-5325
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE420]'
  id: totrans-5326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE420]'
- en: 'The rule: *r1: IF(yield 10-year TB > 2.84%) THEN reduce VWO shares to 240*
    is implemented as follows:'
  id: totrans-5327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE421]'
  id: totrans-5328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE421]'
- en: 'The agent encodes the rule as a chromosome using 2 bits to represent the operator
    and 32 bits for values, as shown in the following diagram:'
  id: totrans-5329
  prefs: []
  type: TYPE_NORMAL
- en: '![XCS rules](img/image01590.jpeg)'
  id: totrans-5330
  prefs: []
  type: TYPE_IMG
- en: In this implementation, there is no need to encode the type of action as the
    agent uses only one type of action—set. A complex action requires encoding of
    its type.
  id: totrans-5331
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Knowledge encoding**'
  id: totrans-5333
  prefs: []
  type: TYPE_NORMAL
- en: This example uses very simple rules with a single predicate as the condition.
    Real-world domain knowledge is usually encoded using complex rules with multiple
    clauses. It is highly recommended that you break down complex rules into multiple
    basic rules of classifiers.
  id: totrans-5334
  prefs: []
  type: TYPE_NORMAL
- en: 'Matching a rule to a new sensor consists of matching the sensor to the signal.
    The algorithm matches the new `new10ytb` sensor (line `2`) against the signal
    in the current population of `s10ytb1` (line `3`) and `s10ytb2` (line `4`) rules
    that use the same sensor or the `10ytb` variable as follows:'
  id: totrans-5335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE422]'
  id: totrans-5336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE422]'
- en: 'In this case, the agent selects the `r23` rule but not `r34` in the existing
    population. The agent then adds the `act12` action to the list of possible actions.
    The agent lists all the rules that match the `r23`, `r11`, and `r46` sensors,
    as shown in the following code:'
  id: totrans-5337
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE423]'
  id: totrans-5338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE423]'
- en: The action with the most references, `act12`, (lines `5` and `6`) is executed.
    The Q-learning algorithm computes the reward from the profit or loss incurred
    by the portfolio following the execution of the selected `r23` and `r46` rules.
    The agent uses the reward to adjust the fitness of `r23` and `r46`, before the
    genetic selection in the next reproduction cycle. These two rules will reach and
    stay in the top tier of the rules in the population, until either a new genetic
    rule modified through crossover and mutation or a rule created through covering,
    triggers a more rewarding action on the environment.
  id: totrans-5339
  prefs: []
  type: TYPE_NORMAL
- en: Covering
  id: totrans-5340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The purpose of the covering phase is to generate new rules if no rule matches
    the input or sensor. The `cover` method of an `XcsCover` singleton generates a
    new `XcsRule` instance given a sensor and an existing set of actions, as shown
    here:'
  id: totrans-5341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE424]'
  id: totrans-5342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE424]'
- en: 'You might wonder why the `cover` method uses a set of actions as arguments
    knowing that covering consists of creating new actions. The method mutates (`^`
    operator) an existing action to create a new one instead of using a random generator.
    This is one of the advantages of defining an action as a gene. One of the constructors
    of `XcsAction` executes the mutation, as follows:'
  id: totrans-5343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE425]'
  id: totrans-5344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE425]'
- en: 'The index of the operator `r` type is a random value in the interval [0, 3]
    because a signal uses four types of operators: `None`, `>`, `<`, and `=`.'
  id: totrans-5345
  prefs: []
  type: TYPE_NORMAL
- en: An implementation example
  id: totrans-5346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Xcs` class has the following purposes:'
  id: totrans-5347
  prefs: []
  type: TYPE_NORMAL
- en: '`gaSolver`: This is the selection and generation of genetically modified rules'
  id: totrans-5348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qlLearner`: This is the rewarding and scoring the rules'
  id: totrans-5349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Xcs`: These are the rules for matching, covering, and generation of actions'
  id: totrans-5350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The extended learning classifier is a data transformation of the `ETransform`
    type with an explicit configuration of the `XcsConfig` type (line `8`) (refer
    to the *Monadic data transformation* section in C[hapter 2](part0018.xhtml#aid-H5A41
    "Chapter 2. Manipulating Data with Breeze"), *Hello World!*):'
  id: totrans-5351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE426]'
  id: totrans-5352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE426]'
- en: The XCS algorithm is initialized with a configuration `config`, an initial set
    of rules `population`, a fitness function `score`, and an `input` to the Q-learning
    policy generate reward matrix for `qlLearner` (line `7`). Being an explicit data
    transformation, the `U` type of an input element and the `V` type of the output
    element to the `|>` predictor are initialized as `XcsSensor` (line `9`) and `List[XcsAction]`
    (line `10`).
  id: totrans-5353
  prefs: []
  type: TYPE_NORMAL
- en: The goals and number of states are extracted from the input to the policy of
    the Q-learning algorithm.
  id: totrans-5354
  prefs: []
  type: TYPE_NORMAL
- en: In this implementation, the `solver` generic algorithm is mutable. It is instantiated
    along with the `Xcs` container class. The Q-learning algorithm uses the same design,
    as any classifier, as immutable. The model of Q-learning is the best possible
    policy to reward rules. Any changes in the number of states or the rewarding scheme
    require a new instance of the learner.
  id: totrans-5355
  prefs: []
  type: TYPE_NORMAL
- en: Benefits and limitations of learning classifier systems
  id: totrans-5356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Learning classifier systems and XCS in particular, hold many promises, which
    are listed as follows:'
  id: totrans-5357
  prefs: []
  type: TYPE_NORMAL
- en: They allow nonscientists and domain experts to describe the knowledge using
    familiar Boolean constructs and inferences such as predicates and rules
  id: totrans-5358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They provide analysts with an overview of the knowledge base and its coverage
    by distinguishing between the need for exploration and exploitation of the knowledge
    base
  id: totrans-5359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, the scientific community has been slow to recognize the merits of
    these techniques. The wider adoption of learning classifier systems is hindered
    by the following factors:'
  id: totrans-5360
  prefs: []
  type: TYPE_NORMAL
- en: The large number of parameters used in both exploration and exploitation phases
    adds to the sheer complexity of the algorithm.
  id: totrans-5361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are too many competitive variants of learning classifier systems
  id: totrans-5362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no clear unified theory to validate the concept of evolutionary policies
    or rules. After all, these algorithms are the merger of standalone techniques.
    The accuracy and performance of the execution of many variants of the learning
    classifier systems depend on each component as well as the interaction between
    components.
  id: totrans-5363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An execution that is not always predictable in terms of scalability and performance.
  id: totrans-5364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-5365
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The software engineering community sometimes overlooks reinforcement learning
    algorithms. Let''s hope that this chapter provides adequate answers to the following
    questions:'
  id: totrans-5366
  prefs: []
  type: TYPE_NORMAL
- en: What is reinforcement learning?
  id: totrans-5367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the different types of algorithms that qualify as reinforcement learning?
  id: totrans-5368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we implement the Q-learning algorithm in Scala?
  id: totrans-5369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can we apply Q-learning to the optimization of option trading?
  id: totrans-5370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the pros and cons of using reinforcement learning?
  id: totrans-5371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are learning classifier systems?
  id: totrans-5372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the key components of the XCS algorithm?
  id: totrans-5373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the potentials and limitations of learning classifier systems?
  id: totrans-5374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This concludes the introduction of the last category of learning techniques.
    The ever-increasing amount of data that surrounds us requires data processing
    and machine learning algorithms to be highly scalable. This is the subject of
    the next and the final chapter.
  id: totrans-5375
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 12. Scalable Frameworks
  id: totrans-5376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The advent of social networking, interactive media, and deep analysis has caused
    the amount of data processed daily to skyrocket. For data scientists, it's no
    longer just a matter of finding the most appropriate and accurate algorithm to
    mine data; it is also about leveraging multi-core CPU architectures and distributed
    computing frameworks to solve problems in a timely fashion. After all, how valuable
    is a data mining application if the model does not scale?
  id: totrans-5377
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many options available to Scala developers to build classification
    and regression applications for very large datasets. This chapter covers the Scala
    parallel collections, Actor model, Akka framework, and Apache Spark in-memory
    clusters. The following topics are covered in this chapter:'
  id: totrans-5378
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Scala parallel collections
  id: totrans-5379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation of performance of a parallel collection on multi-core CPUs
  id: totrans-5380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The actor model and reactive systems
  id: totrans-5381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustered and reliable distributed computing using Akka
  id: totrans-5382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A design of the computational workflow using Akka routers
  id: totrans-5383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to Apache Spark clustering and its design principles
  id: totrans-5384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Spark MLlib for clustering
  id: totrans-5385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relative performance tuning and evaluation of Spark
  id: totrans-5386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benefits and limitations of the Apache Spark framework
  id: totrans-5387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview
  id: totrans-5388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The support for distributing and concurrent processing is provided by different
    stacked frameworks and libraries. Scala concurrent and parallel collections' classes
    leverage the threading capabilities of the Java virtual machine. **Akka.io** implements
    a reliable action model originally introduced as part of the Scala standard library.
    The Akka framework supports remote actors, routing, load balancing protocols,
    dispatchers, clusters, events, and configurable mailbox management. This framework
    also provides support for different transport modes, supervisory strategies, and
    typed actors. Apache Spark's resilient distributed datasets with advanced serialization,
    caching, and partitioning capabilities leverage Scala and Akka libraries.
  id: totrans-5389
  prefs: []
  type: TYPE_NORMAL
- en: 'The following stack representation illustrates the interdependencies between
    frameworks:'
  id: totrans-5390
  prefs: []
  type: TYPE_NORMAL
- en: '![An overview](img/image01591.jpeg)'
  id: totrans-5391
  prefs: []
  type: TYPE_IMG
- en: The Stack representation of scalable frameworks using Scala
  id: totrans-5392
  prefs: []
  type: TYPE_NORMAL
- en: Each layer adds a new functionality to the previous one to increase scalability.
    The Java virtual machine runs as a process within a single host. Scala concurrent
    classes support effective deployment of an application by leveraging multicore
    CPU capabilities without the need to write multithreaded applications. Akka extends
    the Actor paradigm to clusters with advanced messaging and routing options. Finally,
    Apache Spark leverages Scala higher-order collection methods and the Akka implementation
    of the Actor model to provide large-scale data processing systems with better
    performance and reliability, through its resilient distributed datasets and in-memory
    persistency.
  id: totrans-5393
  prefs: []
  type: TYPE_NORMAL
- en: Scala
  id: totrans-5394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Scala standard library offers a rich set of tools, such as parallel collections
    and concurrent classes to scale number-crunching applications. Although these
    tools are very effective in processing medium-sized datasets, they are unfortunately
    quite often discarded by developers in favor of more elaborate frameworks.
  id: totrans-5395
  prefs: []
  type: TYPE_NORMAL
- en: Object creation
  id: totrans-5396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although code optimization and memory management is beyond the scope of this
    chapter, it is worthwhile to remember that a few simple steps can be taken to
    improve the scalability of an application. One of the most frustrating challenges
    in using Scala to process large datasets is the creation of a large number of
    objects and the load on the garbage collector.
  id: totrans-5397
  prefs: []
  type: TYPE_NORMAL
- en: 'A partial list of remedial actions is as follows:'
  id: totrans-5398
  prefs: []
  type: TYPE_NORMAL
- en: Limiting unnecessary duplication of objects in an iterated function using a
    mutable instance
  id: totrans-5399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using lazy values and **Stream** classes to create objects as needed
  id: totrans-5400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging efficient collections such as **bloom filters** or **skip lists**
  id: totrans-5401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running `javap` to decipher the generation of byte code by the JVM
  id: totrans-5402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams
  id: totrans-5403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some problems require the preprocessing and training of very large datasets,
    resulting on significant memory consumption by the JVM. Streams are list-like
    collections in which elements are instantiated or computed lazily. Streams share
    the same goal of postponing computation and memory allocation as views.
  id: totrans-5404
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the computation of the loss function in machine learning. An
    observation of the `DataPoint` type is defined as a features vector, `x`, and
    a labeled or expected value, `y`:'
  id: totrans-5405
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE427]'
  id: totrans-5406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE427]'
- en: 'We can create a loss function, `LossFunction`, that processes a very large
    dataset on a platform with limited memory. The optimizer responsible for the minimization
    of the loss or error invokes the loss function at each iteration or recursion,
    as described in the following diagram:'
  id: totrans-5407
  prefs: []
  type: TYPE_NORMAL
- en: '![Streams](img/image01592.jpeg)'
  id: totrans-5408
  prefs: []
  type: TYPE_IMG
- en: An illustration of Scala streams allocation and release
  id: totrans-5409
  prefs: []
  type: TYPE_NORMAL
- en: 'The constructor of the `LossFunction` class has the following three arguments
    (line `2`):'
  id: totrans-5410
  prefs: []
  type: TYPE_NORMAL
- en: The computation `f` of the loss for each data point
  id: totrans-5411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `weights` of the model
  id: totrans-5412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The size of the entire stream `dataSize`
  id: totrans-5413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  id: totrans-5414
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE428]'
  id: totrans-5415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE428]'
- en: The loss function for the stream is implemented as the `compute` tail recursion
    (line `3`). The recursive method updates the reference of the stream. The type
    of reference of the stream is `WeakReference` (line `1`), so the garbage collection
    can reclaim the memory associated with the slice for which the loss has been computed.
    In this example, the loss function is computed as a sum of squared errors (line
    `4`).
  id: totrans-5416
  prefs: []
  type: TYPE_NORMAL
- en: 'The `compute` method manages the allocation and release of slices of stream:'
  id: totrans-5417
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE429]'
  id: totrans-5418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE429]'
- en: 'The dataset is processed in two steps:'
  id: totrans-5419
  prefs: []
  type: TYPE_NORMAL
- en: The driver allocates (that is, `take`) a slice of the stream of observations
    and then computes the cumulative loss for all the observations in the slice (line
    `5`)
  id: totrans-5420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the computation of the loss for the slice is completed, the memory allocated
    to the weak reference is released (that is, `drop`) (line `6`)
  id: totrans-5421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5422
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**An alternative to weak references**'
  id: totrans-5423
  prefs: []
  type: TYPE_NORMAL
- en: 'There are alternatives to weak references in order for the stream to force
    the garbage collector to reclaim the memory blocks associated with each slice
    of observations, which are as follows:'
  id: totrans-5424
  prefs: []
  type: TYPE_NORMAL
- en: Define the stream reference as `def`
  id: totrans-5425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrap the reference into a method; the reference is then accessible to the garbage
    collector when the wrapping method returns
  id: totrans-5426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a `List` iterator
  id: totrans-5427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average memory allocated during the execution of the loss function for the
    entire stream is the memory needed to allocate a single slice.
  id: totrans-5428
  prefs: []
  type: TYPE_NORMAL
- en: Parallel collections
  id: totrans-5429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Scala standard library includes parallelized collections, whose purpose
    is to shield developers from the intricacies of concurrent thread execution and
    race condition. Parallel collections are a very convenient approach to encapsulate
    concurrency constructs to a higher level of abstraction [12:1].
  id: totrans-5430
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to create parallel collections in Scala, which are as follows:'
  id: totrans-5431
  prefs: []
  type: TYPE_NORMAL
- en: 'Converting an existing collection into a parallel collection of the same semantic
    using the `par` method; for example, `List[T].par: ParSeq[T]`, `Array[T].par:
    ParArray[T]`, `Map[K,V].par: ParMap[K,V]`, and so on'
  id: totrans-5432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the collection classes from the `collection.parallel`, `parallel`. `immutable`,
    or `parallel.mutable` packages; for example, `ParArray`, `ParMap`, `ParSeq`, `ParVector`,
    and so on
  id: totrans-5433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing a parallel collection
  id: totrans-5434
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A parallel collection does lend itself to concurrent processing until a pool
    of threads and a task scheduler are assigned to it. Fortunately, Scala parallel
    and concurrent packages provide developers with a powerful toolbox to map partitions
    or segments of collection to tasks running on different CPU cores. The components
    are as follows:'
  id: totrans-5435
  prefs: []
  type: TYPE_NORMAL
- en: '`TaskSupport`: This trait inherits the generic `Tasks` trait. It is responsible
    for scheduling the operation on the parallel collection. There are three concrete
    implementations of `TaskSupport`.'
  id: totrans-5436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ThreadPoolTaskSupport`: This uses the threads pool in an older version of
    the JVM.'
  id: totrans-5437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ExecutionContextTaskSupport`: This uses `ExecutorService` that delegates the
    management of tasks to either a thread pool or the `ForkJoinTasks` pool.'
  id: totrans-5438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ForkJoinTaskSupport`: This uses the fork-join pools of the `java.util. concurrent.FortJoinPool`
    type introduced in the Java SDK 1.6\. In Java, a **fork-join pool** is an instance
    of `ExecutorService` that attempts to run not only the current task but also any
    of its subtasks. It executes the `ForkJoinTask` instances that are lightweight
    threads.'
  id: totrans-5439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following example implements the generation of a random exponential value
    using a parallel vector and `ForkJoinTaskSupport`:'
  id: totrans-5440
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE430]'
  id: totrans-5441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE430]'
- en: The `rand` parallel vector of random probabilities is created and initialized
    by the main task (line `1`), but the conversion to a vector of a `randExp` exponential
    value is executed by a pool of 16 concurrent tasks (line `2`).
  id: totrans-5442
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5443
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Preserving the order of elements**'
  id: totrans-5444
  prefs: []
  type: TYPE_NORMAL
- en: Operations that traverse a parallel collection using an iterator preserve the
    original order of the element of the collection. Iterator-less methods such as
    `foreach` or `map` do not guarantee that the order of the elements that are processed
    will be preserved.
  id: totrans-5445
  prefs: []
  type: TYPE_NORMAL
- en: The benchmark framework
  id: totrans-5446
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The main purpose of parallel collections is to improve the performance of execution
    through concurrency. The first step is to either select an existing benchmark
    or create our own benchmark.
  id: totrans-5447
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5448
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Scala library benchmark**'
  id: totrans-5449
  prefs: []
  type: TYPE_NORMAL
- en: 'The Scala standard library has a `testing.Benchmark` trait used to test using
    the command line [12:2]. All you need to do is insert your function or code in
    the `run` method:'
  id: totrans-5450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE431]'
  id: totrans-5451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE431]'
- en: 'Let''s create a `ParBenchmark` parameterized class to evaluate the performance
    of operations on parallel collections:'
  id: totrans-5452
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE432]'
  id: totrans-5453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE432]'
- en: 'The user has to supply the data transformation `f` for the `map` (line `1`)
    and `filter` (line `2`) operations of parallel collections as well as the number
    of concurrent tasks `nTasks`. The `timing` method collects the duration of the
    `times` execution of a given operation `g` on a parallel collection:'
  id: totrans-5454
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE433]'
  id: totrans-5455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE433]'
- en: 'Let''s define the mapping and reducing operation for the parallel arrays for
    which the benchmark is defined as follows:'
  id: totrans-5456
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE434]'
  id: totrans-5457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE434]'
- en: The first argument of the benchmark constructor is the default array of the
    Scala standard library (line `3`). The second argument is the parallel data structure
    (or class) associated with the array (line `4`).
  id: totrans-5458
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compare the parallelized and default array on the `map` and `reduce`
    methods of `ParArrayBenchmark` as follows:'
  id: totrans-5459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE435]'
  id: totrans-5460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE435]'
- en: 'The user has to define the mapping function `f` and the number of concurrent
    tasks `nTasks` available to execute a map transformation on the array `u` (line
    `5`) and its parallelized counterpart `v` (line `6`). The `reduce` method follows
    the same design, as shown in the following code:'
  id: totrans-5461
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE436]'
  id: totrans-5462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE436]'
- en: The user-defined function `f` is used to execute the reduce action on the array
    `u` (line `7`) and its parallelized counterpart `v` (line `8`).
  id: totrans-5463
  prefs: []
  type: TYPE_NORMAL
- en: The same template can be used for other higher Scala methods, such as `filter`.
  id: totrans-5464
  prefs: []
  type: TYPE_NORMAL
- en: The absolute timing of each operation is completely dependent on the environment.
    It is far more useful to record the ratio of the duration of execution of the
    operation on the parallelized array, over the single thread array.
  id: totrans-5465
  prefs: []
  type: TYPE_NORMAL
- en: 'The benchmark class `ParMapBenchmark` used to evaluate `ParHashMap` is similar
    to the benchmark for `ParArray`, as shown in the following code:'
  id: totrans-5466
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE437]'
  id: totrans-5467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE437]'
- en: 'For example, the `filter` method of `ParMapBenchmark` evaluates the performance
    of the parallel map `v` relative to a single-threaded map `u`. It applies the
    filtering condition to the values of each map, as follows:'
  id: totrans-5468
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE438]'
  id: totrans-5469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE438]'
- en: Performance evaluation
  id: totrans-5470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first performance test consists of creating a single-threaded and a parallel
    array of random values and executing the `map` and `reduce` evaluation methods,
    on using an increasing number of tasks, as follows:'
  id: totrans-5471
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE439]'
  id: totrans-5472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE439]'
- en: Note
  id: totrans-5473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Measuring performance**'
  id: totrans-5474
  prefs: []
  type: TYPE_NORMAL
- en: The code has to be executed within a loop and the duration has to be averaged
    over a large number of executions to avoid transient actions such as initialization
    of the JVM process or collection of unused memory (GC).
  id: totrans-5475
  prefs: []
  type: TYPE_NORMAL
- en: 'The following graph shows the output of the performance test:'
  id: totrans-5476
  prefs: []
  type: TYPE_NORMAL
- en: '![Performance evaluation](img/image01593.jpeg)'
  id: totrans-5477
  prefs: []
  type: TYPE_IMG
- en: The impact of concurrent tasks on the performance on Scala parallelized map
    and reduce
  id: totrans-5478
  prefs: []
  type: TYPE_NORMAL
- en: The test executes the mapper and reducer functions 1 million times on an 8-core
    CPU with 8 GB of available memory on the JVM.
  id: totrans-5479
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are not surprising in the following respects:'
  id: totrans-5480
  prefs: []
  type: TYPE_NORMAL
- en: The reducer doesn't take advantage of the parallelism of the array. The reduction
    of `ParArray` has a small overhead in the single-task scenario and then matches
    the performance of `Array`.
  id: totrans-5481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of the `map` function benefits from the parallelization of the
    array. The performance levels off when the number of tasks allocated equals or
    exceeds the number of CPU core.
  id: totrans-5482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second test consists of comparing the behavior of the `ParArray` and `ParHashMap`
    parallel collections, on the `map` and `filter` methods, using a configuration
    identical to the first test as follows:'
  id: totrans-5483
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE440]'
  id: totrans-5484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE440]'
- en: 'The test initializes a `HashMap` instance and its `ParHashMap` parallel counter
    with 1 million random values (line `9`). The benchmark `bench` processes all the
    elements of these hash maps with the `mapper` instance introduced in the first
    test (line `10`) and a filtering function `filterer` (line `11`) with `NTASKS`
    equal to 6\. The output is shown in the following diagram:'
  id: totrans-5485
  prefs: []
  type: TYPE_NORMAL
- en: '![Performance evaluation](img/image01594.jpeg)'
  id: totrans-5486
  prefs: []
  type: TYPE_IMG
- en: The impact of concurrent tasks on the performance on Scala parallelized array
    and hash map
  id: totrans-5487
  prefs: []
  type: TYPE_NORMAL
- en: The impact of the parallelization of collections is very similar across methods
    and collections. It's important to notice that the performance of the parallel
    collections levels off at around four times the single thread collections for
    five concurrent tasks and above. **Core parking** is partially responsible for
    this behavior. Core parking disables a few CPU cores in an effort to conserve
    power, and in the case of a single application, it consumes almost all CPU cycles.
  id: totrans-5488
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5489
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Further performance evaluation**'
  id: totrans-5490
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the performance test was to highlight the benefits of using Scala
    parallel collections. You should experiment further with collections other than
    `ParArray` and `ParHashMap` and other higher-order methods to confirm the pattern.
  id: totrans-5491
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, a four times increase in performance is nothing to complain about.
    Having said that, parallel collections are limited to single-host deployments.
    If you cannot live with such a restriction and still need a scalable solution,
    the Actor model provides a blueprint for highly distributed applications.
  id: totrans-5492
  prefs: []
  type: TYPE_NORMAL
- en: Scalability with Actors
  id: totrans-5493
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional multithreaded applications rely on accessing data located in shared
    memory. The mechanism relies on synchronization monitors such as locks, mutexes,
    or semaphores to avoid deadlocks and inconsistent mutable states. Even for the
    most experienced software engineer, debugging multithreaded applications is not
    a simple endeavor.
  id: totrans-5494
  prefs: []
  type: TYPE_NORMAL
- en: The second problem with shared memory threads in Java is the high computation
    overhead caused by continuous context switches. Context switching consists of
    saving the current stack frame delimited by the base and stack pointers into the
    heap memory and loading another stack frame.
  id: totrans-5495
  prefs: []
  type: TYPE_NORMAL
- en: 'These restrictions and complexities can be avoided using a concurrency model
    that relies on the following key principles:'
  id: totrans-5496
  prefs: []
  type: TYPE_NORMAL
- en: Immutable data structures
  id: totrans-5497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asynchronous communication
  id: totrans-5498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Actor model
  id: totrans-5499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Actor model, originally introduced in the **Erlang** programming language,
    addresses these issues [12:3]. The purpose of using the Actor model is twofold
    as follows:'
  id: totrans-5500
  prefs: []
  type: TYPE_NORMAL
- en: It distributes the computation over as many cores and servers as possible
  id: totrans-5501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It reduces or eliminates race conditions and deadlocks, which are very prevalent
    in the Java development
  id: totrans-5502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The model consists of the following components:'
  id: totrans-5503
  prefs: []
  type: TYPE_NORMAL
- en: Independent processing units known as Actors. They communicate by exchanging
    messages asynchronously instead of sharing states.
  id: totrans-5504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immutable messages are sent to queues, known as mailboxes, before being processed
    by each actor one at a time.
  id: totrans-5505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following diagram:'
  id: totrans-5506
  prefs: []
  type: TYPE_NORMAL
- en: '![The Actor model](img/image01595.jpeg)'
  id: totrans-5507
  prefs: []
  type: TYPE_IMG
- en: The representation of messaging between actors
  id: totrans-5508
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two message-passing mechanisms, which are as follows:'
  id: totrans-5509
  prefs: []
  type: TYPE_NORMAL
- en: '**Fire-and-forget or tell**: This sends the immutable message asynchronously
    to the target or receiving Actor and immediately returns without blocking. The
    syntax is `targetActorRef ! message`.'
  id: totrans-5510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Send-and-receive or ask**: This sends a message asynchronously, but returns
    a `Future` instance that defines the expected reply from the `val future = targetActorRef
    ? message` target actor.'
  id: totrans-5511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The generic construct for the Actor message handler is somewhat similar to
    the `Runnable.run()` method in Java, as shown in the following code:'
  id: totrans-5512
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE441]'
  id: totrans-5513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE441]'
- en: The `receive` keyword is, in fact, a partial function of the `PartialFunction[Any,
    Unit]` type [12:4]. The purpose is to avoid forcing developers to handle all possible
    message types. The Actor consuming messages may very well run on a separate component
    or even application, from the Actor producing these messages. It not always easy
    to anticipate the type of messages an Actor has to process in a future version
    of an application.
  id: totrans-5514
  prefs: []
  type: TYPE_NORMAL
- en: A message whose type is not matched is merely ignored. There is no need to throw
    an exception from within the Actor's routine. Implementations of the Actor model
    strive to avoid the overhead of context switching and creation of threads [12:5].
  id: totrans-5515
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5516
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**I/O blocking operations**'
  id: totrans-5517
  prefs: []
  type: TYPE_NORMAL
- en: Although it is highly recommended that you do not use Actors to block operations,
    such as I/O, there are circumstances that require the sender to wait for a response.
    You need to be keep in mind that blocking the underlying threads might starve
    other Actors from CPU cycles. It is recommended that you either configure the
    runtime system to use a large thread pool or allow the thread pool to be resized
    by setting the `actors.enableForkJoin` property as `false`.
  id: totrans-5518
  prefs: []
  type: TYPE_NORMAL
- en: Partitioning
  id: totrans-5519
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A dataset is defined as a Scala collection, for example, `List`, `Map`, and
    so on. Concurrent processing requires the following steps:'
  id: totrans-5520
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down a dataset into multiple subdatasets.
  id: totrans-5521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Processing each dataset independently and concurrently.
  id: totrans-5522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Aggregating all the resulting datasets.
  id: totrans-5523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These steps are defined through a monad associated with a collection in the
    *Abstraction* section under *Why Scala?* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*.
  id: totrans-5524
  prefs: []
  type: TYPE_NORMAL
- en: 'The `apply` method creates the sub-collection or partitions for the first step,
    for example, `def apply[T](a: T): List[T]`.'
  id: totrans-5525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A map-like operation defines the second stage. The last step relies on the
    monoidal associativity of the Scala collection, for example, `def ++ (a: List[T].
    b: List[T): List[T} = a ++ b`.'
  id: totrans-5526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The aggregation, such as `reduce`, `fold`, `sum`, and so on, consists of flattening
    all the subresults into a single output, for example, `val xs: List(…) = List(List(..),
    List(..)).flatten`.'
  id: totrans-5527
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The methods that can be parallelized are `map`, `flatMap`, `filter`, `find`,
    and `filterNot`. The methods that cannot be completely parallelized are `reduce`,
    `fold`, `sum`, `combine`, `aggregate`, `groupBy`, and `sortWith`.
  id: totrans-5528
  prefs: []
  type: TYPE_NORMAL
- en: Beyond actors – reactive programming
  id: totrans-5529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Actor model is an example of the reactive programming paradigm. The concept
    is that functions and methods are executed in response to events or exceptions.
    Reactive programming combines concurrency with event-based systems [12:6].
  id: totrans-5530
  prefs: []
  type: TYPE_NORMAL
- en: Advanced functional reactive programming constructs rely on composable futures
    and **continuation-passing style** (**CPS**). An example of a Scala reactive library
    can be found at [https://github.com/ingoem/scala-react](https://github.com/ingoem/scala-react).
  id: totrans-5531
  prefs: []
  type: TYPE_NORMAL
- en: Akka
  id: totrans-5532
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Akka framework extends the original Actor model in Scala by adding extraction
    capabilities such as support for typed Actor, message dispatching, routing, load
    balancing, and partitioning, as well as supervision and configurability [12:7].
  id: totrans-5533
  prefs: []
  type: TYPE_NORMAL
- en: The Akka framework can be downloaded from the [http://akka.io/](http://akka.io/)
    website or through the Typesafe Activator at [http://www.typesafe.com/platform](http://www.typesafe.com/platform).
  id: totrans-5534
  prefs: []
  type: TYPE_NORMAL
- en: Akka simplifies the implementation of the Actor model by encapsulating some
    of the details of Scala Actor in the `akka.actor.Actor` and `akka.actor.ActorSystem`
    classes.
  id: totrans-5535
  prefs: []
  type: TYPE_NORMAL
- en: 'The three methods you want to override are as follows:'
  id: totrans-5536
  prefs: []
  type: TYPE_NORMAL
- en: '`prestart`: This is an optional method that is invoked to initialize all the
    necessary resources such as file or database connection before the Actor is executed'
  id: totrans-5537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`receive`: This method defines the Actor''s behavior and returns a partial
    function of the `PartialFunction[Any, Unit]` type'
  id: totrans-5538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`postStop`: This is an optional method to clean up resources such as releasing
    memory, closing database connections, and socket or file handles'
  id: totrans-5539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5540
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Typed and untyped actors**'
  id: totrans-5541
  prefs: []
  type: TYPE_NORMAL
- en: Untyped actors can process messages of any type. If the type of the message
    is not matched by the receiving actor, it is discarded. Untyped actors can be
    regarded as contract-less actors. They are the default actors in Scala.
  id: totrans-5542
  prefs: []
  type: TYPE_NORMAL
- en: Typed actors are similar to Java remote interfaces. They respond to a method
    invocation. The invocation is declared publicly, but the execution is delegated
    asynchronously to the private instance of the target actor [12:8].
  id: totrans-5543
  prefs: []
  type: TYPE_NORMAL
- en: Akka offers a variety of functionalities to deploy concurrent applications.
    Let's create a generic template for a master Actor and worker Actors to transform
    a dataset using any preprocessing or classification algorithm inherited from an
    explicit or implicit monadic data transformation, as described in the *Monadic
    data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*
  id: totrans-5544
  prefs: []
  type: TYPE_NORMAL
- en: 'The master Actor manages the worker actors in one of the following ways:'
  id: totrans-5545
  prefs: []
  type: TYPE_NORMAL
- en: Individual actors
  id: totrans-5546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clusters through a **router** or a **dispatcher**
  id: totrans-5547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The router is a very simple example of Actor supervision. Supervision strategies
    in Akka are an essential component to make the application fault-tolerant [12:9].
    A supervisor Actor manages the operations, availability, and life cycle of its
    children, known as **subordinates**. The supervision among actors is organized
    as a hierarchy. Supervision strategies are categorized as follows:'
  id: totrans-5548
  prefs: []
  type: TYPE_NORMAL
- en: '**One-for-one strategy**: This is the default strategy. In case of a failure
    of one of the subordinates, the supervisor executes a recovery, restart, or resume
    action for that subordinate only.'
  id: totrans-5549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**All-for-one strategy**: The supervisor executes a recovery or remedial action
    on all its subordinates in case one of the Actors fails.'
  id: totrans-5550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Master-workers
  id: totrans-5551
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first model to evaluate is the traditional **master-slaves** or **master-workers**
    design for the computation workflow. In this design, the worker Actors are initialized
    and managed by the master Actor, which is responsible for controlling the iterative
    process, state, and termination condition of the algorithm. The orchestration
    of the distributed tasks is performed through message passing.
  id: totrans-5552
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5553
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The design principle**'
  id: totrans-5554
  prefs: []
  type: TYPE_NORMAL
- en: It is highly recommended that you segregate the implementation of the computation
    or domain-specific logic from the actual implementation of the worker and master
    actors.
  id: totrans-5555
  prefs: []
  type: TYPE_NORMAL
- en: Exchange of messages
  id: totrans-5556
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step in implementing the master-worker design is to define the different
    classes of messages exchanged between the master and each worker in order to control
    the execution of the iterative procedure. The implementation of the master-worker
    design is as follows:'
  id: totrans-5557
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE442]'
  id: totrans-5558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE442]'
- en: 'Let''s define the messages that control the execution of the algorithm. We
    need at least the following message types or case classes:'
  id: totrans-5559
  prefs: []
  type: TYPE_NORMAL
- en: '`Start`: This is sent by the client code to the master to start the computation
    (line `1`).'
  id: totrans-5560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Activate`: This is sent by the master to the workers to activate the computation.
    This message contains the time series `x` to be processed by the worker Actors.
    It also contains the reference to `sender` (master actor). (line `2`).'
  id: totrans-5561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Completed`: This is sent by each worker back to `sender`. It contains the
    variance of the data in the group (line `3`).'
  id: totrans-5562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The master stops a worker using a `PoisonPill` message. The different approaches
    to terminate an actor are described in the *The master actor* section.
  id: totrans-5563
  prefs: []
  type: TYPE_NORMAL
- en: 'The hierarchy of the `Message` class is sealed to prevent third-party developers
    from adding another message type. The worker responds to the activate message
    by executing a data transformation of the `ITransform` type. The messages exchanged
    between master and worker actors are shown in the following diagram:'
  id: totrans-5564
  prefs: []
  type: TYPE_NORMAL
- en: '![Exchange of messages](img/image01596.jpeg)'
  id: totrans-5565
  prefs: []
  type: TYPE_IMG
- en: A sketch design of the master-slave communication in an actor framework
  id: totrans-5566
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5567
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Messages as case classes**'
  id: totrans-5568
  prefs: []
  type: TYPE_NORMAL
- en: The actor retrieves the messages queued in its mailbox by managing each message
    instance (copying, matching, and so on). Therefore, the message type has to be
    defined as a case class. Otherwise, the developer will have to override the `equals`
    and `hashCode` methods.
  id: totrans-5569
  prefs: []
  type: TYPE_NORMAL
- en: Worker actors
  id: totrans-5570
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The worker actors are responsible for transforming each partitioned datasets
    created by the master Actor, as follows:'
  id: totrans-5571
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE443]'
  id: totrans-5572
  prefs: []
  type: TYPE_PRE
  zh: '[PRE443]'
- en: The `Worker` class constructor takes the `fct` (the partial function as an argument)
    (line `1`). The worker launches the processing or transformation of the `msg.xt`
    data on arrival of the `Activate` message (line `2`). It returns the `Completed`
    message to the master once the `fct` data transformation is completed.
  id: totrans-5573
  prefs: []
  type: TYPE_NORMAL
- en: The workflow controller
  id: totrans-5574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the *Scalability* section in [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting
    Started"), *Getting Started*, we introduced the concepts of workflow and controller
    to manage the training and classification process as a sequence of transformation
    on a time series. Let''s define an abstract class for all controller actors, `Controller`,
    with the following three key parameters:'
  id: totrans-5575
  prefs: []
  type: TYPE_NORMAL
- en: A time series `xt` to be processed
  id: totrans-5576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `fct` data transformation implemented as a partial function
  id: totrans-5577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of partitions `nPartitions` to break down a time series for concurrent
    processing
  id: totrans-5578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Controller` class can be defined as follows:'
  id: totrans-5579
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE444]'
  id: totrans-5580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE444]'
- en: The controller is responsible for splitting the time series into several partitions
    and assigning each partition to a dedicated worker (line `4`).
  id: totrans-5581
  prefs: []
  type: TYPE_NORMAL
- en: The master actor
  id: totrans-5582
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s define a master actor class `Master`. The three methods to override
    are as follows:'
  id: totrans-5583
  prefs: []
  type: TYPE_NORMAL
- en: '`prestart`: This is a method invoked to initialize all the necessary resources
    such as a file or database connection before the actor executes (line `9`)'
  id: totrans-5584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`receive`: This is a partial function that dequeues and processes the messages
    from the mail box'
  id: totrans-5585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`postStop`: This cleans up resources such as releasing memory and closing database
    connections, sockets, or file handles (line `10`)'
  id: totrans-5586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Master` class can be defined as follows:'
  id: totrans-5587
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE445]'
  id: totrans-5588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE445]'
- en: 'The `Master` class has the following parameters (line `5`):'
  id: totrans-5589
  prefs: []
  type: TYPE_NORMAL
- en: '`xt`: This is the time series to transform'
  id: totrans-5590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fct`: This is the transformation function'
  id: totrans-5591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nPartitions`: This is the number of partitions'
  id: totrans-5592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An aggregating class `aggregator` collects and reduces the results from each
    worker (line `6`):'
  id: totrans-5593
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE446]'
  id: totrans-5594
  prefs: []
  type: TYPE_PRE
  zh: '[PRE446]'
- en: The worker actors are created through the `actorOf` factory method of the `ActorSystem`
    context (line `7`). The worker actors are attached to the context of the master
    actor, so it can be notified when the workers terminate (line `8`).
  id: totrans-5595
  prefs: []
  type: TYPE_NORMAL
- en: 'The `receive` message handler processes only two types of messages: `Start`
    from the client code and `Completed` from the workers, as shown in the following
    code:'
  id: totrans-5596
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE447]'
  id: totrans-5597
  prefs: []
  type: TYPE_PRE
  zh: '[PRE447]'
- en: 'The `Start` message triggers the partitioning of the input time series into
    partitions (line `11`):'
  id: totrans-5598
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE448]'
  id: totrans-5599
  prefs: []
  type: TYPE_PRE
  zh: '[PRE448]'
- en: The partitions are then dispatched to each worker with the `Activate` message
    (line `16`).
  id: totrans-5600
  prefs: []
  type: TYPE_NORMAL
- en: Each worker sends a `Completed` message back to master on the completion of
    their task (line `12`). The master aggregates the results from each worker (line
    `13`). Once all the workers have completed their task, they are removed from the
    master's context (line `14`). The master terminates all the workers through a
    `Terminated` message (line `15`), and finally, terminates itself through a request
    to its `context` to stop it (line `16`).
  id: totrans-5601
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous code snippet uses two different approaches to terminate an actor.
    There are four different methods of shutting down an actor, as mentioned here:'
  id: totrans-5602
  prefs: []
  type: TYPE_NORMAL
- en: '`actorSystem.shutdown`: This method is used by the client to shut down the
    parent actor system'
  id: totrans-5603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`actor ! PoisonPill`: This method is used by the client to send a poison pill
    message to the actor'
  id: totrans-5604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`context.stop(self)`: This method is used by the Actor to shut itself down
    within its context'
  id: totrans-5605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`context.stop(childActorRef)`: This method is used by the Actor to shut itself
    down through its reference'
  id: totrans-5606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Master with routing
  id: totrans-5607
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The previous design makes sense only if each worker has a unique characteristic
    that requires direct communication with the master. This is not the case in most
    applications. The communication and internal management of the worker can be delegated
    to a router. The implementation of the master routing capabilities is very similar
    to the previous design, as shown in the following code:'
  id: totrans-5608
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE449]'
  id: totrans-5609
  prefs: []
  type: TYPE_PRE
  zh: '[PRE449]'
- en: The only difference is that the `context.actorOf` factory creates an extra actor,
    router, along with the workers (line `17`). This particular implementation relies
    on round-robin assignment of the message by the router to each worker (line `18`).
    Akka supports several routing mechanisms that select a random actor, or the actor
    with the smallest mailbox, or the first to respond to a broadcast, and so on.
  id: totrans-5610
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5611
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Router supervision**'
  id: totrans-5612
  prefs: []
  type: TYPE_NORMAL
- en: The router actor is a parent of the worker actors. It is by design a supervisor
    of the worker actors, which are its children actors. Therefore, the router is
    responsible for the life cycle of the worker actors, which includes their creation,
    restarting, and termination.
  id: totrans-5613
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the `receive` message handler is almost identical to
    the message handler in the master without routing capabilities, with the exception
    of the termination of the workers through the router (line `19`):'
  id: totrans-5614
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE450]'
  id: totrans-5615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE450]'
- en: 'The `start` message handler has to be modified to broadcast the `Activate`
    message to all the workers through the router:'
  id: totrans-5616
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE451]'
  id: totrans-5617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE451]'
- en: Distributed discrete Fourier transform
  id: totrans-5618
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's select the **discrete Fourier transform** (**DFT**) on a time series `xt`
    as our data transformation. We discussed this in the *Discrete Fourier transform*
    section in [Chapter 3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"),
    *Data Preprocessing*. The testing code is exactly the same, whether the master
    has routing capabilities or not.
  id: totrans-5619
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s define a master controller `DFTMaster` dedicated to the execution
    of the distributed discrete Fourier transform, as follows:'
  id: totrans-5620
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE452]'
  id: totrans-5621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE452]'
- en: 'The `reducer` method aggregates or reduces the results of the discrete Fourier
    transform (frequencies distribution) from each worker (line `20`). In the case
    of the discrete Fourier transform, the `fReduce` reducer method transposes the
    list of frequencies distribution and then sums up the amplitude for each frequency
    (line `21`):'
  id: totrans-5622
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE453]'
  id: totrans-5623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE453]'
- en: 'Let''s take a look at the test code:'
  id: totrans-5624
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE454]'
  id: totrans-5625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE454]'
- en: 'The input time series is synthetically generated by the noisy sinusoidal function
    `h` (line `22`). The function `h` has three distinct harmonics: `0.005`, `0.05`,
    and `0.2`, so the results of the transformation can be easily validated. The Actor
    system, `ActorSystem`, is instantiated (line `23`) and the master Actor is generated
    through the Akka `ActorSytem.actorOf` factory (line `24`). The main program sends
    a `Start` message to the master to trigger the distributed computation of the
    discrete Fourier transform (line `25`).'
  id: totrans-5626
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5627
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The action instantiation**'
  id: totrans-5628
  prefs: []
  type: TYPE_NORMAL
- en: Although the `scala.actor.Actor` class can be instantiated using the constructor,
    `akka.actor.Actor` is instantiated using an `ActorSystem` context, an `actorOf`
    factory, and a `Props` configuration object. This second approach has several
    benefits, including decoupling the deployment of the actor from its functionality
    and enforcing a default supervisor or parent for the Actor; in this case, `ActorSystem`.
  id: totrans-5629
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sequential diagram illustrates the message exchange between the
    main program, master, and worker Actors:'
  id: totrans-5630
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed discrete Fourier transform](img/image01597.jpeg)'
  id: totrans-5631
  prefs: []
  type: TYPE_IMG
- en: A sequential diagram for the normalization of cross-validation groups
  id: totrans-5632
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of the test is to evaluate the performance of the computation of
    the discrete Fourier transform using the Akka framework relative to the original
    implementation, without actors. As with Scala parallel collections, the absolute
    timing for the transformation depends on the host and the configuration, as shown
    in the following graph:'
  id: totrans-5633
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed discrete Fourier transform](img/image01598.jpeg)'
  id: totrans-5634
  prefs: []
  type: TYPE_IMG
- en: The impact of the number of worker (slave) actors on the performance of the
    discrete Fourier transform
  id: totrans-5635
  prefs: []
  type: TYPE_NORMAL
- en: The single-threaded version of the discrete Fourier transform is significantly
    faster than the implementation using the Akka master-worker model with a single
    worker actor. The cost of partitioning and aggregating (or reducing) the results
    adds a significant overhead to the execution of the Fourier transform. However,
    the master worker model is far more efficient with three or more worker actors.
  id: totrans-5636
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  id: totrans-5637
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The master-worker implementation has a few problems, which are as follows:'
  id: totrans-5638
  prefs: []
  type: TYPE_NORMAL
- en: In the message handler of the master Actor, there is no guarantee that the poison
    pill will be consumed by all the workers before the master stops.
  id: totrans-5639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main program has to sleep for a period of time long enough to allow the
    master and workers to complete their tasks. There is no guarantee that the computation
    will be completed when the main program awakes.
  id: totrans-5640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no mechanism to handle failure in delivering or processing messages.
  id: totrans-5641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The culprit is the exclusive use of the fire-and-forget mechanism to exchange
    data between master and workers. The send-and-receive protocol and futures are
    remedies to these problems.
  id: totrans-5642
  prefs: []
  type: TYPE_NORMAL
- en: Futures
  id: totrans-5643
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A future is an object, more specifically a monad, used to retrieve the results
    of concurrent operations, in a nonblocking fashion. The concept is very similar
    to a callback supplied to a worker, which invokes it when the task is completed.
    Futures hold a value that might or might not become available in the future when
    a task is completed, whether successful or not [12:10].
  id: totrans-5644
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options to retrieve results from futures:'
  id: totrans-5645
  prefs: []
  type: TYPE_NORMAL
- en: Blocking the execution using `scala.concurrent.Await`
  id: totrans-5646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `onComplete`, `onSuccess`, and `onFailure` callback functions
  id: totrans-5647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5648
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Which future?**'
  id: totrans-5649
  prefs: []
  type: TYPE_NORMAL
- en: 'A Scala environment provides developers with two different `Future` classes:
    `scala.actor.Future` and `scala.concurrent.Future`.'
  id: totrans-5650
  prefs: []
  type: TYPE_NORMAL
- en: The `actor.Future` class is used to write continuation-passing style workflows
    in which the current actor is blocked until the value of the future is available.
    Instances of the `scala.concurrent.Future` type used in this chapter are the equivalent
    of `java.concurrent.Future` in Scala.
  id: totrans-5651
  prefs: []
  type: TYPE_NORMAL
- en: The Actor life cycle
  id: totrans-5652
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s reimplement the normalization of cross-validation groups by their variance,
    which we introduced in the previous section, using futures to support concurrency.
    The first step is to import the appropriate classes for execution of the main
    actor and futures, as follows:'
  id: totrans-5653
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE455]'
  id: totrans-5654
  prefs: []
  type: TYPE_PRE
  zh: '[PRE455]'
- en: The Actor classes are provided by the `akka.actor` package, instead of the `scala.actor._`
    package because of Akka's extended actor model (line `26`). The future-related
    classes, `Future` and `Await`, are imported from the `scala.concurrent` package,
    which is similar to the `java.concurrent` package (line `28`). The `akka.util.Timeout`
    class is used to specify the maximum duration the actor has to wait for the completion
    of the futures (line `27`).
  id: totrans-5655
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two options for a parent actor or the main program to manage the
    futures it creates, which are as follows:'
  id: totrans-5656
  prefs: []
  type: TYPE_NORMAL
- en: '**Blocking**: The parent actor or main program stops the execution until all
    futures have completed their tasks.'
  id: totrans-5657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Callback**: The parent actor or the main program initiates the futures during
    the execution. The future tasks are performed concurrently with the parent actor,
    and it is then notified when each future task is completed.'
  id: totrans-5658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blocking on futures
  id: totrans-5659
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following design consists of blocking the actor that launches the futures
    until all the futures have been completed, either returning with a result or throwing
    an exception. Let''s modify the master actor into a `TransformFutures` class that
    manages futures instead of workers or routing actors, as follows:'
  id: totrans-5660
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE456]'
  id: totrans-5661
  prefs: []
  type: TYPE_PRE
  zh: '[PRE456]'
- en: 'The `TransformFutures` class requires the same parameters as the `Master` actor:
    a time series, `xt`, a data transformation, `fct`, and the number of partitions,
    `nPartitions`. The `timeout` parameter is an implicit argument of the `Await.result`
    method, and therefore, needs to be declared as an argument (line `29`). The only
    message, `Start`, triggers the computation of the data transformation of each
    future, and then the aggregation of the results (line `30`). The `transform` and
    `compute` methods have the same semantics as those in the master-workers design.'
  id: totrans-5662
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5663
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The generic message handler**'
  id: totrans-5664
  prefs: []
  type: TYPE_NORMAL
- en: You may have read or even written examples of actors that have generic case
    `_ =>` handlers in the message loop for debugging purposes. The message loop takes
    a partial function as an argument. Therefore, no error or exception is thrown
    if the message type is not recognized. There is no need for such a handler apart
    from the one for debugging purposes. Message types should inherit from a sealed
    abstract class or a sealed trait in order to prevent a new message type from being
    added by mistake.
  id: totrans-5665
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the `transform` method. Its main purpose is to instantiate,
    launch, and return an array of futures responsible for the transformation of the
    partitions, as shown in the following code:'
  id: totrans-5666
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE457]'
  id: totrans-5667
  prefs: []
  type: TYPE_PRE
  zh: '[PRE457]'
- en: 'An array of `futures` (one future per partition) is created (line `31`). The
    `transform` method invokes the partitioning method `partition` (line `32`) and
    then initializes the future with the `fct` partial function (line `33`):'
  id: totrans-5668
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE458]'
  id: totrans-5669
  prefs: []
  type: TYPE_PRE
  zh: '[PRE458]'
- en: 'The `compute` method invokes a user-defined `reduce` function on the futures.
    The execution of the Actor is blocked until the `Await` class'' `scala.concurrent.Await.result`
    method (line `34`) returns the result of each future computation. In the case
    of the discrete Fourier transform, the list of frequencies is transposed before
    the amplitude of each frequency is summed (line `35`), as follows:'
  id: totrans-5670
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE459]'
  id: totrans-5671
  prefs: []
  type: TYPE_PRE
  zh: '[PRE459]'
- en: 'The following sequential diagram illustrates the blocking design and the activities
    performed by the Actor and the futures:'
  id: totrans-5672
  prefs: []
  type: TYPE_NORMAL
- en: '![Blocking on futures](img/image01599.jpeg)'
  id: totrans-5673
  prefs: []
  type: TYPE_IMG
- en: The sequential diagram for actor blocking on future results
  id: totrans-5674
  prefs: []
  type: TYPE_NORMAL
- en: Handling future callbacks
  id: totrans-5675
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Callbacks are an excellent alternative to having the actor blocks on futures,
    as they can simultaneously execute other functions concurrently with the future
    execution.
  id: totrans-5676
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two simple ways to implement the callback function, as follows:'
  id: totrans-5677
  prefs: []
  type: TYPE_NORMAL
- en: '`Future.onComplete`'
  id: totrans-5678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Future.onSuccess` and `Future.onFailure`'
  id: totrans-5679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `onComplete` callback function takes a function of the `Try[T] => U` type
    as an argument with an implicit reference to the execution context, as shown in
    the following code:'
  id: totrans-5680
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE460]'
  id: totrans-5681
  prefs: []
  type: TYPE_PRE
  zh: '[PRE460]'
- en: You can surely recognize the `{Try, Success, Failure}` monad.
  id: totrans-5682
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative implementation is to invoke the `onSuccess` and `onFailure`
    methods that use partial functions as arguments to implement the callbacks, as
    follows:'
  id: totrans-5683
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE461]'
  id: totrans-5684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE461]'
- en: 'The only difference between blocking one future data transformation and handling
    callbacks is the implementation of the `compute` method or reducer. The class
    definition, message handler, and initialization of futures are identical, as shown
    in the following code:'
  id: totrans-5685
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE462]'
  id: totrans-5686
  prefs: []
  type: TYPE_PRE
  zh: '[PRE462]'
- en: 'Each future calls the master actor back with either the result of the data
    transformation, the `onSuccess` message (line `36`), or an exception, the `OnFailure`
    message (line `37`). If every future succeeds, the values of all frequencies for
    all the partitions are summed (line `38`). The following sequential diagram illustrates
    the handling of the callback in the master actor:'
  id: totrans-5687
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling future callbacks](img/image01600.jpeg)'
  id: totrans-5688
  prefs: []
  type: TYPE_IMG
- en: A sequential diagram for actor handling future result with callbacks
  id: totrans-5689
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5690
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The execution context**'
  id: totrans-5691
  prefs: []
  type: TYPE_NORMAL
- en: 'The application of futures requires that the execution context is implicitly
    provided by the developer. There are three different ways to define the execution
    context:'
  id: totrans-5692
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the context: `import ExecutionContext.Implicits.global`'
  id: totrans-5693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Create an instance of the context within the actor (or actor context): `implicit
    val ec = ExecutionContext.fromExecutorService( … )`'
  id: totrans-5694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Define the context when instantiating the future: `val f= Future[T] ={ } (ec)`'
  id: totrans-5695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Putting it all together
  id: totrans-5696
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s reuse the discrete Fourier transform. The client code uses the same
    synthetically created time series as in the master-worker test model. The first
    step is to create a transform future for the discrete Fourier transform, `DFTTransformFuture`,
    as follows:'
  id: totrans-5697
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE463]'
  id: totrans-5698
  prefs: []
  type: TYPE_PRE
  zh: '[PRE463]'
- en: 'The only purpose of the `DFTTransformFuture` class is to define the `reduce`
    aggregation method for the discrete Fourier transform. Let''s reuse the same test
    case as in the *Distributed discrete Fourier transform* section under *Master-workers*:'
  id: totrans-5699
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE464]'
  id: totrans-5700
  prefs: []
  type: TYPE_PRE
  zh: '[PRE464]'
- en: The master actor is initialized as of the `TransformFutures` type with the input
    time series `xt`, the discrete Fourier transform `DFT`, and the number of workers
    or partitions `nPartitions` as arguments (line `39`). The program creates a future
    instance by sending (`ask`) the `Start` message to the master (line `40`). The
    program blocks until the completion of the future (line `41`), and then shuts
    down the Akka actor system (line `42`).
  id: totrans-5701
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark
  id: totrans-5702
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Apache Spark is a fast and general-purpose cluster computing system, initially
    developed as AMPLab/UC Berkeley as part of the **Berkeley Data Analytics Stack**
    (**BDAS**) ([http://en.wikipedia.org/wiki/UC_Berkeley](http://en.wikipedia.org/wiki/UC_Berkeley)).
    It provides high-level APIs for the following programming languages that make
    large and concurrent parallel jobs easy to write and deploy [12:11]:'
  id: totrans-5703
  prefs: []
  type: TYPE_NORMAL
- en: '**Scala**: [http://spark.apache.org/docs/latest/api/scala/index.html](http://spark.apache.org/docs/latest/api/scala/index.html)'
  id: totrans-5704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Java**: [http://spark.apache.org/docs/latest/api/java/index.html](http://spark.apache.org/docs/latest/api/java/index.html)'
  id: totrans-5705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Python**: [http://spark.apache.org/docs/latest/api/python/index.html](http://spark.apache.org/docs/latest/api/python/index.html)'
  id: totrans-5706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5707
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The link to the latest information**'
  id: totrans-5708
  prefs: []
  type: TYPE_NORMAL
- en: The URLs as any reference to Apache Spark may change in future versions.
  id: totrans-5709
  prefs: []
  type: TYPE_NORMAL
- en: The core element of Spark is a **resilient distributed dataset** (**RDD**),
    which is a collection of elements partitioned across the nodes of a cluster and/or
    CPU cores of servers. An RDD can be created from a local data structure such as
    a list, array, or hash table, from the local filesystem or the **Hadoop distributed
    file system** (**HDFS**).
  id: totrans-5710
  prefs: []
  type: TYPE_NORMAL
- en: 'The operations on an RDD in Spark are very similar to the Scala higher-order
    methods. These operations are performed concurrently over each partition. Operations
    on RDDs can be classified as follows:'
  id: totrans-5711
  prefs: []
  type: TYPE_NORMAL
- en: '**Transformation**: This operation converts, manipulates, and filters the elements
    of an RDD on each partition'
  id: totrans-5712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Action**: This operation aggregates, collects, or reduces the elements of
    the RDD from all partitions'
  id: totrans-5713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An RDD can be persisted, serialized, and cached for future computation.
  id: totrans-5714
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark is written in Scala and built on top of Akka libraries. Spark relies
    on the following mechanisms to distribute and partition RDDs:'
  id: totrans-5715
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop/HDFS for the distributed and replicated filesystem
  id: totrans-5716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mesos or Yarn for the management of a cluster and shared pool of data nodes
  id: totrans-5717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Spark ecosystem can be represented as stacks of technology and framework,
    as seen in the following diagram:'
  id: totrans-5718
  prefs: []
  type: TYPE_NORMAL
- en: '![Apache Spark](img/image01601.jpeg)'
  id: totrans-5719
  prefs: []
  type: TYPE_IMG
- en: The Apache Spark framework ecosystem
  id: totrans-5720
  prefs: []
  type: TYPE_NORMAL
- en: The Spark ecosystem has grown to support some machine learning algorithms out
    of the box, such as **MLlib**, a SQL-like interface to manipulate datasets with
    relational operators, **SparkSQL**, a library for distributed graphs, **GraphX**,
    and a streaming library [12:12].
  id: totrans-5721
  prefs: []
  type: TYPE_NORMAL
- en: Why Spark?
  id: totrans-5722
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authors of Spark attempt to address the limitations of Hadoop in terms of
    performance and real-time processing by implementing in-memory iterative computing,
    which is critical to most discriminative machine learning algorithms. Numerous
    benchmark tests have been performed and published to evaluate the performance
    improvement of Spark relative to Hadoop. In the case of iterative algorithms,
    the time per iteration can be reduced by a ratio of 1:10 or more.
  id: totrans-5723
  prefs: []
  type: TYPE_NORMAL
- en: Spark provides a large array of prebuilt transforms and actions that go well
    beyond the basic map-reduce paradigm. These methods on RDDs are a natural extension
    of the Scala collections, making code migration seamless for Scala developers.
  id: totrans-5724
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Apache Spark supports fault-tolerant operations by allowing RDDs to
    persist both in memory and in the filesystem. Persistency enables automatic recovery
    from node failures. The resiliency of Spark relies on the supervisory strategy
    of the underlying Akka actors, the persistency of their mailboxes, and the replication
    schemes of the HDFS.
  id: totrans-5725
  prefs: []
  type: TYPE_NORMAL
- en: Design principles
  id: totrans-5726
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The performance of Spark relies on the following five core design principles
    [12:13]:'
  id: totrans-5727
  prefs: []
  type: TYPE_NORMAL
- en: In-memory persistency
  id: totrans-5728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laziness in scheduling tasks
  id: totrans-5729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform and actions applied to RDDs
  id: totrans-5730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of shared variables
  id: totrans-5731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for data frames (SQL-aware RDDS)
  id: totrans-5732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-memory persistency
  id: totrans-5733
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The developer can decide to persist and/or cache an RDD for future usage. An
    RDD may persist in memory only or on disk only—in memory if available, or on disk
    otherwise as deserialized or serialized Java objects. For instance, an RDD, `rdd`,
    can be cached through serialization through a simple statement, as shown in the
    following code:'
  id: totrans-5734
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE465]'
  id: totrans-5735
  prefs: []
  type: TYPE_PRE
  zh: '[PRE465]'
- en: Note
  id: totrans-5736
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Kryo serialization**'
  id: totrans-5737
  prefs: []
  type: TYPE_NORMAL
- en: Java serialization through the `Serializable` interface is notoriously slow.
    Fortunately, the Spark framework allows the developer to specify a more efficient
    serialization mechanism such as the Kryo library.
  id: totrans-5738
  prefs: []
  type: TYPE_NORMAL
- en: Laziness
  id: totrans-5739
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Scala supports lazy values natively. The left-hand side of the assignment,
    which can either be a value, object reference, or method, is performed once, that
    is, the first time it is invoked, as shown in the following code:'
  id: totrans-5740
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE466]'
  id: totrans-5741
  prefs: []
  type: TYPE_PRE
  zh: '[PRE466]'
- en: The order of the variables printed is `n`, `m`, and then `x`. The instantiation
    of the `Pipeline` class initializes `n` but not `m` or `x` (line `1`). At a later
    stage, the `g` method is called, which in turn invokes the `f` method. The `f`
    method initializes the `m` value it needs, and then `g` initializes `x` to compute
    its power to `m <<1` (line `2`).
  id: totrans-5742
  prefs: []
  type: TYPE_NORMAL
- en: Spark applies the same principle to RDDs by executing the transformation only
    when an action is performed. In other words, Spark postpones memory allocation,
    parallelization, and computation until the driver code gets the result through
    the execution of an action. The cascading effect of invoking all these transformations
    backward is performed by the direct acyclic graph scheduler.
  id: totrans-5743
  prefs: []
  type: TYPE_NORMAL
- en: Transforms and actions
  id: totrans-5744
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Spark is implemented in Scala, so you should not be too surprised to know that
    the most relevant Scala higher methods on collections are supported in Spark.
    The first table describes the transformation methods using Spark, as well as their
    counterparts in the Scala standard library. We use the (K, V) notation for (key,
    value) pairs:'
  id: totrans-5745
  prefs: []
  type: TYPE_NORMAL
- en: '| Spark | Scala | Description |'
  id: totrans-5746
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-5747
  prefs: []
  type: TYPE_TB
- en: '| `map(f)` | `map(f)` | This transforms an RDD by executing the `f` function
    on each element of the collection |'
  id: totrans-5748
  prefs: []
  type: TYPE_TB
- en: '| `filter(f)` | `filter(f)` | This transforms an RDD by selecting the element
    for which the `f` function returns `true` |'
  id: totrans-5749
  prefs: []
  type: TYPE_TB
- en: '| `flatMap(f)` | `flatMap(f)` | This transforms an RDD by mapping each element
    to a sequence of output items |'
  id: totrans-5750
  prefs: []
  type: TYPE_TB
- en: '| `mapPartitions(f)` |   | This executes the `map` method separately on each
    partition |'
  id: totrans-5751
  prefs: []
  type: TYPE_TB
- en: '| `sample` |   | This samples a fraction of the data with or without a replacement
    using a random generator |'
  id: totrans-5752
  prefs: []
  type: TYPE_TB
- en: '| `groupByKey` | `groupBy` | This is called on *(K,V)* to generate a new *(K,
    Seq(V))* RDD |'
  id: totrans-5753
  prefs: []
  type: TYPE_TB
- en: '| `union` | `union` | This creates a new RDD as an union of this RDD and the
    argument |'
  id: totrans-5754
  prefs: []
  type: TYPE_TB
- en: '| `distinct` | `distinct` | This eliminates duplicate elements from this RDD
    |'
  id: totrans-5755
  prefs: []
  type: TYPE_TB
- en: '| `reduceByKey(f)` | `reduce` | This aggregates or reduces the value corresponding
    to each key using the `f` function |'
  id: totrans-5756
  prefs: []
  type: TYPE_TB
- en: '| `sortByKey` | `sortWith` | This reorganizes *(K,V)* in an RDD by ascending,
    descending, or otherwise specified order of the keys, *K* |'
  id: totrans-5757
  prefs: []
  type: TYPE_TB
- en: '| `join` |   | This joins an RDD *(K,V)* with an RDD *(K,W)* to generate a
    new RDD *(K, (V,W))* |'
  id: totrans-5758
  prefs: []
  type: TYPE_TB
- en: '| `coGroup` |   | This implements a join operation but generates an RDD *(K,
    Seq(V), Seq(W))* |'
  id: totrans-5759
  prefs: []
  type: TYPE_TB
- en: 'Action methods trigger the collection or the reduction of the datasets from
    all partitions back to the driver, as listed here:'
  id: totrans-5760
  prefs: []
  type: TYPE_NORMAL
- en: '| Spark | Scala | Description |'
  id: totrans-5761
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-5762
  prefs: []
  type: TYPE_TB
- en: '| `reduce(f)` | `reduce(f)` | This aggregates all the elements of the RDD across
    all the partitions and returns a Scala object to the driver |'
  id: totrans-5763
  prefs: []
  type: TYPE_TB
- en: '| `collect` | `collect` | This collects and returns all the elements of the
    RDD across all the partitions as a list in the driver |'
  id: totrans-5764
  prefs: []
  type: TYPE_TB
- en: '| `count` | `count` | This returns the number of elements in the RDD to the
    driver |'
  id: totrans-5765
  prefs: []
  type: TYPE_TB
- en: '| `first` | `head` | This returns the first element of the RDD to the driver
    |'
  id: totrans-5766
  prefs: []
  type: TYPE_TB
- en: '| `take(n)` | `take(n)` | This returns the first `n` elements of the RDD to
    the driver |'
  id: totrans-5767
  prefs: []
  type: TYPE_TB
- en: '| `takeSample` |   | This returns an array of random elements from the RDD
    back to the driver |'
  id: totrans-5768
  prefs: []
  type: TYPE_TB
- en: '| `saveAsTextFile` |   | This writes the elements of the RDD as a text file
    in either the local filesystem or HDFS |'
  id: totrans-5769
  prefs: []
  type: TYPE_TB
- en: '| `countByKey` |   | This generates an *(K, Int)* RDD with the original keys,
    *K*, and the count of values for each key |'
  id: totrans-5770
  prefs: []
  type: TYPE_TB
- en: '| `foreach` | `foreach` | This executes a `T=> Unit` function on each elements
    of the RDD |'
  id: totrans-5771
  prefs: []
  type: TYPE_TB
- en: Scala methods such as `fold`, `find`, `drop`, `flatten`, `min`, `max`, and `sum`
    are not currently implemented in Spark. Other Scala methods such as `zip` have
    to be used carefully, as there is no guarantee that the order of the two collections
    in `zip` is maintained between partitions.
  id: totrans-5772
  prefs: []
  type: TYPE_NORMAL
- en: Shared variables
  id: totrans-5773
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a perfect world, variables are immutable and local to each partition to
    avoid race conditions. However, there are circumstances where variables have to
    be shared without breaking the immutability provided by Spark. To this extent,
    Spark duplicates shared variables and copies them to each partition of the dataset.
    Spark supports the following types of shared variables:'
  id: totrans-5774
  prefs: []
  type: TYPE_NORMAL
- en: '**Broadcast values**: These values encapsulate and forward data to all the
    partitions'
  id: totrans-5775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accumulator variables**: These variables act as summations or reference counters'
  id: totrans-5776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The four design principles can be summarized in the following diagram:'
  id: totrans-5777
  prefs: []
  type: TYPE_NORMAL
- en: '![Shared variables](img/image01602.jpeg)'
  id: totrans-5778
  prefs: []
  type: TYPE_IMG
- en: An interaction between the Spark driver and RDDs
  id: totrans-5779
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding diagram illustrates the most common interaction between the Spark
    driver and its workers, as listed in the following steps:'
  id: totrans-5780
  prefs: []
  type: TYPE_NORMAL
- en: The input data, residing in either the memory as a Scala collection or HDFS
    as a text file, is parallelized and partitioned into an RDD.
  id: totrans-5781
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A transformation function is applied to each element of the dataset across all
    the partitions.
  id: totrans-5782
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An action is performed to reduce and collect the data back to the driver.
  id: totrans-5783
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data is processed locally within the driver.
  id: totrans-5784
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A second parallelization is performed to distribute computation through the
    RDDs.
  id: totrans-5785
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A variable is broadcast to all the partitions as an external parameter of the
    last RDD transformation.
  id: totrans-5786
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the last action aggregates and collects the final result back in the
    driver.
  id: totrans-5787
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you take a look at it closely, the management of datasets and RDDs by the
    Spark driver is not very different from that by the Akka master and worker actors
    of futures.
  id: totrans-5788
  prefs: []
  type: TYPE_NORMAL
- en: Experimenting with Spark
  id: totrans-5789
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Spark's in-memory computation for iterative computing makes it an excellent
    candidate to distribute the training of machine learning models, implemented with
    dynamic programming or optimization algorithms. Spark runs on Windows, Linux,
    and Mac OS operating systems. It can be deployed either in local mode for a single
    host or master mode for a distributed environment. The version of the Spark framework
    used is 1.3.
  id: totrans-5790
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5791
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**JVM and Scala compatible versions**'
  id: totrans-5792
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, the version of Spark 1.3.0 required Java 1.7 or higher
    and Scala 2.10.2 or higher. Spark 1.5.0 supports Scala 2.11 but requires the framework
    to be reassembled with the flag D-scala2.11.
  id: totrans-5793
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Spark
  id: totrans-5794
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The easiest way to learn Spark is to deploy a localhost in standalone mode.
    You can either deploy a precompiled version of Spark from the website, or build
    the JAR files using the **simple build tool** (**sbt**) or Maven [12:14] as follows:'
  id: totrans-5795
  prefs: []
  type: TYPE_NORMAL
- en: Go to the download page at [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  id: totrans-5796
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a package type (Hadoop distribution). The Spark framework relies on the
    HDFS to run in cluster mode; therefore, you need to select a distribution of Hadoop
    or an open source distribution such as MapR or Cloudera.
  id: totrans-5797
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download and decompress the package.
  id: totrans-5798
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are interested in the latest functionality added to the framework, check
    out the newest source code at [http://github.com/apache/spark.git](http://github.com/apache/spark.git).
  id: totrans-5799
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you need to build, or assemble, the Apache Spark libraries from the top-level
    directory using either Maven or sbt:'
  id: totrans-5800
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Maven**: Set the following Maven options to support build, deployment, and
    execution:'
  id: totrans-5801
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE467]'
  id: totrans-5802
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE467]'
- en: 'The following are some examples:'
  id: totrans-5803
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Building on Hadoop 2.4 using Yarn clusters manager and Scala 2.10 (default):'
  id: totrans-5804
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE468]'
  id: totrans-5805
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE468]'
- en: 'Building on Hadoop 2.6 using Yarn clusters manager and Scala 2.11:'
  id: totrans-5806
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE469]'
  id: totrans-5807
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE469]'
- en: '**A simple build tool**: Use the following command:'
  id: totrans-5808
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE470]'
  id: totrans-5809
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE470]'
- en: 'The following are some examples:'
  id: totrans-5810
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Building on Hadoop 2.4 using Yarn clusters manager and Scala 2.10 (default):'
  id: totrans-5811
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE471]'
  id: totrans-5812
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE471]'
- en: 'Building on Hadoop 2.6 using Yarn clusters manager and Scala 2.11:'
  id: totrans-5813
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE472]'
  id: totrans-5814
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE472]'
- en: Note
  id: totrans-5815
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Installation instructions**'
  id: totrans-5816
  prefs: []
  type: TYPE_NORMAL
- en: The directory and name of artifacts used in Spark will undoubtedly change over
    time. You can refer to the documentation and installation guide for the latest
    version of Spark.
  id: totrans-5817
  prefs: []
  type: TYPE_NORMAL
- en: 'Apache supports multiple deployment modes:'
  id: totrans-5818
  prefs: []
  type: TYPE_NORMAL
- en: '**Standalone mode**: The drivers and executors run as master and slave Akka
    actors, bundled with the default spark distribution JAR file.'
  id: totrans-5819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Local mode**: This is a standalone mode running on a single host. The slave
    actors are deployed across multiple cores within the same host.'
  id: totrans-5820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Yarn clusters manager**: Spark relies on the Yarn resource manager running
    on Hadoop version 2 and higher. The Spark driver can run either on the same JVM
    as the client application (client mode) or on the same JVM as the master (cluster
    mode).'
  id: totrans-5821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Mesos resource manager**: This deployment allows dynamic and scalable
    partitioning. Apache Mesos is an open source and general-purpose cluster manager
    that has to be installed separately (refer to [http://mesos.apache.org/](http://mesos.apache.org/)).
    Mesos manages abstracted the hardware artifacts such as memory or storage.'
  id: totrans-5822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The communication between a master node (or driver), cluster manager, and set
    of slave (or worker) nodes is illustrated in the following diagram:'
  id: totrans-5823
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Spark](img/image01603.jpeg)'
  id: totrans-5824
  prefs: []
  type: TYPE_IMG
- en: The communication between a master, slave nodes, and a cluster manager
  id: totrans-5825
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5826
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Installation under Windows**'
  id: totrans-5827
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop relies on some UNIX/Linux utilities that need to be added to the development
    environment when running on Windows. The `winutils.exe` file has to be installed
    and added to the `HADOOP_PATH` environment variable.
  id: totrans-5828
  prefs: []
  type: TYPE_NORMAL
- en: Using Spark shell
  id: totrans-5829
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Use any of the following methods to use the Spark shell:'
  id: totrans-5830
  prefs: []
  type: TYPE_NORMAL
- en: The shell is an easy way to get your feet wet with Spark-resilient distributed
    datasets. To launch the shell locally, execute `./bin/spark-shell –master local[8]`
    to execute the shell on an 8-core localhost.
  id: totrans-5831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To launch a Spark application locally, connect to the shell and execute the
    following command line:'
  id: totrans-5832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE473]'
  id: totrans-5833
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE473]'
- en: The command launches the application, `myApplication`, with the `myApp.main`
    main method on a 4-core CPU localhost and 12 GB of memory.
  id: totrans-5834
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To launch the same Spark application remotely, connect to the shell execute
    the following command line:'
  id: totrans-5835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE474]'
  id: totrans-5836
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE474]'
- en: 'The output will be as follows:'
  id: totrans-5837
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Spark shell](img/image01604.jpeg)'
  id: totrans-5838
  prefs: []
  type: TYPE_IMG
- en: A partial screenshot of the Spark shell command line output
  id: totrans-5839
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5840
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Potential pitfalls with the Spark shell**'
  id: totrans-5841
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your environment, you might need to disable logging information
    into the console by reconfiguring `conf/ log4j.properties`. The Spark shell might
    also conflict with the declaration of classpath in the profile or the environment
    variables' list. In this case, it has to be replaced by `ADD_JARS` as an environment
    variable such as `ADD_JARS = path1/jar1, path2/jar2`.
  id: totrans-5842
  prefs: []
  type: TYPE_NORMAL
- en: MLlib
  id: totrans-5843
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MLlib is a scalable machine learning library built on top of Spark. As of version
    1.0, the library is a work in progress.
  id: totrans-5844
  prefs: []
  type: TYPE_NORMAL
- en: 'The main components of the library are as follows:'
  id: totrans-5845
  prefs: []
  type: TYPE_NORMAL
- en: Classification algorithms, including logistic regression, Naïve Bayes, and support
    vector machines
  id: totrans-5846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering limited to K-means in version 1.0
  id: totrans-5847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L1 and L1 regularization
  id: totrans-5848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization techniques such as gradient descent, logistic gradient and stochastic
    gradient descent, and L-BFGS
  id: totrans-5849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear algebra such as the singular value decomposition
  id: totrans-5850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data generator for K-means, logistic regression, and support vector machines
  id: totrans-5851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The machine learning bytecode is conveniently included in the Spark assembly
    JAR file built with the simple build tool.
  id: totrans-5852
  prefs: []
  type: TYPE_NORMAL
- en: RDD generation
  id: totrans-5853
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The transformation and actions are performed on RDDs. Therefore, the first
    step is to create a mechanism to facilitate the generation of RDDs from a time
    series. Let''s create an `RDDSource` singleton with a `convert` method that transforms
    a time series `xt` into an RDD, as shown here:'
  id: totrans-5854
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE475]'
  id: totrans-5855
  prefs: []
  type: TYPE_PRE
  zh: '[PRE475]'
- en: 'The last `rddConfig` argument of the `convert` method specifies the configuration
    for the RDD. In this example, the configuration of the RDD consists of enabling/disabling
    cache and selecting the persistency model, as follows:'
  id: totrans-5856
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE476]'
  id: totrans-5857
  prefs: []
  type: TYPE_PRE
  zh: '[PRE476]'
- en: It is fair to assume that `SparkContext` has already been implicitly defined
    in a manner quite similar to `ActorSystem` in the Akka framework.
  id: totrans-5858
  prefs: []
  type: TYPE_NORMAL
- en: 'The generation of the RDD is performed in the following steps:'
  id: totrans-5859
  prefs: []
  type: TYPE_NORMAL
- en: Create an RDD using the `parallelize` method of the context and convert it into
    a vector (`SparseVector` or `DenseVector`) (line `3`).
  id: totrans-5860
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify the persistency model or the storage level if the default level needs
    to be overridden for the RDD (line `3`).
  id: totrans-5861
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify whether the RDD has to persist in memory (line `5`).
  id: totrans-5862
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5863
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**An alternative for the creation of an RDD**'
  id: totrans-5864
  prefs: []
  type: TYPE_NORMAL
- en: An RDD can be generated from data loaded from either the local filesystem or
    HDFS using the `SparkContext.textFile` method that returns an RDD of a string.
  id: totrans-5865
  prefs: []
  type: TYPE_NORMAL
- en: Once the RDD is created, it can be used as an input for any algorithm defined
    as a sequence of transformation and actions. Let's experiment with the implementation
    of the K-means algorithm in Spark/MLlib.
  id: totrans-5866
  prefs: []
  type: TYPE_NORMAL
- en: K-means using Spark
  id: totrans-5867
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first step is to create a `SparkKMeansConfig` class to define the configuration
    of the Apache Spark K-means algorithm, as follows:'
  id: totrans-5868
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE477]'
  id: totrans-5869
  prefs: []
  type: TYPE_PRE
  zh: '[PRE477]'
- en: 'The minimum set of initialization parameters for MLlib K-means algorithm is
    as follows:'
  id: totrans-5870
  prefs: []
  type: TYPE_NORMAL
- en: The number of clusters, `K` (line `6`)
  id: totrans-5871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum number of iterations for the reconstruction of the total errors,
    `maxIters` (line `7`)
  id: totrans-5872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of training runs, `numRuns` (line `8`)
  id: totrans-5873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `SparkKMeans` class wraps the Spark `KMeans` into a data transformation
    of the `ITransform` type, as described in the *Monadic data transformation* section
    in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello World!"), *Hello World!*
    The class follows the design template for a classifier, as explained in the *Design
    template for immutable classifiers* section in the [Appendix A](part0229.xhtml#aid-6QCGQ2
    "Appendix A. Basic Concepts"), *Basic Concepts*:'
  id: totrans-5874
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE478]'
  id: totrans-5875
  prefs: []
  type: TYPE_PRE
  zh: '[PRE478]'
- en: 'The constructor takes three arguments: the Apache Spark `KMeans` configuration
    `kMeansConfig`, the RDD configuration `rddConfig`, and the `xt` input time series
    for clustering (line `9`). The return type of the `ITransform` trait''s partial
    function `|>` is defined as an `Int` (line `10`).'
  id: totrans-5876
  prefs: []
  type: TYPE_NORMAL
- en: 'The generation of `model` merely consists of converting the time series `xt`
    into an RDD using `rddConfig` and invoking MLlib `KMeans.run` (line `11`). Once
    it is created, the model of clusters (`KMeansModel`) is available for predicting
    a new observation, `x`, (line `12`), as follows:'
  id: totrans-5877
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE479]'
  id: totrans-5878
  prefs: []
  type: TYPE_PRE
  zh: '[PRE479]'
- en: The `|>` prediction method returns the index of the cluster of observations.
  id: totrans-5879
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s write a simple client program to exercise the `SparkKMeans`
    model using the volatility of the price of a stock and its daily trading volume.
    The objective is to extract clusters with features (volatility and volume), each
    cluster representing a specific behavior of the stock:'
  id: totrans-5880
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE480]'
  id: totrans-5881
  prefs: []
  type: TYPE_PRE
  zh: '[PRE480]'
- en: 'The first step is to define the minimum configuration for the `sc` context
    (line `13`) and initialize it (line `14`). The `vty` and `vol` volatility variables
    are used as features for K-means and extracted from a CSV file (line `15`):'
  id: totrans-5882
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE481]'
  id: totrans-5883
  prefs: []
  type: TYPE_PRE
  zh: '[PRE481]'
- en: The execution creates a configuration `config` for the K-means (line `16`) and
    another configuration for the Spark RDD, `rddConfig`, (line `17`). The `pfnSparkKMeans`
    partial function, which implements the K-means algorithm, is created with the
    K-means, RDD configurations, and the input data `vtyVol` (line `18`).
  id: totrans-5884
  prefs: []
  type: TYPE_NORMAL
- en: Performance evaluation
  id: totrans-5885
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's execute the normalization of the cross-validation groups on an 8-core
    CPU machine with 32 GB of RAM. The data is partitioned with a ratio of two partitions
    per CPU core.
  id: totrans-5886
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5887
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**A meaningful performance test**'
  id: totrans-5888
  prefs: []
  type: TYPE_NORMAL
- en: The scalability test should be performed with a large number of data points
    (normalized volatility, normalized volume), in excess of 1 million, in order to
    estimate the asymptotic time complexity.
  id: totrans-5889
  prefs: []
  type: TYPE_NORMAL
- en: Tuning parameters
  id: totrans-5890
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The performance of a Spark application depends greatly on the configuration
    parameters. Selecting the appropriate value for those configuration parameters
    in Spark can be overwhelming—there are 54 configuration parameters as of the last
    count. Fortunately, the majority of those parameters have relevant default values.
    However, there are few parameters that deserve your attention, including the following:'
  id: totrans-5891
  prefs: []
  type: TYPE_NORMAL
- en: The number of cores available to execute transformation and actions on RDDs
    (`config.cores.max`).
  id: totrans-5892
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory available for the execution of the transformation and actions (`spark.executor.memory`).
    Setting the value to 60 percent of the maximum JVM heap is a generally a good
    compromise.
  id: totrans-5893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of concurrent tasks to use across all the partitions for shuffle-related
    operations; they use a key such as `reduceByKey` (`spark.default.parallelism`).
    The recommended formula is *parallelism = total number of cores x 2*. The value
    of the parameter can be overridden with the `spark.reduceby.partitions` parameter
    for specific RDD reducers.
  id: totrans-5894
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A flag to compress a serialized RDD partition for `MEMORY_ONLY_SER` (`spark.rdd.compress`).
    The purpose is to reduce memory footprints at the cost of extra CPU cycles.
  id: totrans-5895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum size of messages containing the results of an action is sent to
    the `spark.akka.frameSize` driver. This value needs to be increased if a collection
    may potentially generate a large size array.
  id: totrans-5896
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A flag to compress large size broadcasted `spark.broadcast.compress` variables.
    It is usually recommended.
  id: totrans-5897
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tests
  id: totrans-5898
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The purpose of the test is to evaluate how the execution time is related to
    the size of the training set. The test executes K-means from the MLlib library
    on the volatility and trading session volume on the **Bank of America** (**BAC**)
    stock over the following periods: 3 months, 6 months, 12 months, 24 months, 48
    months, 60 months, 72 months, 96 months, and 120 months.'
  id: totrans-5899
  prefs: []
  type: TYPE_NORMAL
- en: 'The following configuration is used to perform the training of K-means: 10
    clusters, 30 maximum iterations, and 3 runs. The test is run on a single host
    with 8-CPU cores and 32 GB of RAM. The test was conducted with the following values
    of parameters:'
  id: totrans-5900
  prefs: []
  type: TYPE_NORMAL
- en: '`StorageLevel = MEMORY_ONLY`'
  id: totrans-5901
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spark.executor.memory = 12G`'
  id: totrans-5902
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spark.default.parallelism = 48`'
  id: totrans-5903
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spark.akka.frameSize = 20`'
  id: totrans-5904
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spark.broadcast.compress = true`'
  id: totrans-5905
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No serialization
  id: totrans-5906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first step after executing a test for a specific dataset is to log in to
    the Spark monitoring console at `http://host_name:4040/stages`:'
  id: totrans-5907
  prefs: []
  type: TYPE_NORMAL
- en: '![Tests](img/image01605.jpeg)'
  id: totrans-5908
  prefs: []
  type: TYPE_IMG
- en: The average duration of the K-means clustering versus size of trading data in
    months
  id: totrans-5909
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, each environment produces somewhat different performance results
    but confirms that the time complexity of the Spark K-means is a linear function
    of the training set.
  id: totrans-5910
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5911
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Performance evaluation in a distributed environment**'
  id: totrans-5912
  prefs: []
  type: TYPE_NORMAL
- en: A Spark deployment on multiple hosts will add latency to the overall execution
    time of the TCP communication. The latency is related to the collection of the
    results of the clustering back to the Spark driver, which is negligible and independent
    of the size of the training set.
  id: totrans-5913
  prefs: []
  type: TYPE_NORMAL
- en: Performance considerations
  id: totrans-5914
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This test barely scratches the surface of the capabilities of Apache Spark.
    The following are the lessons learned from personal experience in order to avoid
    the most common performance pitfalls when deploying Spark 1.3+:'
  id: totrans-5915
  prefs: []
  type: TYPE_NORMAL
- en: Get acquainted with the most common Spark configuration parameters regarding
    partitioning, storage level, and serialization.
  id: totrans-5916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid serializing complex or nested objects unless you use an effective Java
    serialization library such as Kryo.
  id: totrans-5917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look into defining your own partitioning function to reduce large key-value
    pair datasets. The convenience of `reduceByKey` has its price. The ratio of number
    of partitions to number of cores has an impact on the performance of a reducer
    using keys.
  id: totrans-5918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid unnecessary actions such as `collect`, `count`, or `lookup`. An action
    reduces the data residing in the RDD partitions, and then forwards it to the Spark
    driver. The Spark driver (or master) program runs on a single JVM with limited
    resources.
  id: totrans-5919
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rely on shared or broadcast variables whenever necessary. Broadcast variables,
    for instance, improve the performance of operations on multiple datasets with
    very different sizes. Let's consider the common case of joining two datasets of
    very different sizes. Broadcasting the smaller dataset to each partition of the
    RDD of the larger dataset is far more efficient than converting the smaller dataset
    into an RDD and executing a join operation between the two datasets.
  id: totrans-5920
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use an accumulator variable for summation as it is faster than using a reduce
    action on an RDD.
  id: totrans-5921
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pros and cons
  id: totrans-5922
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An increasing number of organizations are adopting Spark as their distributed
    data processing platform for real-time or pseudo real-time operations. There are
    several reasons for the fast adoption of Spark:'
  id: totrans-5923
  prefs: []
  type: TYPE_NORMAL
- en: It is supported by a large and dedicated community of developers [12:15]
  id: totrans-5924
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-memory persistency is ideal for iterative computation found in machine learning
    and statistical inference algorithms
  id: totrans-5925
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excellent performance and scalability that can be extended with the Streaming
    module
  id: totrans-5926
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Spark leverages Scala functional capabilities and a large number of open
    source Java libraries
  id: totrans-5927
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark can leverage the Mesos or Yarn cluster manager, which reduces the complexity
    of defining fault-tolerance and load balancing between worker nodes
  id: totrans-5928
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark needs to be integrated with commercial Hadoop vendors such as Cloudera
  id: totrans-5929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, no platform is perfect and Spark is no exception. The most common
    complaints or concerns regarding Spark are as follows:'
  id: totrans-5930
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Spark application can be intimidating for a developer with no prior
    knowledge of functional programming.
  id: totrans-5931
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The integration with the database has been somewhat lagging, relying heavily
    on Hive. The Spark development team has started to address these limitations with
    the introduction of SparkSQL and data frame RDDs.
  id: totrans-5932
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0xdata Sparkling Water
  id: totrans-5933
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Sparkling Water** is an initiative to integrate **0xdata H2O** with Spark
    and complement MLlib [12:16]. H2O from 0xdata is a very fast, open source, in-memory
    platform for machine learning for very large datasets ([http://0xdata.com/product/](http://0xdata.com/product/)).
    The framework is worth mentioning for the following reasons:'
  id: totrans-5934
  prefs: []
  type: TYPE_NORMAL
- en: It has a Scala API
  id: totrans-5935
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is fully dedicated to machine learning and predictive analytics
  id: totrans-5936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It leverages both the frame data representation of H2O and in-memory clustering
    of Spark
  id: totrans-5937
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O has an extensive implementation of the generalized linear model and gradient
    boosted classification, among other goodies. Its data representation consists
    of hierarchical **data frames**. A data frame is a container of vectors potentially
    shared with other frames. Each vector is composed of **data chunks**, which themselves
    are containers of **data elements** [12:17]. At the time of writing, Sparkling
    Water is in beta version.
  id: totrans-5938
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-5939
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This completes the introduction of the most common scalable frameworks built
    using Scala. It is quite challenging to describe frameworks, such as Akka and
    Spark, as well as new computing models such as Actors, futures, and RDDs, in a
    few pages. This chapter should be regarded as an invitation to further explore
    the capabilities of those frameworks in both a single host and a large deployment
    environment.
  id: totrans-5940
  prefs: []
  type: TYPE_NORMAL
- en: 'In this last chapter, we learned:'
  id: totrans-5941
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of asynchronous concurrency
  id: totrans-5942
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The essentials of the actor model and composing futures with blocking or callback
    modes
  id: totrans-5943
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to implement a simple Akka cluster to squeeze performance of distributed
    applications
  id: totrans-5944
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ease and blazing performance of Spark's resilient distributed datasets and
    the in-memory persistency approach
  id: totrans-5945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A. Basic Concepts
  id: totrans-5946
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning algorithms make significant use of linear algebra and optimization
    techniques. Describing the concept and the implementation of linear algebra, calculus,
    and optimization algorithms in detail would have added significant complexity
    to the book and distracted the reader from the essence of machine learning.
  id: totrans-5947
  prefs: []
  type: TYPE_NORMAL
- en: The appendix lists a basic set of elements of linear algebra and optimization
    mentioned throughout the book. It also summarizes the coding practices and acquaints
    the reader with basic knowledge of financial analysis.
  id: totrans-5948
  prefs: []
  type: TYPE_NORMAL
- en: Scala programming
  id: totrans-5949
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is a partial list of coding practices and design techniques used throughout
    the book.
  id: totrans-5950
  prefs: []
  type: TYPE_NORMAL
- en: List of libraries and tools
  id: totrans-5951
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The precompiled *Scala for Machine Learning* code is `ScalaMl-2.11-0.99.jar`
    located in the `$ROOT/project/target/scala-2.11` directory. Not all the libraries
    are needed for every chapter. The list is as follows:'
  id: totrans-5952
  prefs: []
  type: TYPE_NORMAL
- en: Java JDK 1.7 or 1.8 is required for all chapters
  id: totrans-5953
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scala 2.10.4 or higher is required for all chapters
  id: totrans-5954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scala IDE for Eclipse 4.0 or higher
  id: totrans-5955
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IntelliJ IDEA Scala plugin 13.0 or higher
  id: totrans-5956
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: sbt 0.13 or higher
  id: totrans-5957
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Commons Math 3.5+ is required for [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*, [Chapter 4](part0178.xhtml#aid-59O442
    "Chapter 4. Unsupervised Learning"), *Unsupervised Learning*, and [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*
  id: totrans-5958
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JFChart 1.0.7 is required for [Chapter 1](part0155.xhtml#aid-4JQ761 "Chapter 1. Getting
    Started"), *Getting Started*, [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*, [Chapter 5](part0182.xhtml#aid-5DI6C1 "Chapter 5. Naïve
    Bayes Classifiers"), *Naïve Bayes Classifiers*, and [Chapter 9](part0207.xhtml#aid-65D4E1
    "Chapter 9. Artificial Neural Networks"), *Artificial Neural Networks*
  id: totrans-5959
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iitb CRF 0.2 (including the LBGFS and Colt libraries) is required for [Chapter
    7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"), *Sequential
    Data Models*
  id: totrans-5960
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIBSVM 0.1.6 is required for [Chapter 8](part0200.xhtml#aid-5UNGG2 "Chapter 8. Kernel
    Models and Support Vector Machines"), *Kernel Models and Support Vector Machines*
  id: totrans-5961
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akka framework 2.2 or higher is required for [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*
  id: totrans-5962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Spark/MLlib 1.3 or higher is required for [Chapter 12](part0223.xhtml#aid-6KLDE1
    "Chapter 12. Scalable Frameworks"), *Scalable Frameworks*
  id: totrans-5963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Maven 3.3 or higher (required for Apache Spark 1.4 or higher)
  id: totrans-5964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-5965
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**A note for Spark developers**'
  id: totrans-5966
  prefs: []
  type: TYPE_NORMAL
- en: The Scala library and compiler JAR files bundled with the assembly JAR file
    for Apache Spark contain a version of the Scala standard library and compiler
    JAR file that may conflict with an existing Scala library (that is, Eclipse default
    ScalaIDE library).
  id: totrans-5967
  prefs: []
  type: TYPE_NORMAL
- en: 'The `lib` directory contains the following JAR files related to the third-party
    libraries or frameworks used in the book: colt, CRF, LBFGS and LIBSVM.'
  id: totrans-5968
  prefs: []
  type: TYPE_NORMAL
- en: Code snippets format
  id: totrans-5969
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the sake of readability of the implementation of algorithms, all nonessential
    code such as error checking, comments, exception, or import have been omitted.
    The following code elements are discarded in the code snippets presented in the
    book:'
  id: totrans-5970
  prefs: []
  type: TYPE_NORMAL
- en: 'Comments:'
  id: totrans-5971
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE482]'
  id: totrans-5972
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE482]'
- en: 'Validation of class parameters and method arguments:'
  id: totrans-5973
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE483]'
  id: totrans-5974
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE483]'
- en: 'Class qualifiers such as `final` and `private`:'
  id: totrans-5975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE484]'
  id: totrans-5976
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE484]'
- en: 'Method qualifiers and access control (`final`, `private`, and so on):'
  id: totrans-5977
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE485]'
  id: totrans-5978
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE485]'
- en: 'Serialization:'
  id: totrans-5979
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE486]'
  id: totrans-5980
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE486]'
- en: 'Validation of partial functions:'
  id: totrans-5981
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE487]'
  id: totrans-5982
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE487]'
- en: 'Validation of intermediate states:'
  id: totrans-5983
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE488]'
  id: totrans-5984
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE488]'
- en: 'Java style exceptions:'
  id: totrans-5985
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE489]'
  id: totrans-5986
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE489]'
- en: 'Scala style exceptions:'
  id: totrans-5987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE490]'
  id: totrans-5988
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE490]'
- en: 'Nonessential annotations:'
  id: totrans-5989
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE491]'
  id: totrans-5990
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE491]'
- en: 'Logging and debugging code:'
  id: totrans-5991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE492]'
  id: totrans-5992
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE492]'
- en: Auxiliary and nonessential methods
  id: totrans-5993
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices
  id: totrans-5994
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Encapsulation
  id: totrans-5995
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One important objective while creating an API is to reduce the access to support
    a helper class. There are two options to encapsulate helper classes, as follows:'
  id: totrans-5996
  prefs: []
  type: TYPE_NORMAL
- en: '**A package scope**: The supporting classes are first-level classes with protected
    access'
  id: totrans-5997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A class or object scope**: The supported classes are nested in the main class'
  id: totrans-5998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The algorithms presented in this book follow the first encapsulation pattern.
  id: totrans-5999
  prefs: []
  type: TYPE_NORMAL
- en: Class constructor template
  id: totrans-6000
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The constructors of a class are defined in the companion object using `apply`
    and the class has a package scope (`protected`):'
  id: totrans-6001
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE493]'
  id: totrans-6002
  prefs: []
  type: TYPE_PRE
  zh: '[PRE493]'
- en: 'For example, the `SVM` class that implements the support vector machine is
    defined as follows:'
  id: totrans-6003
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE494]'
  id: totrans-6004
  prefs: []
  type: TYPE_PRE
  zh: '[PRE494]'
- en: 'The `SVM` companion object is responsible for defining all the constructors
    (instance factories) relevant to the `SVM` protected class:'
  id: totrans-6005
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE495]'
  id: totrans-6006
  prefs: []
  type: TYPE_PRE
  zh: '[PRE495]'
- en: Companion objects versus case classes
  id: totrans-6007
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the preceding example, the constructors are explicitly defined in the companion
    object. Although the invocation of the constructor is very similar to the instantiation
    of case classes, there is a major difference; the Scala compiler generates several
    methods to manipulate an instance as regular data (equals, copy, hash, and so
    on).
  id: totrans-6008
  prefs: []
  type: TYPE_NORMAL
- en: Case classes should be reserved for single state data objects (no methods).
  id: totrans-6009
  prefs: []
  type: TYPE_NORMAL
- en: Enumerations versus case classes
  id: totrans-6010
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is quite common to read or hear discussions regarding the relative merit
    of enumerations and pattern matching with case classes in Scala [A:1]. As a very
    general guideline, enumeration values can be regarded as lightweight case classes
    or case classes can be considered as heavy weight enumeration values.
  id: totrans-6011
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take an example of a Scala enumeration that consists of evaluating the
    uniform distribution of the `scala.util.Random` library:'
  id: totrans-6012
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE496]'
  id: totrans-6013
  prefs: []
  type: TYPE_PRE
  zh: '[PRE496]'
- en: The pattern matching is very similar to the Java's `switch` statement.
  id: totrans-6014
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the following example of pattern matching using case classes
    that selects a mathematical formula according to the input:'
  id: totrans-6015
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE497]'
  id: totrans-6016
  prefs: []
  type: TYPE_PRE
  zh: '[PRE497]'
- en: The pattern matching is performed using the default equals method, whose byte
    code is automatically set for each case class. This approach is far more flexible
    than the simple enumeration at the cost of extra computation cycles.
  id: totrans-6017
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of using enumerations over case classes are as follows:'
  id: totrans-6018
  prefs: []
  type: TYPE_NORMAL
- en: Enumerations involve less code for a single attribute comparison
  id: totrans-6019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enumerations are more readable, especially for Java developers.
  id: totrans-6020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The advantages of using case classes are as follows:'
  id: totrans-6021
  prefs: []
  type: TYPE_NORMAL
- en: Case classes are data objects and support more attributes than enumeration IDs
  id: totrans-6022
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pattern matching is optimized for sealed classes as the Scala compiler is aware
    of the number of cases
  id: totrans-6023
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In short, you should use enumeration for single value constants and case classes
    to match data objects.
  id: totrans-6024
  prefs: []
  type: TYPE_NORMAL
- en: Overloading
  id: totrans-6025
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Contrary to C++, Scala does not actually overload operators. Here is the definition
    of the very few operators used in code snippets:'
  id: totrans-6026
  prefs: []
  type: TYPE_NORMAL
- en: '`+=`: This adds an element to a collection or container'
  id: totrans-6027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`+`: This sums two elements of the same type'
  id: totrans-6028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design template for immutable classifiers
  id: totrans-6029
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The machine learning algorithms described in this book uses the following design
    pattern and components:'
  id: totrans-6030
  prefs: []
  type: TYPE_NORMAL
- en: The set of configuration and tuning parameters for the classifier is defined
    in a class inheriting from `Config` (that is, `SVMConfig`).
  id: totrans-6031
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The classifier implements a monadic data transformation of the `ITransform`
    type for which the model is implicitly generated from a training set (that is,
    `SVM[T]`). The classifier requires at least three parameters, which are as follows:'
  id: totrans-6032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A configuration for the execution of the training and classification tasks
  id: totrans-6033
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An input dataset, `xt`, of the `Vector[T]` type
  id: totrans-6034
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A vector of labels or `expected` values
  id: totrans-6035
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A model of type inherited from `Model`. The constructor is responsible for creating
    the model through training (that is, `SVMModel`).
  id: totrans-6036
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following diagram:'
  id: totrans-6037
  prefs: []
  type: TYPE_NORMAL
- en: '![Design template for immutable classifiers](img/image01606.jpeg)'
  id: totrans-6038
  prefs: []
  type: TYPE_IMG
- en: A generic UML class diagram for classifiers
  id: totrans-6039
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the key components of the support vector machine package are the
    classifier SVMs:'
  id: totrans-6040
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE498]'
  id: totrans-6041
  prefs: []
  type: TYPE_PRE
  zh: '[PRE498]'
- en: The training set is created by combining or zipping the input dataset `xt` with
    the labels or expected values `expected`. Once trained and validated, the model
    is available for prediction or classification.
  id: totrans-6042
  prefs: []
  type: TYPE_NORMAL
- en: 'This design has the main advantage of reducing the life cycle of a classifier:
    a model is either defined, available for classification, or is not created.'
  id: totrans-6043
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration and model classes are implemented as follows:'
  id: totrans-6044
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE499]'
  id: totrans-6045
  prefs: []
  type: TYPE_PRE
  zh: '[PRE499]'
- en: Note
  id: totrans-6046
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Implementation considerations**'
  id: totrans-6047
  prefs: []
  type: TYPE_NORMAL
- en: The validation phase is omitted in most of the practical examples throughout
    the book for the sake of readability.
  id: totrans-6048
  prefs: []
  type: TYPE_NORMAL
- en: Utility classes
  id: totrans-6049
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data extraction
  id: totrans-6050
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A CSV file is the most common format used to store historical financial data.
    It is the default format used to import data throughout the book. The data source
    relies on a `DataSourceConfig` configuration class, as follows:'
  id: totrans-6051
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE500]'
  id: totrans-6052
  prefs: []
  type: TYPE_PRE
  zh: '[PRE500]'
- en: 'The parameters of the `DataSourceConfig` class are as follows:'
  id: totrans-6053
  prefs: []
  type: TYPE_NORMAL
- en: '`pathName`: This is the relative pathname of a data file to be loaded if the
    argument is a file or the directory containing multiple input data files. Most
    of files are CSV files.'
  id: totrans-6054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`normalize`: This is the flag that is used to specify whether the data has
    to be normalized over [0, 1].'
  id: totrans-6055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reverseOrder`: This is the flag that is used to specify whether the order
    of the data in the file has to be reversed (for example, a time series) if its
    value is `true`.'
  id: totrans-6056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`headerLines`: This specifies the number of lines for the column headers and
    comments.'
  id: totrans-6057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data source `DataSource` implements data transformation of the `ETransform`
    type using an explicit configuration `DataSourceConfig`, as described in the *Monadic
    data transformation* section in [Chapter 2](part0165.xhtml#aid-4TBCQ2 "Chapter 2. Hello
    World!"), *Hello World!*:'
  id: totrans-6058
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE501]'
  id: totrans-6059
  prefs: []
  type: TYPE_PRE
  zh: '[PRE501]'
- en: 'The `srcFilter` argument specifies the filter or condition of some of the row
    fields to skip the dataset (that is, missing data or incorrect format). Being
    an explicit data transformation, the constructor for the `DataSource` class has
    to initialize the `U` input type and the `V` output type of the `|>` extracting
    method. The method takes the extractor from a row of literal values to double
    floating point values:'
  id: totrans-6060
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE502]'
  id: totrans-6061
  prefs: []
  type: TYPE_PRE
  zh: '[PRE502]'
- en: The data is loaded from the file using the `load` helper method (line `1`).
    The data is normalized if required (line `2`) by converting each literal to a
    floating point value using an instance of the `MinMax` class (line `3`). Finally,
    the `MinMax` instance normalizes the sequence of floating point values (line `4`).
  id: totrans-6062
  prefs: []
  type: TYPE_NORMAL
- en: The `DataSource` class implements a significant set of methods that are documented
    in the source code available online.
  id: totrans-6063
  prefs: []
  type: TYPE_NORMAL
- en: Data sources
  id: totrans-6064
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The examples in the book rely on three different sources of financial data
    using the CSV format:'
  id: totrans-6065
  prefs: []
  type: TYPE_NORMAL
- en: '`YahooFinancials`: This is for Yahoo schema for the historical stock and ETF
    price'
  id: totrans-6066
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GoogleFinancials`: This is for Google schema for the historical stock and
    ETF price'
  id: totrans-6067
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Fundamentals`: This is for fundamental financial analysis ration (a CSV file)'
  id: totrans-6068
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s illustrate the extraction from a data source using `YahooFinancials`
    as an example:'
  id: totrans-6069
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE503]'
  id: totrans-6070
  prefs: []
  type: TYPE_PRE
  zh: '[PRE503]'
- en: 'Let''s take a look at an example of an application of a `DataSource` transformation:
    loading the historical stock data from the Yahoo finance site. The data is downloaded
    as a CSV formatted file. Each column is associated with an extractor function
    (line `5`):'
  id: totrans-6071
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE504]'
  id: totrans-6072
  prefs: []
  type: TYPE_PRE
  zh: '[PRE504]'
- en: The list of stocks for which the historical data has to be downloaded is defined
    as an array of symbols (line `6`). Each symbol is associated with a CSV file (that
    is, `CSCO => resources/CSCO.csv`) (line `7`). Finally, the `YahooFinancials` extractor
    for the `adjClose` price is invoked (line `8`).
  id: totrans-6073
  prefs: []
  type: TYPE_NORMAL
- en: 'The format for the financial data extracted from the Google financial pages
    are similar to the format used in the Yahoo finances pages:'
  id: totrans-6074
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE505]'
  id: totrans-6075
  prefs: []
  type: TYPE_PRE
  zh: '[PRE505]'
- en: The `YahooFinancials`, `YahooFinancials`, and `Fundamentals` classes implement
    a significant number of methods that are documented in the source code available
    online.
  id: totrans-6076
  prefs: []
  type: TYPE_NORMAL
- en: Extraction of documents
  id: totrans-6077
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `DocumentsSource` class is responsible for extracting the date, title,
    and content of a list of text documents or text files. The class does not support
    HTML documents. The `DocumentsSource` class implements a monadic data transformation
    of the `ETransform` type with an explicit configuration of the `SimpleDataFormat`
    type:'
  id: totrans-6078
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE506]'
  id: totrans-6079
  prefs: []
  type: TYPE_PRE
  zh: '[PRE506]'
- en: 'The `DocumentsSource` class takes two arguments: the format of the date associated
    with the document and the name of the path in which the documents are located
    (line `1`). Being an explicit data transformation, the constructor of the `DocumentsSource`
    class has to initialize the `U` input type (line `2`) as a date and convert it
    into a `Long` and `V` output type (line `3`) as a `Corpus` to extract the `|>`
    method.'
  id: totrans-6080
  prefs: []
  type: TYPE_NORMAL
- en: The `|>` extractor generates a corpus associated with a specific date and converts
    it into a `Long` type (line `4`). The `getAll` method does the heavy lifting to
    extract or sort documents (line `5`).
  id: totrans-6081
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of the `getAll` method as well as other methods of the `DocumentsSource`
    class are described in the documented source code available online.
  id: totrans-6082
  prefs: []
  type: TYPE_NORMAL
- en: DMatrix class
  id: totrans-6083
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some discriminative learning models require operations to be performed on rows
    and columns of a matrix. The `DMatrix` class facilitates the read and write operations
    on columns and rows:'
  id: totrans-6084
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE507]'
  id: totrans-6085
  prefs: []
  type: TYPE_PRE
  zh: '[PRE507]'
- en: The `apply` method returns an element of the matrix. The `row` method returns
    a row array, and the `col` method returns the indexed sequence of column elements.
    The `diagonal` method returns the indexed sequence of diagonal elements, and the
    `trace` method sums the diagonal elements.
  id: totrans-6086
  prefs: []
  type: TYPE_NORMAL
- en: The `DMatrix` class supports normalization of elements, rows, and columns; transposition;
    and updation of elements, columns and rows. The `DMatrix` class implements a significant
    number of methods that are documented in the source code available online.
  id: totrans-6087
  prefs: []
  type: TYPE_NORMAL
- en: Counter
  id: totrans-6088
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Counter` class implements a generic mutable counter for which the key
    is a parameterized type. The number of occurrences of a key is managed by a mutable
    hash map:'
  id: totrans-6089
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE508]'
  id: totrans-6090
  prefs: []
  type: TYPE_PRE
  zh: '[PRE508]'
- en: The `+=` operator updates the counter of the `t` key and returns itself. The
    `+` operator updates and then duplicates the updated counters. The `++` operator
    updates this counter with another counter. The `/` operator divides the count
    for each key by the counts of another counter.
  id: totrans-6091
  prefs: []
  type: TYPE_NORMAL
- en: The `Counter` class implements a significant set of methods that are documented
    in the source code available online.
  id: totrans-6092
  prefs: []
  type: TYPE_NORMAL
- en: Monitor
  id: totrans-6093
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Monitor` class has two purposes:'
  id: totrans-6094
  prefs: []
  type: TYPE_NORMAL
- en: It stores log information and error messages using the `show` and `error` methods
  id: totrans-6095
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It collects and displays variables related to the recursive or iterative execution
    of an algorithm
  id: totrans-6096
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data is collected at each iteration or recursion and then displayed as
    a time series with iterations as *x* axis values:'
  id: totrans-6097
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE509]'
  id: totrans-6098
  prefs: []
  type: TYPE_PRE
  zh: '[PRE509]'
- en: The `counters` method returns an array associated with a specific key. The `count`
    method updates the data associated with a key. The `display` method plots the
    time series. Finally, the `show` and `error` methods send information and error
    messages to the standard output.
  id: totrans-6099
  prefs: []
  type: TYPE_NORMAL
- en: The documented source code for the implementation of the `Monitor` class is
    available online.
  id: totrans-6100
  prefs: []
  type: TYPE_NORMAL
- en: Mathematics
  id: totrans-6101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section very briefly describes some of the mathematical concepts used in
    this book.
  id: totrans-6102
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebra
  id: totrans-6103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many algorithms used in machine learning such as minimization of a convex loss
    function, principal component analysis, or least squares regression invariably
    involves manipulation and transformation of matrices. There are many good books
    on the subject, from the inexpensive [A:2] to the sophisticated [A:3].
  id: totrans-6104
  prefs: []
  type: TYPE_NORMAL
- en: QR decomposition
  id: totrans-6105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The QR decomposition (or the QR factorization) is the decomposition of a matrix
    *A* into a product of an orthogonal matrix *Q* and upper triangular matrix *R*.
    So, *A=QR* and *Q^T* *Q=I* [A:4].
  id: totrans-6106
  prefs: []
  type: TYPE_NORMAL
- en: 'The decomposition is unique if *A* is a real, square, and invertible matrix.
    In the case of a rectangle matrix *A*, *m by n* with *m > n*, the decomposition
    is implemented as the dot product of two vector of matrices: *A = [Q[1], Q[2]].[R[1],
    R[2]]^T*, where *Q[1]* is an *m by n* matrix, *Q[2]* is an *m by n* matrix, *R[1]*
    is an *n by n* upper triangle matrix, and *R[2]* is an *m by n* null matrix.'
  id: totrans-6107
  prefs: []
  type: TYPE_NORMAL
- en: The QR decomposition is a reliable method used to solve a large system of linear
    equations for which the number of equations (rows) exceeds the number of variables
    (columns). Its asymptotic computational time complexity for a training set of
    *m* dimensions and *n* observations is *O(mn²-n³/3)*.
  id: totrans-6108
  prefs: []
  type: TYPE_NORMAL
- en: It is used to minimize the loss function for ordinary least squares regression
    (refer to the *Ordinary least squares regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*).
  id: totrans-6109
  prefs: []
  type: TYPE_NORMAL
- en: LU factorization
  id: totrans-6110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**LU factorization** is a technique used to solve a matrix equation *A.x =
    b*, where *A* is a nonsingular matrix and *x* and *b* are two vectors. The technique
    consists of decomposing the original matrix *A* as the product of a simple matrix
    *A= A[1]A[2]…A[n]*.'
  id: totrans-6111
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic LU factorization**: This defines *A* as the product of a lower unit
    triangular matrix *L* and an upper triangular matrix *U*. So, *A=LU*.'
  id: totrans-6112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**LU factorization with a pivot**: This defines *A* as the product of a permutation
    matrix *P*, a lower unit triangular matrix *L*, and an upper triangular matrix
    *U*. So, *A=PLU*.'
  id: totrans-6113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LDL decomposition
  id: totrans-6114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The** **LDL decomposition** for real matrices defines a real positive matrix
    *A* as the product of a lower unit triangular matrix *L*, a diagonal matrix *D*,
    and the transposed matrix of *L*, that is, *L^T*. So, *A=LDL^T*.'
  id: totrans-6115
  prefs: []
  type: TYPE_NORMAL
- en: Cholesky factorization
  id: totrans-6116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Cholesky** **factorization** (or the **Cholesky decomposition**) of real
    matrices is a special case of the LU factorization [A:4]. It decomposes a positive
    definite matrix *A* into a product of a lower triangular matrix *L* and its conjugate
    transpose *L^T*. So, *A=LL^T*.
  id: totrans-6117
  prefs: []
  type: TYPE_NORMAL
- en: The asymptotic computational time complexity for the Cholesky factorization
    is *O(mn²)*, where *m* is the number of features (model parameters) and *n* is
    the number of observations. The Cholesky factorization is used in linear least
    squares Kalman filter (refer to the *The recursive algorithm* section in [Chapter
    3](part0172.xhtml#aid-5410O2 "Chapter 3. Data Preprocessing"), *Data Preprocessing*)
    and nonlinear Quasi-Newton optimizer.
  id: totrans-6118
  prefs: []
  type: TYPE_NORMAL
- en: Singular Value Decomposition
  id: totrans-6119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **singular value decomposition** (**SVD**) of real matrices defines an *m
    by n* real matrix *A* as the product of an *m* real square unitary matrix *U*,
    an *m by n* rectangular diagonal matrix *Σ*, and the transpose matrix *V^T* of
    a real matrix. So, *A=UΣV^T*.
  id: totrans-6120
  prefs: []
  type: TYPE_NORMAL
- en: The columns of the *U* and *V* matrices are the orthogonal bases and the value
    of the diagonal matrix *Σ* is a singular value [A:4]. The asymptotic computational
    time complexity for the singular value decomposition for *n* observations and
    *m* features is *O(mn²-n³)*. The singular value decomposition is used to minimize
    the total least squares and solve homogeneous linear equations.
  id: totrans-6121
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvalue decomposition
  id: totrans-6122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Eigen decomposition of a real square matrix *A* is the canonical factorization,
    *A* *x = λx*.
  id: totrans-6123
  prefs: []
  type: TYPE_NORMAL
- en: '*λ* is the **eigenvalue** (scalar) corresponding to the vector *x*. The *n
    by n* matrix *A* is then defined as *A = QDQ^T*. *Q* is the square matrix that
    contains the eigenvectors and *D* is the diagonal matrix whose elements are the
    eigenvalues associated with the eigenvectors [A:5] and [A:6]. The Eigen decomposition
    is used in Principal Components Analysis (refer to the *Principal components analysis*
    section in [Chapter 4](part0178.xhtml#aid-59O442 "Chapter 4. Unsupervised Learning"),
    *Unsupervised Learning*).'
  id: totrans-6124
  prefs: []
  type: TYPE_NORMAL
- en: Algebraic and numerical libraries
  id: totrans-6125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are many more open source algebraic libraries available to developers
    as APIs besides Apache Commons Math, which is used in [Chapter 3](part0172.xhtml#aid-5410O2
    "Chapter 3. Data Preprocessing"), *Data Preprocessing*, [Chapter 5](part0182.xhtml#aid-5DI6C1
    "Chapter 5. Naïve Bayes Classifiers"), *Naïve Bayes Classifiers*, [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*,
    and Apache Spark/MLlib in [Chapter 12](part0223.xhtml#aid-6KLDE1 "Chapter 12. Scalable
    Frameworks"), *Scalable Frameworks*. They are as follows:'
  id: totrans-6126
  prefs: []
  type: TYPE_NORMAL
- en: '**jBlas 1.2.3** (Java) created by Mikio Braun under the BSD revised license.
    This library provides Java and Scala developers a high-level Java interface to
    **BLAS** and **LAPACK** ([https://github.com/mikiobraun/jblas](https://github.com/mikiobraun/jblas)).'
  id: totrans-6127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Colt 1.2.0** (Java) is a high-performance scientific library developed at
    CERN under the European Organization for Nuclear Research license ([http://acs.lbl.gov/ACSSoftware/colt/](http://acs.lbl.gov/ACSSoftware/colt/)).'
  id: totrans-6128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AlgeBird 2.10** (Scala) developed at Twitter under Apache Public License
    2.0\. It defines concepts of abstract linear algebra using monoid and monads.
    This library is an excellent example of high-level functional programming using
    Scala ([https://github.com/twitter/algebird](https://github.com/twitter/algebird)).'
  id: totrans-6129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breeze 0.8** (Scala) is a numerical processing library using Apache Public
    License 2.0 originally created by David Hall. It is a component of the ScalaNLP
    suite of machine learning and numerical computing libraries ([http://www.scalanlp.org/](http://www.scalanlp.org/)).'
  id: totrans-6130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Apache Spark/MLlib framework bundles jBlas, Colt, and Breeze. The Iitb framework
    for conditional random fields uses Colt linear algebra components.
  id: totrans-6131
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-6132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**An alternative to Java/Scala libraries**'
  id: totrans-6133
  prefs: []
  type: TYPE_NORMAL
- en: If your application or project needs a high-performance numerical processing
    tool under limited resources (CPU and RAM memory), then using a C/C++ compiled
    library is an excellent alternative if portability is not a constraint. The binary
    functions are accessed through the Java Native Interface (JNI).
  id: totrans-6134
  prefs: []
  type: TYPE_NORMAL
- en: First order predicate logic
  id: totrans-6135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Propositional logic** is the formulation of **axioms** or propositions. There
    are several formal representations of propositions:'
  id: totrans-6136
  prefs: []
  type: TYPE_NORMAL
- en: '**Noun-VERB-Adjective**: For example, *Variance of the stock price EXCEEDS
    0.76* or *Minimization of the loss function DOES NOT converge*'
  id: totrans-6137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Entity-value = Boolean**: For example, *Variance of the stock price GREATER+THAN
    0.76 = true* or *Minimization of the loss function converge = false*'
  id: totrans-6138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variable op value**: For example, *Variance_stock_price > 0.76* or *Minimization_loss_function
    != converge*'
  id: totrans-6139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Propositional logic is subject to the rules of Boolean calculus. Let''s consider
    three propositions: *P*, *Q*, and *R* and the three Boolean operators *NOT*, *AND*,
    and *OR*:'
  id: totrans-6140
  prefs: []
  type: TYPE_NORMAL
- en: '*NOT (NOT P) = P*'
  id: totrans-6141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P AND false = false*, *P AND true = P*, *P or false = P*, and *P or true =
    P*'
  id: totrans-6142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P AND Q = Q AND P* and *P OR Q = Q OR P*'
  id: totrans-6143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P AND (Q AND R) = (P AND Q) AND R*'
  id: totrans-6144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**First order predicate logic,** also known as **first order predicate calculus,**
    is the quantification of a propositional logic [A:7]. The most common formulations
    of the first order logic are as follows:'
  id: totrans-6145
  prefs: []
  type: TYPE_NORMAL
- en: Rules (for example, *IF P THEN action*)
  id: totrans-6146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existential operators
  id: totrans-6147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First order logic is used to describe the classifiers in the learning classifier
    systems (refer to the *XCS rules* section in [Chapter 11](part0220.xhtml#aid-6HPRO2
    "Chapter 11. Reinforcement Learning"), *Reinforcement Learning*).
  id: totrans-6148
  prefs: []
  type: TYPE_NORMAL
- en: Jacobian and Hessian matrices
  id: totrans-6149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s consider a function with *n* variables *x[i]* and *m* outputs *y[j]*
    such that *f: {x[i]} -> {y[j] =f[j](x)}*.'
  id: totrans-6150
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Jacobian matrix** [A:8] is the matrix of the first order partial derivatives
    of the output values of a continuous, differential function:'
  id: totrans-6151
  prefs: []
  type: TYPE_NORMAL
- en: '![Jacobian and Hessian matrices](img/image01607.jpeg)'
  id: totrans-6152
  prefs: []
  type: TYPE_IMG
- en: 'The **Hessian matrix** is the square matrix of the second order partial derivatives
    of a continuously, twice differentiable function:'
  id: totrans-6153
  prefs: []
  type: TYPE_NORMAL
- en: '![Jacobian and Hessian matrices](img/image01608.jpeg)'
  id: totrans-6154
  prefs: []
  type: TYPE_IMG
- en: 'An example is as follows:'
  id: totrans-6155
  prefs: []
  type: TYPE_NORMAL
- en: '![Jacobian and Hessian matrices](img/image01609.jpeg)'
  id: totrans-6156
  prefs: []
  type: TYPE_IMG
- en: Summary of optimization techniques
  id: totrans-6157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The same comments regarding linear algebra algorithms apply to optimization.
    Treating such techniques in depth would have rendered the book impractical. However,
    optimization is critical to the efficiency and, to a lesser extent, the accuracy
    of the machine learning algorithms. Some basic knowledge in this field goes a
    long way to build practical solutions for large datasets.
  id: totrans-6158
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent methods
  id: totrans-6159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Steepest descent
  id: totrans-6160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **steepest descent** (or gradient descent) method is one of the simplest
    techniques used to find a local minimum of any continuous, differentiable function
    *F* or the global minimum for any defined, differentiable, and convex function
    [A:9]. The value of a vector or data point *x[t+1]* at iteration *t+1* is computed
    from the previous value *x[t]* using the *gradient* *∇* *F* of function *F* and
    the slope *γ*:'
  id: totrans-6161
  prefs: []
  type: TYPE_NORMAL
- en: '![Steepest descent](img/image01610.jpeg)'
  id: totrans-6162
  prefs: []
  type: TYPE_IMG
- en: The steepest gradient algorithm is used to solve systems of nonlinear equations
    and minimization of the loss function in the logistic regression (refer to the
    *Numerical optimization* section in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression
    and Regularization"), *Regression and Regularization*), in support vector classifiers
    (refer to the *The nonseparable case – the soft margin* section in [Chapter 8](part0200.xhtml#aid-5UNGG2
    "Chapter 8. Kernel Models and Support Vector Machines"), *Kernel Models and Support
    Vector Machines*), and in multilayer perceptrons (refer to the *Training and classification*
    section in [Chapter 9](part0207.xhtml#aid-65D4E1 "Chapter 9. Artificial Neural
    Networks"), *Artificial Neural Networks*).
  id: totrans-6163
  prefs: []
  type: TYPE_NORMAL
- en: Conjugate gradient
  id: totrans-6164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **conjugate gradient** solves unconstrained optimization problems and systems
    of linear equations. It is an alternative to the LU factorization for positive,
    definite, and symmetric square matrices. The solution *x** of the equation *Ax
    = b* is expanded as the weighted summation of *n* basis orthogonal directions
    *p[i]* (or **conjugate directions**):'
  id: totrans-6165
  prefs: []
  type: TYPE_NORMAL
- en: '![Conjugate gradient](img/image01611.jpeg)'
  id: totrans-6166
  prefs: []
  type: TYPE_IMG
- en: The solution *x** is extracted by computing the *i^(th)* conjugate vector *p[i]*
    and then computing the coefficients *α[i]*.
  id: totrans-6167
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient descent
  id: totrans-6168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **stochastic gradient** method is a variant of the steepest descent that
    minimizes the convex function by defining the objective function *F* as the sum
    of differentiable, basis function *f[i]*:'
  id: totrans-6169
  prefs: []
  type: TYPE_NORMAL
- en: '![Stochastic gradient descent](img/image01612.jpeg)'
  id: totrans-6170
  prefs: []
  type: TYPE_IMG
- en: The solution *x[t+1]* at iteration *t+1* is computed from the value *x[t]* at
    iteration *t*, the step size (or the learning rate) *α*, and the sum of the gradient
    of the basis functions [A:10]. The stochastic gradient descent is usually faster
    than other gradient descents or quasi-Newton methods in converging toward a solution
    for convex functions. The stochastic gradient descent is used in logistic regression,
    support vector machines, and backpropagation neural networks.
  id: totrans-6171
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic gradient is particularly suitable for discriminative models with
    large datasets [A:11]. Spark/MLlib makes extensive use of the stochastic gradient
    method.
  id: totrans-6172
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-6173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The batch gradient descent**'
  id: totrans-6174
  prefs: []
  type: TYPE_NORMAL
- en: The batch gradient descent is introduced and implemented in the *Step 5 – implementing
    the classifier* section under *Let's kick the tires* in [Chapter 1](part0155.xhtml#aid-4JQ761
    "Chapter 1. Getting Started"), *Getting Started*.
  id: totrans-6175
  prefs: []
  type: TYPE_NORMAL
- en: Quasi-Newton algorithms
  id: totrans-6176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Quasi-Newton** algorithms are variations of Newton''s method of finding the
    value of a vector or data point that maximizes or minimizes a function *F* (first
    order derivative is null) [A:12].'
  id: totrans-6177
  prefs: []
  type: TYPE_NORMAL
- en: 'The Newton''s method is a well-known and simple optimization method used to
    find the solution of equations *F(x) = 0* for which *F* is continuous and second
    order differentiable. It relies on the Taylor series expansion to approximate
    the function *F* with a quadratic approximation of variable *∆x = x[t+1]-x[t]*
    to compute the value at the next iteration using the first order *F''* and second
    order *F"* derivatives:'
  id: totrans-6178
  prefs: []
  type: TYPE_NORMAL
- en: '![Quasi-Newton algorithms](img/image01613.jpeg)'
  id: totrans-6179
  prefs: []
  type: TYPE_IMG
- en: Contrary to Newton's method, quasi-Newton methods do not require that the second
    order derivative, Hessian matrix, of the objective function be computed; it just
    has to be approximated [A:13]. There are several approaches to approximate the
    computation of the Hessian matrix.
  id: totrans-6180
  prefs: []
  type: TYPE_NORMAL
- en: BFGS
  id: totrans-6181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **Broyden-Fletcher-Goldfarb-Shanno** (**BGFS**) is a quasi-Newton iterative
    numerical method used to solve unconstrained nonlinear problems. The hessian matrix
    *H[t+1]* at iteration *t* is approximated using the value of the previous iteration
    *t* as *H[t+1]=H[t] + U[t] + V[t]* applied to the Newton equation for the direction
    *p[t]*:'
  id: totrans-6182
  prefs: []
  type: TYPE_NORMAL
- en: '![BFGS](img/image01614.jpeg)'
  id: totrans-6183
  prefs: []
  type: TYPE_IMG
- en: The BFGS is used in the minimization of the cost function for the conditional
    random field and L[1] and L[2] regressions.
  id: totrans-6184
  prefs: []
  type: TYPE_NORMAL
- en: L-BFGS
  id: totrans-6185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The performance of the BFGS algorithm is related to the caching of the approximation
    of the Hessian matrix in the memory (*U*, *V*) at the cost of high-memory consumption.
  id: totrans-6186
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Limited memory Broyden-Fletcher-Goldfarb-Shanno** (**L-BFGS**) algorithm
    is a variant of BFGS that uses a minimum amount of computer RAM. The algorithm
    maintains the last *m* incremental updates of the values *∆x[t]* and gradient
    *∆G[t]* at iteration *t*, and then computes these values for the next step *t+1*:'
  id: totrans-6187
  prefs: []
  type: TYPE_NORMAL
- en: '![L-BFGS](img/image01615.jpeg)'
  id: totrans-6188
  prefs: []
  type: TYPE_IMG
- en: It is supported by the Apache Commons Math 3.3+, Apache Spark/MLlib 1.0+, Colt
    1.0+, and Iiitb CRF libraries. L-BFGS is used in the minimization of the loss
    function in conditional random fields (refer to the *Conditional random fields*
    section in [Chapter 7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"),
    *Sequential Data Models*).
  id: totrans-6189
  prefs: []
  type: TYPE_NORMAL
- en: Nonlinear least squares minimization
  id: totrans-6190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s consider the classic minimization of the least squares of a nonlinear
    function *y = F(x, w)* with *w[i]* parameters for observations *{y, x[i]}*. The
    objective is to minimize the sum of the squares of residuals *r[i]*, which is
    as follows:'
  id: totrans-6191
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonlinear least squares minimization](img/image01616.jpeg)'
  id: totrans-6192
  prefs: []
  type: TYPE_IMG
- en: Gauss-Newton
  id: totrans-6193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Gauss-Newton technique is a generalization of Newton''s method. The technique
    solves nonlinear least squares by updating the parameters *w[t+1]* at iteration
    *t+1* using the first order derivative (or Jacobian):'
  id: totrans-6194
  prefs: []
  type: TYPE_NORMAL
- en: '![Gauss-Newton](img/image01617.jpeg)'
  id: totrans-6195
  prefs: []
  type: TYPE_IMG
- en: The Gauss-Newton algorithm is used in logistic regression (refer to the *Logistic
    regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2 "Chapter 6. Regression
    and Regularization"), *Regression and Regularization*).
  id: totrans-6196
  prefs: []
  type: TYPE_NORMAL
- en: Levenberg-Marquardt
  id: totrans-6197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Levenberg-Marquardt algorithm is an alternative to the Gauss-Newton technique
    used to solve nonlinear least squares and curve fitting problems. The method consists
    of adding the gradient (Jacobian) terms to the residuals *r[i]* to approximate
    the least squares error:'
  id: totrans-6198
  prefs: []
  type: TYPE_NORMAL
- en: '![Levenberg-Marquardt](img/image01618.jpeg)'
  id: totrans-6199
  prefs: []
  type: TYPE_IMG
- en: The Levenberg-Marquardt algorithm is used in the training of logistic regression
    (refer to the *Logistic regression* section in [Chapter 6](part0188.xhtml#aid-5J99O2
    "Chapter 6. Regression and Regularization"), *Regression and Regularization*).
  id: totrans-6200
  prefs: []
  type: TYPE_NORMAL
- en: Lagrange multipliers
  id: totrans-6201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Lagrange multipliers** methodology is an optimization technique used to
    find the local optima of a multivariate function, subject to equality constraints
    [A:14]. The problem is stated as *maximize f(x) subject to g(x) = c, where c is
    a constant and x is a variable or features vector*.
  id: totrans-6202
  prefs: []
  type: TYPE_NORMAL
- en: 'This methodology introduces a new variable *λ* to integrate the constraint
    *g* into a function, known as the Lagrange function *ℒ* *(x, λ)*. Let''s note
    *∇ℒ*, which is the gradient of *ℒ* over the variables *x[i]* and *λ*. The Lagrange
    multipliers are computed by maximizing *ℒ*:'
  id: totrans-6203
  prefs: []
  type: TYPE_NORMAL
- en: '![Lagrange multipliers](img/image01619.jpeg)'
  id: totrans-6204
  prefs: []
  type: TYPE_IMG
- en: 'An example is as follows:'
  id: totrans-6205
  prefs: []
  type: TYPE_NORMAL
- en: '![Lagrange multipliers](img/image01620.jpeg)'
  id: totrans-6206
  prefs: []
  type: TYPE_IMG
- en: Lagrange multipliers are used to minimize the loss function in the nonseparable
    case of linear support vector machines (refer to the *The nonseparable case –
    the soft margin case* section in [Chapter 8](part0200.xhtml#aid-5UNGG2 "Chapter 8. Kernel
    Models and Support Vector Machines"), *Kernel Models and Support Vector Machines*).
  id: totrans-6207
  prefs: []
  type: TYPE_NORMAL
- en: Overview of dynamic programming
  id: totrans-6208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of **dynamic programming** is to break down an optimization problem
    into a sequence of steps known as **substructures** [A:15]. There are two types
    of problems for which dynamic programming is suitable.
  id: totrans-6209
  prefs: []
  type: TYPE_NORMAL
- en: The solution of a global optimization problem can be broken down into optimal
    solutions for its subproblems. The solution of the subproblems is known as **optimal
    substructures**. Greedy algorithms or the computation of the minimum span of a
    graph are examples of the decomposition into optimal substructures. Such algorithms
    can be implemented either recursively or iteratively.
  id: totrans-6210
  prefs: []
  type: TYPE_NORMAL
- en: The solution of the global problem is applied recursively to the subproblems
    if the number of subproblems is small. This approach is known as dynamic programming
    using **overlapping substructures**. Forward-backward passes on hidden Markov
    models, the Viterbi algorithm (refer to *The Viterbi algorithm* section in [Chapter
    7](part0193.xhtml#aid-5O1SI1 "Chapter 7. Sequential Data Models"), *Sequential
    Data Models*), or the backpropagation of error in a multilayer perceptron (refer
    to the *Step 2 – error backpropagation* section in [Chapter 9](part0207.xhtml#aid-65D4E1
    "Chapter 9. Artificial Neural Networks"), *Artificial Neural Networks*) are good
    examples of overlapping substructures.
  id: totrans-6211
  prefs: []
  type: TYPE_NORMAL
- en: The mathematical formulation of a dynamic programming solution is specific to
    the problem it attempts to resolve. Dynamic programming techniques are also commonly
    used in mathematical puzzles such as *The Tower of Hanoi*.
  id: totrans-6212
  prefs: []
  type: TYPE_NORMAL
- en: Finances 101
  id: totrans-6213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The exercises presented throughout this book are related to historical financial
    data and require the reader to have some basic understanding of financial markets
    and reports.
  id: totrans-6214
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental analysis
  id: totrans-6215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fundamental analysis is a set of techniques used to evaluate a security (stock,
    bond, currency, or commodity) that entails attempting to measure its intrinsic
    value by examining both macro and micro financial and economy reports. Fundamental
    analysis is usually applied to estimate the optimal price of a stock using a variety
    of financial ratios.
  id: totrans-6216
  prefs: []
  type: TYPE_NORMAL
- en: 'Numerous financial metrics are used throughout this book. Here are the definitions
    of the most commonly used metrics [A:16]:'
  id: totrans-6217
  prefs: []
  type: TYPE_NORMAL
- en: '**Earnings per share (EPS)**: This is the ratio of net earnings to the number
    of outstanding shares.'
  id: totrans-6218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price/earnings ratio (PE)**: This is the ratio of the market price per share
    to earnings per share.'
  id: totrans-6219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price/sales ratio (PS)**: This is the ratio of the market price per share
    to gross sales (or revenue).'
  id: totrans-6220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price/book value ratio (PB)**: This is the ratio of the market price per
    share to the total balance sheet value per share.'
  id: totrans-6221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price to earnings/growth (PEG)**: This is the ratio of price/earnings per
    share (PE) to the annual growth of earnings per share.'
  id: totrans-6222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operating income**: This is the difference between the operating revenue
    and operating expenses.'
  id: totrans-6223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Net sales**: This is the difference between the revenue or gross sales and
    cost of goods or cost of sales.'
  id: totrans-6224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operating profit margin**: This is the ratio of the operating income to the
    net sales.'
  id: totrans-6225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Net profit margin**: This is the ratio of the net profit to the net sales
    (or the net revenue).'
  id: totrans-6226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short interest**: This is the quantity of shares sold short and not yet covered.'
  id: totrans-6227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short interest ratio**: This is the ratio of the short interest to the total
    number of shares floated.'
  id: totrans-6228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cash per share**: This is the ratio of the value of cash per share to the
    market price per share.'
  id: totrans-6229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pay-out ratio**: This is the percentage of the primary/basic earnings per
    share, excluding extraordinary items paid to common stockholders in the form of
    cash dividends.'
  id: totrans-6230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Annual dividend yield**: This is the ratio of the sum of dividends paid during
    the previous 12-month rolling period over the current stock price. Regular and
    extra dividends are included.'
  id: totrans-6231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dividend coverage ratio**: This is the ratio of the income available to common
    stockholders, excluding extraordinary items, for the most recent trailing 12 months
    to gross dividends paid to common shareholders, expressed as percent.'
  id: totrans-6232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gross Domestic Product** (**GDP**): This is the aggregate measure of the
    economic output of a country. It actually measures the sum of values added by
    the production of goods and delivery of services.'
  id: totrans-6233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer Price Index** (**CPI**): This is an indicator that measures the
    change in the price of an arbitrary basket of goods and services used by the Bureau
    of Labor Statistics to evaluate the inflationary trend.'
  id: totrans-6234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Federal Fund rate**: This is the interest rate at which banks trade balances
    held at the Federal Reserve. The balances are called Federal Funds.'
  id: totrans-6235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical analysis
  id: totrans-6236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Technical analysis is a methodology used to forecast the direction of the
    price of any given security through the study of the past market information derived
    from price and volume*. In simpler terms, it is the study of price activity and
    price patterns in order to identify trade opportunities [A:17]. The price of a
    stock, commodity, bond, or financial future reflects all the information publicly
    known about that asset as processed by the market participants.'
  id: totrans-6237
  prefs: []
  type: TYPE_NORMAL
- en: Terminology
  id: totrans-6238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Bearish or bearish position**: This attempts to profit by betting that the
    prices of the security will fall.'
  id: totrans-6239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bullish or bullish position**: This attempts to profit by betting that the
    price of the security will rise.'
  id: totrans-6240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long position**: This is the same as Bullish.'
  id: totrans-6241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neutral position**: This attempts to profit by betting that the price of
    the security will not change significantly.'
  id: totrans-6242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oscillator**: This is a technical indicator that measures the price momentum
    of a security using some statistical formula.'
  id: totrans-6243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overbought**: This is a security that is overbought when its price rises
    too fast as measured by one or several trading signals or indicators.'
  id: totrans-6244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Oversold**: This is a security that is oversold when its price drops too
    fast as measured by one or several trading signals or indicators.'
  id: totrans-6245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relative strength index** (**RSI**): This is an oscillator that computes
    the average of number of trading sessions for which the closing price is higher
    than the opening price over the average of number of trading sessions for which
    the closing price is lower than the opening price. The value is normalized over
    [0, 1] or [0, 100%].'
  id: totrans-6246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resistance**: This is the upper limit of the price range of a security. The
    price falls back as soon as it reaches the resistance level.'
  id: totrans-6247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Short position**: This is the same as Bearish.'
  id: totrans-6248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Support**: This is the lower limit of the price range of a security over
    a period of time. The price bounces back as soon as it reaches the support level.'
  id: totrans-6249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Technical indicator:** This is a variable derived from the price of a security
    and possibly its trading volume.'
  id: totrans-6250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trading range**: The trading range for a security over a period of time is
    the difference between the highest and lowest price for this period of time.'
  id: totrans-6251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trading signal**: This is a signal that is triggered when a technical indicator
    reaches a predefined value, upward or downward.'
  id: totrans-6252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volatility**: This is the variance or standard deviation of the price of
    a security over a period of time.'
  id: totrans-6253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trading data
  id: totrans-6254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The raw trading data extracted from Google or Yahoo financials pages consists
    of the following:'
  id: totrans-6255
  prefs: []
  type: TYPE_NORMAL
- en: '**adjClose** (or **close**): This is the adjusted or nonadjusted price of a
    security at closing of the trading session'
  id: totrans-6256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**open**: This is the price of the security at the opening of the trading session'
  id: totrans-6257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**high**: This is the highest price of the security during the trading session'
  id: totrans-6258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**low**: This is the lowest price of the security during the trading session'
  id: totrans-6259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following graph:'
  id: totrans-6260
  prefs: []
  type: TYPE_NORMAL
- en: '![Trading data](img/image01621.jpeg)'
  id: totrans-6261
  prefs: []
  type: TYPE_IMG
- en: 'We can derive the following metrics from the raw trading data:'
  id: totrans-6262
  prefs: []
  type: TYPE_NORMAL
- en: 'Price volatility: *volatility = 1.0 – high/low*'
  id: totrans-6263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Price variation: *vPrice = adjClose – open*'
  id: totrans-6264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Price difference (or change) between two consecutive sessions: *dPrice = adjClose
    – prevClose = adjClose(t) – adjClose(t-1)*'
  id: totrans-6265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume difference between two consecutive sessions: *dVolume = volume(t)/volume(t-1)
    – 1.0*'
  id: totrans-6266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volatility difference between two consecutive sessions: *dVolatility = volatility(t)/volatility(t-1)
    – 1.0*'
  id: totrans-6267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relative price variation over the last *T* trading days: *rPrice = price(t)/average(price
    over T) – 1.0*'
  id: totrans-6268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relative volume variation over the last *T* trading days: *rVolume = volume(t)/average(volume
    over T) – 1.0*'
  id: totrans-6269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Relative volatility variation over the last *T* trading days: *rVolatility
    = volatility(t)/average(volatility over T) – 1.0*'
  id: totrans-6270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trading signals and strategy
  id: totrans-6271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The purpose is to create a set variable *x*, derived from price and volume *x=
    f (price, volume)*, and then generate predicates *x op c* for which *op* is a
    Boolean operator, such as *>* or *=* that compares the value of *x* to a predetermined
    threshold *c*.
  id: totrans-6272
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider one of the most common technical indicators derived from price:
    the relative strength index *RSI* or the normalized RSI *nRSI*, whose formulation
    is provided here as a reference:'
  id: totrans-6273
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-6274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The relative strength index**'
  id: totrans-6275
  prefs: []
  type: TYPE_NORMAL
- en: 'The RSI for a period of *T* sessions with *p[o]* opening price and *p[c]* closing
    price is defined as:'
  id: totrans-6276
  prefs: []
  type: TYPE_NORMAL
- en: '![Trading signals and strategy](img/image01622.jpeg)'
  id: totrans-6277
  prefs: []
  type: TYPE_IMG
- en: 'A **trading signal** is a predicate using a technical indicator *nRSI[T](t)
    < 0.2*. In trading terminology, a signal is emitted for any time period *t* for
    which the predicate is true:'
  id: totrans-6278
  prefs: []
  type: TYPE_NORMAL
- en: '![Trading signals and strategy](img/image01623.jpeg)'
  id: totrans-6279
  prefs: []
  type: TYPE_IMG
- en: The visualization of oversold and overbought positions using the relative strength
    index
  id: totrans-6280
  prefs: []
  type: TYPE_NORMAL
- en: Traders do not usually rely on a single trading signal to make a rational decision.
  id: totrans-6281
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if *G* is the price of gold, *I[10]* is the current rate of the
    10-year Treasury bond, and *RSI[sp500]* is the relative strength index of the
    S&P 500 index, then we can conclude that the increase in the exchange rate of
    US$ to the Japanese Yen is maximized for the following trading strategy: *{G <
    $1170 and I[10]* *> 3.9% and RSI[sp500]* *> 0.6 and RSI[sp500]* *< 0.8}*.'
  id: totrans-6282
  prefs: []
  type: TYPE_NORMAL
- en: Price patterns
  id: totrans-6283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Technical analysis assumes that historical prices contains some recurring albeit
    noisy, patterns that can be discovered using statistical methods. The most common
    patterns used in this book are the trend, support, and resistance levels [A:18],
    as illustrated in the following chart:'
  id: totrans-6284
  prefs: []
  type: TYPE_NORMAL
- en: '![Price patterns](img/image01624.jpeg)'
  id: totrans-6285
  prefs: []
  type: TYPE_IMG
- en: An illustration of trend, support, and resistance levels in technical analysis
  id: totrans-6286
  prefs: []
  type: TYPE_NORMAL
- en: Options trading
  id: totrans-6287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An option is a contract that gives the buyer the right, but not the obligation,
    to buy or sell a security at a specific price on or before a certain date [A:19].
  id: totrans-6288
  prefs: []
  type: TYPE_NORMAL
- en: 'The two types of options are calls and puts, as described here:'
  id: totrans-6289
  prefs: []
  type: TYPE_NORMAL
- en: A call gives the holder the right to buy a security at a certain price within
    a specific period of time. Buyers of calls expect that the price of the security
    will increase substantially over the strike price before the option expires.
  id: totrans-6290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A put option gives the holder the right to sell a security at a certain price
    within a specific period of time. Buyers of puts expect that the price of the
    stock will fall below the strike price before the option expires.
  id: totrans-6291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s consider a call option contract of 100 shares at a strike price of $23
    for a total cost of $270 ($2.7 per option). The maximum loss the holder of the
    call can incur is the loss of premium or $270 when the option expires. However,
    the profit can be potentially almost unlimited. If the price of the security reaches
    $36 when the call option expires, the owner will have a profit of ($36 - $23)*100
    - $270 = $1030\. The return on the investment is 1030/270 = 380%. Buying and then
    selling the stock would have generated a return on the investment of 36/24 -1=
    50%. This example is simple and does not take into account a transaction fee or
    margin cost [A:20]:'
  id: totrans-6292
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the following chart:'
  id: totrans-6293
  prefs: []
  type: TYPE_NORMAL
- en: '![Options trading](img/image01625.jpeg)'
  id: totrans-6294
  prefs: []
  type: TYPE_IMG
- en: An illustration of the pricing of a call option
  id: totrans-6295
  prefs: []
  type: TYPE_NORMAL
- en: Financial data sources
  id: totrans-6296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are numerous sources of financial data available to experiment with machine
    learning and validation models [A:21]:'
  id: totrans-6297
  prefs: []
  type: TYPE_NORMAL
- en: 'Yahoo finances (stocks, ETFs, and indices): [http://finance.yahoo.com](http://finance.yahoo.com)'
  id: totrans-6298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google finances (stocks, ETFs, and indices): [https://www.google.com/finance](https://www.google.com/finance)'
  id: totrans-6299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NASDAQ (stocks, ETFs, and indices): [http://www.nasdaq.com](http://www.nasdaq.com)'
  id: totrans-6300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'European Central Bank (European bonds and notes): [http://www.ecb.int](http://www.ecb.int)'
  id: totrans-6301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TrueFx (Forex): [http://www.truefx.com](http://www.truefx.com)'
  id: totrans-6302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quandl (Economics and financials statistics): [http://www.quantl.com](http://www.quantl.com)'
  id: totrans-6303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dartmouth University (portfolio and simulation): [http://mba.tuck.dartmouth.edu](http://mba.tuck.dartmouth.edu)'
  id: totrans-6304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suggested online courses
  id: totrans-6305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Practical Machine Learning*, J. Leek, R. Peng, B. Caffo, Johns Hopkins University
    ([https://www.coursera.org/jhu](https://www.coursera.org/jhu))'
  id: totrans-6306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Probabilistic Graphical Models*, D. Koller, Stanford University ([https://www.coursera.org/course/pgm](https://www.coursera.org/course/pgm))'
  id: totrans-6307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Machine Learning*, A. Ng, Stanford University ([https://www.coursera.org/course/ml](https://www.coursera.org/course/ml))'
  id: totrans-6308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  id: totrans-6309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[A:1] *Daily Scala: Enumeration*. J. Eichar. 2009 ([http://daily-scala.blogspot.com/2009/08/enumerations.html](http://daily-scala.blogspot.com/2009/08/enumerations.html))'
  id: totrans-6310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:2] *Matrices and Linear Transformations 2nd Edition*. C. Cullen. Dover Books
    on Mathematics. 1990'
  id: totrans-6311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:3] *Linear Algebra: A Modern Introduction*. D Poole. BROOKS/COLE CENGAGE
    Learning. 2010'
  id: totrans-6312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:4] *Matrix decomposition for regression analysis*. D. Bates. 2007 ([http://www.stat.wisc.edu/courses/st849-bates/lectures/Orthogonal.pdf](http://www.stat.wisc.edu/courses/st849-bates/lectures/Orthogonal.pdf))'
  id: totrans-6313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:5] *Eigenvalues and Eigenvectors of Symmetric Matrices*. I. Mateev. 2013
    ([http://www.slideshare.net/vanchizzle/eigenvalues-and-eigenvectors-of-symmetric-matrices](http://www.slideshare.net/vanchizzle/eigenvalues-and-eigenvectors-of-symmetric-matrices))'
  id: totrans-6314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:6] *Linear Algebra Done Right 2nd Edition* (§5 Eigenvalues and Eigenvectors)
    S Axler. Springer. 2000'
  id: totrans-6315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:7] *First Order Predicate Logic*. S. Kaushik. CSE India Institute of Technology,
    Delhi ([http://www.cse.iitd.ac.in/~saroj/LFP/LFP_2013/L4.pdf](http://www.cse.iitd.ac.in/~saroj/LFP/LFP_2013/L4.pdf))'
  id: totrans-6316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:8] *Matrix Recipes*. J. Movellan. 2005 ([http://www.math.vt.edu/people/dlr/m2k_svb11_hesian.pdf](http://www.math.vt.edu/people/dlr/m2k_svb11_hesian.pdf))'
  id: totrans-6317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:9] *Gradient descent*. Wikipedia ([http://en.wikipedia.org/wiki/Gradient_descent](http://en.wikipedia.org/wiki/Gradient_descent))'
  id: totrans-6318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:10] *Large Scale Machine Learning: Stochastic Gradient Descent Convergence*.
    A. Ng. Stanford University ([https://class.coursera.org/ml-003/lecture/107](https://class.coursera.org/ml-003/lecture/107))'
  id: totrans-6319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:11] *Large-Scala Machine Learning with Stochastic Gradient Descent*. L Bottou.
    2010 ([http://leon.bottou.org/publications/pdf/compstat-2010.pdf](http://leon.bottou.org/publications/pdf/compstat-2010.pdf))'
  id: totrans-6320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:12] *Overview of Quasi-Newton optimization methods*. Dept. Computer Science,
    University of Washington ([https://homes.cs.washington.edu/~galen/files/quasi-newton-notes.pdf](https://homes.cs.washington.edu/~galen/files/quasi-newton-notes.pdf))'
  id: totrans-6321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:13] *Lecture 2-3: Gradient and Hessian of Multivariate Function*. M. Zibulevsky.
    2013 ([http://www.youtube.com](http://www.youtube.com))'
  id: totrans-6322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:14] *Introduction to the Lagrange Multiplier*. ediwm.com video ([http://www.noodle.com/learn/details/334954/introduction-to-the-lagrange-multiplier](http://www.noodle.com/learn/details/334954/introduction-to-the-lagrange-multiplier))'
  id: totrans-6323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:15] *A brief introduction to Dynamic Programming (DP)*. A. Kasibhatla. Nanocad
    Lab ([http://nanocad.ee.ucla.edu/pub/Main/SnippetTutorial/Amar_DP_Intro.pdf](http://nanocad.ee.ucla.edu/pub/Main/SnippetTutorial/Amar_DP_Intro.pdf))'
  id: totrans-6324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:16] *Financial ratios*. Wikipedia ([http://en.wikipedia.org/wiki/Financial_ratio](http://en.wikipedia.org/wiki/Financial_ratio))'
  id: totrans-6325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:17] *Getting started in Technical Analysis* (§1 Charts: Forecasting Tool
    or Folklore?) J Schwager. John Wiley & Sons. 1999'
  id: totrans-6326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:18] *Getting started in Technical Analysis* (§4 Trading Ranges, Support
    & Resistance) J Schwager. John Wiley & Sons. 1999'
  id: totrans-6327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:19] *Options: a personal seminar* (§1 Options: An Introduction, What is
    an Option) S. Fullman, New York Institute of Finance. Simon Schuster. 1992'
  id: totrans-6328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:20] *Options: a personal seminar* (§2 Purchasing Options) S. Fullman New
    York Institute of Finance. Simon Schuster. 1992'
  id: totrans-6329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A:21] *List of financial data feeds*. Wikipedia ([http://en.wikipedia.org/wiki/List_of_financial_data_feeds](http://en.wikipedia.org/wiki/List_of_financial_data_feeds))'
  id: totrans-6330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
