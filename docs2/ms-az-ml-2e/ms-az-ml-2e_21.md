# *第十七章*：为成功的 ML 之旅做好准备

恭喜你，你已经成功了——你经历了多么不可思议的旅程！到现在，你应该已经学会了如何在云中预处理数据，实验**ML**模型，在自动扩展集群上训练深度学习模型和推荐引擎，优化模型，并将它们部署到你想要的地方。你应该知道如何通过**MLOps**将这些步骤操作化，为蛋糕增添一抹亮色。

在最后一章，我们将回顾我们在这次旅程中学到的一些重要启示。很容易在技术和算法选择中迷失或感到不知所措。你可能会深入研究建模、基础设施或监控，但可能离拥有一个好的预测模型更远。

在第一部分，我们将提醒你，ML 主要关于数据。人工智能可能应该被称为数据清洗和标注，但当然，这听起来没有 AI 那么好。你会明白你的数据是出色性能的关键，所以你最应该关心的是这个。你的数据就是一切！

在接下来的部分，我们将向你展示如何开始你的 ML 项目。我们将通过提供一些指导并强调干净的基础设施和深思熟虑的监控的重要性来实现这一点。

之后，我们将重申自动化的重要性以及新技术将如何带我们进一步进入**机器学习即服务**（**MLaaS**）的世界。了解技术的发展方向总是很好的，在机器学习的情况下，它是元学习和系统，它们已经自动建议合适的模型并将它们堆叠起来以实现良好的预测性能。当建模完全自动化时，剩下的是什么？正是——你的数据！

在此之后，我们将讨论云服务的持续变化和演变，同时关注 PaaS 服务。我们将探讨为什么 PaaS 解决方案被构建以及它们的基石是什么。这将帮助你了解如何最好地准备应对变化，以及为什么尽管服务不断变化，你仍然在正确的基石上押注。

最后，我们将讨论在这本书中我们主要忽略的一个主题。我们将讨论在开始任何 ML 项目之前你应该思考的一些问题：你应该这样做吗？你模型的成果会对人们的生活产生严重影响吗？你可能已经猜到了：我们将从数据处理的角度讨论**伦理**。在一个越来越互联的世界中，你不应该滥用他人的个人信息，你不应该构建对某些群体极端有偏见的模型，你不应该通过你的部署解决方案负面地影响人们的生活。

本章将涵盖以下主题：

+   记住数据的重要性

+   从一个深思熟虑的基础设施开始

+   自动化重复性任务

+   预期持续变化

+   思考你的责任

# 记住数据的重要性

许多用于预测和模型拟合的算法问题难以使用经典优化算法或复杂启发式方法进行建模、计算和优化。监督式机器学习提供了一种利用优化和大量标记训练数据解决最复杂问题的强大新方法。

有些人可能认为你只需将大量数据扔给模型。想象一下，你有成千上万张同一只鸟从每个可能角度的照片。基于这些照片训练的模型可能对分类不同的鸟类家族的预测并不具有很高的预测性。

为你的模型选择合适的数据样本

当模型使用高度独特的数据样本和对你模型应预测的上下文有用的数据样本时，其质量会提高。

因此，当你使用机器学习算法工作时，你需要记住，模型是由你提供给它们的训练数据和训练标签驱动的。好的数据是良好性能的关键。

了解这一点，让我们再次强调在处理数据和训练机器学习模型时的关键要点：

+   **大部分时间用于处理数据**：正如我们在本书开头讨论的那样，在大多数机器学习项目中，你将花费大约 80%的时间进行数据分析、预处理和特征工程。彻底理解你的数据对于开发成功的预测模型至关重要。这样想：使你与众不同的唯一东西就是你的数据。很可能，你的竞争对手可以访问与你类似的算法、优化和计算基础设施。他们唯一没有的是你的数据和你的技能来分析这些数据（希望如此）。因此，这就是你成功的关键所在：在解释、清理、建模和准备你的数据以进行高质量预测。

+   **强调特征工程**：你获得的最大机会是提高任何模型的基础预测性能，这可以通过改进你的基础数据集，通过更好的特征工程或添加更多预测性特征来实现。不要迷失在尝试调整和堆叠模型的过程中。相反，你应该把大部分的时间和资源投入到数据预处理和特征工程中。特征工程是你可以发光和赢得预测游戏的地方。你正在处理日期吗？引入其他数据源，例如当地和全球的节假日以及附近的事件；添加相对日期，例如节假日前的天数，周末前的天数等等。你正在处理位置、城市或国家吗？在这里，你应该引入人口统计数据、政治数据或地理数据。你明白这个意思。

+   **不要被模型调优分散注意力**：你的模型能做的事情是有限的。是的，你可以堆叠多个模型，调整和优化它们，针对不同的指标进行优化，等等。然而，你的最大优势是你的数据。任何机器学习模型的好计划都是从一个非常简单的基础模型开始。你是在处理分类数据吗？如果是这样，选择梯度提升树集成，并坚持默认参数。你是在预测连续值吗？如果是这样，选择逻辑回归模型。从小处着手，确保你在开始调整模型之前，你的数据是正确的。

+   **始终从基础模型开始**：使用基础模型，并围绕它构建所有自动化、基础设施和指标。值得注意的是，基础模型应该比随机方法表现更好。一旦管道完成，你就可以深入数据，添加新数据，进行更好的特征工程，再次部署，测试，并重新迭代。将你的模型简化为原始的基础模型是一个困难的步骤，但它将帮助你成功管理项目第一阶段的工作重点。为什么基础模型方法如此重要？因为它为迭代项目设定了你的心态，在这个项目中，你不断地测量、添加数据、重新训练并改进你的模型。你的模型将需要重新训练，你需要测量何时需要这样做。为了重新训练，你需要新的训练数据。

+   **持续收集新的、相关的数据样本**：在一个完美的设置中，你会安装一个持续的数据收集管道，直接从你的当前产品中收集新的训练数据和训练标签。你的模型预测搜索相关性吗？收集搜索查询和点击结果。你的模型预测欺诈吗？收集新的数据和手动验证的欺诈案例的结果。你的模型预测标签吗？跟踪预测，并让用户在它们不准确时更改它们。在这些所有例子中，我们持续跟踪相关的训练数据，我们可以用这些数据不断重新训练和微调。拥有这种持续的训练数据流可能是你业务的竞争优势，让你为成功做好准备。因此，当你监督一个机器学习项目时，考虑你将如何在未来重新训练模型。

除了遵循这些技术规则来处理机器学习项目外，了解你公司的业务方面至关重要。这样的项目通常需要一个跨学科团队才能成功。因此，获得公司数据策略的 C 级支持至关重要。数据是你的燃料，它通常以大量数据孤岛的形式分散在公司的各个部门。你可能需要访问大量这些来源来实现和改进机器学习模型，因此，拥有访问和使用这些数据的权限至关重要。

这通常需要大多数公司进行思维上的转变，因为来自不同部门的数据需要结合和分析，以便用于预测。因此，数据质量很重要，数据来源很重要，这样你才能了解它来自哪里，及时性很重要，正确性是必不可少的。所以，确保数据在你的公司中得到应有的支持、关爱和照顾。

现在我们已经重申了关于数据处理的重要事实，让我们谈谈你正在工作的环境。

# 从一个深思熟虑的基础设施开始

成功应用的机器学习项目依赖于迭代的方法来处理数据收集、数据清洗、特征工程和建模。在成功部署和推广后，你应该回到起点，关注你的指标，并收集更多数据。现在应该很清楚，你将在机器学习项目的生命周期中重复一些开发和部署步骤。

从一开始就正确设置你的机器学习项目的基础设施和环境将为你节省很多麻烦。成功基础设施的一个关键在于自动化和版本控制，正如我们在上一章中讨论的那样。因此，我们建议你花几天时间来设置你的基础设施和自动化，并在 Azure 机器学习中注册你的数据集、模型和环境。

这同样适用于监控。为了做出明智的决定，比如你的模型是否按预期工作，训练数据是否仍然准确，或者资源利用率是否足够高，你需要准确的指标。在部署后添加指标相当棘手。因此，你应该事先了解你想要衡量什么，以及你想要提前被提醒什么。在你的项目开始时，花些额外的时间思考你将要跟踪的指标。

最后，在处理数据和模型的同时优先考虑基础设施是困难的。如果你能承担将它们分成单独的团队进行机器学习基础设施、建模和数据工作的奢侈，那么这可能不是你首要考虑的事情。然而，这种情况通常并不存在。为了避免这种优先级问题，我们建议从简单的基线模型开始，并基于这个简单的模型定义你的基础设施自动化。

让我们看看当你开始你的机器学习项目时应该执行哪些步骤：

1.  **选择一个基线模型**：为你的用例选择具有默认参数的最简单模型，一小部分训练数据以及最重要的工程特征。

1.  **构建一个简单的流水线**：将这些模型训练步骤放入一个流水线中，自动构建你的模型并将其部署到预发布环境中。这种方法的优点在于你自动优先考虑基础设施，并且始终输出一个已部署的评分服务。这将为你成功奠定基础。

1.  **深入数据**：确保你理解数据及其质量，如何填充缺失值，以及如何预处理特征。你可以添加额外的数据，并从事特征工程，将你的原始输入数据转换为可解释的数据。如果你选择了一个好的基线模型，这项工作应该会极大地提高基线模型的性能，并给你的同事提供一个评分服务 API，以便与新的服务一起使用。

1.  **实验更复杂的模型**：一旦你确信你已经建立了一个稳固的数据管道，你就可以着手建模，包括模型选择、训练、验证、优化和堆叠。再次强调，你应该能够看到可以衡量并持续部署到任何 QA 环境中的渐进式改进。一旦你的性能足够好，就可以将服务推广给你的客户，并开始收集指标和更多训练数据。

1.  **监控云使用**：当你使用云中的计算基础设施进行开发时，很容易迅速花费几千美元用于一些未使用或利用率低的虚拟机。我们建议你定期检查机器的数量及其利用率。如果某些东西不再被使用，就进行扩展或关闭。请记住，云的最大好处是可扩展的基础设施。所以，请充分利用它。

遵循这些指导原则将帮助你建立一个干净且可监控的基础设施，你可以在这个过程中不断演进。

现在我们已经讨论了你应该设置的基础设施，让我们再次谈谈自动化。

# 自动化重复性任务

训练机器学习模型是一个复杂且迭代的流程，包括数据准备、特征工程、模型选择、优化和部署。最重要的是，一个企业级的端到端机器学习管道需要是可重复的、可解释的、安全的和自动化的，这对大多数公司来说在知识、成本和基础设施要求方面都提出了额外的挑战。

在前面的章节中，我们学习了这个过程的方方面面，因此我们可以确认它没有什么是简单或容易的。调整特征工程方法会影响模型训练；数据清洗过程中的缺失值策略将影响优化过程。

首先，你的模型所捕获的信息很少是恒定的，因此大多数机器学习模型都需要频繁的重训练和部署。这导致了对 MLOps 的新要求：一个用于机器学习的 DevOps 管道，以确保数据的持续集成和持续部署。

自动化机器学习通过自动化许多这些挑战来简化这个复杂且迭代的流程。而不是手动调整输入数据，然后手动选择、优化和部署机器学习模型，自动化服务只需要输入数据，以及一些与业务相关的配置，例如要训练的预测类型。

因此，使用 Azure DevOps 和 Azure 机器学习管道等工具可以大大减少错误和系统停机时间，并使用户从执行大量手动任务中解放出来。此外，Azure 自动机器学习等服务允许用户优化机器学习训练，甚至堆叠多个模型以提高预测性能。最大的好处是用户可以专注于机器学习过程最重要的部分：理解、获取和清理数据。

在许多情况下，自动机器学习服务将优于手动训练的模型，同时显著降低训练和运营成本。原因在于许多任务，如选择正确的分类嵌入、处理不平衡数据、选择最佳模型、找到最佳参数以及结合多个模型以提高性能，可以系统地优化，而不是手动选择。

每个主要的云服务提供商都提供成熟的服务，以便您可以在云中执行自动机器学习，并方便地部署这些模型。自动机器学习是一种节省时间和成本的同时，为现有员工提供训练复杂端到端机器学习管道所需工具的绝佳方式。这使得自动机器学习成为一种真正的服务——机器学习即服务（MLaaS）。

谈到工具，让我们谈谈当您使用现代云系统时需要跟上的一些变化。

# 期待持续变化

一切都处于持续变化的状态。15 年前，只有少数人听说过神经网络和机器学习。今天，您可以访问大量的机器学习库、程序和云服务。每天，都在取得新的进展，以自动化机器学习任务并改进机器学习建模。只需想想您可能使用的语音助手以及自动驾驶汽车正在发生的事情。

由于这个原因，您将面临对机器学习库及其工具进行的大量持续变化。这在云环境中尤其如此，与许可软件相比，更新可以快速推送到用户群体。正如我们之前所学的，查看大型云服务提供商，他们的服务通常可以分为以下几类：

+   **基础设施即服务**（**IaaS**）：IaaS 服务是所有基础设施抽象，如虚拟机（计算）、磁盘（存储）和网络。

+   **平台即服务**（**PaaS**）：PaaS 服务是在这些组件之上构建的平台，具有额外的功能，可以暴露服务同时隐藏底层基础设施和操作系统。

+   **软件即服务**（**SaaS**）：与 PaaS 服务相反，SaaS 服务通过用户界面暴露，不提供对底层软件和硬件堆栈的任何访问。

Azure 机器学习是一个很好的 PaaS 服务的例子，因为它结合了不同的基础设施服务、UI 和 SDK，为你提供了全新的功能，并提供了对底层服务的完全访问，例如 blob 存储、训练集群和容器注册表，而在大多数情况下，操作系统则被置于幕后。在你的每月 Azure 账单上，你会发现当你使用 PaaS 解决方案时，你大部分的钱都花在了基础设施服务上。

虽然底层基础设施为所有云服务奠定了基础，但它们在接下来的几年内不太可能发生剧烈变化。新的改进将进入市场，通常集中在吞吐量水平和网络安全上。尽管如此，你不应该期望对现有 API 进行重大更改。此外，这些服务不太可能被终止，因为它们是许多服务的基石。

对于 PaaS 服务来说，情况并非如此。它们被设计用来回答客户关于抽象解决方案的需求，这样他们就可以免于编写大量的样板代码和处理解决方案的低级基础设施细节。你有多少次看到 Azure 机器学习的一个功能，心想，“嘿，我完全可以自己实现这个功能”？这当然是对的，但你可能希望有人帮你解决这个简单的问题，这样你就可以专注于你试图解决的复杂问题。这就是 PaaS 最初存在的原因。

然而，客户驱动的需求带来的不利之处在于，这些需求和用法模式始终在不断发展。新的用例（如 MLOps）不断出现，需要支持新的服务或对现有服务的扩展。因此，你应该始终期待 PaaS 会随着时间的推移而变化。

如果你查看这本书的第一版，你会发现其中近一半的代码和功能要么已经弃用，要么被新的东西所取代，或者与 Azure 机器学习服务的其他部分合并。根据你阅读这本书的时间，你可能已经发现我们在这里描述的功能或 API 与 Azure 当前 API 和功能之间存在差异。

如果你感到困惑是可以理解的，并问自己这本书怎么会已经过时了，我们想向你保证，我们展示的是正确的技术，值得下注。PaaS 服务总体上，以及 MLaaS 服务具体来说，总是在经历巨大的变化和改进。期待变化！

让我们看看你可能随着时间的推移会遇到的一些可能的变更：

+   **预期名称会发生变化**：这可能是最常见的变更。公司通常在命名产品方面做得不好，Azure 和其他所有云服务提供商也不例外。这可能看起来像是一个很大的变化或不便，但实际上只是更改服务或组件的名称，或者将其隐藏在云平台的其他地方。在过去的几年里，针对 Azure 的机器学习（ML）进行了许多变更。曾经有一个名为**Azure Machine Learning Studio (classic)**的服务，它主要作为 Azure 机器学习中的**Designer**存在。曾经有，现在仍然有名为**Azure Batch**、**Azure BatchAI**和**AML Compute**的服务，它们提供了与您现在在 Azure 机器学习中找到的批推理计算集群大致相同的功能。简单来说，不要让自己被这些变化分散注意力。预期会出现一些有趣的新名称，用于您所熟悉和喜爱的功能。

+   **预期 UI 会发生变化**：这是最明显的变化，在最近的云服务中相当常见。许多服务都得到了全新的 UI，一些被整合到 Azure UI 中，还有一些被放置在单独的应用程序中。预期某些功能可能只在一个 UI 中暴露，而在另一个 UI 中则不暴露。然而，通常情况下，新的 UI 意味着相同或类似的功能可以通过新的界面访问。这也是我们为什么训练你更多地使用 Python API 或 Azure CLI 而不是图形界面工作的原因之一。

+   **预期 SDK 中的类和包会发生变化**：大多数云服务提供商的机器学习解决方案的 API 都在不断演变。Azure 在它的机器学习服务上投入了大量的资金，因此变化是不可避免的。为应对这种变化，一个很好的做法是将代码抽象成特定的实现，这样就可以轻松地用新功能替换。另一个好的做法是对库更新保持谨慎，但也不要落后于最新版本太久。

你是否同意，在这些情况下，变化是唯一的不变因素？请记住，所有 PaaS 解决方案最终都是建立在底层基础设施之上的，这为你的计算、存储和网络提供了坚实的基础。

因此，请记住：尽管变化不断，你是在正确的基石上构建！

在讨论了在使用云平台进行机器学习时应考虑的大部分内容之后，让我们谈谈一个更加重要的话题：数据伦理。

# 考虑到你的责任

在本书的最后一节，我们想要从模型、部署和优化中退一步，来谈谈一个更加重要的主题：处理数据时的伦理，或者今天所知的**负责任的 AI/ML**。

在*第一章*《理解端到端机器学习过程》中，我们讨论了数据中的**偏差**，它如何有意或无意地被引入数据集中，以及你需要注意什么。这只是反映你如何收集数据以及你的训练模型如何对他人生活产生负面影响的一个小小拼图。

想象一下，你正在训练一个机器学习模型，建议银行柜员允许面前的客户获得贷款，以及客户可以获得的贷款利率。使用自动化系统做出这个决定可能是一种祝福或诅咒。如果公司的大多数银行柜员存在固有的偏差，而你构建了一个公平的模型，那么这可能会是一种祝福。然而，如果你的模型基于那些银行柜员的先前决策，你必须密切关注你的数据中的大量偏差。如果不这样做，你可能会创造一个更加不公平的世界，因为现在，你的机器学习系统负责。一个公平的柜员发放贷款，即使他们可能了解你的机器学习系统中存在偏差，现在可能也不允许他们推翻它。

虽然有比这更糟糕的例子，但这应该能给你一个很好的概念，了解我们想要讨论的内容。

一般而言，我们可以将你的责任分为以下几类：

+   **可解释性**：你如何解释你的模型及其生成的结果？

+   **公平性**：你如何通过消除数据中的偏差来确保公平性？

+   **隐私**：在你的基础数据和模型中，个人的**可识别信息**（**PII**）得到了多好的保护？谁可以访问它？

+   **合规性**：你所使用和可以访问的每一件事物都有多好的文档记录？你是如何追踪谁在使用你的数据或模型的？

让我们更详细地看看你需要注意的事项，以及 Azure 机器学习提供的哪些工具可以帮助你在进行这项工作时得到支持。

## 解释模型

任何部署的机器学习模型都是一个黑盒。我们通过模型发送输入并接收以预测或分类形式呈现的输出。因此，利益相关者很难理解为什么系统会做出某些决策以及为什么不会。为了缓解这种情况，你可以应用新的工具来解释你的模型。

但在我们讨论解释机器学习模型的工具和方法之前，让我们将模型分为两类：

+   **黑盒模型**：计算如此复杂，以至于我们不知道决策是如何形成的。

+   **玻璃箱模型**：结果可以相对容易地解释和计算的模型。例如，考虑线性回归模型。

玻璃盒模型通常更简单，所以权衡似乎是在可解释性和复杂性（因此，可能是准确性）之间。但如果您的模型处理大量个人信息，您将想知道模型是如何得出结论的。

因此，出现了对黑盒模型进行解释的需求，这种解释器被称为**黑盒解释器**。以下是最为知名的两种解释器：

+   **Shapley 增量解释**（**SHAP**）：这是一种将博弈论应用于机器学习模型的方法，主要用于可解释性。这个方法族假设模型中的每个特征都是一个游戏中的**玩家**。基于这个假设，您可以使用所谓的**Shapley 值**来计算特征值对预测的平均贡献。简单来说，这是通过向**联盟**中添加和删除特征来完成的，在博弈论中，联盟是合作的一组玩家。SHAP 可以用于任何类型的模型，但它对线性回归、树、集成树以及使用 TensorFlow 或 Keras 的深度学习有很好的定义。此外，它还可以解释单个预测，而不仅仅是全局层面的解释。您可以在其开源版本中了解更多关于 SHAP 的信息([`github.com/slundberg/shap`](https://github.com/slundberg/shap))。

+   **局部可解释模型无关解释**（**LIME**）：这是一种创建所谓的代理玻璃盒模型的方法，基于任何黑盒分类器模型。代理模型试图模仿底层模型的行为，同时降低其复杂性。这是通过在特定实例附近训练一个线性模型来实现的。用户可以查看这个新创建的玻璃盒模型，以了解黑盒模型对这个邻域或预测子集的输出。因此，LIME 可以解释黑盒模型的单个预测。您可以在其开源版本中了解更多关于 LIME 的信息([`github.com/marcotcr/lime`](https://github.com/marcotcr/lime))。

这些是您可以用来解释黑盒模型的技术。为了稍微缓解玻璃盒模型的情况，微软研究院正在开发一个名为**可解释提升机**（**EBM**）的机器学习模型，它在准确度上与梯度提升相当，同时仍然完全可解释。他们的原始论文可以在[`arxiv.org/abs/2106.09680`](https://arxiv.org/abs/2106.09680)找到。

要尝试这些解释器，您可以直接在项目中使用这些包，或者您可以使用来自 Azure ML SDK 的`azureml-interpret`包([`docs.microsoft.com/en-us/python/api/azureml-interpret`](https://docs.microsoft.com/en-us/python/api/azureml-interpret))。这个包为您提供了访问**Interpret Community SDK**([`github.com/interpretml/interpret-community`](https://github.com/interpretml/interpret-community))的权限。您可以阅读该包上可用的解释器。

如果你想尝试一下，可以查看以下指南：[`docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml`](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml)。当你在这本书的所有动手练习中查看 Azure Machine Learning 工作室页面时，你可能已经注意到训练运行和模型中有一个名为**解释**的标签。当你使用这个包时，你可以将解释器的结果添加到训练运行中，并在之后在线查看视觉效果。

想要进一步阅读，可以查看**InterpretML**项目([`interpret.ml/docs/intro.html`](https://interpret.ml/docs/intro.html))，该项目提供了不同类型解释器的概述。

现在我们已经了解了如何解释我们模型的结果，让我们来看看公平性。

## 模型训练中的公平性

分析模型公平性的主要工具之一称为**Fairlearn**([`fairlearn.org/`](https://fairlearn.org/))。为了定义模型是否公平，Fairlearn 包中的算法和指标寻找两种可能造成的损害，如下所示：

+   **分配损害**：一个保留机会、资源或信息的模型或系统。这符合我们之前的例子，其中我们讨论了一个 ML 系统向个人发放贷款。

+   **服务质量损害**：一个不保留任何东西但对待不同群体行为不同的模型或系统。

为了评估给定模型的公平性，使用了两种结构，评估指标和缓解算法。这些可以按以下方式分类：

+   **评估指标**：可以通过比较多个模型为单个模型计算指标，也可以为通过缓解算法创建的模型计算指标。它们包括从计算模型召回率等简单指标到添加分组信息以分析模型结果。更多信息请参阅[`fairlearn.org/main/user_guide/assessment.html`](https://fairlearn.org/main/user_guide/assessment.html)。

+   **减少算法**：这些算法在评估后从重新加权的训练数据集中构建一个新的标准黑盒模型。用户可以通过不同的模型运行来调整，以找到准确性和公平性之间的最佳权衡。更多信息请参阅[`fairlearn.org/main/user_guide/mitigation.html#reductions`](https://fairlearn.org/main/user_guide/mitigation.html#reductions)。

+   **后处理算法**：这些算法将原始模型和敏感特征结合起来计算应用于模型预测的转换。通过这个过程，我们避免了重新训练原始模型。

请注意，像 Fairlearn 这样的包仍在开发中。由于决定公平性不是一个简单的话题，不要仅依赖于这样的工具。当你思考可以引入的类型偏见时，要反思你所做的事情，并使用这些工具来获得更多见解。Fairlearn 的开发者指出了以下几点：

“公平性本质上是一个社会技术挑战。许多关于公平性的方面，如正义和正当程序，都无法通过定量公平指标来捕捉。此外，还有许多定量公平指标无法同时满足。我们的目标是使人类能够评估不同的缓解策略，并根据他们的场景做出适当的权衡。”

有关如何使用 Fairlearn 包与 Azure 机器学习结合使用以及如何上传您的结果的指南，请访问[`docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml`](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml)。

最后，让我们学习如何使用 Azure 机器学习处理隐私和合规性。

## 处理 PII 数据和合规要求

随着欧洲的**通用数据保护条例**（**GDPR**）和加州的**加州消费者隐私法案**（**CCPA**）等立法的出台，企业现在处于困境。除了有明确的指导说明如何利用 PII 数据外，他们通常还要求存储涉及此数据的任何行动的审计跟踪，从用户到访问此数据的公司员工。

因此，拥有支持这一努力的工具非常重要。大多数 Azure 服务都设有安全措施来应对外部入侵者并构建多租户应用程序，帮助客户避免看到他人的 PII 数据。然而，在大多数组织中，系统管理员通常可以访问这些明文数据。对于构建机器学习模型的人来说也是如此。此外，Azure 上的数据库通常可以记录任何访问并建立审计跟踪以供审查。但机器学习建模管道或部署管道又如何呢？谁能在什么形式和什么时间点看到数据？

所有这些问题都需要得到解答。让我们看看一些可用的工具和在这个领域正在进行的研究：

+   **差分隐私**: 该机制用于向数据添加噪声或随机性，以使个人的数据无法识别。这样做，我们仍然可以在略微改变的数据集上构建一个准确模型。请注意，这并不是指明显的 PII 数据，例如你的姓名或电子邮件地址。为了让你思考一下：你很可能会直接通过你使用的浏览器版本和安装的浏览器插件被识别。这种方法在名为 **SmartNoise** ([`github.com/opendp/smartnoise-core`](https://github.com/opendp/smartnoise-core)) 的软件包中实现，你可以在你的机器学习项目中使用它。有关此主题的更多信息，请参阅[`docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy`](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy)。

+   **同态加密**: 这允许在加密数据上执行计算，而不允许访问解密密钥。只需要用秘密密钥解密计算结果。到目前为止，即使使用加密数据并使用密钥解密，也相当麻烦，因为对 TB 级数据运行加密是耗时的。现在，这项由微软研究的技术，通过 **Microsoft SEAL** 项目 ([`www.microsoft.com/en-us/research/project/microsoft-seal/`](https://www.microsoft.com/en-us/research/project/microsoft-seal/)) 提供使用。此外，你可以通过遵循[`docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal`](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal)上的指南来学习如何使用这个方法与推理网络服务一起使用。

+   **模型数据表**: 这提供了记录机器学习资产及其生命周期的指南。为了符合法规并且工作得更加整洁，可以采用名为 **关于机器学习** 的指南 **ABOUT ML** ([`partnershiponai.org/paper/about-ml-reference-document/`](https://partnershiponai.org/paper/about-ml-reference-document/))。在 Azure 机器学习环境中如何采用此指南的示例可以在此找到：[`github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb`](https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb)。

请密切关注这些主题的发展，因为未能遵守这些法规可能会产生严重的后果。

正如你所见，我们在这个章节中讨论的所有包都还处于 alpha 或 beta 阶段，因为可解释性、公平性和隐私性在机器学习背景下相对较新。在过去十年中，机器学习更多的是一个研究课题，而不是实际的生产环境。如今，基于机器学习的解决方案已经融入了我们的日常生活。因此，我们需要退一步，开始思考我们是否可以不质疑其有效性就让机器为我们做决定。

因此，当你运行下一个注定要投入生产的 ML 项目时，将这些话题带入讨论，因为它们需要从一开始就得到处理。

# 摘要

在这一章中，我们通过涵盖数据、基础设施、监控、自动化、变更管理和伦理等方面，从更高的层次审视了一些内容。我们希望你在阅读这本书后，对这些话题的理解是合理的。

重要的是要理解，你的数据将控制和影响一切，因此，将数据作为你公司的一等公民是第一步重要的举措。雇佣一个*数据副总裁*并定义数据质量、血缘和可发现性的标准只是你可以采取的一些措施。

在自动化方面，我们看到自动化机器学习将在几年内统治世界。这个想法很简单：一个训练好的元模型在提出、训练、优化和堆叠模型以实现更高的预测性能方面将始终优于人类。这完全说得通。这只是另一个参数优化步骤，也包括模型架构。另一个有趣的思考是，自动化机器学习将为不熟悉机器学习的人提供真正的 MLaaS。也许 Excel 中会提供一个预测列，或者在 Power BI 中有一个机器学习转换步骤，这意味着普通的 Office 用户可以通过电子表格应用程序突然利用机器学习的力量。

我们还提到，在云中使用 PaaS 时，变化是不可避免的。这是因为 PaaS 解决方案旨在实施典型的客户解决方案，并推动你消费更多的基础设施服务。随着客户需求的变化，这些 PaaS 提供的产品也会随之变化。因此，一个很好的经验法则是不要过于依赖产品名称、UI 或 SDK 包。

最后，我们理解了在数据处理中伦理的重要性。我们讨论了构建可解释的模型、评估我们模型公平性以及如何保护个人数据不受我们自己和其他人侵害的话题。

我们希望你喜欢这本书，并学会了如何掌握机器学习和 Azure 机器学习。然而，这个兔子洞比这本书深得多。所以，继续学习吧，我们也会这样做。在社交媒体上联系我们，告诉我们你学到了什么，你喜欢什么，以及这本书中可以改进的地方。我们非常乐意听到你的反馈。

在那时之前，祝大家机器学习愉快！
