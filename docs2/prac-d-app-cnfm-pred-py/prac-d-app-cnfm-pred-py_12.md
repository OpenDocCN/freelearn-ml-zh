

# 第十二章：多类一致性预测

欢迎来到本书的最后一章，我们将深入探讨多类**一致性预测**的迷人世界。本章将向您介绍各种可以有效地应用于多类分类问题的一致性预测方法。

我们将探讨多类分类的概念，这是机器学习（ML）中的一种常见场景，其中实例可以属于许多类别之一。理解这个问题是有效应用一致性预测技术的第一步。

接下来，我们将研究用于评估多类分类问题的度量标准。这些度量标准为我们模型的性能提供了定量衡量，理解它们对于有效模型评估和选择至关重要。

最后，我们将学习如何将一致性预测应用于多类分类问题。本节将提供实用的见解和技术，可以直接应用于你的工业应用。

到本章结束时，你将掌握在多类分类中的宝贵技能和知识，并学会如何有效地将这些方法应用于这些问题。那么，让我们深入其中，开始我们的多类一致性预测之旅！

在本章中，我们将涵盖以下主要主题：

+   多类分类问题

+   多类分类问题的度量标准

+   如何将一致性预测应用于多类分类问题

# 多类分类问题

在机器学习中，分类问题是普遍存在的。它们涉及为实例预测一个离散的类别标签输出。虽然二元分类——预测两种可能结果之一——是一种常见场景，但许多现实世界的问题需要预测超过两个类别。这就是多类分类发挥作用的地方。

多类分类是一个实例可以属于许多类别之一的问题。例如，考虑一个设计用于将新闻文章分类到主题的机器学习模型。这些文章可以被分类到如*体育*、*政治*、*科技*、*健康*等类别。每个这些类别代表一个类别，由于有超过两个类别，这是一个多类分类问题。

需要注意的是，在多类分类中，每个实例恰好属于一个类别。如果每个实例可以属于多个类别，那么它将是一个多标签分类问题，这属于不同类型的问题。

多类分类问题是机器学习中的基本问题，它们需要与二元分类问题略有不同的方法。让我们更深入地探讨多类分类的复杂性。

## 多类分类算法

几种机器学习算法可以直接处理多类分类问题。这些包括但不限于以下：

+   **决策树**：如**分类与回归树**（CARTs）之类的决策树算法可以自然地处理多分类。

+   **朴素贝叶斯**：朴素贝叶斯将每个类别视为一个单独的一对多二分类问题，并选择概率最高的结果。

+   然后，可以使用`softmax`激活函数来计算每个类别的概率分布。

许多机器学习算法天生是为两个类别之间的二分类设计的。为了将这些模型扩展到具有两个以上类别的多分类问题，必须采用特殊策略。两种常见的方法是“一对多”和“一对一”。

接下来，我们将更详细地探讨这些一对多和一对一策略，包括如何将二分类结果汇总以做出最终的多分类预测。我们还将讨论使用适用于具有两个以上类别的问题的专用性能指标来评估多分类分类器。

## 一对多和一对一策略

对于不原生支持多分类的算法，可以使用以下策略，如一对多（也称为一对余）和一对一：

+   **一对一策略**：对于具有*n*个类别的难题，将训练*n*个独立的二分类模型。每个模型被训练以区分一个类别的实例与其他所有类别的实例。所有*n*个模型都应用于一个新实例，并且给出最高置信度分数的模型确定实例的类别。

+   **一对一策略**：在这种策略中，为每一对类别训练一个二分类模型。对于*n*个类别，这将产生*n(n-1)/2*个模型。每个模型的决策都会对投票方案做出贡献，并且获得最多投票的类别被选为实例的最终类别。例如，对于 4 个类别的难题，将构建 4*3/2=6 个二进制模型，每个类别一对。每个模型对其预测的类别投一票，所有模型中投票最多的类别被选为最终预测。因此，如果有四个类别，如果三个模型预测类别 A，两个预测类别 B，一个预测类别 C，则由于它获得了最多的投票，类别 A 将被选中。这样，每个模型的决策都会对投票方案做出贡献，以确定整体预测的类别。

以下部分将讨论用于评估多分类问题的指标。理解这些指标对于评估我们模型的性能以及就模型选择和优化做出明智决策至关重要。

# 多分类问题的指标

在多类分类领域，评估模型性能与开发模型一样重要。有效的评估依赖于利用正确的指标，这些指标可以准确衡量多类分类模型的性能并提供改进的见解。本节揭示了评估多类分类模型性能所必需的各种指标，为选择和采用适合您特定用例的正确指标提供了坚实的基础。

## 混淆矩阵

评估多类分类模型的基本指标之一是**混淆矩阵**。它提供了一个算法性能的可视化，通常是**监督学习**（**SL**）算法。混淆矩阵的每一行代表实际类别的实例，每一列代表预测类别的实例。它是理解模型性能（超越整体准确率）的重要工具，可以深入了解分类错误。

## 精确率

**精确率**（或**阳性预测值**；简称**PPV**）是一个衡量指标，它检查模型做出的所有正预测中真正正预测的数量。高精确率表明假正率低。对于多类分类问题，每个类别的精确率分别计算，可以平均以了解整体性能。

## 召回率

**召回率**（或**灵敏度**或**真正正率**；简称**TPR**）衡量实际正例中真正正预测的数量。对于识别所有实际正例至关重要的问题，这是一个关键指标。与精确率一样，召回率对每个类别进行计算，可以平均以进行整体性能评估。

## F1 分数

**F1 分数**是精确率和召回率的调和平均数，平衡了这两个指标。在处理不平衡数据集时尤其有用，它提供了一个超越准确率的模型性能的更全面视角。

## 宏观和微观平均指标

在多类分类问题中，对精确率、召回率和 F1 分数等指标进行平均，通常称为宏观和微观平均，可以以多种方式完成：

+   **宏观平均**为每个类别独立计算指标，然后取平均值，对待所有类别同等对待

+   **微观平均**将所有类别的贡献汇总起来计算平均指标

## 曲线下面积（AUC-ROC）

另一个重要的指标是**受试者工作特征曲线下面积**（**AUC-ROC**）。虽然它主要用于二元分类问题，但可以通过考虑每个类别与其他类别的关系来扩展到多类分类。

## 对数损失及其在衡量多类模型校准中的应用

对数损失，也称为 **逻辑损失** 或 **交叉熵损失**，是分类问题（包括多类分类）中常用的损失函数。它通过衡量预测的不确定性来量化分类模型的性能。对数损失对错误分类施加惩罚；对自信错误的预测的惩罚更高。

### 数学表示

从数学上讲，多类分类的对数损失可以表示如下：

− 1/N ∑(i=1 to N) ∑(j=1 to M) y_ij log(p_ij)

在这里，以下适用：

+   *N* 是观察的数量

+   *M* 是类别的数量。

+   y_ij 是一个二进制指示符，表示类 *j* 是否是观察 i 的正确分类。

+   p_ij 是观察 *i* 属于类 *j* 的预测概率。

### 使用对数损失来衡量校准

一个校准良好的模型是指其预测概率可靠地反映了预测结果的真正可能性。在多类分类中，校准意味着如果模型预测一个类别的概率为 *p*，那么该类别应该在大约 *p* 百分比的所有实例中发生，这些实例被预测为具有概率 *p*。

#### 对数损失和校准

对数损失是评估多类分类模型校准的适当指标，因为它直接比较了预测概率（预测的置信度）与实际类别。一个校准良好的模型将具有较低的对数损失，因为实际类别的预测概率将更高。

#### 如何使用对数损失评估校准

+   **预测概率**：使用您的多类分类模型预测验证数据集中每个观察的每个类别的概率

+   **计算对数损失**：使用之前显示的公式计算对数损失

+   **解释结果**：较低的对数损失值表示校准更好，因为它表明预测概率更接近实际类别

评估您的多类分类模型的对数损失可以为您提供有关模型校准的见解。具有较低对数损失的模型校准更好，提供更可靠的预测概率估计。理解和使用对数损失作为衡量校准的指标对于确保您的多类分类模型在现实世界应用中表现最佳至关重要。

## Brier 分数及其在衡量多类模型校准中的应用

Brier 分数，或二次损失，是另一个用于评估分类模型性能的流行指标，包括多类分类问题。它量化了预测概率与实际类别之间的差异，对校准良好的模型赋予较低的分值。

### 数学表示

对于多类分类，Brier 分数的计算如下：

1/N ∑(i=1 to N) ∑(j=1 to M) (p_ij − o_ij)²

在这里，以下适用：

+   *N*是观察值的数量。

+   *M*是类别的数量。

+   y_ij 是一个二元指示器，表示类别 j 是否是观察 i 的正确分类。

+   p_ij 是预测观察 i 属于类别 j 的概率。

### 使用 Brier 分数来衡量校准

Brier 分数是一种有效的指标，用于评估多类模型的校准情况，因为它在预测概率与实际结果之间存在较大差异时对模型进行更多惩罚。一个校准良好的模型将具有较低的 Brier 分数，因为其预测概率将更接近实际结果。

### 如何使用 Brier 分数评估校准

Brier 分数提供了一种定量评估多类分类器预测概率校准程度的方法。评估校准对于确保在实际部署中的可靠性至关重要。

要使用 Brier 分数，主要有三个步骤：

1.  **预测概率**：使用你的多类分类模型来估计验证数据集中每个观察值的每个类别的概率。

1.  **计算 Brier 分数**：使用提供的公式计算 Brier 分数。

1.  **解释结果**：较低的 Brier 分数表示校准更好。它表明模型的预测概率与实际结果更一致，从而使模型更可靠。

从本质上讲，使用 Brier 分数来评估你的多类模型的校准有助于确保模型概率估计的可靠性。较低的 Brier 分数，反映了预测概率与实际概率之间差异较小，表明模型校准良好，增强了模型在实际应用中的可信度。理解并利用 Brier 分数作为校准指标对于优化实际场景中多类分类模型的性能至关重要。

理解和运用适当的指标对于评估和改进多类分类模型至关重要。对这些指标有深入的了解可以让我们进行更细致的分析，为开发稳健且高效的多类分类模型以及确保其在实际场景中的成功部署铺平道路。

# 一致性预测如何应用于多类分类问题

一致性预测是一个强大的框架，可以应用于多类分类问题。它提供了一种带有确定性度量的预测方法，这在处理多个类别时尤其有用。

在前面的章节中，我们已经探讨了在多类分类的背景下，一致性预测是如何为给定实例的每个类别分配一个*p*值的。

p 值代表了对该类别的预测置信水平。p 值越高，模型对该实例属于该类别的信心就越强。

将共形预测应用于多类分类的步骤如下：

1.  **校准**：将一部分训练数据，称为校准集，留出。模型在剩余数据上训练。

1.  **预测**：对于每个类别，模型预测类别得分。一致性得分，它衡量预测与校准集中实际结果的一致性，被计算出来。

1.  **p 值计算**：对于一个新的实例，模型为每个类别计算一个非一致性得分。然后，每个类别的 p 值被计算为校准集中具有更高非一致性得分的实例比例。

1.  **输出**：模型输出预测的类别标签及其 p 值。类别按其 p 值排序，为每个预测提供了置信度度量。

将共形预测应用于多类分类问题提供了几个好处：

+   **置信度度量**：共形预测为每个预测提供了一个置信度度量（p 值），这在决策过程中非常有用

+   **有效性**：共形预测提供了有效性的理论保证，这意味着预测的错误率将接近用户设定的显著性水平

+   **效率**：共形预测在计算上效率高，可以应用于大型数据集

+   **通用性**：共形预测可以与任何机器学习算法一起使用，使其成为多类分类问题的多功能工具

下一个部分将探讨如何将 Venn-ABERS 预测器应用于多类分类问题。

## 使用归纳和交叉 Venn-ABERS 预测器进行多类概率分类

Venn-ABERS 是由 Vladimir Vovk、Ivan Petej 和 Valentina Fedorova 开发的一种共形预测方法（*带有和没有有效性保证的大规模概率预测器*，[`papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html`](https://papers.nips.cc/paper/2015/hash/a9a1d5317a33ae8cef33961c34144f84-Abstract.html)），以解决像 Platt 缩放和等调回归这样的经典校准器的局限性。它无论数据分布、数据集大小或底层分类模型如何，都保证了数学有效性。

Venn-ABERS 预测器通过拟合等调回归两次来工作，假设每个测试对象都可以具有标签 `0` 和标签 `1`。这为每个测试对象产生两个概率，*p0* 和 *p1*，代表该对象属于类别 1 的概率。这些概率为类别 1 的概率创建了一个预测区间，并提供了数学保证，即实际概率落在这个区间内。

Venn-ABERS 预测是一个多预测因子，区间（p0, p1）的宽度包含了关于分类置信度的宝贵信息。在关键情况下，Venn-ABERS 预测器输出准确且校准良好的概率，并通过扩大（p0, p1）区间发出“警报”。这个警报表明决策过程应考虑增加的不确定性。

这些概率可以通过*p = p1 / (1 - p0 + p1)*组合成一个单一值，用于实际决策目的。这个类别 1 的联合概率*p*可以用于决策任务。

Valery Manokhin 的研究论文《使用归纳和交叉 Venn-Abers 预测器的多类概率分类》，介绍了一种将 Venn-ABERS 预测器应用于多类分类的方法。您可以通过以下链接访问该论文：http://proceedings.mlr.press/v60/manokhin17a/manokhin17a.pdf。

实验结果表明，所提出的多类预测器在准确性方面优于未校准和现有的经典校准方法，这表明在多类概率分类方面可能取得了实质性的进步。

对于渴望采用这种技术的实践者和研究人员，GitHub 上有一个快速 Venn-ABERS 预测器的 Python 实现，用于二元分类（[`github.com/valeman/Multi-class-probabilistic-classification`](https://github.com/valeman/Multi-class-probabilistic-classification)）。这个教育资源提供了亲身体验实现细节和利用 Venn-ABERS 预测器在现实世界机器学习场景中的实际优势的机会。

提出的使用**归纳**和**交叉-Venn-ABERS 预测器**（**IVAPs**和**CVAPs**）进行多类概率估计的方法，基于将多类分类器转换为二元分类器。在此方法中，二元分类器被训练以区分每个类别与其他所有类别的组合。

例如，在一个有三个类别 A、B 和 C 的三类问题中，训练了三个二元分类器：一个用于区分 A 和（B 或 C），一个用于区分 B 和（A 或 C），一个用于区分 C 和（A 或 B）。然后使用 IVAP 来估计给定测试实例每个类别的概率。IVAP 计算一个类别的概率为将实例分类为属于该类别的二元分类器的比例。

转换成对分类得分和成对类概率的公式使用了论文《具有概率输出的成对神经网络分类器》中介绍的方法（[`proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf`](https://proceedings.neurips.cc/paper_files/paper/1994/file/210f760a89db30aa72ca258a3483cc7f-Paper.pdf)）。

具体来说，如果 *rij* 是从相应的二元模型中得到的类 *j* 上类 *i* 的分数，则类 *i* 的估计概率按以下方式计算。

关键思想是首先使用专门的二元分类器计算每对类之间的成对概率。然后，可以将这些成对概率组合起来，估计所有类别的归一化概率分布：

p i PKPD =  1 ___________ ∑ j:j≠i n   1 _ r ij − (k − 2)

这提供了一种将成对二元分类结果转换为适合多类评估和校准的类概率估计的原则性方法。

在计算概率（这种技术被称为 **PKPD** 方法）之后，对这些值进行归一化是至关重要的，以确保它们的总和为 1。这些成对概率可以通过对成对分类分数/概率应用 IVAPs 和 CVAPs 来获得，这些分数/概率用于校准底层分类模型产生的分类分数。

简而言之，PKPD 方法有助于将二元比较（成对概率）中的概率转换为多类概率。然后，计算出的多类概率被用来将测试对象分类为 *k* 个可能类别之一。这种分类使得可以计算指标，这些指标可以与各种校准算法的性能进行比较。

现在，让我们通过一个现实世界的例子来了解如何将一致性预测应用于多类分类问题。以下是一个代码示例，展示了这一应用。

让我们分析来自 `Chapter_12.ipynb` 笔记本（代码可以在本书的 GitHub 仓库[`github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb`](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_12.ipynb)）的代码。该笔记本演示了一致性预测在多类分类问题中的应用。

多类分类的一般步骤如下：

1.  **数据准备**：

    1.  加载数据集。

    1.  将数据集划分为特征 (*X*) 和目标 (*y*)。

    1.  将数据分为训练集和测试集。

1.  **模型训练**：

    1.  在训练数据上训练一个分类模型。

    1.  使用训练好的模型在测试数据上进行预测。

1.  **应用** **一致性预测**：

    1.  将一致性预测应用于训练好的模型。

    1.  获取预测的置信度和可信度度量。

1.  **评估**：

    1.  使用适当的指标评估模型。

    1.  比较校准模型与原始模型的性能。

1.  使用 `evaluate_model_performance` 函数评估不同模型和校准方法的性能。

1.  它训练模型，进行预测，并使用各种指标（如准确率、对数损失和 Brier 损失）来评估性能。

+   **校准**：

    1.  不同的校准方法，如 Platt、等调和其他方法，被应用于模型中。

    1.  校准模型的预测被评估以分析性能改进。*   `evaluate_model_performance` 函数应用于每个模型。*   每个模型和校准方法的成果被存储，可以进行分析以确定表现最佳的模型和校准方法。

让我们接下来总结本章内容。

# 摘要

在本书的最后一章，我们探索了多类一致性预测这个迷人的领域。我们首先理解了多类分类的概念，这是机器学习中一个普遍的场景，其中实例可以属于许多类别之一。这种理解对于有效地应用一致性预测技术至关重要。

我们接着深入探讨了用于评估多类分类问题的指标。这些指标定量地衡量我们模型的表现，对于有效的模型评估和选择至关重要。

最后，我们学习了如何将一致性预测应用于多类分类问题。本节提供了可以直接应用于您工业应用的实用见解和技术。

到本章结束时，你应该已经获得了在多类分类以及如何有效地将这些问题应用于一致性预测方面的宝贵技能和知识。这些知识将在你作为数据科学家、机器学习工程师或研究人员的旅程中证明是无价的。

我们涵盖了不同的主要主题，包括多类分类问题，我们探讨了多类分类及其在机器学习中的重要性。我们还讨论了多类分类和多标签分类问题的区别。然后我们研究了用于评估多类分类问题的指标。理解这些指标对于评估我们模型的表现和做出关于模型选择和优化的明智决策至关重要。最后，我们学习了如何将一致性预测应用于多类分类问题。本节提供了可以直接应用于您工业应用的实用见解和技术。

本章标志着我们进入一致性预测旅程的结束。我们希望你所获得的知识和技能将在你未来在机器学习领域的努力中大有裨益。祝您学习愉快！
