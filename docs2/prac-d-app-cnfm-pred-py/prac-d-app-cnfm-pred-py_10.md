

# 第十章：自然语言处理的一致性预测

**自然语言处理**（**NLP**）处理人类语言的复杂性，其中不确定性是一个固有的挑战。随着 NLP 模型成为风险敏感和关键应用的核心，确保其可靠性至关重要。一致性预测作为一种有前景的技术，提供了一种量化这些模型预测可信度的方法，尤其是在面对深度学习模型产生的误校准输出时。

在本章中，我们将探索 NLP 一致性预测的世界，了解其重要性，并学习如何利用其力量进行更可靠和自信的预测。

在本章中，我们将涵盖以下主要主题：

+   NLP 的不确定性量化

+   为什么深度学习会产生误校准的预测

+   量化 NLP 问题的各种方法

+   NLP 的一致性预测

+   使用一致性预测构建 NLP 分类器

+   NLP 中用于一致性预测的开源工具

# NLP 的不确定性量化

NLP 中的不确定性量化是模型开发和部署中一个基本但常常被忽视的方面。随着 NLP 模型越来越多地集成到关键应用中——从医疗诊断到金融预测——理解和传达其输出置信水平的需求变得至关重要。不确定性量化提供了一个评估预测可靠性的框架，使用户和开发者能够评估模型的决断力和依赖其结果可能存在的潜在风险。本节深入探讨了 NLP 中不确定性量化的重要性、方法和实际考虑，强调了它在构建稳健和可信的语言模型中的关键作用。

我们现在将探讨自然语言处理（NLP）中的不确定性以及量化 NLP 应用中不确定性的益处和挑战。

## NLP 中的不确定性是什么？

自然语言处理（NLP）的核心是理解人类语言——一种以其丰富性、模糊性和多样性而闻名的媒介。语言使用中的固有可变性、由上下文驱动的含义以及语言结构不断演变的本质使得 NLP 任务本质上具有不确定性。例如，“银行”一词可能指金融机构或河流的一侧，这取决于上下文。

## 量化 NLP 中不确定性的益处

在 NLP 中量化不确定性不仅仅是一个理论练习；它具有以下实际益处：

+   **可信度**：量化不确定性要么增强对特定预测的信心，要么突出需要谨慎的领域。

+   **性能评估**：这通过检查其指标中的不确定性来评估各种模型的有效性。

+   **增强机会**：它能够识别模型可以改进的领域，尤其是在主动学习等场景中。

+   **风险管理**：通过理解预测的不确定性程度，利益相关者可以做出更明智的决策。例如，一个预测情感的自然语言处理模型可能对一条评论是积极的预测有 80%的确定性。了解这一点后，企业可能会优先处理模型确定性较低的评价。

+   **模型透明度**：能够表达其不确定性的模型被认为更加透明和可信。模型的使用者可以更好地理解何时信任模型的输出，何时需要谨慎对待。

+   **模型训练**：在训练阶段，理解高不确定性区域可以指导数据收集工作。如果一个模型对特定数据类型不确定，收集更多此类数据可以导致更稳健的训练。

## 自然语言处理中的不确定性挑战

尽管其重要性不言而喻，但在自然语言处理中管理不确定性具有挑战性。以下是原因之一：

+   **数据稀疏性**：许多自然语言处理任务缺乏所有可能的语言变体的代表性数据，导致模型对较少见的数据点不确定。

+   **语言歧义**：如前所述，根据上下文，单词可以有多种含义，这导致固有的不确定性。

+   **模型复杂性**：深度学习等高级模型有时会像黑盒一样运作，这使得识别不确定性区域变得具有挑战性。

在构建稳健的自然语言处理（NLP）系统中，理解和量化不确定性变得至关重要。随着我们深入本章，我们将探讨一些技术，特别是**一致性预测**，这些技术提供了一种结构化的方法来直面这些挑战。

# 理解为什么深度学习会产生失准的预测

在快速发展的自然语言处理领域，深度学习在使机器以人类曾经独占的方式处理和生成语言方面发挥了关键作用。下一节将介绍深度学习的关键概念和里程碑，这些概念和里程碑对自然语言处理产生了重大影响。

## 自然语言处理中的深度学习简介

**深度学习**是机器学习的一个子集，它依赖于具有许多层的神经网络（因此称为“深度”）来分析各种数据因素。在自然语言处理的背景下，深度学习已经是一个颠覆性的变革，使机器以前所未有的准确性理解和生成人类语言：

+   **架构演变**：这一旅程始于简单的架构，如前馈神经网络和**循环神经网络**（**RNNs**）。后者能够记住过去的信息，在基于序列的任务（如语言翻译）中特别有影响力。后来，更先进的架构，如**长短期记忆**（**LSTM**）和**Transformer 模型**，进一步提升了性能标准。

+   **BERT 和 Transformer**：**双向 Transformer 编码器表示**（**BERT**）的引入是一个重要的里程碑。BERT 通过分析单词的整个上下文（包括单词的左右两侧）在众多 NLP 任务中实现了最先进的成果。BERT 所基于的 Transformer 架构引入了注意力机制，允许模型关注输入文本的特定部分，就像人类在理解语言时关注特定单词一样。

+   **语言模型和大型语言模型**：**大型语言模型**（**LLMs**）如**生成预训练 Transformer**（**GPT**）及其迭代版本，如 ChatGPT，在 NLP 中设定了新的标准。这些模型拥有数十亿个参数，可以生成类似人类的文本，回答问题，甚至帮助进行创意写作。特别是 ChatGPT，在创建能够进行更自然和连贯交互的对话代理方面产生了重大影响。

+   **迁移学习和微调**：这些发展的革命性方面之一是迁移学习的概念。例如 BERT 和 GPT 等模型在庞大的语料库上进行了预训练，并且可以在较小的数据集上针对特定任务进行微调。这种方法使得 NLP 中的深度学习民主化，允许资源有限的团队实现具有竞争力的成果。

随着这些进步，深度学习模型已成为许多现代 NLP 应用的基础，从聊天机器人到搜索引擎。然而，正如我们将在后续章节中探讨的，它们的复杂性和规模引入了挑战，尤其是在校准方面。

## NLP 中深度学习预测的挑战

深度学习无疑提高了 NLP 的能力，但也带来了几个挑战和陷阱。在我们探索 NLP 中的深度学习领域时，我们必须意识到这些问题。一些显著挑战包括以下内容：

+   **模型过度自信**：深度学习模型，鉴于其拟合复杂模式的能力，往往对其预测过度自信。例如，在情感分析中，一个模型可能会以 60%的置信度预测一段文本为正面，而实际上，由于措辞含糊，实际的置信度应该低得多。

+   **数据分布偏移**：NLP 模型通常在特定的数据集上训练，可能没有接触到真实世界输入的全部语言多样性。当面对分布外的数据时，这些模型可能会产生校准不当的预测。

+   **缺乏显式的不确定性建模**：传统的深度学习方法本身不建模不确定性。它们优化准确性，通常以可靠的不确定性估计为代价。

+   **复杂性和非线性**：深度学习模型的复杂架构，特别是多层和非线性激活，有时会导致不可预测的行为，尤其是在处理边缘情况或罕见的语言结构时。

接下来，让我们探讨校准偏差的影响。

## 校准偏差的影响

NLP 模型中的校准偏差不仅仅是一个纯粹学术上的问题。在现实世界的应用中，它可能导致基于错误信息的决策、不恰当的信任，甚至可能产生有害的结果，尤其是在医疗保健、金融和法律系统等敏感领域：

+   **决策风险**：过于自信的模型可能导致利益相关者基于误导性的自信做出决策，可能造成误解或策略上的缺陷。

+   **信任丧失**：如果 NLP 系统频繁表达对错误预测的高度自信，用户可能会对它失去信心。

+   **资源错配**：在自动化系统中，校准不当的模型可能会低效地优先处理任务，在人类干预更合适的情况下浪费计算资源。

认识到这些挑战是第一步。随着我们前进，我们将深入研究一致性预测——这是一种针对困扰自然语言处理（NLP）深度学习模型的校准问题的可行解决方案。

# 量化 NLP 问题不确定性的各种方法

为了解决校准偏差和语言固有的不可预测性的挑战，已经探索了多种量化 NLP 问题不确定性的方法。

现在，我们将探讨贝叶斯方法在不确定性量化中的应用。

贝叶斯不确定性量化方法

贝叶斯方法为建模不确定性提供了一个框架。通过将模型参数视为分布而不是固定值，贝叶斯神经网络提供了与预测相关的不确定性度量。这种概率方法确保模型不仅给出估计，还传达了该估计的置信度或分布。

这些是贝叶斯方法在不确定性量化中的一些例子。

+   **变分推断**是一种近似模型参数后验分布的技术，使网络能够输出用于预测的分布。

+   **贝叶斯神经网络**（**BNNs**）是具有概率分布权重的神经网络。通过从这些分布中进行采样，BNNs 可以产生一系列输出，反映预测的不确定性。

+   **蒙特卡洛 dropout**是一种在推理过程中应用 dropout 的技术。通过多次运行模型并观察输出方差，我们可以了解模型的不确定性。

## 自助方法和集成技术

自助涉及通过重采样从原始训练数据创建多个数据集。通过在这些数据集上训练不同的模型，我们可以捕捉模型的不确定性。不同重采样之间的方差允许我们更稳健地评估输入数据的变化如何影响预测。

现在，我们将探讨一些自助方法和模型集成的一些例子。

+   **Bagging**：简称为自助聚合，涉及在不同的自助样本上训练多个模型。模型之间预测的方差提供了一个不确定性的估计。

+   **模型集成**：结合多个模型的预测也可以捕捉到不确定性。如果基于相同数据但具有不同架构的模型在预测上意见不一致，这表明更高的不确定性。

## 分布外（OOD）检测

识别与训练数据显著不同的输入也有助于不确定性估计：

+   **基于似然的方法**：这些方法比较新数据点的似然性与训练数据。较低的似然性表示更高的不确定性。

+   **对抗训练**：通过训练模型识别对抗性示例，我们可以增强它们识别不确定输入的能力。

考虑到人类语言的固有歧义和细微差别，理解和恰当地运用这些技术在 NLP 中至关重要。每种方法都有其优势和适用场景，因此从业者必须根据他们 NLP 任务的具体情况明智地选择。

# NLP 中的正规预测

正规预测是一种灵活且统计上稳健的不确定性量化方法。它是一个无分布框架，可以在不要求模型重新训练或访问有限的 API 的情况下估计机器学习模型的不确定性。正规预测背后的核心思想是输出一个包含正确输出的预测集，其概率由用户指定。正规预测可以帮助量化语言模型预测中的不确定性。

正规预测是一个提供预测有效置信区间的框架，无论底层机器学习模型如何。在 NLP 领域，由于其固有的歧义、上下文敏感性和语言多样性等挑战，正规预测提供了一种结构化的方法来量化不确定性。

**有效性和效率**是正规预测的两个基本原则。有效性确保预测区域（或集合）以预定义的概率是正确的，而效率确保这些区域尽可能紧凑。

## 正规预测在 NLP 中的工作原理

正规预测的机制基于根据其“奇特性”或非一致性得分对预测进行排序。其想法是理解新观察与先前观察相比有多大的不同：

+   **非一致性得分**：这个得分衡量了新预测与任何 NLP 任务中先前预测的不同程度。例如，非一致性可能基于文本分类中决策边界的距离。

+   **P 值**：P 值是基于非一致性得分计算的，表示预测的置信水平。

## 正规预测在 NLP 中的实际应用

一致性预测不仅仅是一个理论结构；它在自然语言处理中的实际应用范围广泛：

+   **情感分析**：在确定文本片段的情感时，一致性预测可以提供一个或一组可能的情感，每个情感都有其置信度水平

+   **命名实体识别**：一致性预测可以对每个标记的实体给出置信度分数，而不仅仅是标记实体，这有助于精度至关重要的任务

+   **机器翻译**：除了翻译文本之外，一致性预测可以为不同的翻译选择提供置信区间，有助于翻译错误可能产生重大后果的任务

## 使用一致性预测在自然语言处理中的优势

一致性预测，作为不确定性量化领域的一个相对较新的发展，为自然语言处理带来了新的视角和许多好处。随着我们进入一个对可靠和值得信赖的模型需求不断增长的时代，像一致性预测这样的方法脱颖而出，有望解决自然语言处理中的一些固有问题。让我们深入了解将一致性预测整合到自然语言处理任务中的独特优势：

+   **模型无关性**：一致性预测的一个优势是它与任何机器学习模型兼容。一致性预测可以应用于任何统计、机器或深度学习模型。

+   **透明和可解释性**：一致性预测不是作为一个黑盒运行。非一致性分数和结果 p 值提供了可解释的不确定性度量。

+   **适应性**：一致性预测适用于其应用的数据。它不做强烈的分布假设，因此在处理多样化的语言数据时仍然稳健。

将一致性预测引入自然语言处理工具箱为从业者提供了一个有前景的途径来处理人类语言固有的不确定性。提供有效的和可靠的置信度度量有助于构建更稳健和值得信赖的自然语言处理系统。

这里讨论了应用于自然语言处理任务的一致性预测的一个例子，例如基于评论内容的“正面”和“负面”情感类别标签预标记的 IMDB 电影评论：[`github.com/M-Soundouss/density_based_conformal_prediction/tree/master/imdb`](https://github.com/M-Soundouss/density_based_conformal_prediction/tree/master/imdb)。

自然语言处理和大型语言模型的一致性预测是一个新兴且至关重要的研究领域。

该领域的一个显著贡献是 Kumar 等人发表的一篇论文，题为《基于大型语言模型的多选题*回答*的一致性预测》([`arxiv.org/abs/2305.18404`](https://arxiv.org/abs/2305.18404))。

本文深入探讨了如何使用一致性预测量化语言模型中的不确定性，从而为大型语言模型的更可靠和可靠的部署铺平道路，特别是在安全至关重要的场景中。

论文的主要焦点是多项选择题回答任务。通过一系列实验，它展示了一致性预测在推导与预测准确度强相关的不确定性估计方面的有效性。

深入实验设置，作者使用了 LLaMA-13B 模型。这个模型拥有 130 亿个参数，在令人惊叹的 1000 亿个标记上进行了训练，为来自`MMLU 基准`数据集（[`paperswithcode.com/sota/multi-task-language-understanding-on-mmlu`](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)）的 MCQA 问题生成了预测。

实验围绕一个用于训练一致性预测模型的校准集和一个用于测试模型能力的评估集来构建。采用交叉验证方法以确保实验的完整性，确保校准集和评估集是从一致分布中抽取的。

性能指标是多方面的，包括准确度、覆盖率和效率。一个关键的观察结果是，LLaMA-13B 模型的 softmax 输出，尽管平均而言进行了合理的校准，但表现出信心不足和过度自信的倾向，尤其是在概率分布的极端部分。这一观察在诸如形式逻辑和大学化学等主题中尤为明显，这些主题本质上具有更多的模糊性和复杂性，使得它们对 LLM 准确导航变得具有挑战性。

其中一个引人注目的发现是，一致性预测提供的不确定性估计与预测准确度之间存在着强烈的关联。这种关联意味着当模型对其预测表现出更高的不确定性时，它更容易出错。这一见解对于下游应用，如选择性分类，极为宝贵。通过利用这些不确定性估计，可以过滤掉低质量的预测，从而提升整体用户体验。

论文强调了一致性预测作为 LLM 中不确定性量化灯塔的潜力。通过整合这种方法，LLM 可以更加可靠，尤其是在高风险环境中，增强其可信度和扩大其适用范围。

第二篇关键论文是《寻求帮助的机器人：大型语言模型规划者的不确定性对齐》（[`robot-help.github.io`](https://robot-help.github.io)），由普林斯顿大学和 DeepMind 的研究团队发表。

在机器人和人工智能领域，赋予机器人辨别不确定性的能力是一个关键挑战。本文针对这一挑战进行了探讨，特别是针对通过语言指令控制的机器人。语言固有的灵活性为人类提供了自然接口，用于传达任务、上下文信息和意图。它还便于人类在机器人遇到不确定性时提供澄清。

近期进展展示了 LLMs 在规划方面的潜力。这些模型可以解释和响应非结构化语言指令，生成时间扩展的计划。这些 LLMs 的优势在于它们能够利用预训练过程中所获得的广泛知识和丰富上下文，从而提高抽象推理能力。然而，当前 LLMs 的一个显著障碍是它们倾向于“幻觉”。换句话说，它们倾向于生成具有高度自信的输出，虽然看似合理，但可能是不正确的，并且没有基于现实。

这种对输出的过度自信可能是有害的，尤其是在基于 LLM 的机器人规划中。当在现实世界设置中提供通常充满固有或无意模糊性的自然语言指令时，这种情况会进一步加剧。误解此类指令可能导致不希望看到的行为，在极端情况下，甚至可能是不安全的行为。

为了说明，本文提供了一个例子，其中一台被分配加热食物的机器人被指令将碗放入微波炉中。在存在多个碗的情况下，这样的指令变得模糊。此外，如果其中一个碗是金属的，将其放入微波炉中将是危险的。理想情况下，机器人应该识别其不确定性并寻求澄清。虽然基于语言规划的前期工作要么忽视了这种澄清的需要，要么过度依赖广泛的提示，但本文介绍了**KNOWNO**。

KNOWNO 是一个旨在衡量和调整基于 LLM 规划者不确定性的框架。它确保这些规划者了解自己的局限性，并在需要时寻求帮助。KNOWNO 的基础建立在符合预测理论之上，该理论在完成任务时提供统计保证，同时在复杂的多步骤规划设置中最大限度地减少对人类干预的需求。在各种模拟和真实机器人设置中的实验证明了该框架的有效性。这些实验涵盖了具有不同模糊模式的任务，从空间不确定性到数值不确定性，从人类偏好到 Winograd 模式。

本文提出 KNOWNO 作为一种有潜力的轻量级方法来建模不确定性。它能够无缝地补充并扩展基础模型日益增长的能力。通过利用符合预测，LLMs 可以变得更加可靠，尤其是在精度和安全至关重要的场合。

# 摘要

在本章中，我们探讨了 NLP 领域中固有的不确定性挑战。认识到 NLP 模型在当今关键系统中的关键作用，本章强调了确保这些模型的预测是可信和可靠的的重要性。本章介绍了一致性预测作为解决深度学习模型输出中出现的误校准问题的解决方案，提供了一种稳健地量化预测置信度的方法。在本章中，您获得了对 NLP 中不确定性量化复杂性的洞察，了解了为什么深度学习模型经常产生误校准预测的原因，以及量化 NLP 中不确定性的各种方法。最后，我们深入研究了针对 NLP 任务定制的一致性预测技术。

在本章结束时，您应该对 NLP 中不确定性的挑战、一致性预测的优点和机制，以及如何有效地将此技术应用于 NLP 问题的实用知识有一个全面的理解。

在下一章中，我们将深入探讨不平衡数据的迷人世界，展示一致性预测如何解决处理此类场景中存在的挑战。

# 第四部分：高级主题

本部分将提供如何使用一致性预测来解决不平衡数据问题的示例，向您介绍可用于多类分类问题的各种一致性预测方法。

本节包含以下章节：

+   *第十一章*, *处理不平衡数据*

+   *第十二章*, *多类一致性预测*
