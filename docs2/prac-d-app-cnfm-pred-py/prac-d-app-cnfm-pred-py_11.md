# 11

# 处理不平衡数据

本章深入探讨了不平衡数据的迷人世界，以及如何使符合预测成为处理此类场景的转折点。

不平衡数据集是机器学习中常见的挑战，往往导致预测偏差和模型表现不佳。本章将为您提供解决这些问题的知识和技能。

我们将了解不平衡数据，并学习为什么它在机器学习应用中构成一个重大挑战。然后，我们将探讨传统上用来解决不平衡数据问题的各种方法。

本章的重点是符合预测在解决不平衡数据问题中的应用。

本章将通过以下主题来展示如何通过符合预测解决不平衡数据问题：

+   介绍不平衡数据

+   为什么不平衡数据问题难以解决

+   解决不平衡数据的方法

+   如何将符合预测应用于帮助解决不平衡数据问题

加入我们这次启发性的旅程，我们将揭示不平衡数据的复杂性，并通过符合预测发现创新解决方案。

到本章结束时，您将深入了解如何有效地应用符合预测来处理不平衡数据，从而提高机器学习模型的性能和可靠性。

# 介绍不平衡数据

在机器学习中，我们经常遇到需要更加平衡的数据集。但一个数据集不平衡意味着什么？

一个不平衡的数据集是指不同类别样本分布不均匀的情况。换句话说，某一类别的样本数量显著多于其他类别。这在许多实际应用中很常见。例如，在用于欺诈检测的数据集中，非欺诈交易（多数类别）的数量通常远高于欺诈交易（少数类别）。

想象一个记录罕见疾病实例的医疗数据集。大多数患者将无病，导致大量健康记录的大类别，而受疾病影响的患者比例极小。这种类别分布的不平衡就是我们所说的不平衡数据。

不平衡数据可能导致预测建模中的重大挑战。由于机器学习算法的本质是设计来最小化错误并最大化准确率，当在不平衡数据上训练时，它们往往偏向于多数类别，这通常是以牺牲少数类别的预测准确率为代价的。

在我们的医学示例中，一个简单的模型可能会预测没有人患有疾病，由于健康记录的数量巨大，因此实现了高准确率，但未能识别出少数几个确实患有疾病的病例。这样的模型可能会因为不平衡而误导，导致在现实世界中产生严重的后果。

不平衡数据的性质在各个行业中普遍存在。从金融中的欺诈检测，欺诈交易虽然罕见但至关重要，到气象学中的自然灾害预测，感兴趣的（例如，龙卷风或地震）事件虽然不常见但意义重大，不平衡带来了专业人士必须能够应对的挑战。

认识和理解不平衡数据是有效解决其挑战的第一步。随着我们继续前进，我们将深入探讨为什么这些问题特别难以解决，并探讨处理它们的方法，重点关注符合预测的潜力。

# 为什么不平衡数据问题难以解决

解决不平衡数据并非易事，原因如下。挑战的核心是传统机器学习算法的性质。这些算法最小化总体错误，并假设类别分布平衡。当面对不平衡数据集时，这就会成为问题，导致对多数类别的明显偏差。

当我们意识到在许多情况下，少数类别的信息更为重要时，这个问题的重要性就变得显而易见了。以欺诈检测或医疗诊断为例。虽然欺诈交易或疾病实例可能很少，但它们的正确识别至关重要。然而，在倾斜数据上训练的模型可能会经常倾向于预测多数类别，表面上达到很高的准确率，但未能实现其核心目标。

更进一步，传统的指标，如准确率，在这里有时并不是我们的朋友。一个只有 2%欺诈交易的数据库可能会让我们产生自满：一个简单地将每笔交易预测为合法的模型会吹嘘 98%的准确率，掩盖了它在检测欺诈方面的彻底失败。

关于这个主题的学术文献迷宫使事情变得更加困难。由于有许多方法和理论，确定哪些真正有效就像在 haystack 中找针一样。经常讨论的方法，如**合成少数过采样技术**（**SMOTE**），需要经过仔细分析来评估其实际的有效性。

给那些刚开始学习数据科学的人一些建议：用敏锐的眼光看待不平衡分类的领域。并非所有闪光的东西都是金子。虽然寻找一个神奇的解决方案很有吸引力，但有时它关乎重新定义问题。通过转变我们的视角，关注更相关的指标，我们可以找到一条出路，做出明智而有效的决策。

我们现在将探讨一些处理不平衡数据的常见方法。

# 解决不平衡数据的方法

面对不平衡类别分布的挑战时，我们应该转向何处？虽然该领域的大部分资源建议使用重采样方法，包括欠采样、过采样以及如 SMOTE 等技术，但重要的是要注意，这些建议通常回避了基础理论和实际应用。

在深入探讨不平衡类别的解决方案之前，首先理解其潜在性质是至关重要的。这个问题可能更适合在特定场景中解决，例如异常检测，而不是在传统的分类问题中。

在特定场景中，类别不平衡不是静态的。它可能演变或可能受到对适当标签的需求的影响。例如，考虑一个监控系统网络流量以检测潜在安全威胁的系统。最初，威胁可能很少，导致类别不平衡。然而，随着系统的成熟和更多潜在危害被识别和标记，不平衡可能发生变化，减少或逆转偏差。

解决这种动态不平衡需要自适应方法，这些方法可以在数据特征变化时重新校准，确保模型在其生命周期内保持有效。

当这些挑战不存在时，明智的做法是将重点转向评估指标。我们之前已经检查了如对数损失和 Brier 损失等指标，这些指标在评估模型校准方面至关重要。值得注意的是，使用这些指标与重采样技术可能会对模型的校准产生不利影响。

对于不平衡数据，一个经常提出的补救措施是通过各种重采样技术修改数据集。

重采样方法是用来平衡不平衡数据集中类别分布的技术。这些方法可以大致分为两大类：

+   **过采样**：这涉及到增加少数类别的实例数量。方法包括以下几种：

    +   **随机过采样**：这涉及到复制少数类别的随机记录。

    +   **SMOTE**：SMOTE 通过遵循特定的算法在特征空间中为少数类别创建合成样本。它首先随机选择一个少数类别实例，并找到其 k 个最近的少数类别邻居。SMOTE 从这些邻居中随机选择一个，并计算其特征与所选实例特征之间的差异。然后，它将这个差异乘以 0 到 1 之间的随机数，并将结果加到原始实例的特征上。这个过程生成一个新的、合成的数据点，它位于连接实际实例与其所选邻居的实际线段上，从而有效地创建出对构建更平衡数据集有贡献的合理新实例。

    +   **自适应合成（ADASYN）采样**：通过遵循它们的密度分布为少数类创建合成实例。对于比容易学习的样本更具学习挑战性的少数样本，会产生额外的合成数据。

+   **欠采样**：这涉及到减少多数类的实例数量。方法包括以下几种：

    +   **随机欠采样**：这涉及到随机消除多数类实例。

    +   **Tomek 链接**：这识别了最近邻类中实例的对，并从这对中移除多数类实例。

    +   **聚类中心**：这种方法用 k-means 算法的聚类中心替换多数样本的聚类。

    +   **邻域清洗规则**：这种方法结合了欠采样和**编辑最近邻**（**ENN**）方法，以去除被 KNN 分类器错误分类的多数类实例以及被错误分类的少数类实例。

+   **结合过采样和欠采样**：可以使用技术来同时过采样少数类和欠采样多数类以达到平衡。

+   **集成重采样**：这涉及到通过重采样创建多个平衡子集，并通过构建模型集成。

虽然重采样方法可以帮助平衡类分布，但它们并不总是能提高模型性能，特别是在校准方面。在单独的、未受干扰的验证集上评估模型，并考虑其他策略，如选择适当的评估指标，是至关重要的。

尽管像 SMOTE 这样的重采样方法多年来一直被视为潜在解决方案，但并没有证据表明这些方法在广泛的数据库集上都能有效工作。例如，在 Kaggle 竞赛中，SMOTE 从未成功作为获胜方案的一部分被使用。

多年来，重采样方法，尤其是 SMOTE，一直被推崇为解决不平衡数据集挑战的潜在解决方案。然而，对这些方法有效性的深入研究描绘出一幅更为复杂的图景。尽管它们在文献和教程中被广泛提及，但支持它们在多样化数据集上有效性的实证证据却明显不足。这一点在 Kaggle 竞赛的世界中得到了证明，在那里精确度、创新和有效性至关重要。值得注意的是，SMOTE 和类似策略很少，如果不是从未，成为获胜方案的一部分。这不仅仅是一个统计异常或巧合。它强调了深刻的观察：虽然这些方法可能在某些情况下提供表面上的缓解，但它们并不普遍适用或可靠有效。任何追求尖端性能的从业者都应该以健康程度的怀疑态度和彻底的验证来对待重采样方法。

Ruben Van Den Goorbergh、Maarten van Smeden、Dirk Timmerman、Ben Van Calster 的研究论文《使用逻辑回归对类别不平衡纠正对风险预测模型的影响：说明和模拟》探讨了类别不平衡调整对逻辑回归模型性能的影响。研究仔细审查了模型的常规和岭回归惩罚版本，评估这些纠正如何影响它们的歧视能力、校准准确性和分类有效性。

论文分析了随机欠采样和 SMOTE 等技术，利用蒙特卡洛模拟和针对卵巢癌诊断的真实世界案例研究。

有趣的是，尽管这些纠正方法一致导致模型校准不准确（对落入少数类别的可能性高估明显），但它们并不一定增强了通过接收者操作特征曲线下的面积来衡量的歧视能力。然而，它们确实提高了分类指标，如敏感性和特异性。仅通过调整概率阈值就可以实现类似的分类结果。

论文认为，类别不平衡纠正技术可能会损害预测模型的性能，特别是在校准方面。研究确定，结果的不平衡并不一定构成问题，而试图纠正这种不平衡可能会降低模型的性能。

论文的研究结果表明，类别不平衡本身并不固有地存在问题，而纠正它的努力可能会无意中降低模型性能。

在数据科学中，区分预测和分类至关重要。分类往往要求做出过早的决定，将预测与决策过程合并，可能会忽视实际决策者的考虑。这在决策成本转移或数据采样标准改变时尤其如此。另一方面，预测保持中立，作为任何决策者的工具。

在他的文章《分类与预测》([`www.fharrell.com/post/classification/`](https://www.fharrell.com/post/classification/))中，Frank Harell 认为，分类可能导致草率的决策，其在机器学习中的应用有时是误导性的。另一方面，概率建模量化了潜在的模式，通常更紧密地与项目的核心目标相一致。

当结果明确时，分类最为合适，预测者提供几乎确定的预测结果。然而，许多机器学习爱好者倾向于使用分类器，忽视了深深植根于统计学中的概率思维的丰富性。一个例子是将逻辑回归频繁误分类为仅仅是一种分类工具，而实际上它提供了丰富的概率估计。

认为二元决策需要二元分类是一种误解。通常，决策可能是收集更多数据或采取分阶段的方法。例如，医生可能会根据不断发展的症状选择渐进式治疗，而不是一开始就做出二元决策。

考虑一个高清晰度场景，例如光学字符识别。在这里，结果主要是确定性的，机器学习分类器表现卓越。然而，当存在内在变异性时，例如在预测疾病结果时，概率估计变得至关重要。它们本质上提供了误差范围，帮助决策者理解相关的风险。

在不平衡场景中，分类器也存在挑战。例如，在一个绝大多数为非疾病患者的数据集中，一个简单的分类器可能会将所有人标记为非疾病，从而实现高准确率，但在实际检测中却失败了。解决这种不平衡通常涉及诸如子采样等实践，这可能导致更多问题。相比之下，逻辑回归可以通过为不同的数据集或流行度重新校准来优雅地处理这种情况。

准确性指标的选取也是至关重要的。选择简单的准确性度量可能会导致误导性的模型。相反，应该关注更细微且统计上可靠的准确性评分规则。

总之，虽然分类器可能适用于具有高清晰度结果的确定性场景，但对于大多数具有内在变异性及细微差别的现实世界情况，基于概率的模型，如逻辑回归，更为合适、灵活且具有洞察力。

重采样方法的问题在于它们破坏了校准，这对于决策至关重要；重采样技术并没有增加任何新信息。SMOTE 论文被广泛接受，并获得了超过 25K 次的引用，这是非常不幸的，特别是考虑到该论文已经 20 年历史，仅使用了几个数据集，并使用了一些弱分类器，如 C4.5（决策树分类器）、Ripper（基于规则的算法）和朴素贝叶斯分类器。

该论文还关注了不适当的指标，仅关注**曲线下面积**（**AUC**）和 ROC 凸包，而没有考虑测量分类器校准的指标。因此，该论文未能报告 SMOTE 对校准产生的负面影响。

在下一节中，我们将探讨有效应对机器学习中不平衡数据集挑战的策略。

# 解决不平衡数据的方法

解决不平衡数据的问题不仅仅是实现平衡的类别分布；它涉及到理解问题的细微差别，并采取涵盖模型性能所有方面的整体方法。让我们来探讨这些方法：

+   **理解问题**：第一步是对问题有深入的理解。重要的是要辨别数据不平衡的原因。是因为数据的性质，还是由于数据收集中的某些外部因素或偏差？识别根本原因可以为最有效的策略提供见解。

+   **优先考虑校准**：一个经常被忽视的关键方面是校准。模型提供反映真实可能性的概率估计的能力至关重要，尤其是在基于这些概率做出决策时。确保模型校准良好通常比单纯的类别分离更为关键。

+   **超越 ROC AUC 的指标**：虽然**接收者操作特征曲线下的面积**（ROC AUC）是一个流行的指标，但仅仅依赖它可能会误导，尤其是在数据不平衡的数据集中。纳入能够捕捉校准本质的指标至关重要。例如，**预期校准误差**（ECE）、对数损失和 Brier 分数等指标，我们在前面的章节中已经探讨过，它们提供了对模型性能的更全面理解。

+   **重采样技术**：尽管过采样、欠采样和 SMOTE 等技术被宣传为潜在解决方案，但理解它们的含义至关重要。虽然它们可能平衡类分布，但它们不一定总是改善或维持模型的校准。因此，任何重采样都应该谨慎进行，并且结果模型应该在未接触的验证集上严格评估。

+   **成本敏感学习**：另一种方法是给少数类和多数类的误分类分配不同的成本。通过这样做，算法在训练过程中内在地给予少数类更多权重，旨在减少更昂贵的错误。

+   **阈值调整**：通过调整决策阈值（对于二分类通常为默认值 0.5）来远离，可以在少数类中表现更好。这关乎于在精确度和召回率之间找到平衡，当现实世界中假阳性与假阴性的成本不同时，这种技术尤其有效。

最终目标是通过构建能够区分类别并提供校准可靠概率估计的有效模型。强调理解、校准和正确指标的多方面方法是解决数据不平衡问题的途径。

接下来，我们将探讨如何将符合性预测应用于帮助解决数据不平衡问题，并探讨其增强数据分析的潜力。

# 通过应用符合性预测解决数据不平衡问题

符合性预测是一种可以应用于处理数据不平衡问题的技术。以下是它可以用作的一些方式：

+   **优雅地处理不平衡数据集**：一致性预测可以优雅地处理大型不平衡数据集。它严格定义了所需的相似度水平，消除了任何歧义。它可以处理严重不平衡的数据集，其比例为 1:100 到 1:1000，而无需过采样或欠采样。

+   **局部聚类一致性预测**（**LCCP**）：LCCP 在一致性预测框架内采用双层分区方法。最初，它根据类别分类将不平衡的训练数据集分割成子集。然后，它进一步使用聚类技术将多数类别的示例进一步分割成子集。LCCP 的目标是在提高预测过程效率的同时，为其预测提供可靠的置信水平。

+   **蒙德里安一致性预测**（**MCP**）：这可以处理不平衡数据集。它根据各自标签对数据进行分类，并为每个类别分配一个独特的显著性水平，确保在不同类别之间保持预测的有效性。

+   **非一致性评分**：一致性预测的核心是非一致性度量，它根据新观察结果相对于训练数据“奇怪”的程度进行排名。这个度量可以适应不平衡数据集，为少数类赋予更多权重，确保模型对与该类相关的模式更加敏感。

+   **具有有效性的校准**：一致性预测保证如果我们声称一个预测区间具有 95%的置信水平，那么在长期来看，它将包含实际结果 95%的时间。这种内置校准，即使在不平衡数据集中也能保持，确保预测区间或集合真正反映了模型的不确定性。

+   **与底层模型的灵活性**：一致性预测并不局限于特定的机器学习算法。这意味着，即使在处理不平衡数据的情况下，从业者也可以选择表现最佳的基模型（基于树的算法、神经网络或线性模型），然后应用一致性框架以获得可靠的预测。

+   **透明性和可解释性**：一致性预测框架的透明性质允许简单的解释。这种透明性对于不平衡数据集来说非常有价值，使利益相关者能够理解为什么做出特定的预测，以及模型对这些预测的确定性。

+   **适应变化的分布**：不平衡数据的一个挑战是少数类的分布可能会随时间变化。由于它强调根据新观察的非一致性进行排名，一致性预测可以适应这些变化，确保即使底层数据分布演变，预测仍然保持校准。

一致性预测提供了一种框架，可以适应以各种方式处理不平衡数据集，为机器学习中这个常见问题提供潜在解决方案。虽然分类现在很常见，但最终目标是实现明智的决策，这需要即使在有偏的类别数据中也能提供可靠的概率估计。

## 使用 Venn-Abers 预测器解决不平衡数据

在机器学习不断发展的世界中，解决分类问题已经变得很常见。从区分猫和狗到更复杂的挑战，分类的真正目的不仅仅是标记；它还在于促进明智的决策。为此，仅仅类别标签是不够的。我们需要良好的类别概率校准。

大多数数据科学家，尤其是在他们职业生涯早期的人，倾向于使用标准指标如准确率、精确率和召回率来评估分类模型。虽然这些指标对于更直接的任务很有洞察力，但它们对于更复杂、更现实的问题可能会产生误导。分类的真正本质在于校准，这是入门课程中经常被忽视的一个方面。

对于从事关键应用（从金融到医疗保健）的专业人士来说，分类器的校准至关重要。分类问题的关键在于做出明智的决策。这些决策围绕着各种场景的概率，每种场景都有潜在的成本和收益。

以银行业为例。如果一个模型仅仅预测一个潜在客户不会违约，它需要为决策提供更多深度，尤其是在涉及大量资金的情况下。所需的是一个提供各种结果良好校准概率的模型，以便对风险和回报进行细致的评价。

然而，出现了一个重大挑战：许多机器学习模型本身并不产生类别概率。即使它们能产生，这些概率也常常被校准不当，导致错误的决策。这在关键领域尤其令人担忧。例如，由于概率校准不当而误解障碍物的自动驾驶汽车可能导致事故。

那么，如何才能实现更好的校准呢？经典方法，如 Platt 的缩放法([`en.wikipedia.org/wiki/Platt_scaling`](https://en.wikipedia.org/wiki/Platt_scaling))和等调回归([`en.wikipedia.org/wiki/Isotonic_regression`](https://en.wikipedia.org/wiki/Isotonic_regression))，是早期的解决方案。然而，这些方法存在局限性，通常根源于限制性假设，这阻碍了它们在多样化数据集上的有效性。

进入**Venn-Abers 预测器**，这是分类器校准中的希望灯塔。Venn-Abers 预测器，符合性预测框架的一个子集，承诺了一种更稳健的校准方法。与传统的不同，它们不依赖于过于简化的假设，并提供了适用于当今复杂数据集的更通用的校准工具。

从本质上讲，如果你想在 2022 年及以后充分利用机器学习分类器的潜力，Venn-Abers 和更广泛的符合性预测框架值得探索。它们可能是解锁良好校准、可靠的机器学习模型的关键。

Venn-Abers 预测器在机器学习中脱颖而出，为测试数据标签提供概率驱动预测。使它们与众不同的地方在于它们内置的校准保证。这种保证建立在数据观察通常独立来源于一致分布的典型前提之上。

Venn-Abers 方法的核心灵感来源于等调回归。它精炼了 Zadrozny 和 Elkan 开创的概率预测校准方法。与 Platt 的缩放器、等调回归等技术相比，Venn-Abers 预测器配备了固有的数学证明，确保其无偏有效性。

Venn-Abers 预测器的一个有趣特性是它们能够为*类别 1*标签生成双重概率预测。这种双重输出捕捉了预测不确定性的范围。因此，这些预测器提供了校准预测并揭示了与每个预测相关的内在置信度。这使得它们成为增强基于概率预测校准的无价工具。以下是方法：

+   **真实生活的概率区间**：Venn-Abers 预测器在提供校准概率区间方面表现出色。这确保了它们产生的概率真正代表了事件的实际可能性，消除了过度自信或低估的陷阱。

+   **跨模型的通用性**：Venn-Abers 校准的美丽之处在于其适应性。无论你是在处理决策树、随机森林，甚至是 XGBoost 模型，Venn-Abers 都可以重新校准它们，微调过于雄心勃勃和过于谨慎的模型以提高其准确性。

+   **具有有效区间的增强决策支持**：预测器不仅停留在标签上。对于每一次预测，尤其是来自通常复杂的模型（如随机森林和 XGBoost）的预测，Venn-Abers 提供概率区间。这个区间的跨度是预测可靠性的晴雨表。

Venn-Abers 预测器对于那些在处理不平衡数据问题中航行的人来说是一盏灯塔。它们精炼了各种机器学习模型的预测准确性，并为用户提供可信的概率区间，使决策更加明智和自信。

为了说明不平衡数据问题中的各种问题，我们将使用以下笔记本：`https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_11.ipynb`

本笔记本将探讨处理不平衡类别问题的各种方法，并将符合性预测应用于校准类别概率。

我们将使用 Kaggle 的信用卡欺诈检测数据集：https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

该数据集包含 2013 年 9 月欧洲持卡人的信用卡交易数据。交易发生在两天内，共有 492 笔欺诈交易，占 284,807 笔交易中的 0.17%。数据集高度不平衡，正类（欺诈交易）占所有交易的 0.17%。

该数据集包含由 PCA 变换得到的数值特征；由于保密性和隐私问题，原始特征已被保留。

特征`V1`、`V2`、... `V28`是使用 PCA 获得的主成分：

+   唯一保留的原始特征是`Time`和`Amount`

+   特征`Time`包含每个交易相对于数据集中第一个交易的时间（以秒为单位）

+   特征`Amount`是交易金额

+   `label`类是需要预测的因变量（标记为 1 的欺诈交易）

我们将使用各种分类器，包括 XGBoost、LightGBM、CatBoost、随机森林和逻辑回归等流行分类器。

## 信用卡欺诈检测笔记本的关键见解

在我们对信用卡欺诈检测数据集的探索中，我们发现了几个关键见解，这些见解可以重塑我们对不平衡数据的处理方法：

+   **拥抱简单性**：最有效的策略通常是保持数据不变。与复杂的重采样技术相比，简约的方法有时可以产生更优的结果。

+   **重新审视不平衡**：与其将不平衡数据视为需要直接解决的困境，不如理解不平衡并不总是根本问题。追求的目标不应该是平衡天平，而应该从数据中提取有意义的见解，无论分布如何。

+   **稳健性度量指标的力量**：度量指标的选择可以决定你的分析成败。通过采用一套全面的度量指标，你可以准确定义问题并为实际解决方案铺平道路。

+   **校准的核心作用**：在校准现实世界的决策场景中，特别是在关键应用中，校准是不可协商的。准确的概率估计至关重要，确保决策基于可靠的数据。

+   **重采样的双刃剑**：虽然重采样方法可能看起来很有希望，但它们通常会损害模型的校准。我们的分析表明，这些技术可能会降低校准指标，如 ECE、对数损失和 Brier 分数。

+   **一致性预测** **作为灯塔**：在处理不平衡数据带来的挑战和重采样的潜在陷阱时，一致性预测成为一线希望。它提供了一种可靠的方法来校准概率，确保即使在重采样之后，数据仍然有利于明智的决策。

通过内化这些见解，我们可以以更精细的视角来处理不平衡数据集，优先考虑有意义的分析而非表面的修复。

# 摘要

在机器学习中，不平衡数据集的挑战往往导致预测偏差和模型结果受损。本章深入探讨了这类数据集的复杂性，并通过一致性预测，一种处理这些场景的突破性方法，照亮了前进的道路。

传统方法，如重采样技术以及度量标准，如 ROC AUC，往往无法有效解决不平衡问题。此外，它们有时甚至会导致结果更加偏斜。另一方面，一致性预测作为一种稳健的解决方案，提供了校准和可靠的概率估计。

这些方法的实际应用通过 Kaggle 的信用卡欺诈检测数据集进行说明，这是一个固有的不平衡数据集。这种探索强调了理解数据、使用稳健的度量标准以及一致性预测的变革潜力。

从本质上讲，尽管不平衡数据带来挑战，但从业者可以使用如一致性预测等正确工具，朝着校准和有洞察力的预测方向前进。

在本书的下一章中，我们将深入探讨多类一致性预测的迷人世界。本章将向您介绍各种可以有效地应用于多类分类问题的一致性预测方法。
