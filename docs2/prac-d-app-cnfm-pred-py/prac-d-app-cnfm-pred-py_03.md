

# 一致性预测的基础

本章将深入探讨**一致性预测**，这是一个强大且多功能的概率预测框架。一致性预测允许在机器学习应用中有效地量化不确定性。通过学习和利用一致性预测技术，您将能够做出更明智的决策，并更有效地管理与数据驱动解决方案相关的风险。

本章将涵盖一致性预测的数学基础。您将学习如何准确测量预测伴随的不确定性。您还将熟悉非一致性度量，掌握预测集的概念，并能够以全面和有意义的方式评估您模型的性能。通过本章，您将获得在各个学术和工业领域中非常有价值的能力，在这些领域中，理解与预测相关的不确定性是至关重要的。

在本章中，我们将涵盖以下主要内容：

+   一致性预测的基础知识

+   一致性预测的基本组件

通过掌握本章中介绍的概念和技术，您将能够充分利用一致性预测的力量，并有效地将其应用于您的工业应用中。

# 一致性预测的基础

在本节中，我们将涵盖一致性预测的基础知识。一致性预测有两种变体——**归纳一致性预测**（**ICP**）和**归纳一致性预测**（**TCP**）。我们将讨论一致性预测框架的优势，了解一致性预测的基本组件和非一致性度量的不同类型。我们还将学习如何使用非一致性度量在分类任务中创建概率预测集。

## 定义和原则

一致性预测是一种机器学习框架，它量化不确定性以产生概率预测。这些预测可以是分类任务的预测集或回归任务的预测区间。一致性预测在为统计、机器学习和深度学习模型提供有价值附加功能方面具有显著优势，这些功能可以增强对预测的信心。

此外，它还是唯一提供强大数学保证的不确定性量化框架，即错误率永远不会超过用户确定的显著性水平。简单来说，一致性预测模型总是生成有效且无偏的预测集和预测区间，这是做出明智决策的关键方面。

想要获取全面资源，请访问 *Awesome Conformal Prediction* ([`github.com/valeman/awesome-conformal-prediction`](https://github.com/valeman/awesome-conformal-prediction))。这是关于一致预测最全面、专业整理的资源。随着时间的推移，一致预测已经发展成为一个广泛的框架，适用于与任何底层点预测模型一起使用，无论数据集的大小、底层点预测模型或数据分布如何。

今天，一致预测的原则可以表达如下：

+   **有效性**：一致预测的目标是创建**预测区域**（例如，对于分类任务的**预测集**或对于回归任务的**预测区间**），这些区域以用户指定的置信水平包含实际的目标值。目标是达到至少与用户定义的置信水平一样大的覆盖概率。例如，如果用户选择 95%的置信水平，预测区域（集或区间）应该至少在 95%的时间内包含正确的目标值。

+   **效率**：一致预测旨在生成尽可能小的预测区间或区域，同时保持所需的置信水平。这种方法确保预测有效且精确，同时传达有用的信息。

+   **适应性**：一致预测旨在生成对个别示例具有适应性的预测集。对于难以预测的示例，预测集预计会更宽，以考虑到预测的不确定性。

+   **无分布依赖性**：一致预测是一个多才多艺且稳健的框架，可以用于各种数据类型和机器学习任务，因为它不依赖于底层数据分布的特定假设。一致预测所做的唯一假设是数据可交换性，这是一个比**独立同分布**（**IID**）数据要求更宽松的条件。尽管如此，一致预测在许多超出可交换性的应用中取得了成功，包括时间序列和预测应用。

+   **在线适应性**：一致预测可以在在线和离线场景中运行。在在线设置中，一致预测器可以调整到新的数据点，并相应地修改其预测，而无需重新训练模型。

+   **兼容性**：一致预测是一个灵活的框架，可以无缝集成到各种统计和机器学习技术中，包括决策树、神经网络、支持向量机、提升树（XGBoost/LightGBM/CatBoost）、袋装树（随机森林）和深度学习模型。这是通过定义一个适当的非一致性度量来实现的，该度量可以应用于任何现有的机器学习算法。

+   **非侵入性**: 符合预测不需要对统计、机器学习或深度学习点预测模型进行更改。这对于已经部署到生产中的模型尤为重要。符合预测可以作为不确定性量化层添加到任何已部署模型之上，无需任何修改或了解预测模型的工作方式。

+   **可解释性**: 符合预测生成易于理解和提供明确测量不确定性的预测集和区间。这使得它成为金融、医疗保健和自动驾驶汽车等行业的有价值工具，在这些行业中，理解预测不确定性至关重要。

在下一节中，我们将探讨符合预测器的基本组件，并了解非一致性度量。

# 符合预测器的基本组件

我们现在将探讨符合预测器的基本组件：

+   **非一致性度量**: 非一致性度量是一个函数，用于评估新数据点与现有数据点之间的差异程度。它将新的观测值与整个数据集（在符合预测的完整归纳版本中）或校准集（在最受欢迎的变体——**ICP**中）进行比较。非一致性度量的选择基于特定的机器学习任务，如分类、回归或时间序列预测，以及底层模型。本章将探讨几个适合分类和回归任务的非一致性度量。

+   **校准集**: 校准集是数据集的一部分，用于计算已知数据点的非一致性得分。这些得分是建立新测试数据点的预测区间或区域时的参考。校准集应该是整个数据分布的代表样本，通常是随机选择的。校准集应包含足够数量的数据点（至少 500 个）。如果数据集较小，不足以保留足够的校准集数据，用户应考虑其他符合预测的变体——包括**TCP**（例如，参见*Mastering Classical Transductive Conformal Prediction in Action* – [`medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b`](https://medium.com/@valeman/how-to-use-full-transductive-conformal-prediction-7ed54dc6b72b))）。

+   **测试集**: 测试集包含用于生成预测的新数据点。对于测试集中的每一个数据点，符合预测模型使用非一致性度量来计算非一致性得分，并将其与校准集的得分进行比较。通过这种比较，符合预测器生成一个包含目标值并具有用户定义置信水平的预测区域。

所有这些组件协同工作，创建了一个一致预测框架，该框架有助于在广泛的机器学习任务中进行有效的和高效的不确定性量化。

在上一章中，我们探讨了非一致性度量，这是任何一致预测模型的基本元素。为了回顾，非一致性度量的主要作用是通过评估新数据点与先前观察到的数据差异的程度，来量化新数据点的不确定性。

在一致预测框架中，任何模型都提供有效的预测集，无论选择的是哪种非一致性度量。然而，选择合适的非一致性度量对于创建更精确、信息丰富和自适应的预测区域至关重要。

在一致预测中，这些区域的大小决定了预测系统的有效性。较小的区域被认为是更有效和更有信息的。

一致预测模型的有效性可能受到用户选择的非一致性度量的影响。然而，最适合机器学习的非一致性度量取决于上下文。

为了进一步理解，您可以探索*没有免费的午餐*定理，该定理讨论了通用优化和学习算法的限制。您可以在[`en.wikipedia.org/wiki/No_free_lunch_theorem`](https://en.wikipedia.org/wiki/No_free_lunch_theorem)上找到有关此定理的更多信息。

尽管该定理有影响，但研究论文已经提供了关于选择有效非一致性度量的宝贵见解。这些论文检查了不同的数据集，并提供了关于选择在各种场景中已证明有效的非一致性度量的指导。通过利用这些研究成果，您可以在为特定的机器学习任务选择非一致性度量时做出明智的决定。

在题为*Model-Agnostic Nonconformity Functions for Conformal Classification*的研究论文[`ieeexplore.ieee.org/abstract/document/7966105`](https://ieeexplore.ieee.org/abstract/document/7966105)中，作者们检查了三种模型无关的非一致性度量在分类问题中的效率。在用神经网络和神经网络集成作为分类器对 21 个多类数据集进行的实验中，作者们发现非一致性度量的选择对预测集的效率有显著影响。这些发现强调了选择适当非一致性度量以增强分类问题中一致预测效率的重要性。

研究人员得出结论，选择最佳的非一致性度量取决于最适合用例的效率指标。当从单标签预测（单例）的比例来评估效率时，基于边界的非一致性度量成为首选选项。另一方面，当评估预测集的平均宽度时，铰链损失度量产生了最窄的预测集，这表明它在产生更精确和专注的预测方面的有效性。

在一致性预测中，非一致性度量是从底层点预测模型生成的预测中推导出来的。更容易误分类或具有更高内在不确定性的实例被分配更高的非一致性得分。一致性预测模型的效率取决于底层模型的准确性和所选非一致性度量的质量。在选择合适的非一致性度量时，尤其是在处理需要额外支持以准确分类对象的具有挑战性的数据集时，这一点变得尤为重要。

## 非一致性度量的类型

非一致性度量有两种类型——**模型依赖型**和**模型独立型**。

基于模型的非一致性度量是针对一致性预测中使用的特定类型底层模型而言的。这些度量依赖于模型的内部工作或特征来计算非一致性得分。与可以应用于任何类型点预测模型的模型无关的非一致性度量不同，模型依赖性度量是根据特定模型定制的。

基于模型的非一致性度量利用底层模型的独特特征或属性来评估新数据点与训练数据（在经典 TCP 中）或校准数据（在 ICP 中）的偏差或不确定性。这些度量可以根据模型的输出进行定制，例如概率估计或决策边界。它们还可以利用模型特定的属性，如学习到的权重或参数，来确定非一致性得分。

基于模型的非一致性度量的例子包括支持向量机中支持向量的距离、线性回归模型中的残差误差，或在概率分类器中预测类别概率与实际类别概率之间的差异。

基于模型的非一致性度量具有潜在地捕捉模型特定信息和特性的优势，从而实现定制和可能更准确的不确定性量化。然而，它们仅限于它们设计的特定模型，并且可能无法很好地推广到其他模型。因此，我们只将涵盖模型无关的非一致性度量。

在《适用于一致性分类的模型无关非一致性函数》一文中，作者研究了三种流行的损失函数——鸟结损失、边界和布里尔分数——作为预测分类中模型无关非一致性度量的流行选择。由于这些函数与任何产生类别估计的分类模型一起工作，因此它们可以与任何生成类别分数的分类器一起使用，这使得它们具有模型无关性。

重要的是要注意，在一致性预测器中，只有非一致性得分的顺序很重要。在双类问题中，所有三个损失函数——鸟结损失、边界和布里尔分数——都将实例按相同的顺序排列，从而产生相同的效率。

为了比较这些效率度量，作者关注了多类问题。

让我们更详细地看看三种非一致性度量。

### 鸟结损失

鸟结损失（有时也称为**LAC 损失**或**逆概率**）可以在分类问题的背景下进行描述，在这种情况下，我们从模型中获得类别概率作为输出。

对于特定的实例，假设真实标签是*y*，模型对该标签的预测概率是*P(y)*。那么，该实例的鸟结损失计算如下：

鸟结损失 = 1 − P(y)

#### 解释

如果模型非常自信，并将概率 1 分配给真实标签*y*，那么鸟结损失为 0。这表明了一个完美的预测。

如果模型将 0 的概率分配给真实标签*y*，那么鸟结损失为 1。这表明了一个完全错误的预测。

对于介于 0 和 1 之间的概率，鸟结损失将在 0 和 1 之间变化，较高的值表示对正确标签的信心较低，反之亦然。

从本质上讲，鸟结损失给出了预测与真实标签“偏离”程度的度量。较低的鸟结损失值更好，表明预测的真实标签概率更接近 1。相反，较高的鸟结损失值表示预测概率与真实标签之间的差异更大。

为了说明如何计算鸟结损失非一致性得分，考虑一个产生三个类别分数的分类器：*class_0 = 0.5*，*class_1 = 0.3*，和*class_2 = 0.2*，以及实际标签*y = 1*。

为了计算非一致性得分，取真实类别的概率分数（在这种情况下，1）并从 1 中减去。因此，这个示例的逆概率（鸟结）非一致性得分是 0.7。

### 边界非一致性度量

边界非一致性度量定义为预测的最可能错误类别标签的概率与真实标签的预测概率之间的差异：

Δ[h(x i), y i] = max y≠y  i  ˆ P  h(y ∣ x i) − ˆ P  h(y i ∣ x i)

#### 解释

该度量捕捉了分配给任何错误标签的最高概率与实例 *x*i 的真实标签 *y*i 的概率之间的差异。对于具有真实标签 *y*i 的特定实例 *x*i，我们首先确定最可能错误的类别的概率，然后从该值中减去真实标签的概率以得到边缘。

如果边缘值接近零或为负，这意味着模型对其对真实类别标签的预测有信心，并且没有其他类别具有接近竞争概率。这表明是一个符合规范的反例。

如果边缘值是正的且较大，这表明模型为另一个类别（一个错误的类别）分配了比真实类别更高的概率。这是一个不符合规范的反例，表明模型对错误类别的信心比对真实类别的信心更大。

边缘越大，反例越不符合规范，因为它表明预测的真实类别的概率与最可能错误的类别的概率之间的不一致性更大。

从本质上讲，基于边缘的非一致性度量提供了一个关于预测“风险”的指示。如果度量值高，表明模型对该实例的预测可能存在问题，表明预测可能不可靠。如果度量值接近零或为负，这意味着模型对其对真实类别的预测更有信心。

为了说明如何计算边缘非一致性得分，考虑一个产生三个类别得分的分类器：*class_0 = 0.5*，*class_1 = 0.3*，*class_2 = 0.2*，以及实际标签 *y =* *1*。

要计算边缘非一致性得分，需要取最可能但错误的类别的概率（在这种情况下，为 0）并从真实类别的概率（1）中减去，以得到 0.2 的边缘非一致性得分。

### Brier 得分

Brier 得分衡量分类任务中基于概率的预测的准确性。它计算预测概率与实际二元结果之间的平方差。该分数的值可以从 0（完美准确性）到 1（完全不准确）不等。

Brier 得分是**正确评分规则**的一个例子（分类问题中另一个正确的评分规则是交叉熵损失）。

正确评分规则是一种用于评估概率预测准确性的度量。具体来说，它是一种规则，为每个预测分配一个数值分数，使得最准确（或校准）的概率预测在平均情况下将获得更好的（通常是更低的）分数，比任何其他有偏或不太准确的预测。

正确评分规则背后的思想是鼓励诚实地报告概率。如果一个评分规则是“正确的”，那么预报员在报告他们的真实信念或真实估计的概率时，而不是夸大或贬低他们的预测时，将获得最佳的预期分数。

从本质上讲，合适的评分规则确保预报员在提供对事件概率的真实评估时，在评分方面获得最佳回报。

作为一种合适的评分规则，布里尔分数促进了准确度良好的概率估计。它独特地捕捉了校准，即预测概率与实际结果之间的对齐，以及区分度，即模型区分类别的能力。

格伦·W·布里尔（Glenn W. Brier），在气象预报领域工作，于 20 世纪 50 年代发明了布里尔分数（Brier score），并在他的论文《以概率表示的预报验证》（[`journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml`](https://journals.ametsoc.org/view/journals/mwre/78/1/1520-0493_1950_078_0001_vofeit_2_0_co_2.xml)）中对其进行了描述）。与对数损失一样，布里尔分数今天被广泛用于评估概率分类器的性能和理解预测概率的质量。

为了说明如何使用我们的示例计算布里尔分数，考虑同一个分类器，它产生了三个类别得分：*class_0 = 0.5*，*class_1 = 0.3*，*和 class_2 = 0.2*，以及实际标签*y = 1*。以下是计算给定示例布里尔分数的逐步指南：

1.  *编码实际类别*：

    对于多类别问题，您将希望使用 one-hot 编码对实际标签进行编码：

    +   *class_0*: 0

    +   *class_1*: 1

    +   *class_2*: 0

1.  *计算每个类别的平方差异*：

    计算预测概率与实际结果之间的平方差异：

    +   *对于类别 0: (0-0.5)² =* *0.25*

    +   *对于类别 1: (1-0.3)² =* *0.49*

    +   *对于类别 2: (0-0.2)² =* *0.04*

1.  *平均平方差异*：

布里尔分数 = 0.25 + 0.49 + 0.04 _______ 3 = 0.26

因此，此例的布里尔分数为 0.26。较低的布里尔分数表示更好的性能，0 是最佳可能分数。

### 模型无关非一致性度量措施的有效性

在论文《用于一致性分类的模型无关非一致性函数》中，作者使用两个标准评估了三种非一致性措施的有效性：**单类别分类**（**OneC**）和*AvgC*。

*OneC*指的是所有预测中只包含一个标签的单例集的比例。这些集是期望的，因为它们提供了最有信息的预测。

另一方面，**AvgC**指的是预测集中类别标签的平均数量。较低的**AvgC**值表明模型在消除不适合的类别标签后，能更好地产生更具体和有信息的预测。

例如，考虑一个二元分类问题，以下是对五个实例的预测：

+   *预测集 1: {0}*

+   *预测集 2: {1}*

+   *预测集 3: {**0, 1}*

+   *预测集 4: {1}*

+   *预测集 5: {0}*

在这种情况下，有五个预测，其中四个是单例集（预测集 1、2、4 和 5）。为了计算**OneC**，我们计算所有预测中单例集的比例：

*OneC = (单例集数量) / (预测集总数) = (4) / (5) =* *0.8*

较高的**OneC**值表明，符合预测模型更有效地产生具体和有信息的预测。在这个例子中，80%的预测集是单例集，反映了相对高效的分类器。

为了计算代表预测集中平均类别标签数的**AvgC**，我们首先计算每个预测集中类别标签的总和：

+   **预测集 1**：1 个标签

+   **预测集 2**：1 个标签

+   **预测集 3**：2 个标签

+   **预测集 4**：1 个标签

+   **预测集 5**：1 个标签

类别标签的总和是 1 + 1 + 2 + 1 + 1 = 6。

接下来，我们将这个总和除以预测集的总数：

*AvgC = (类别标签总和) / (预测集总数) = (6) / (5) =* *1.2*

在这个例子中，**AvgC**为 1.2，表示平均每个预测集包含 1.2 个类别标签。较低的**AvgC**值表明模型在产生更具体和有信息的预测方面表现更好。在这种情况下，**AvgC**值为 1.2 反映了相对高效的分类器，因为它接近最小可能值 1，这会在所有预测集都是单例集时发生。

研究人员已经确定，最有效的方法是使用基于边界的非一致性函数来实现高比例的单例预测（**OneC**）。

另一方面，使用铰链（逆概率）非一致性度量的非一致性度量在平均**AvgC**值上产生了最小的标签集，这是通过**AvgC**来衡量的。

#### 这种结果背后的直觉是什么？

为了获得高的**OneC**分数，预测应该主要是包含单个标签的单例集。这意味着必须将所有其他标签分配高非一致性分数。基于边界的非一致性度量促进了这种结果，尤其是在基础模型赋予单个标签高概率的情况下。在这种情况下，与该单个标签相关的概率被添加到所有其他标签的非一致性分数中，从而有效地促进了单例集的选择，并因此提高了**OneC**性能。

然而，铰链损失函数，它对每个标签进行单独评估，可能只排除一些标签，而在某些情况下保留高概率的标签。这种情况发生是因为所有其他标签必须具有固有的低概率，而铰链损失函数并没有考虑到剩余的概率质量是如何具体分配给高概率标签的。因此，铰链损失函数无法考虑这种分布可能导致它只排除一些标签，而不一定专注于高概率的标签。这两种非一致性度量分配分数的不同导致基于边界的非一致性度量更适合实现高比例的单例预测。

另一方面，为了通过**AvgC**获得平均更小的标签集，基于铰链（逆概率）非一致性度量的非一致性度量更有效。这是因为铰链损失函数只考虑真实类标签的概率。相比之下，基于边界的非一致性度量考虑了真实类标签的概率以及最可能的错误类标签的概率。这导致基于边界的非一致性度量平均产生更宽的集合，而铰链损失函数更有可能排除错误标签，并产生更小、更有信息的集合。

与分类相比，回归问题在选择非一致性度量方面相对简单：

+   **绝对误差**：绝对误差非一致性度量是给定数据点的预测值与真实目标值之间的绝对差值。这个度量可以与任何回归模型一起使用：

非一致性（x）= |y_pred - y_true|

+   **归一化误差**：归一化误差非一致性度量是绝对误差除以预测误差尺度的估计，例如**平均绝对误差**（**MAE**）或残差的方差。这个度量可以与任何回归模型一起使用，并有助于解释数据中的异方差性：

    非一致性（x）= |y_pred - y_true| / scale

现在让我们考虑回归问题中这两种非一致性度量的优缺点。

#### 绝对误差

优点如下：

+   **简单性**：计算和理解都很简单，因此成为许多实践者的首选选择

+   **统一解释**：由于它没有缩放，解释在不同数据集之间保持一致

缺点如下：

+   **尺度敏感性**：绝对误差可能对目标变量的尺度敏感。对于具有大目标值的数据集，即使预测相对准确，绝对误差也可能很大。

+   **不考虑数据分布**：它不考虑数据集中误差的变异性或分布，这可能导致过于乐观或悲观的符合预测。

#### 归一化误差

优点如下：

+   **尺度不变性**：通过根据误差的尺度（例如，平均绝对误差或残差的标准差）归一化误差，它对目标变量的尺度变得不那么敏感，从而允许在具有不同尺度的数据集上实现更一致的性能。

+   **解释异方差性**：这种度量对于表现出异方差性（即误差的变异性随数据变化）的数据尤其有用。通过使用一个度量来归一化，它可以更准确地表示预测的相对准确性。

+   **更适应**：归一化因子可以适应数据的局部特性，提供更有意义的误差度量。

缺点如下：

+   **复杂性**：它引入了一个额外的复杂性层，因为需要确定最佳归一化误差的方法。归一化的选择（例如，使用平均绝对误差与残差的标准差）可能会影响结果。

+   **误导性结果的风险**：如果归一化因子选择不当或从小的样本中计算得出，可能会导致误导性的符合预测。

+   **需要更多数据**：估计预测误差的尺度通常需要一个足够大的样本量才能可靠。

在回归的符合预测的背景下，这些度量之间的选择通常取决于数据的特性和应用的特定需求。如果存在异方差性的担忧，归一化误差可能更合适。否则，绝对误差的简单性可能更受欢迎。

符合预测器的第二个组成部分是**校准集**，用于计算已知数据点的非符合度分数。校准集是最受欢迎的变体 ICP 的特征，而 TCP 不需要校准集。与 ICP 相比，TCP 利用所有可用数据，在数据使用方面效率更高。然而，TCP 在计算上效率低下，需要为每个新的测试对象重新训练底层点预测模型。

我们将关注 ICP，这是当前研究和开源库中最流行和最广泛使用的变体，以更好地理解符合预测。ICP 是在 2002 年的一篇论文中引入的，题为《用于回归的归纳置信机器》(*Inductive Confidence Machines for Regression*) ([`link.springer.com/chapter/10.1007/3-540-36755-1_29`](https://link.springer.com/chapter/10.1007/3-540-36755-1_29))。

ICP 在计算效率方面具有显著优势，因为它几乎与底层点预测模型一样快。这是因为 ICP 基于训练数据生成单个模型，然后可以使用该模型为所有测试实例生成预测。任何预测模型都可以与 ICP 结合，将其转换为符合预测器。

在开发 ICP 时，请记住，训练集仅用于训练基础预测模型。不要用它来构建符合预测器。同样，校准集应仅保留用于符合预测器，而不是用于训练基础模型。

符合预测的主要目标是为新出现的未见示例提供有效的预测集。ICP 方法通过比较底层点预测模型做出的预测与实际标签，使模型能够了解不确定性。

ICP 的构建如下：

1.  将您的训练数据分为两个不相交的子集 IT 和 IC，其中 T 和 C 分别表示适当的训练集和校准集。

1.  使用适当的训练集 IT 中的数据来训练您的点预测模型 H。如前一章所述，H 可以是任何点预测模型，包括统计模型、机器学习、深度学习，甚至是基于专家意见、业务规则或启发式方法的任何模型。

1.  使用适当的非一致性度量来计算分类或回归任务的非一致性得分α1, α2, ..., αn，其中 n 代表校准数据集中的数据点总数。

1.  暂时将标签 y 分配为新测试点 x 的潜在标签，并计算(x,y)的非一致性得分α。

1.  按以下方式计算 p 值：

    p = |{z i : α i ≥ : α T}| + 1 _ n + 1 .

    让我们简要讨论计算每个测试数据点的 p 值这一重要步骤。在前面的步骤中，我们计算了校准集中所有点的非一致性得分。然后，我们计算新测试点的非一致性得分，以确定测试点的非一致性得分与校准集中的那些得分相比如何。p 值提供了一个衡量测试对象与校准数据差异的指标，基于其非一致性得分。它是通过首先使用模型计算测试对象的非一致性得分，然后使用相同的模型计算校准集中所有对象的非一致性得分来计算的。然后，计算校准对象中非一致性得分大于或等于测试对象得分的对象数量，并将 1 加到这个计数上。这个计数加 1 然后除以校准对象总数加 1，以确定 p 值，这表明了至少与测试对象一样极端的校准对象的比例。得到的 p 值提供了测试对象与校准数据模式非一致性的定量指标，低 p 值意味着测试对象与校准数据相比非常不寻常。

1.  符合性预测的核心思想是为测试点分配一个暂定的标签 y（在分类问题中是一个类别标签，在回归问题中是一个真实的 y 值）并评估测试对象（包括其特征和分配的标签）与校准集中观察到的对象如何拟合。为了衡量这种拟合，我们通过比较测试对象的“异常性”来计算 p 值，使用的是测试对象的非一致性得分与校准集对象的得分。

    重要的是要注意，在计算 p 值时，分子和分母（n+1）包括测试对象，与校准集数据一起放在同一个袋子里。由于可交换性假设，数据可以被洗牌，使得所有数据点在顺序方面都是等效的。

    一旦我们得到了具有暂时分配标签的测试点的 p 值，我们就将其与显著性水平进行比较。如果 p 值低于显著性水平，这表明校准集中几乎没有，如果有的话，对象与我们的测试点一样异常。这表明提出的标签 y 不适合，我们将其排除在预测集之外。

    另一方面，如果 p 值等于或高于显著性水平，考虑到观察到的数据，将潜在标签 y 分配给我们的测试对象并不会使其显得特别异常。从这个意义上讲，我们使用 p 值来测试在可交换性假设下，每个潜在 y 值是否适合之前观察到的数据。

1.  我们对 y 的每个可能值重复上述过程。结果，我们获得一个包含真实标签的概率为 1 - ε的预测集，其中ε是我们选择的显著性水平（例如，5%）。

现在，我们将讨论置信度和可信度的概念，这些概念有助于评估预测的质量：

+   **置信度水平**：置信度水平，用(1 - ε)表示，代表真实标签（或值）落在预测集中的概率。更高的置信度水平表明预测更有可能是准确的。置信度水平通常提前选择，常见值是 0.95（95%）或 0.99（99%）。例如，以 95%的置信度水平，可以预期真实标签将有 95%的时间包含在预测集中。

+   **可信度水平**：可信度水平，用 p 表示，衡量预测集中每个元素是真实标签的可能性。我们讨论了计算标签‘y’每个潜在值的 p 值。在分类任务中，可信度水平可以解释为对每个类别标签的置信度的归一化度量。可信度水平有助于确定回归任务预测区间内最可能的价值。可信度水平可以用作阈值来过滤掉不太可能的预测，从而得到更精确、尽管规模较小的预测集。

让我们考虑一个具有两个可能类别标签的二分类问题：*A*和*B*。我们将使用符合性预测框架来计算测试数据点的置信度和可信度水平。

假设我们已经训练了一个点预测模型，并计算了校准数据集和测试点的非一致性得分。

校准数据集的非一致性得分如下：

+   *第 1 点（标签*A*）：0.4*

+   *第 2 点（标签*A*）：0.3*

+   *第 3 点（标签*B*）：0.2*

+   *第 4 点（标签*B*）：0.5*

使用模型的预测标签和概率来计算测试点的非一致性得分。例如，如果模型为类别 A 产生 0.75 的概率估计，为类别 B 产生 0.65 的概率估计，则非一致性得分将按以下方式计算：

+   对于类别 A，模型分配的概率为 0.75。非一致性得分是通过从 1 减去这个概率来计算的，即 1–0.75 = 0.25。

+   对于类别 B，模型分配的概率为 0.65。非一致性得分为 1–0.65 = 0.35。

通常，非一致性得分是 1 减去模型对候选标签的概率。这衡量了预测与完全置信（概率为 1）的偏差程度。更高的非一致性得分意味着模型的标签分配不太确定或不一致。当模型为每个类别输出概率估计时，通常会使用 Hinge 损失。从 1 减去概率提供了一个直观的非一致性度量。

现在，我们将为每个候选标签计算 p 值：

1.  *标签 A*：计算非一致性得分大于或等于 0.25 的校准点数量：3（点 1、2 和 4）

    p 值 = (3 + 1) / (4 + 1) = 4 / 5 = 0.8

1.  *标签 B*：计算非一致性得分大于或等于 0.35 的校准点数量：2（点 1 和 4）

    p 值 = (2 + 1) / (4 + 1) = 3 / 5 = 0.6

这些 p 值是每个标签的可信度水平。因此，标签 A 的可信度为 0.8，标签 B 的可信度为 0.6。

我们期望的置信水平是 95%（1–ε = 0.95，ε = 0.05）。由于两个可信度水平（p 值）都大于选择的显著性水平ε = 0.05，我们将标签 A 和 B 都包含在预测集中。

在这个例子中，置信水平为 95%，表示真实标签有 95%的概率包含在预测集中。可信度水平为标签 A 的 0.8 和标签 B 的 0.6，这表明标签 A 更有可能是正确的标签，而不是标签 B。

然而，由于两个标签的可信度水平都高于显著性水平，它们都被包含在预测集中。

在线一致性预测和离线一致性预测是两种不同的一致性预测变体，它们在处理和整合新数据点的方式上有所不同：

+   **离线一致性预测**：在离线一致性预测中，模型在固定数据集上训练，并为单独的校准数据集计算非一致性得分。当新数据点可用时，模型不会更新或改变。这种方法适用于数据集静态或你有大量数据可用于训练和校准时。离线一致性预测的缺点是它不适应新的数据或数据分布随时间的变化。

+   **在线一致性预测**：在线一致性预测中，当新数据点可用时，模型会持续更新。它通过更新非一致性得分并相应调整预测来整合新信息。在线一致性预测在处理流数据或当潜在数据分布随时间变化时特别有用。这种方法使模型能够与最新数据保持同步，在动态环境中提供更准确的预测。然而，由于需要不断更新，在线一致性预测可能计算上要求更高。

条件覆盖和无条件覆盖是评估预测模型预测区间性能的两个标准。它们评估预测区间对真实值的覆盖情况，但它们关注不同的方面：

+   **无条件覆盖**：无条件覆盖评估真实值落在预测区间内的比例，而不考虑特定的条件或模式。它衡量预测区间在整个数据集上捕捉真实值的能力。具有良好无条件覆盖的模型将在指定比例（例如，95%）的时间内将真实值包含在预测区间内。无条件覆盖对于评估模型的总体性能很有用，但它不考虑观察之间的潜在依赖关系或数据分布的变化。

+   **条件覆盖**：另一方面，条件覆盖在考虑数据中的特定条件或模式的同时，评估预测区间的性能。它检查预测区间在考虑具有某些特征或依赖关系（例如，时间段、类别等）的数据子集时，捕捉真实值的程度。具有良好条件覆盖的模型将保持每个特定条件或数据子集所需的覆盖率。条件覆盖为模型性能提供了一种更细致的评价，有助于识别模型对某些数据子集预测中可能存在的弱点或偏差。

总结来说，无条件覆盖评估模型预测区间包含真实值的总体能力。相比之下，条件覆盖评估在特定条件或数据子集中预测区间的性能。这两个标准对于理解预测模型的性能都很重要，但它们关注模型预测的不同方面。

符合性预测是一个产生可靠和有效预测并具有可量化不确定性的框架。它可以应用于广泛的机器学习、统计或深度学习模型以及其他预测方法。在这里，我们将讨论符合性预测与其他框架的关系：

+   **传统机器学习框架**：符合性预测可以与传统机器学习方法（例如，线性回归、SVM、决策树等）相结合，为预测提供有效的置信度或可信度度量。通过这样做，符合性预测增强了这些方法，使用户能够更好地理解与每个预测相关的不确定性。

+   **集成方法**：例如，袋装、提升和随机森林等集成方法也可以从符合性预测中受益。通过将这些方法与符合性预测相结合，集成可以产生一个点估计和一个带有相关置信水平的预测区间或集合。

+   **深度学习框架**：一致性预测可以与深度学习模型（如神经网络）集成，为其预测提供可量化的不确定性估计。这允许从业者更好地理解这些复杂模型产生的预测的可靠性。

+   **贝叶斯框架**：贝叶斯方法本质上通过概率分布提供不确定性量化。然而，一致性预测仍然可以与贝叶斯框架结合，以提供一种频率主义的不确定性量化方法。这种结合可以提供对预测相关不确定性的补充视角。

+   **模型验证技术**：一致性预测可以与交叉验证或自助法等模型验证技术结合使用，以评估模型的性能。虽然这些验证技术评估模型的准确性和泛化能力，但一致性预测提供了对模型不确定性量化的补充视角。

在*第四章*中，我们将探讨在概率预测模型背景下有效性和效率的概念，基于前几章所奠定的基础。

# 摘要

在本章中，我们深入探讨了一致性预测的基本原理和数学基础，这是一个强大且通用的概率预测框架。我们学习了在分类和回归中使用的不同非一致性度量，为将一致性预测应用于您的行业应用奠定了坚实的基础。

在下一章中，我们将探讨在概率预测模型背景下有效性和效率的概念，基于前几章所奠定的基础。
