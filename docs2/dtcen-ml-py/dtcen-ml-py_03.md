# 3

# 数据中心化机器学习的原则

在本章中，你将学习以数据为中心的机器学习的关键原则。我们将在本章中介绍数据中心化的基础原则，以提供一个高级结构和框架，供你在本书的其余部分进行工作并参考。这些原则将在我们深入探讨下一章中与每个原则相关的具体技术和方法之前——即“为什么”——为你提供重要的背景信息。

阅读原则时，请记住，以数据为中心的机器学习是模型中心方法的扩展——而不是替代品。本质上，模型中心化和数据中心化技术协同工作，以从你的努力中获得最大价值。

到本章结束时，你将对每个原则及其如何共同形成一个以数据为中心的框架有很好的理解。

在本章中，我们将涵盖以下主题：

+   原则 1 – 数据应该是机器学习发展的中心

+   原则 2 – 有效利用标注者和**主题专家**（**SMEs**）

+   原则 3 – 使用机器学习来改进你的数据

+   原则 4 – 遵循道德、负责任和良好治理的机器学习实践

# 有时候，你所需要的只是正确的数据

几年前，我（乔纳斯）领导着一个数据科学家团队，他们面临着一个有趣但具有挑战性的问题。我们工作的金融服务业务吸引了大量新的在线访客，他们希望通过公司的网站向我们开设新账户。然而，由于未知原因，相当数量的潜在客户无法完成开户流程，这就是为什么公司转向数据科学家寻求帮助的原因。

这个未激活账户和失去客户的问题是多方面的，但我们决心在草堆中找到每一根针。开户流程相当直接，旨在使某人能够在 10 分钟内（无需支持）轻松开设新账户。对于客户来说，步骤如下：

1.  输入个人详细信息。

1.  验证身份。

1.  验证联系信息。

1.  接受条款和条件并开设账户。

这个过程在大多数情况下都有效，但对于相当一部分申请人来说，在**步骤 2**和**步骤 3**中出现了问题。如果某人的身份无法在线验证（**步骤 2**），那么个人必须亲自验证，这对许多人来说是一个明显的减分项，并导致了显著的用户流失。

在**步骤 3**中出现的这些问题不太明显。大约 10%的用户会在这一点上放弃他们的旅程，尽管大部分艰苦的工作已经完成。为什么有人会经历整个过程，然后最终决定不继续进行？

我们收集了我们能得到的所有相关数据点，但遗憾的是，我们没有一个非常深入的数据集来工作，因为账户开设过程非常简单，这些是新客户。我们对数据集进行了分析，并使用了各种监督和无监督的机器学习技术来找出与账户未开设相关的任何行为，但我们的分析中没有突出的事物。

我们决定深入挖掘。由于这些客户分享了他们的联系信息，我们可以将他们的电话号码与我们的通话记录相匹配，并获取与匹配电话号码的录音对话。我们提取了数百个通话录音并开始收听。

很快，一个清晰的模式出现了：“我点击了**验证联系信息**按钮，但从未收到验证码，”一位录音中的呼叫者说。“我已经等了 10 分钟，但验证码还没有到来，”另一位说。用户无法通过验证，因为他们没有收到作为短信的最终验证码——即使呼叫中心的工作人员重新发送了。但并非所有新用户都遇到这种情况，那么这个特定群体出了什么问题？

随着我们继续收听通话录音，另一个微弱的信号出现了：“我不应该回来，”一位用户说。“自从我上次来这里，你们的系统并没有变得更好，”另一位说。

我们查看了一些关闭的客户账户，果然，这些人以前是我们的客户。问题很简单，企业系统将这些用户视为现有客户，因此没有发送所需的短信，无论用户或工作人员提示多少次。这个问题每周大约发生 200 次，这意味着企业每年失去了 10,000 名新客户。为什么没有人早点发现这个问题？

只有 200 次中的少数几次会生成呼叫，而且由于整个星期都有数百名呼叫中心工作人员值班，这似乎是一个罕见的故障，只偶尔发生。没有人能看出问题，因为它太不频繁，我们的模型也无法标记。毕竟，初始数据集噪音太多，信号不足。

我们之所以能够找到这个问题的根源，并从混乱中找到我们的“针”，是因为我们遵循了本章讨论的数据中心化的四个原则。让我们更详细地探讨这些原则中的每一个。

# 原则 1——数据应该是机器学习发展的中心

正如我们在*第二章**从以模型为中心到以数据为中心——机器学习的演变*中讨论的那样，占主导地位的模式中心方法在几个方面存在不足：计算和存储已经商品化，算法已经实际上自动化并且高度依赖数据，模型是可访问的但不太灵活，深度学习和 AutoML 工具无处不在。但数据呢？嗯，那还是未知数。

而不是依赖于强大的计算和存储环境以及需要大量数据的复杂算法来给我们带来模型准确性的增量提升，一个更好的方法是由数据驱动——具体来说，是由手头问题可用且相关的数据驱动。

数据对每个公司、问题和情况都是独特的，数据驱动的范式通过在模型之前将焦点和开发努力放在数据上，来认可这一点。数据不再是可以在一开始收集后就被遗忘的静态资产；现在它是一种独特的商品，需要充分利用其全部潜力以做出更好的预测。我们将论证，在许多情况下，公司的专有数据是其唯一的真正独特的竞争优势——只要得到充分利用。

通过关注数据，数据驱动的范式帮助公司区别于其竞争对手。大多数公司都能访问相同的算法和大量的计算和存储，但他们使用的数据以及从这些数据中获得的见解可以给他们带来决定性的竞争优势。

在我们的观察中，关注数据质量除了获得更好的数据外，还为组织带来了实质性的好处。关注数据质量意味着超越简单的数据精炼，因为高质量数据是业务运营的关键组成部分。

为了提高数据质量，通常需要数字化和自动化流程，并创建对流程遵守的强大问责制。强大的数据治理流程将分配数据质量的拥有权、监护权和问责制，这反过来又依赖于遵循、衡量和管理的数据收集标准和流程。

数据质量通常是底层过程质量和对这些过程遵守情况的症状。如果一个组织擅长收集高质量数据，那么它也更有可能拥有良好的通用流程。随着公司改进数据收集，它们推动更好的问责制、准确性、可靠性和整体一致性。因此，关注数据质量可以产生深远的影响，而不仅仅是改善数据完整性和可靠性。它是运营卓越的关键驱动因素。

如果我们回顾本章开头讨论的缺失验证码的例子，对现有数据集进行任何模型选择、参数调整或特征工程都不会揭示问题的根本原因。

这个问题只能通过收集手头问题的正确数据来发现和解决。在这种情况下，缺失的数据点如下：

+   验证码没有被接收

+   这仅适用于之前客户返回并开设新账户的情况

验证码问题的发现导致业务运营方式发生了两项关键变化。首先，IT 部门修复了负责触发发送验证码的代码，在其他条件相同的情况下，这导致了新账户开设数量的显著增加。其次，客服中心团队建立了一个中央流程来记录客户的技术问题，无论大小，这样我们就能发现任何新系统问题的“冰山一角”。换句话说，现在公认的文化是收集高质量数据是改进运营流程的核心。

这对一线员工在两个方面产生了心态转变。首先，他们对数据作为一项强大的资产有了新的认识，这项资产可以汇总和分析，以了解他们工作的整体情况。其次，一线团队现在感到更有权力：如果我做好我的部分工作，捕捉和指出重要问题，就有机会修复它们。

我们的数据科学家也对数据收集和整理作为他们角色关键部分有了不同的认识。通过站在客户和一线员工的角度看问题，他们看到了他们能够产生的影响，这使团队解决问题的方法发生了深刻的变化。而不是接受数据（质量）作为既定事实，数据工程现在渗透到模型开发和部署过程的每个步骤。

## 数据中心的清单

为了忠实于数据中心的机器学习第一原则，在处理机器学习项目时拥有一个数据聚焦的任务清单非常有价值。以下是我们的清单，分布在模型开发生命周期中的五个步骤中。

### 第 1 步 – 确定业务问题，界定项目范围，并定义数据需求

任何机器学习项目的第一部分始终应该是清楚地定义你试图解决的问题；这应该与关键利益相关者，如最终用户和行业专家合作完成。当你对你要解决的问题有一个清晰的定义，以及问题解决后的成功样子时，识别数据差距会容易得多。

一个强大的建模数据集包含内容和上下文。内容是你正在测量的特定对象、事件或状态，上下文描述了对象、事件或状态发生的情境。在我们之前的缺失验证码示例中，内容是*(缺失的)验证码*，上下文是*对于以前，* *回归客户*。

定义项目范围的一个关键要素是概述你试图模拟的过程。我们通过将相关最终用户和行业专家与数据科学家一起放在一个房间里，直到他们能够绘制出业务问题背后的过程或情况，来做到这一点。这使所有参与者能够深入了解问题的内容和背景，同时确定构建模型所需的重要数据点。

在这一步骤中，以下是一些需要考虑的问题清单：

+   我们是否清楚地定义了我们试图解决的问题？

+   这是不是我们首先应该解决的问题？

+   通过解决这个问题的我们期望实现什么结果？

+   我们是否已经与专家一起确定了问题的关键部分？

+   根据专家的意见，过程中的关键步骤或时刻是什么，我们的数据是否适当地捕捉了这些？

+   我们的数据点是否包含*内容*和*上下文*？

+   从我们的解决方案中可能会产生哪些偏差，我们需要在以后留意这些偏差？

+   这些偏差会导致任何群体或部分受到不公平对待吗？我们如何在验证阶段（*步骤 4*）识别这些偏差？

+   在我们的数据集中使用所有特征是否合法和道德？

+   输出将进行内部或外部审计吗？

### 步骤 2 – 准备和标记数据

对于许多数据科学家来说，数据准备是一项令人畏惧的任务。我们确实认为数据准备既可能是重复的，也可能是耗时的，但作为数据为中心的机器学习的倡导者，我们鼓励您将其视为工作中最重要的部分。

数据准备涉及收集、清理、结构化、增强和增强您的输入数据，以增加数据集中的信号并减少噪声。这些任务可能既具有技术挑战性，又具有回报性——特别是当您开始看到 AUC 分数上升时。到目前为止，您已经意识到，如果您投入正确的努力，这个过程可能会给您带来非常强大的建模结果。

以下清单对于指导您完成数据准备过程非常有用。我们将在本书的其余部分详细教授您如何执行这些任务。

这里是清单问题：

+   我们是否对数据质量进行了技术验证？（见*第五章**，数据清理技术*。）

+   我们能否通过清理数据来增强数据集的强度？（见*第五章**，数据清理技术*。）

+   我们需要收集额外数据或使用人工标记员提高现有数据集的质量吗？（见*第四章**，数据标记是一个*协作过程*。）

+   我们需要定义特定的标记规则并培训专家吗？（见*第四章**，数据标记是一个*协作过程*。）

+   我们能否通过程序化标记提高数据质量或填补缺失值？（见*第六章**，机器学习中程序化标记的技术*。）

+   我们是否应该使用合成数据来增强或提高数据中某些类别的质量？（见*第七章**，在数据为中心的机器学习中使用合成数据*。）

+   我们是否需要保护数据集中个人的隐私？（见*第七章**，在数据为中心的机器学习中使用合成数据*。）

+   我们的数据集是否包含有偏见的类别，我们需要调整这些类别吗？（参见*第八章**，识别和* *消除偏见* *的技术。）

+   我们的数据集是否包含足够数量的正确类型的罕见事件？我们需要添加更多或删除异常值吗？（参见*第九章**，在* *机器学习* *中处理边缘情况和罕见事件。）

+   我们能否从现有数据集中工程化新的特征？

### 第 3 步 – 训练模型

模型训练阶段是数据中心化和模型中心化机器学习原则结合在一起以产生协同效应的地方。再次强调，重要的是不要丢弃你基于模型中心方法已经知道的所有关于如何构建和增强机器模型的知识。数据中心化只是给你工具箱中额外的一套工具，并允许你放大模型的影响。

特征选择是这一协同过程的重要组成部分，因为它筛选出对模型无用（在最坏的情况下，可能是有问题的）特征。一般来说，希望有更少的属性对模型做出贡献是可取的，因为这减少了不必要的噪声，并使模型更容易解释。

考虑特征选择作为模型选择过程的一部分是很重要的，因为模型及其输入数据是手牵手产生预测的。它们本质上是相互联系的。实际上，这意味着你应该与模型一起选择特征，而不是使用静态的预选特征数据集来选择模型。

这里是清单问题：

+   你怀疑你的数据是否脏（例如，错误的标签、缺失值、无意义的模式或不相关的输出）？

+   我们能否通过提高数据集的质量来提高模型的准确性？本书中概述的长期数据中心化技术列表旨在帮助你完成这项任务！

+   我们工程化的特征是否表明数据中存在需要我们收集额外数据（特征或观察）的关系？

+   我们（工程化）的特征是否表明数据中存在任何我们应该与行业专家（SMEs）验证的关系？与其假设我们的新特征是正确的，不如将任何有影响力的相关性与行业专家交叉检查，以确保它们在解决方案的上下文中相关性和有效性。

+   我们能否在不损失预测能力的情况下减少模型中的特征数量？通过应用降维技术或特征选择方法，我们可能能够减少模型中的特征数量，而不会显著降低其预测准确性。

### 第 4 步 – 评估性能、公平性和偏见

以数据为中心的机器学习方法在模型评估期间对检测偏见和公平性问题给予了高度重视。为了验证机器学习模型的准确性，您仍然应该从传统的验证任务开始，例如将数据分为训练集和测试集，执行交叉验证，并生成混淆矩阵。以下清单假设您将已经执行这些任务，使用标准性能评估，使用如准确率、精确率、召回率、F1 分数等指标。

偏见检测是揭示机器学习模型中潜在的不公平性和歧视的重要工具。这可以通过为每个子组单独创建混淆矩阵来实现，以比较各组之间的假阳性率和假阴性率，并评估各组之间的群体平衡（平等代表）和机会平等（平等的真阳性率）或等概率（平等的假阳性率）。与性别或种族相关的子组间的差异是偏见或不公平的常见来源。

这里是清单问题：

+   我们能否通过提高数据质量或收集新特征来提升模型的表现？

+   我们能否检测到对特定群体或部分的任何偏见或不公平？

+   敏感属性与模型做出的预测之间是否存在任何大的相关性？

+   模型在处理未见过的数据时，在公平性和偏见方面的表现如何？

我们将在*第八章**，*识别和消除偏见的技术*中介绍识别和消除偏见的技术。

### 第 5 步 – 部署和监控

机器学习模型的有效监控也依赖于以数据为中心的原则。在监控模型性能时，包括数据质量、数据覆盖范围、数据相关性和标注一致性指标是很重要的。

数据质量指的是数据的准确性、完整性和一致性，而数据覆盖范围指的是拥有足够的数据点来首先做出自信的预测。数据相关性确保用于训练模型的数据适合该任务。最后，数据标注一致性确保用于训练模型的数据点具有正确的标签。

几种技术和工具可以帮助数据科学家有效地监控机器学习模型。例如，数据漂移检测有助于检测数据特征的变化，如均值、方差和分布。同样，异常值检测有助于识别与常见分布显著不同的数据点。此外，偏见检测技术有助于识别和纠正机器学习模型中的偏见实例。

除了依赖报告和指标来监控 ML 模型之外，理解监控是一个持续的过程，需要数据科学团队以外的利益相关者的参与至关重要。利益相关者可能包括领域专家、业务所有者和最终用户。这些利益相关者应协作评估模型的表现，解释结果，并确定需要解决的问题。

这里是清单问题：

+   模型中使用的数据源是否自动化、一致且可靠？

+   我们是否设计了一个监控和报告计划，以捕捉失败、偏差和漂移？

+   我们的监控是否量化了数据质量、数据覆盖范围、数据相关性和标签一致性？

+   我们是否为最终用户提供了对模型性能进行持续反馈的机制？

我们的设计清单问题旨在让您在模型开发过程的每一步都思考数据质量及其影响。换句话说，它们是对更多以模型为中心的开发任务的补充，而不是替代。

数据中心化需要从“我将用这些数据构建最好的模型”的心态转变为“我们如何构建最佳数据集来解决这个特定问题？”为了做到这一点，我们需要整个组织参与协调一致的努力。这使我们来到了数据中心化机器学习的第二个原则。

# 原则 2 – 有效利用标注者和领域专家

无论您在阅读此内容时 AI 炒作周期处于哪个阶段，AI 和 ML 开发不太可能已经发展到不再需要人类输入和标注的阶段。

近年来，我们在 AI 技术的复杂性方面经历了大幅增长，尤其是在生成 AI 领域。尽管如此，一个事实仍然存在，即即使是功能最强大、最具革命性的 AI 技术，如 ChatGPT，也依赖于由人类标注者组成的小型军队来完善和提升其能力。

这些个人会审查和标注数据样本，然后这些样本会被反馈到模型中，以提升其对自然语言和上下文的理解。人类标注者采用的一些关键方法和技巧包括以下内容：

+   **领域专业知识**：具有主题领域专业知识的标注者可以提供有价值的见解和标注，帮助模型更好地理解特定主题和领域。

+   **主动学习**：这种方法涉及优先处理模型认为模糊或具有挑战性的数据样本，使标注者能够专注于他们输入可以产生最大影响的领域。

+   **视角多样性**：通过涉及来自不同背景和具有不同经验水平的标注者，模型可以接触到更广泛的语言细微差别、文化背景和观点，从而提高其整体性能。

+   **质量控制**：定期审计和评估标注器的输出可以帮助确保标注质量的一致性和遵循指南，这对于有效的模型训练至关重要。

简而言之，人工标注员对于机器学习至关重要，我们模型的质量取决于我们训练、组织和与这些标注员合作的能力。从广义上讲，在机器学习开发过程中利用行业专家的方式有三种：

+   作为数据点的直接标注员

+   作为输出质量验证者和不良输出（如有害内容）的检测器

+   作为知识专家，他们可以帮助我们制定标注规则

有效利用行业专家需要从仅为标注员创建标注规则（尽管这仍然很重要）的心态转变到利用行业专家和数据科学家结合的强项，通过明确的标注规则覆盖问题空间。

我们的经验表明，采用这种方法不仅提供了强大的标注功能，还有助于我们追踪模糊的例子并提高模型性能，但同样重要的是，它允许数据科学家和行业专家进行合作。随着数据科学家了解主题内容，行业专家学习数据科学的工作方式，这会产生一个飞轮效应，导致新想法、洞察和知识的产生。

让我们更详细地探讨三种人工标注方法。

## 直接由人工标注员进行标注

人工标注数据的主要优势是其准确性。人类能够以计算机无法做到的方式识别模式和主观性。这意味着分配给数据的标签可能比自动化过程生成的标签更准确。此外，人类可以提供自动化过程中可能丢失的数据背景。

人工标注数据也比自动化流程提供了更大的灵活性。标注员可以根据具体需求或要求定制他们的标注过程，使他们能够调整标注以适应项目目标。这使得机器能够更准确、更快速地解释数据。

最后，与其它标注方法相比，人工标注数据可能更具成本效益。这一点在数据集规模从小到中等时尤为正确。

小型数据集可能包含几百到几千个观察值，通常可以由一个小型标注团队管理。中型数据集可能有数万个观察值。虽然手动标注仍然是可能的，但随着复杂性和所需时间的增加，它开始变得在经济上不太可行。

面对更大的数据集时，由于数据量巨大和潜在的复杂性，手动标注可能会变得重复且容易出错。在这个规模上，数据中的复杂性也可能增加，需要更细腻的理解，这可能对标注员保持一致性构成挑战。

对于更大或更复杂的数据集，我们建议走程序化标注的道路，我们将在下一部分进行讨论。有趣的是，混合方法也可以有效，其中大型数据集的一个子集被手动标注，作为程序化标注算法的训练数据。这样，你可以利用人工标注的准确性和机器学习的可扩展性，确保即使是大型数据集也能获得高质量的标签。

回想一下我们在本章开头概述的丢失验证码的故事。一旦我们确定了与尚未发现的议题相关的电话，我们选择手动监听数百个电话，而不是使用机器学习技术来捕捉主题。为什么？

因为我们想确保我们理解了这些交互的内容和上下文，而人类更有可能做好这项工作。同时，我们只听了数百个电话，而不是数百万个，所以人工标注是找到噪声中的信号和定位我们“大海捞针”问题的最经济有效的方式。

虽然人工标注是数据驱动方法的重要组成部分，但在使用人工标注员时，有一些陷阱和错误需要避免。在*第四章*《数据标注是一个协作过程》中，我们将教你如何最大限度地发挥专家和人工标注员的作用，同时管理潜在的负面影响。

## 使用人工标注员验证输出质量

如前所述，即使是像 ChatGPT 这样非常复杂的 AI 解决方案，也严重依赖人工标注员来引导算法达到最佳结果。ChatGPT 是基于监督学习和一种称为**人类反馈强化学习**（RLHF）的技术构建的。

强化学习是机器学习的一个领域，其中代理通过与环境的互动来学习做出决策。代理的目标是选择能够最大化累积奖励的行动。然而，为复杂任务定义合适的奖励函数可能具有挑战性。

这就是人类反馈发挥作用的地方。在 RLHF 中，AI 代理从人类提供的奖励和惩罚中学习，而不是从预定义的奖励函数中学习。这种方法结合了机器学习算法的力量与人类专家的直觉、经验和知识。

该过程包括以下步骤：

1.  代理与环境互动并采取行动。

1.  人类观察者评估代理的行为，并以奖励或惩罚的形式提供反馈。

1.  代理使用这些反馈来更新其学习并随着时间的推移改进其决策。

通过这些交互，AI 代理学会通过结合人类指导来执行复杂任务。

使用 RLHF（强化学习与人类反馈）的好处有几个。首先，人类反馈使得 AI 代理能够从人类所拥有的丰富知识和经验中学习。这种方法使得代理能够学习复杂的行为，这些行为可能用传统的算法难以实现。同时，通过调整人类专家提供的反馈，学习过程可以针对特定的需求或目标进行定制。

在循环中有人类存在的不利之处在于，人类可能会犯错误或提供不一致的反馈，这可能会影响代理的学习。此外，使用人类反馈训练 AI 代理可能是一个缓慢的过程，因为它需要人类专家的持续输入。换句话说，它往往劳动密集且可能成本高昂。因此，重要的是要提前估计此类项目所需的人类和财务资源，以确保其可行性。

重要的是要注意，行业专家几乎可以成为任何机器学习练习的极其宝贵的贡献者。例如，我们经常使用行业专家来帮助我们审查模型的输出，因为这使我们能够发现问题空间中的新上下文，这些上下文应该成为训练数据中的特征。

在缺失验证码的例子中，我们通过首先通过采访呼叫中心工作人员（一种行业专家）和听取通话录音（我们自己成为行业专家）来深入了解具体的失败点，从而发现了问题的根源。一旦我们缩小了可能的问题范围，我们就与 IT 部门的同事（另一种行业专家）一起深入核心系统的内部运作，以验证故障。

这种方法与强化学习不同，但它强调了在整个开发过程中涉及行业专家的价值，即使这需要人工输入。

## 使用程序化标注来规范标注规则

使用人工标注的传统方法有时是过程中的瓶颈，可能会阻止我们以既高效又经济的方式创建高质量的训练集。这通常是在处理大量数据集时出现的问题。随着机器学习模型变得更加复杂，数据集变得更大，时间和成本效益高的训练变得越来越重要。

进入程序化标注。从本质上讲，程序化标注是一个基于预定义的规则或算法自动为数据点分配标签的过程。程序化标注相对于人工标注的主要优势是，它可以比人工标注更快、更准确地完成——一旦建立了稳健的标注功能。这使得它非常适合大型数据集，在这些数据集中，人工标注可能耗时过长或成本过高。

程序化标注的过程始于定义需要分配给每个数据点的标签。这可以通过 SMEs 手动完成，或者通过自动化方法，如**自然语言处理**（**NLP**）算法或基于规则的系统来完成。一旦定义了标签，就可以使用监督学习或无监督学习算法将它们应用于数据点。

程序化标注的主要好处如下：

+   **可扩展性**：程序化标注可以比人工标注更高效地处理大量数据，从而实现更快的模型训练和迭代。

+   **一致性**：自动化的标注方法确保在整个数据集中一致地应用规则和标准，减少变异性以及可能由人为主观性引起的潜在错误。

+   **成本效益**：通过自动化标注过程，组织可以节省在培训、管理和补偿人工标注员所需的时间和资源。

+   **速度**：程序化标注可以比人工标注更快地处理和标注数据，从而加速整个机器学习流程。

+   **减少人为错误**：自动化最小化了在人工标注过程中可能引入的人为错误和不一致性风险。

+   **可重复性**：自动化的标注过程易于复制，确保结果可以在不同的数据集和项目中重复和验证。

+   **适应性**：程序化标注算法可以根据需要微调和更新，以适应不断变化的需求、新的数据源或不断发展的项目目标。

+   **24/7 可用性**：与人工标注员不同，程序化标注可以持续运行，无需休息或停机时间，从而确保机器学习项目进展不间断。

我们将在*第六章*“*机器学习中的程序化标注技术*”中向您展示如何使用特定的程序化标注技术。

程序化标注技术通常足以提高数据质量。然而，在某些情况下，特征之间的关系过于复杂，基于规则的算法无法完成这项工作。这使我们来到了数据为中心的机器学习的第三原则。

# 原则 3 – 使用机器学习改进你的数据

正如我们可以使用程序化或算法方法来标注我们的数据一样，我们也可以使用机器学习来识别可能错误或不明确的数据点。通过利用可解释性、错误分析和半监督方法的发展，我们可以创建新的标签并找到改进或丢弃的数据点。

这里有一些使用机器学习生成更好输入数据的实际步骤：

+   **丢弃噪声示例**：有时，更多的数据并不总是更好的。噪声数据可能导致预测不准确。通过移除噪声示例，我们可以提高输入数据的质量。例如，如果你正在分析客户评论，其中一些评论充满了随机字符或不相关信息，这些可以被认为是“噪声”并予以移除。

+   **使用技术来关注数据子集以提高质量**：并非所有数据都具有相同的价值。我们可以关注数据子集来提高输入数据的质量。例如，如果你正在分析销售数据，你可能只会关注你最有利可图的地区的子集数据，以获得最大的回报，其他条件相同。

+   **通过利用专家输入的 ML 泛化来扩展可用的标签数据**：ML 可以通过使用专家输入来实现类似精度和更大覆盖范围来扩展可用的标签数据。例如，鸟类物种的专家可以提供关于有限图像集的输入，ML 可以使用这些输入来准确地为更大的图像集打标签。

+   **使用半监督方法**：包括弱学习和主动学习在内的半监督方法可以用来识别需要专家审查的数据点。例如，你可能会使用主动学习来识别需要由人工进行情感分析的客户电子邮件。

+   **使用可解释性**：可解释性在识别数据中的模式和确保模型有意义方面至关重要。复杂的模型需要特定的或模型无关的可解释性方法，包括局部和全局方法以及 SHAP 值。例如，使用 SHAP 值可以帮助你理解为什么你的模型在贷款审批过程中预测了某个特定的结果，确保决策过程透明且可解释。

+   **使用错误分析**：错误分析可以帮助识别模型在数据中犯错的模式，从而帮助我们提高输入数据的质量。例如，如果你的模型在图像识别中将猫错误地识别为其他东西，错误分析可以帮助你找出它在哪里以及为什么犯这些错误。

执行这些步骤所需的技术将在本书随后的章节中概述。

通过在生产中应用这些步骤，我们可以识别标签函数或模型中的性能漂移。此外，我们可以识别需要人工审查的数据点，从而提高输入数据的质量并改善预测准确性。

使用 ML 来提高输入数据质量是传统 ML 方法的一个根本性转变。它需要从使用 ML 模型进行最佳预测的心态转变为使用 ML 来识别那些不利于模型性能的数据点。毕竟，以数据为中心的 ML 的目标是增加输入数据中的信号并减少噪声。

采用数据中心的做法也为我们提供了一个独特的机会，以符合伦理、负责任和良好治理的机器学习实践的方式收集和精炼数据。这种关注点的转变使我们能够设计我们的数据策略，不仅围绕性能提升，还围绕公平、透明和问责制原则。

在我们继续前进的过程中，我们将探讨这种方法如何帮助我们将伦理嵌入到我们的数据收集和精炼过程的内核。这样，我们可以确保提高数据质量与保持我们机器学习应用的完整性和可靠性相辅相成。

# 原则 4 - 遵循道德、负责任和良好治理的机器学习实践

随着数据中心的兴起，我们能够应对更多高风险挑战，道德和负责任的机器学习实践变得越来越重要。这要求你在设计算法时考虑透明度、公平性和问责制等因素，以确保它们不会歧视某些群体或个人。此外，负责实施这些系统的人必须了解它们的工作原理，并理解它们的局限性，以便他们可以就其使用做出明智的决定。

很不幸，道德和负责任的机器学习实践通常不如应有的那样发达。在 2021 年，IBM 商业价值研究所和牛津经济研究所进行了一项研究 1，其中 75%的高管将 AI 伦理视为重要；然而，不到 20%的高管强烈同意他们的组织实践与声明的原则和价值观相一致。

作为数据中心的机器学习从业者，我们需要考虑的是，“数据质量”这个术语比单个数据点的客观准确性要广泛得多。高质量的数据还应使我们能够在整个机器学习开发过程及其之外识别和监控潜在的伦理问题。

人工智能伦理和责任不仅仅是打勾作业，它可能是一个潜在的差异化来源。关注 AI 伦理的组织更有可能获得客户的信任，而忽视它的组织可能会遭受客户的反感和声誉损害 2。

英国 2020 年*学校评级丑闻*的故事突显了在高风险环境中使用机器学习时忽视伦理考虑可能发生的事情。在 COVID-19 大流行期间，由于封锁，英国各地的学生无法参加考试。相反，使用了一个算法来评定学生的考试成绩，导致大量学生获得的分数低于他们应得的分数。这引起了学生、教师和学术界的强烈不满，因为它被视为不公平和不公正。

英国监管机构 Ofqual 使用的算法旨在标准化不同学校的成绩，以便进行比较。它考虑了诸如先前成就和学校表现等因素。然而，它没有考虑个别学生的表现或教师评估，这导致许多学生获得的分数低于他们应有的分数。

相反，该模型偏袒来自私立机构和富裕地区的学生，这对公立、公立资助学校的高绩效个体产生了重大影响。因此，许多学生因考试成绩降低而失去了大学录取资格。这给那些努力学习考试却因未能准确反映其能力的算法而失望的学生带来了极大的痛苦。最终，算法给出的分数被取消，并由更公平但更手动评分的方法所取代。

为了避免未来发生类似英国评分灾难等类似事件，AI 系统必须从一开始就考虑到道德因素进行设计。总的来说，这一事件突显了与 AI 系统相关的某些伦理问题，并说明了为什么在我们设计和实施这些系统时考虑这些问题非常重要。它还提醒我们，如果我们希望这些系统能够成为我们社会中决策的有效工具，我们必须确保这些系统是透明的、公平的和可问责的。

我们将在*第四章**，数据标注是一个协作过程*中讨论处理标注模糊性的具体方法，并在*第八章**，识别和消除偏差的技术*中向您展示一系列识别和消除偏差的技术。

# 摘要

在本章中，我们概述了以数据为中心的机器学习的四个原则。通过遵循这些原则，您将能够创建基于高质量数据的机器学习模型，这些数据已经通过人类、标签函数和机器学习技术进行了增强、交叉检查和验证。

这使我们能够从数据中获得更多信号，从而提高我们在小型或大型数据集上构建强大模型的能力。最后，我们可以在整个开发生命周期中捕捉到伦理考虑，这最终确保我们使用我们的力量行善。

在下一章中，我们将探讨您可以如何结构化、优化和治理使用人工标注员进行您的机器学习项目的流程。

# 参考文献

1.  [`www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action`](https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action)，2023 年 6 月 1 日访问

1.  [解码 AI 在商业成果中的信任与伦理](https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/), 访问于 2023 年 6 月 1 日
