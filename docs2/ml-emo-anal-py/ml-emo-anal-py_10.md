# 10

# 多分类器

在前面的章节中，我们看到了多标签数据集，其中一条推文可能有零个、一个或多个标签，与每个推文恰好有一个标签的简单多类数据集相比，处理起来要困难得多，尽管这些标签来自一个包含多个选项的集合。在本章中，我们将探讨处理这些情况的方法，特别是探讨使用**中性**标签来处理允许推文有零个标签的情况；使用不同的阈值来使标准分类器返回可变数量的标签；以及训练多个分类器，每个标签一个，并允许它们各自对其训练的标签做出决定。结论，一如既往，将是没有单一的“银弹”可以在每种情况下提供最佳解决方案，但总的来说，使用多个分类器往往比其他方法更好。

本章我们将涵盖以下主题：

+   使用混淆矩阵来分析复杂数据上分类器的行为

+   使用**中性**标签来处理未分配标签的推文

+   使用不同的阈值来处理多标签数据集

+   训练多个分类器来处理多标签数据集

在本章结束时，您将了解如何实施几种处理多标签数据集的策略，并会对这些策略对不同类型数据的有效性有所认识。

# 多标签数据集难以处理

我们将从查看前几章中选择的几个分类器在主要数据集上的性能开始。我们曾多次提到多标签数据集特别具有挑战性，但将表现最好的算法的结果汇集在一起，可以看到它们究竟有多具挑战性。*图 10.1*包括了迄今为止我们查看的所有主要分类器。多标签数据集以灰色突出显示，每行的最佳性能分类器以粗体/星号标记：

|  | **LEX** | **CP** | **NB** | **SVM** | **SNN** | **DNN** | **Transformers** |
| --- | --- | --- | --- | --- | --- | --- | --- |
| **SEM4-EN** | 0.497 | 0.593 | 0.775 | 0.845 | 0.829 | 0.847 | ***** **0.927 *** |
| **SEM11-EN** | 0.348 | 0.353 | 0.227 | 0.224 | 0.242 | 0.246 | ***** **0.418 *** |
| **WASSA-EN** | 0.437 | 0.505 | 0.709 | ***** **0.770 *** | 0.737 | 0.752 | 0.753 |
| **CARER-EN** | 0.350 | 0.395 | 0.776 | 0.770 | ***** **0.820*** | 0.804 | 0.816 |
| **IMDB-EN** | 0.667 | 0.722 | 0.738 | 0.736 | 0.793 | 0.793 | ***** **0.826 *** |
| **SEM4-AR** | 0.509 | 0.513 | 0.531 | 0.514 | 0.504 | 0.444 | ***** **0.710 *** |
| **SEM11-AR** | ***** **0.386 *** | 0.382 | 0.236 | 0.216 | 0.221 | 0.207 | 0.359 |
| **KWT.M-AR** | 0.663 | ***** **0.666 *** | 0.494 | 0.631 | 0.028 | 0.026 | 0.053 |
| **SEM4-ES** | 0.420 | 0.177 | 0.360 | 0.412 | 0.337 | 0.343 | ***** **0.663 *** |
| **SEM11-ES** | 0.271 | 0.278 | 0.230 | 0.226 | 0.221 | 0.222 | ***** **0.340 *** |

图 10.1 – 标准数据集选择的 Jaccard 分数（多标签数据集以灰色显示）

从这张表中，有两点特别突出：

+   在这个表格的大部分条目中，LEX 是最差的分类器，其次是 NB，然后其他分类器的得分通常相当相似。然而，对于多标签情况，LEX 或 CP 总是优于除变压器以外的任何其他分类器，而且在几个情况下，它们甚至优于变压器。鉴于这些数据集似乎是最现实的，因为许多推文没有表达情感，相当一部分推文表达了多个情感，因此值得更详细地研究这些情况中发生的事情。

+   多标签情况的整体得分也显著更差 – 虽然 LEX 和 CP 在这些情况下的表现优于大多数其他分类器，但它们通常在这些情况下的得分低于其他情况，而对于所有其他分类器，这些情况与单一情感/推文情况之间的差距是显著的。

这些情况在实践中似乎最有用，因为大多数推文都没有表达任何情感，相当一部分推文表达了多个情感，所以处理这些情况不佳的算法可能不适合这项任务。

在**混淆矩阵**部分，我们将查看各种算法对这两种数据集的处理方式。一旦我们更清楚地了解为什么多标签数据集比单标签数据集更难处理，并且我们已经看到它们对特定算法造成的具体问题，我们将探讨处理这类数据集的方法。我们不会使用基于变压器的模型进行这些实验，部分原因是训练变压器的耗时使得这不可行，但更重要的是，我们需要深入了解模型以了解其工作原理 – 这在基于变压器的模型中几乎是不可能的。

# 混淆矩阵

仅通过查看原始输出，很难看出分类器犯了什么错误。**混淆矩阵**使我们能够可视化分类器的行为，使我们能够看到两个类别是否被系统地混淆，或者某个类别是否被分配了太多或太少的项目。考虑以下数据集，其中每个项目由黄金标准（G）分类为 A、B 或 C，并且还有一个预测值（P）：

| G | C | C | A | B | C | B | C | B | B | B | A | A | B | B | C | C | B | C | B | B | C | A | B | A | A | C | C | C | A | A | A | C | B | C | A | A | B | A |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| P | C | B | B | B | C | A | A | B | B | A | A | A | C | B | A | B | B | C | B | C | C | A | B | B | B | C | B | B | B | A | B | C | B | B | A | A | B | A |

图 10.2 – 示例数据的黄金标准和预测值

在这个表格中很难看出任何模式。简单地计算 G 和 P 值相同的案例数量，我们得到 22 个案例中的 38 个 – 即，准确率为 0.58 – 但很难看出它做对了什么，做错了什么。将此转换为混淆表可以帮助解决这个问题。我们通过计算应该分配 C1 作为其值的项被预测为具有 C2 的次数来实现这一点，从而产生一个正确与预测分配的表格。例如，图 10.3 中的混淆矩阵显示，七个本应被分配标签 A 的项确实被分配了该标签，但五个被分配了 B，而六个本应被分配 C 的项被分配了 C 但五个被分配了 B。这表明 B 的某些属性使得在它们应该被分配到 A 或 C 时容易将它们分配到这个类别，这可能导致对导致此问题的 B 的哪些属性进行调查的探究：

|  | **A** | **B** | **C** |
| --- | --- | --- | --- |
| **A** | 7 | 5 | 0 |
| **B** | 2 | 9 | 2 |
| **C** | 2 | 5 | 6 |

图 10.3 – 图 10.2 中数据的混淆矩阵

如果 `gs` 和 `p` 是一组点的黄金标准值，那么 `confusion` 将计算混淆矩阵：`c` 是一个表格，其中为 `gs` 中的每个标签都有一个条目，该标签的值是预测为该标签的次数集合：

```py
def confusion(gs, p):    c = {}
    for x, y in zip(gs, p):
        if not x in c:
            c[x] = counter()
        c[x].add(y)
```

混淆矩阵可以提供大量关于分类器所做事情的信息。然而，当黄金标准和预测可以包含不同数量的情绪时，构建混淆矩阵会有一些小问题。例如，假设某些推文的黄金标准是**爱+喜悦**，而预测是**爱+悲伤+愤怒**。我们想要承认当分类器预测**爱**时是正确的，但关于它遗漏了**喜悦**（即存在一个假阴性）以及预测了**悲伤**和**愤怒**（两个假阳性）的事实我们该如何处理？

对于这个问题没有正确答案。我们按照以下方式调整构建混淆矩阵的标准方法，其中 C[e1][e2] 是黄金标准中 *e1* 和预测中 *e2* 的得分。我们需要为“未分配情绪”添加一行和一列（我们将使用 **--** 表示此类类别）：

+   对于黄金标准和预测包含给定情绪 *e* 的每个情况，将 1 添加到 *C[e][e]*，并从黄金标准和预测中删除 *e*。

+   如果黄金标准现在为空，那么预测中剩余的每个 *e* 必须是一个假阳性，因此对于每个剩余的 *e*，将 1 添加到 *C[--][e]*。

+   如果预测为空，那么黄金标准中剩余的每个 *e* 必须是一个假阴性，因此将 1 添加到 *C[e][--]*。

+   如果在移除共享案例后两者都不为空，很难看出要做什么。考虑前面的例子。在移除**爱**之后，我们在金标准中剩下**快乐**，在预测中剩下**悲伤+愤怒**。**快乐**是**悲伤**的错误，而**愤怒**是假阳性吗？**快乐**是**愤怒**的错误，而**悲伤**是假阳性吗？**快乐**是假阴性，而**悲伤**和**愤怒**都是假阳性吗？最后一个建议似乎不正确。假设我们有一个案例，其中**快乐**与**悲伤+愤怒**相匹配，另一个案例中它与**悲伤+恐惧**相匹配，还有一个案例中它与**悲伤**相匹配。如果我们将这些情况都标记为**快乐**是假阴性而**悲伤**是假阳性的案例，我们就会错过**快乐**和**悲伤**之间似乎存在联系的事实。

我们是这样处理的。假设在移除了两者都出现的标签之后，金标准中剩下**G**个项目，预测中剩下**P**个项目。在这里，对于金标准中的每个**g**和预测中的每个**p**，我们向**C[p][g]**中添加**1/P**。这样做总共向混淆矩阵中添加了**G**，从而承认金标准中的情绪数量尚未匹配，预测中的每个项目被视为有同等可能性是应该替换**g**的那个。

计算修改后的混淆矩阵的机制相当复杂，将其包含在这里对前面的解释增加的很少。这本书的 GitHub 仓库中有这个代码——目前，最好只是注意一下，当一个项目可以分配多个标签时，混淆矩阵必须考虑到金标准和预测都分配了多个标签的情况，分配的集合大小不同，并且有些标签两者都有，有些只出现在金标准中，有些只出现在预测中。

我们这样做的方式在金标准与预测之间并不对称，但它确实提供了混淆矩阵，这些矩阵告诉我们关于给定分类器正在做什么的一些有用的信息。对于金标准和预测中恰好有一个项目的情况，它将退化为标准版本，而对于每个中都有不同数量项目的情况，它确实提供了一幅正在发生的事情的图景。

我们将首先查看使用 SVM 作为分类器（SVM 和 DNN 的分数非常相似，混淆矩阵也非常相似，因此为了方便，我们将在这里使用 SVM）的 CARER-EN 混淆矩阵。以下矩阵是使用一个简单的 SVM 版本获得的，该版本只是为每条推文选择最可能的情绪，而不是使用阈值来尝试确定是否有任何情绪足够可能被计算，如果是这样，是否有几个可以计算：

|  | **愤怒** | **恐惧** | **快乐** | **爱** | **悲伤** | **惊讶** |  |
| --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 124 | 0 | 1 | 0 | 1 | 0 |  |
| **恐惧** | 1 | 128 | 0 | 0 | 0 | 1 |  |
| **快乐** | 0 | 0 | 337 | 1 | 0 | 0 |  |
| **爱** | 0 | 0 | 1 | 73 | 0 | 0 |  |
| **悲伤** | 0 | 1 | 1 | 0 | 293 | 0 |  |
| **惊讶** | 0 | 0 | 0 | 0 | 0 | 37 |  |

图 10.4 – 使用 SVM 作为分类器的 CARER-EN，每条推文一个情感，混淆矩阵

这是你期望的混淆矩阵看起来像什么——对角线上的最大分数和一些其他分配的散点，最大的混淆发生在**爱**和**快乐**之间。当我们对 SEM11-EN 使用相同的算法时，我们得到了一个非常不同的图像：

|  | **愤怒** | **反** | **厌恶** | **恐惧** | **快乐** | **爱** | **乐观** | **悲观** | **悲伤** | **惊讶** | **信任** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 311 | 2 | 0 | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |
| **期待** | 8 | 65 | 1 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 12 |
| **厌恶** | 10 | 3 | 36 | 1 | 3 | 0 | 0 | 0 | 0 | 0 | 1 | 182 |
| **恐惧** | 9 | 0 | 0 | 46 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 34 |
| **快乐** | 11 | 2 | 1 | 1 | 186 | 0 | 0 | 0 | 0 | 0 | 1 | 39 |
| **爱** | 0 | 1 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 0 | 0 | 40 |
| **乐观** | 7 | 1 | 0 | 2 | 2 | 0 | 20 | 1 | 0 | 0 | 0 | 119 |
| **悲观** | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 19 | 0 | 0 | 0 | 26 |
| **悲伤** | 9 | 3 | 1 | 1 | 3 | 0 | 0 | 1 | 16 | 0 | 0 | 119 |
| **惊讶** | 4 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 16 |
| **信任** | 2 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 15 |
| **--** | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 21 | 0 |

图 10.5 – 使用 SVM 作为分类器的 SEM11-EN，每条推文一个情感，混淆矩阵

我们得到了几个错误阳性（预期没有但预测到了的地方——即以**--**为首的行：其中两个被分配了**愤怒**，21 个**信任**）。这是因为我们迫使分类器在黄金标准不期望任何东西的情况下也要选择一些东西。我们还有许多地方存在错误阴性（以**--**为首的列），预期有东西但什么也没有找到，通常是因为黄金标准有多个标签，而只有一个预测。还有许多情况，分配是错误的，大量的事情被错误地标记为**愤怒**，而它们应该是其他东西。

问题在于，如果分类器被强制为每条推文分配恰好一种情绪，那么它无法避免产生误报（如果黄金标准说没有任何东西应该被分配）和漏报（如果黄金标准说应该分配多种情绪）。如果我们仔细查看测试集，我们会看到有 23 条没有分配情绪的推文，这些推文显示为误报，还有 645 条分配了多种情绪的推文，这些推文显示为 1,065 条漏报（因为其中一些被分配了三种或更多情绪）。*如果我们的分类器假设每条推文只有一个情绪，那么对此就无能为力了*。

假设我们共有*N*条推文，其中*X*条没有分配情绪，*Y*条分配了多种情绪。在这种情况下，至少会有*X*条误报（每条应该没有标签但分类器分配了一个标签的推文）和至少*Y*条漏报（每条应该有多个标签但分类器只分配了一个标签的推文），这意味着最佳可能的 Jaccard 分数是*(N-X)/((N-X)+X+Y)*。对于 SEM11-EN 中的 772 条推文集合，这个分数是*(772-23)/(772-23+(1065+23)) = 0.41*（由于应该分配两个以上标签的推文占多数，漏报的数量非常高——这个方程假设推文被分配了零、一或两个标签）。这是一个严格的上限。没有任何分类器能够在这个数据集上实现高于 0.41 的 Jaccard 分数。

位置比这还要糟糕。仔细检查对角线显示，一些情绪在对角线上有很好的分数（**愤怒**，**快乐**），而其他情绪在对角线上分数非常低，并且有很多漏报（**厌恶**，**爱情**，**乐观**），其中几种情绪与**愤怒**混淆。

当我们查看 KWT.M-AR 数据集时，我们会看到一些方面相似但并不令人鼓舞的输出：

|  | **愤怒** | **厌恶** | **恐惧** | **快乐** | **爱情** | **乐观** | **悲观** | **拒绝** | **信任** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 0 |
| **不满** | 0 | 21 | 0 | 0 | 0 | 0 | 0 | 0 | 31 | 1 |
| **恐惧** | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |
| **快乐** | 0 | 0 | 0 | 11 | 0 | 0 | 0 | 0 | 12 | 0 |
| **爱情** | 0 | 0 | 0 | 0 | 50 | 0 | 0 | 0 | 44 | 3 |
| **乐观** | 0 | 0 | 0 | 0 | 0 | 22 | 0 | 0 | 17 | 0 |
| **悲观** | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 2 | 2 |
| **拒绝** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |
| **信任** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 14 | 0 |
| **--** | 0 | 1 | 0 | 0 | 8 | 3 | 0 | 0 | 751 | 0 |

图 10.6 – 使用 SVM 作为分类器的 KWT.M-AR 每条推文一个情绪的混淆矩阵

这次，有大量的假阳性，这反映了这些数据集在黄金标准中未分配情感的比例非常高（在本测试集中，有 763 个，占总数的 76.3%，最大可达到的 F1 分数约为 0.42）。同样，这是不可避免的——如果一条推文应该没有任何情感分配，而分类器被迫分配一个，那么我们将得到一个假阳性。还值得注意的是，尽管对角线上的非平凡条目很多，但令人惊讶的是，有大量情况中正确的分配被替换为 `angry: 2.38`，`fuming: 2.32`，`annoying: 2.31`，`revenge: 2.26`，……对于 `positivity: 1.82`，💕`: 1.75`，`rejoice: 1.74`，`gift: 1.72`，`laughing: 1.70` 对于 `flat: 1.25`，`com: 1.19`，`cup: 1.06`，`need: 1.05`，`major: 1.05`。这些不是显然与信任相关的词，而且它们与这种情感之间的联系并不强。因此，当分类器被迫为不包含任何与特定情感相关联的词汇的推文选择情感时，它很可能会选择那些本就不期望有此类词汇的情感。

如果，如前所述，大量推文表达的是没有情感或多种情感，那么我们必须处理这些问题。我们可以尝试以下几种方法：

+   我们可以包含一个明确的“以上皆非”或“中性”类别来表示一条推文没有任何情感权重。对于“零情感”的情况，这是最容易做到的，尽管在推文被分配了多种情感的情况下，这并不理想。

+   我们可以利用某些分类器为每种情绪计算分数的事实。我们将在稍后更详细地探讨这一点。

+   我们可以训练一组二元分类器——**快乐**与**非快乐**，**愤怒**与**非愤怒**，等等。这可能会处理两种情况：如果这些分类器中的每一个都返回负版本，我们将得到一个整体零分配，如果有多个返回正版本，我们将得到多个分配。

在本章剩余部分，我们将专注于 SEM-11 和 KWT 数据集，因为这些是唯一具有可变标签数量的数据集。如果你的训练数据为每条推文分配了恰好一种情绪，并且你希望在运行分类器对实时数据进行分类时也恰好分配一种情绪，那么其他方法通常能提供最佳解决方案——LEXCLASSIFIER 通常在极短的训练时间内提供相当准确的结果，Transformer 通常提供最佳结果但需要大量训练，而 SVM 和 DNN 在准确性和训练时间之间处于中等水平。

# 使用“中性”作为标签

我们可以通过查看 Gold Standard 分配的标签来简单地引入**中性**作为标签。这不会影响 CARER-EN 集：训练数据中没有分配**中性**，因此没有找到与该标签相关的单词，因此，反过来，分类器没有分配任何内容。对 SEM11-EN 数据的影响更有趣：

|  | **愤怒** | **反义** | **厌恶** | **恐惧** | **喜悦** | **爱情** | **乐观** | **悲观** | **悲伤** | **惊讶** | **信任** | **中性** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 311 | 2 | 0 | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |
| **期待** | 8 | 65 | 1 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 12 |
| **厌恶** | 10 | 3 | 36 | 1 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 182 |
| **恐惧** | 9 | 0 | 0 | 46 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 34 |
| **喜悦** | 11 | 2 | 1 | 1 | 186 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 39 |
| **爱情** | 0 | 1 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 0 | 0 | 0 | 40 |
| **乐观** | 7 | 1 | 0 | 2 | 2 | 0 | 20 | 1 | 0 | 0 | 0 | 1 | 118 |
| **悲观** | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 19 | 0 | 0 | 0 | 0 | 26 |
| **悲伤** | 9 | 3 | 1 | 1 | 3 | 0 | 0 | 1 | 16 | 0 | 0 | 0 | 119 |
| **惊讶** | 4 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 16 |
| **信任** | 2 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 15 |
| **中性** | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 21 | 0 |

图 10.7 - SEM11-EN 的混淆矩阵，每条推文一个情绪，使用 SVM 作为分类器，中性作为标签

在对角线以下的变化非常小——也就是说，分类器在有或没有**中性**标签的情况下，对相同的实际情绪的判断是相同的；大多数本应被归类为中性的事物确实被标记为中性，有少数被错误地标记为**愤怒**；有几件事物被错误地标记为**中性**，而它们不应该被这样标记；由于有很多推文本应被赋予多个标签，因此仍然有很多假阴性。这些推文不能被分类器标记为**中性**，因为分类器只能为每条推文分配一个标签，所以任何本应被赋予多个标签的推文都将导致假阴性集的增加。

KWT 示例的情况很吸引人。这些示例中有大量没有分配情绪的推文，因此我们预计如果分类器设置为每条推文分配一个情绪，将会出现很多假阳性。这里给出了 KWT.M-AR 在有和没有**中性**标签时的混淆矩阵：

|  | **愤怒** | **厌恶** | **恐惧** | **喜悦** | **爱情** | **乐观** | **悲观** | **拒绝** | **信任** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 7 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 |
| **不满** | 0 | 19 | 0 | 0 | 0 | 0 | 0 | 0 | 17 | 4 |
| **恐惧** | 0 | 0 | 3 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |
| **喜悦** | 0 | 0 | 0 | 11 | 0 | 0 | 0 | 0 | 23 | 2 |
| **爱** | 0 | 0 | 0 | 0 | 82 | 0 | 0 | 0 | 47 | 1 |
| **优化** | 0 | 0 | 0 | 0 | 0 | 37 | 0 | 0 | 18 | 2 |
| **悲观** | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 2 | 0 |
| **拒绝** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 2 | 0 |
| **信任** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 12 | 1 |
| **--** | 0 | 2 | 0 | 3 | 13 | 2 | 0 | 0 | 697 | 0 |

图 10.8 - KWT.M-AR 的混淆矩阵，每条推文一个情感，使用 SVM 作为分类器，不包括中性

如前所述，对角线上的大多数分数都相当好——也就是说，大多数时候，分类器在需要分配标签的地方分配了正确的标签。不可避免的是，存在大量错误阳性，几乎所有这些都被分配给了**信任**。如前所述，在几乎每个金标准说应该没有标签的情况下，分类器都选择了**信任**，而不是将错误阳性均匀分配。再次，似乎发生的情况是分类器没有特别强烈地将任何单词与**信任**关联起来，因此当它被给出一个没有任何非常显著单词的推文时，它决定它不可能是其他任何类别，因为这些类别有更强的线索，所以它选择了**信任**。

当我们允许**中性**作为标签时，情况发生了相当大的变化。现在，几乎所有错误阳性都被分配给了**中性**，这是最合理的结果。由于这个数据集包含具有多个标签的推文，因此存在一些错误阴性，但对角线变得更加清晰——大多数情感都被正确分配，大多数没有情感的情况都被分配给了**中性**：

|  | **愤怒** | **不满** | **恐惧** | **快乐** | **爱** | **优化** | **悲观** | **拒绝** | **信任** | **中性** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 7 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 |
| **不满意** | 0 | 19 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 17 | 4 |
| **恐惧** | 0 | 0 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 |
| **快乐** | 0 | 0 | 0 | 11 | 0 | 0 | 0 | 0 | 0 | 24 | 1 |
| **爱** | 0 | 0 | 0 | 0 | 81 | 0 | 0 | 0 | 0 | 48 | 1 |
| **优化** | 0 | 0 | 0 | 0 | 0 | 37 | 0 | 0 | 0 | 18 | 2 |
| **悲观** | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 2 | 0 |
| **拒绝** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 2 | 0 |
| **信任** | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 5 | 1 |
| **中性** | 0 | 2 | 0 | 2 | 14 | 2 | 0 | 0 | 0 | 697 | 0 |

图 10.9 - KWT.M-AR 的混淆矩阵，每条推文一个情感，使用 SVM 作为分类器，包括中性

因此，使用**中性**作为标签为无标签和多个标签的问题提供了一个部分解决方案，但它**不能**提供一个完整的解决方案。即使分类器在为应该恰好有一个标签的推文分配标签时是 100%准确的，并且当它为应该没有标签的推文分配**中性**时，它也必须为应该有多个标签的情况引入错误阴性。

现在是引入一个新的性能度量指标的好时机。大多数既没有被分类为**中性**也没有被赋予任何标签的案例都位于对角线上，这表明一组推文被分配的总体分类可能有助于衡量观点，即使对个别推文的分配是不可靠的。特别是，当你试图发现一般趋势时，假阴性可能不是很重要，只要分类器分配标签的案例与基本现实一致。

当然，不可能确定某件事是假阴性还是真正的中性分配实例，然后询问假阴性的分配应该是什么。如果我们能这样做，那么我们最初就会训练分类器来完成这项任务，同样对于假阳性也是如此。我们能做的最好的事情就是评估如果我们接受分类器做出的所有分配，我们可能会被误导到何种程度。因此，我们将分类器的**比例性**定义为金标准中分配给每种情感的推文比例与预测（即忽略分配为**中性**或完全没有标签的推文）之间的余弦距离。这个值越接近 1，我们越可以期待我们的分类器给出一个可靠的总体情况，即使一些个别分配是错误的。

以一个简单的例子来说明，假设我们有一个包含 SEM11 数据中 11 种情感的语料库，悲观和悲伤的推文数量相同，并且它几乎完全正确，除了恰好将一半本应被标记为悲观的推文标记为悲伤，以及恰好将一半本应被标记为悲伤的推文标记为悲观。在这种情况下，比例将是完美的，你可以安全地使用这个分类器来对整体情况做出判断，即使你不能依赖它来告诉你某个推文是否悲伤或悲观。同样，如果每个类别中一半的推文都没有被分配情感，那么比例将是完美的，而如果最常见的类别中一半的推文被分配为中性，但没有其他推文被分配，那么这将是相当差的。

从现在起，我们将对我们在训练过程中生成的所有分类器都这样做，因为与单个折叠相关的测试集相对较小（这就是我们最初进行交叉折叠验证的原因），并且通过忽略中性和未分配的推文，我们失去了很多实例。为了计算比例性，我们只需计算预测/金标准中包含每种情感的推文数量，*忽略中性和未分配的推文*，并将结果归一化：

```py
def proportions(clsfs, emotions, which=lambda x: x.predicted, ignore=["neutral", "--"]):    conf = numpy.zeros(len(emotions))
    for clsf in clsfs:
        for t in clsf.test.tweets:
            for i, k in enumerate(which(t)):
                if not emotions[i] in ignore:
                    if k == 1:
                        conf[i] += 1
    return conf/sum(conf)
```

现在，我们可以对预测和金标准进行这样的操作，并使用余弦相似度来计算两者之间的相似度：

```py
def scoreproportions(clsfs):    ignore = ["neutral", "--"]
    emotions = clsfs[0].train.emotions
    predictedproportions = proportions(clsfs, emotions, ignore)
    gsproportions = proportions(clsfs, emotions, ignore,
                                which=lambda x: x.GS)
    return cosine_similarity(predictedproportions.reshape(1, -1),
                             gsproportions.reshape(1, -1))[0][0]
```

对于 SEM11-EN，允许每条推文有任意数量的情感，并使用 LEX 作为分类器以及`neutral`作为标签，例如，预测和黄金标准中分配给每个标签的推文比例分别为`愤怒：0.30`，`期待：0.00`，`厌恶：0.31`，`恐惧：0.02`，`快乐：0.25`，`爱情：0.00`，`乐观：0.04`，`悲观：0.00`，`悲伤：0.06`，`惊讶：0.00`，`信任：0.00`和`愤怒：0.18`，`期待：0.06`，`厌恶：0.17`，`恐惧：0.06`，`快乐：0.15`，`爱情：0.04`，`乐观：0.12`，`悲观：0.04`，`悲伤：0.12`，`惊讶：0.02`，`信任：0.02`，相应的比例分数为 0.89。如果我们使用相同的分类器，以`neutral`作为标签，但允许每条推文恰好有一个标签，比例分数将降至 0.87。

如果我们将此应用于 KWT.M-AR 数据集，我们得到预测为`愤怒：0.03`，`不满：0.07`，`恐惧：0.00`，`快乐：0.07`，`爱情：0.69`，`乐观：0.10`，`悲观：0.00`，`拒绝：0.02`，`信任：0.02`，对于黄金标准为`愤怒：0.04`，`不满：0.16`，`恐惧：0.02`，`快乐：0.10`，`爱情：0.43`，`乐观：0.18`，`悲观：0.01`，`拒绝：0.01`，`信任：0.05`，比例分数为 0.94。如果我们没有忽略中性/未分配的案例，分数将高得多，达到 0.99，因为在这个数据集中中性案例的巨大优势。因此，我们有一个有用的单一数字，它让我们能够了解分类器在提供整体图景方面的可靠性，即使它未能为每条推文分配具体标签（也就是说，有些可能什么都没有分配，或者被分配了**中性**）。

这个分数通常相当高，因为在大多数情况下，大多数具体分数都位于对角线上。重要的是中性/未分配案例的分布是否遵循具体案例的一般分布——如果遵循，那么即使有时在应该分配具体标签时未能分配，分类器也会对评估总体趋势有用。因此，我们将在此章的剩余部分使用此度量标准，除了 Jaccard 之外来评估分类器。*图 10.10*和*10.12*中的表格显示了当我们添加**中性**作为标签，并坚持为每条推文分配一个确切标签时，各种分类器的比例发生了什么变化。作为一个参考点，我们首先看看如果我们指定每个分类器在未使用**中性**的情况下返回会发生什么。与之前一样，具有最佳 Jaccard 分数的分类器用粗体标出：

|  | **LEX** | **NB** | **SVM** | **DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | 0.224 (0.813) | 0.229 (0.690) | 0.223 (0.771) | *** 0.242 (****0.677) *** |
| **SEM11-AR** | *** 0.247 (****0.824) *** | 0.216 (0.667) | 0.204 (0.736) | 0.207 (0.613) |
| **SEM11-ES** | 0.225 (0.799) | *** 0.226 (****0.788) *** | 0.215 (0.888) | 0.222 (0.774) |
| **KWT.M-AR** | *** 0.208 (****0.973) *** | 0.108 (0.352) | 0.078 (0.207) | 0.026 (0.148) |

图 10.10 – Jaccard 和比例（括号内），每条推文一个标签，不包括中性

*图 10*.10 表明，如果我们简单地使用原始分类器不变——也就是说，每条推文一个情感，并且没有**中性**作为标签——我们得到的 Jaccard 分数相当低，但 LEX 的比例分数从合理到相当好，其他分类器在这个指标上通常表现更差。特别是 LEX 在 KWT.M-AR 数据集上的比例分数比这个数据集上其他任何分类器的相同分数都要好得多。关键在于 NB、SVM 和 DNN 将几乎所有应该被标记为**中性**的案例分配给了**信任**，因为这些案例缺乏在更明显标记的情感中常见的区分性词汇，而 LEX 则更接近地分配了它们。值得注意的是，对于给定的数据集，得分最高的分类器并不总是产生该集合的最佳比例：

|  | **ange** | **diss** | **fear** | **joy** | **love** | **opti** | **pess** | **reje** | **trus** | **--** |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **anger** | 9 | 19 | 0 | 0 | 11 | 2 | 0 | 0 | 0 | 14 |  |
| **dissat** | 4 | 133 | 0 | 2 | 71 | 1 | 0 | 0 | 0 | 0 |  |
| **fear** | 0 | 3 | 2 | 0 | 12 | 2 | 0 | 0 | 0 | 2 |  |
| **joy** | 1 | 6 | 0 | 53 | 50 | 8 | 0 | 0 | 1 | 18 |  |
| **love** | 0 | 7 | 0 | 8 | 548 | 12 | 0 | 0 | 0 | 0 |  |
| **optimi** | 0 | 5 | 0 | 1 | 44 | 180 | 0 | 0 | 1 | 2 |  |
| **pessim** | 0 | 4 | 0 | 0 | 7 | 2 | 2 | 0 | 1 | 1 |  |
| **reject** | 0 | 2 | 0 | 0 | 3 | 0 | 0 | 3 | 0 | 2 |  |
| **信任** | 1 | 9 | 0 | 2 | 28 | 8 | 0 | 0 | 13 | 3 |  |
| **--** | 30 | 880 | 4 | 159 | 2008 | 577 | 2 | 1 | 61 | 0 |  |

图 10.11 – KWT.M-AR 的混淆矩阵，每条推文一个标签，使用 LEX 作为分类器，不包括中性

当我们允许**中性**作为一个标签时，NB 和 SVM 可以选择这个标签作为具有最少独特术语的类别，因此将应该被分配为**中性**的案例分配给它，这导致这些分类器的 Jaccard 和比例都得到了大幅提升：

|  | **LEX** | **NB** | **SVM** | **DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | **0.222 (0.813)** | **0.227 (0.690)** | **0.222 (0.768)** | *** 0.239 (****0.677) *** |
| **SEM11-AR** | *** 0.246 (****0.824) *** | **0.216 (0.666)** | **0.204 (0.736)** | **0.207 (0.615)** |
| **SEM11-ES** | **0.221 (0.800)** | *** 0.222 (****0.787) *** | **0.211 (0.885)** | **0.216 (0.774)** |
| **KWT.M-AR** | **0.608 (0.984)** | **0.510 (0.986)** | *** 0.632 (****0.992) *** | **0.595 (0.905)** |

图 10.12 – Jaccard 和比例，每条推文一个标签，包括中性

因此，我们可以看到，使用比例作为指标使我们能够发现一般趋势。如果我们允许**中性**作为标签，我们的大部分分类器在多标签数据集上表现更好，尤其是在查看比例时，但 LEX 即使没有**中性**作为标签也能表现得相当好。

# 阈值和局部阈值

接下来要探索的选项是使用阈值。正如我们所见，我们的大多数分类器为每条推文的每个选项提供分数，默认设置是选择分数最高的选项。在*第六章*中，*朴素贝叶斯*，我们了解到假设我们的分类器将为每条推文分配一个精确的标签，这给其性能设定了一个相当紧的上限，而我们可以设置一个阈值，并说超过该阈值的任何内容都应被视为标签。

考虑以下推文：“*嗨，大家好！我现在通过 Skype 上课！联系我获取更多信息。# skype # lesson # basslessons # teacher # free lesson # music # groove # rock #* *blues*。”

金标准将此推文的分数分配为（‘愤怒’，0），（‘期待’，1），（‘厌恶’，0），（‘恐惧’，0），（‘快乐’，1），（‘爱情’，0），（‘乐观’，0），（‘悲观’，0），（‘悲伤’，0），（‘惊讶’，0），（‘信任’，0），因此它应该被标记为**期待+快乐**。

朴素贝叶斯将此推文分配的分数为（‘愤怒’，‘0.00’），（‘期待’，‘0.88’），（‘厌恶’，‘0.00’），（‘恐惧’，‘0.00’），（‘快乐’，‘0.11’），（‘爱情’，‘0.00’），（‘乐观’，‘0.00’），（‘悲观’，‘0.00’），（‘悲伤’，‘0.00’），（‘惊讶’，‘0.00’），（‘信任’，‘0.00’），因此如果我们把阈值设为 0.1，我们会得到**期待+快乐**；如果我们把阈值设为 0.2，我们只会得到**期待**；如果我们把阈值设为 0.9，我们则一无所获。

对于同一推文，SVM 分配的分数为（‘愤怒’，‘-0.77’），（‘期待’，‘0.65’），（‘厌恶’，‘-2.64’），（‘恐惧’，‘-1.67’），（‘快乐’，‘-0.99’），（‘爱情’，‘-1.93’），（‘乐观’，‘-3.52’），（‘悲观’，‘-1.61’），（‘悲伤’，‘-2.58’），（‘惊讶’，‘-1.47’），（‘信任’，‘-3.86’）。因此，这次，如果我们把阈值设为-1，我们会得到**愤怒+期待+快乐**；如果我们把阈值设为 0，我们只会得到**期待**；如果我们把阈值设为 1，我们则一无所获。

因此，使用阈值将使我们能够生成零个或多个标签。我们必须优化阈值，但我们可以通过找到任何推文中任何标签分配的最小和最大值，并在这些值之间均匀递增来实现这一点。《`bestThreshold`》函数，如*第五章*中所述，*情感词典和向量空间模型*，将像在那里一样与朴素贝叶斯、SVM 和 DNN 产生的原始分数一样工作。

如果我们将之前通过要求单个标签获得的分数与我们使用阈值允许零个或多个标签在关键数据集上获得的分数进行对比，我们将看到，总的来说，后者产生了更好的结果：

|  | **LEX** | **NB** | **SVM** | **DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | * 0.347 (0.898) * | 0.270 (0.764) | 0.250 (0.828) | 0.273 (0.729) |
| **SEM11-AR** | * 0.377 (0.940) * | 0.257 (0.761) | 0.224 (0.798) | 0.246 (0.731) |
| **SEM11-ES** | * 0.266 (0.890) * | 0.250 (0.837) | 0.228 (0.924) | 0.238 (0.791) |
| **KWT.M-AR** | * 0.691 (0.990) * | 0.522 (0.988) | 0.631 (0.998) | 0.604 (0.935) |

图 10.13 – 每条推文中零个或多个情感，带有最佳全局阈值

这里的分数比使用简单分类器时的分数要好得多，有些情况下比例分数几乎完美。然而，如果我们想要正确地为单个推文标签分配标签，而不仅仅是得到一个良好的整体印象，我们还有很长的路要走。下一步是为每个标签设置一个阈值，而不是为整个数据集设置。我们将从*第五章**，情感词典和向量空间模型*中调整`bestThreshold`，以便我们可以为标签分配单独的阈值。我们将对原始定义进行两项更改：

+   我们将把它分成两种情况 – 一种用于计算全局阈值（适用于所有情况的单个阈值）和另一种用于为每个标签计算局部阈值。

+   在原始版本中，我们查看数据中的每一列，找到任何地方出现的最小值和最大值，然后查看每一列的预测值来计算每个潜在阈值的 Jaccard 分数。为了计算局部阈值，我们只需要一次查看一列。如果我们指定一个列的范围，从`start`到`end`，我们可以处理这两种情况。对于全局情况，我们必须设置`start=0`和`end=sys.maxsize`；对于我们要为`i`列选择最佳阈值的情况，我们必须设置`start=i`和`end=i+1`。这使得我们可以使用相同的机制来计算这两种类型的阈值。以下更新版本中的主要更改已突出显示：

    ```py
        def bestThreshold(self, bestthreshold, start=0, end=sys.maxsize):
    ```

    ```py
            train = self.train.tweets[:len(self.test.tweets)]
    ```

    ```py
            self.applyToTweets(train, threshold=0, probs=True)
    ```

    ```py
            if bestthreshold == "global":
    ```

    ```py
                predicted = [t.predicted for t in train]
    ```

    ```py
                # select the required columns from the prediction
    ```

    ```py
                predicted = numpy.array(predicted)[start:end, :]
    ```

    ```py
                lowest = threshold = numpy.min(predicted)
    ```

    ```py
                highest = numpy.max(predicted)
    ```

    ```py
                step = (highest-lowest)/20
    ```

    ```py
                best = []
    ```

    ```py
                GS = numpy.array([t.GS for t in train])[:, start:end]
    ```

    ```py
                for i in range(20):
    ```

    ```py
                    l = self.applyToTweets(train, threshold=threshold)
    ```

    ```py
                    l = numpy.array(l)[:, start:end]
    ```

    ```py
                    m = metrics.getmetrics(GS, l, show=False)
    ```

    ```py
                    (macroF, tp, tn, fp, fn) = m
    ```

    ```py
                    j = tp/(tp+fp+fn)
    ```

    ```py
                    best = max(best, [j, threshold])
    ```

    ```py
                    if show:
    ```

    ```py
                        print("%.2f %.3f"%(threshold, j))
    ```

    ```py
                    threshold += step
    ```

    ```py
                return best[1]
    ```

    ```py
            elif bestthreshold == "local":
    ```

    ```py
                # do the global version, but just for each column in turn
    ```

    ```py
                localthresholds = []
    ```

    ```py
                for i in range(len(self.train.emotions)):
    ```

    ```py
                    localthreshold = self.bestThreshold("global",
    ```

    ```py
                                                        start=i, end=i+1)
    ```

    ```py
                    localthresholds.append(localthreshold)
    ```

    ```py
                return localthresholds
    ```

    ```py
            else:
    ```

    ```py
                raise Exception("%s unexpected value for bestthreshold"%(bestthreshold))
    ```

允许分类器为不同的标签选择不同的阈值的结果如下所示：

|  | **LEX** | **NB** | **SVM** | **DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | * 0.371 (0.987) * | 0.271 (0.827) | 0.270 (0.809) | 0.277 (0.811) |
| **SEM11-AR** | 0.371 (0.965) | 0.255 (0.854) | 0.236 (0.809) | 0.238 (0.795) |
| **SEM11-ES** | * 0.267 (0.962) * | 0.192 (0.674) | 0.222 (0.983) | 0.202 (0.852) |
| **KWT.M-AR** | 0.681 (0.989) | 0.217 (0.163) | 0.615 (0.987) | 0.226 (0.167) |

图 10.14 – 每条推文中零个或多个情感，带有最佳局部阈值

LEX 的比例分数都有所提高，现在 LEX 很容易给出 SEM11-EN 的最佳比例分数，朴素贝叶斯现在几乎对所有 KWT.U-AR 和其他大多数分数都回归到选择中性/未分配，尽管 Jaccard 分数只有 SEM11-EN 和 SEM11-ES 有所提高。再次强调，不同的分类器更适合不同的数据集和不同的任务。

# 多个独立的分类器

使用 LEX 与最优局部阈值或朴素贝叶斯或 SVM 与最优全局阈值，通过第七章中的*支持向量机*的`MULTICLASSIFIER`类，允许在较低级别使用不同类型的分类器。这里与原始版本的关键变化在于，我们在可选参数集中指定要使用的分类器，而不是假设我们将使用`SVMCLASSIFIER`：

```py
    def __init__(self, train, showprogress=True, args={}):        self.train = train
        T = time.time()
        self.datasets = {}
        self.classifiers = {}
        self.args = args
        # Find what kind of classifier to use for the individual emotions
        subclassifier = args["subclassifiers"]
        for i in range(len(self.train.emotions)):
            squeezed = self.squeeze(i)
            if squeezed:
                self.datasets[i] = squeezed
                self.classifiers[i] = subclassifier(self.datasets[i], args=args)
```

这将使用指定的子分类器类型创建双向分类器，用于**愤怒**与**非愤怒**、**爱情**与**非爱情**等。对于单个分类器，由于一条推文可以同时满足**爱情**和**喜悦**，或者**愤怒**和**恐惧**，但让一条推文同时满足**愤怒**和**非愤怒**是没有意义的。如果，例如，同时满足**爱情**与**非爱情**和**喜悦**与**非喜悦**，我们仍然可以得到多个标签，如果选择了所有负面标签，我们仍然可以得到零标签，但允许单个分类器分配零个或多个标签是没有意义的。

如同以往，各种子分类器有广泛的设置。主要的多分类器只是结合了单个子分类器的结果，因此除了选择作为子分类器的选项之外，没有显著的超参数，但单个子分类器有通常的选项范围。以下表格报告了使用每个子分类器一个标签的分数，但允许或不允许中性作为标签：

|  | **多分类器** | **多 NB** | **多 SVM** | **多 DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | 0.348 (0.868) | *0.441 (0.996) * | 0.385 (1.000) | 0.422 (0.991) |
| **SEM11-AR** | 0.363 (0.878) | 0.376 (0.996) | 0.314 (0.997) | 0.333 (0.956) |
| **SEM11-ES** | 0.260 (0.852) | * 0.296 (0.993) * | 0.256 (0.995) | 0.236 (0.936) |
| **KWT.M-AR** | 0.304 (0.979) | 0.236 (0.989) | 0.294 (0.996) | 0.182 (0.938) |

图 10.15（a）- 每条推文 0 个或多个情绪，多个分类器，-中性

|  | **多分类器** | **多 NB** | **多 SVM** | **多 DNN** |
| --- | --- | --- | --- | --- |
| **SEM11-EN** | 0.342 (0.861) | 0.438 (0.996) | 0.381 (1.000) | 0.419 (0.991) |
| **SEM11-AR** | 0.363 (0.879) | 0.376 (0.996) | 0.313 (0.997) | 0.333 (0.956) |
| **SEM11-ES** | 0.256 (0.836) | 0.290 (0.993) | 0.250 (0.995) | 0.234 (0.938) |
| **KWT.M-AR** | 0.665 (0.984) | 0.546 (0.989) | 0.617 (0.996) | 0.599 (0.950) |

图 10.15 (b) – 每条推文 0 或更多情绪，多个分类器，+中性

在这里，整体情况是使用多个独立的分类器来决定一条推文是否应该有特定的标签，对于零到多个数据集产生了最佳的比例结果。尽管 Jaccard 分数只对 SEM11-EN 和 SEM11-ES 有所提高，但在这种制度下，不同分类器的性能之间存在相当大的差异。当我们不允许**中性**作为标签时，所有四个分类器在 SEM11 案例上的表现都略有改善，但当我们允许**中性**时，它们在 KWT.M-AR 数据集上的表现都显著提高。这有点令人惊讶，因为允许个别分类器选择不分配它们的标签，因此对于特定的推文，即使不允许**中性**，也有可能得到“未分配标签”的结果。*图 10**.16*显示了当我们查看 KWT.M-AR 的+/-中性分类器时分数的变化：

|  | **精确度** | **召回率** | **微观 F1** | **宏观 F1** | **Jaccard** | **比例** |
| --- | --- | --- | --- | --- | --- | --- |
| **多词法，-****中性** | 0.400 | 0.559 | 0.467 | 0.319 | 0.304 | 0.979 |
| **多 LEX，+****中性** | 0.731 | 0.881 | 0.799 | 0.817 | 0.665 | 0.984 |
| **多 NB，-****中性** | 0.338 | 0.441 | 0.383 | 0.247 | 0.236 | 0.989 |
| **多 NB，+****中性** | 0.645 | 0.781 | 0.707 | 0.714 | 0.546 | 0.989 |
| **多 SVM，-****中性** | 0.598 | 0.367 | 0.455 | 0.294 | 0.294 | 0.996 |
| **多 SVM，+****中性** | 0.764 | 0.763 | 0.763 | 0.747 | 0.617 | 0.996 |
| **多 DNN，-****中性** | 0.255 | 0.389 | 0.308 | 0.194 | 0.182 | 0.938 |
| **多 DNN，+****中性** | 0.725 | 0.776 | 0.750 | 0.758 | 0.599 | 0.950 |

图 10.16 – KWT.M-AR，多个分类器，有无中性

在所有情况下，当我们允许中性作为标签时，召回率和精确度都会上升。

观察朴素贝叶斯（其他方法非常相似，但朴素贝叶斯给出了最佳的整体结果，因此是最有趣的）的混淆矩阵可以揭示一些信息：

|  | **愤怒** | **厌恶** | **恐惧** | **快乐** | **爱** | **乐观** | **悲观** | **拒绝** | **信任** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 31 | 7 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 23 |
| **不满** | 0 | 111 | 0 | 0 | 15 | 0 | 0 | 0 | 0 | 94 |
| **恐惧** | 0 | 2 | 3 | 0 | 1 | 0 | 0 | 0 | 0 | 15 |
| **快乐** | 0 | 6 | 0 | 56 | 12 | 6 | 0 | 0 | 0 | 66 |
| **爱** | 0 | 2 | 0 | 4 | 327 | 4 | 0 | 0 | 0 | 155 |
| **乐观** | 0 | 2 | 0 | 3 | 0 | 123 | 0 | 0 | 0 | 70 |
| **悲观** | 1 | 2 | 0 | 0 | 1 | 0 | 2 | 0 | 0 | 15 |
| **拒绝** | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 6 |
| **信任** | 0 | 4 | 0 | 1 | 2 | 0 | 0 | 0 | 26 | 50 |
| **--** | 65 | 329 | 5 | 182 | 527 | 318 | 6 | 3 | 67 | 0 |

图 10.17（a）- 混淆矩阵，多分类器，NB 作为子分类器，KWT.M-AR，-中性

|  | **愤怒** | **不满意** | **恐惧** | **快乐** | **爱情** | **乐观** | **悲观** | **拒绝** | **信任** | **中性** | **--** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **愤怒** | 35 | 3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 23 | 4 |
| **不满意** | 0 | 118 | 0 | 0 | 12 | 0 | 0 | 0 | 0 | 92 | 4 |
| **恐惧** | 0 | 1 | 3 | 0 | 1 | 0 | 0 | 0 | 0 | 13 | 3 |
| **快乐** | 0 | 3 | 0 | 58 | 12 | 3 | 0 | 0 | 0 | 67 | 8 |
| **爱情** | 0 | 2 | 0 | 2 | 343 | 2 | 0 | 0 | 1 | 138 | 11 |
| **乐观** | 0 | 1 | 0 | 1 | 0 | 126 | 0 | 0 | 0 | 67 | 3 |
| **悲观** | 0 | 2 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 18 | 0 |
| **拒绝** | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 7 | 0 |
| **信任** | 0 | 2 | 0 | 0 | 1 | 0 | 0 | 0 | 27 | 54 | 0 |
| **中性** | 2 | 14 | 0 | 15 | 162 | 64 | 0 | 0 | 5 | 3521 | 0 |
| **--** | 60 | 333 | 5 | 165 | 398 | 273 | 6 | 3 | 63 | 378 | 0 |

图 10.17（b）- 混淆矩阵，多分类器，NB 作为子分类器，KWT.M-AR，-中性

两个表格的主要部分分数之间有一些小的差异——对角线上的分数略好，其他标签之间的混淆略低——但关键的区别是，正如之前一样，当我们没有**中性**作为标签时，我们会得到大量的误报。使用**中性**作为标签可以减少误报的数量，即使我们有多个独立的分类器，每个分类器都根据自己的推荐结果而不看其他分类器的结果。

# 摘要

在过去的几章中，我们研究了许多不同的分类器，并比较了它们在各种数据集上的性能。现在，是时候反思我们所学的知识了。我们针对所研究数据集的最佳分类器的最终表格如下：

|  | **SVM** | **SNN** | **Transformers** | **MULTI-NB** | **LEX, MULTI** |
| --- | --- | --- | --- | --- | --- |
| **SEM4-EN** | 0.845 | 0.829 | * 0.927 |  |  |
| **SEM11-EN** | 0.224 | 0.242 | 0.418 | * 0.438 | 0.347 |
| **WASSA-EN** | * 0.770 | 0.737 | 0.753 |  |  |
| **CARER-EN** | 0.770 | * 0.820 | 0.816 |  |  |
| **IMDB-EN** | 0.736 | 0.793 | * 0.826 |  |  |
| **SEM4-AR** | 0.514 | 0.504 | * 0.710 |  |  |
| **SEM11-AR** | 0.216 | 0.221 | 0.359 | * 0.412 | 0.377 |
| **KWT.M-AR** | 0.631 | 0.028 | 0.053 | 0.537 | * 0.691 |
| **SEM4-ES** | 0.412 | 0.337 | * 0.663 |  |  |
| **SEM11-ES** | 0.226 | 0.221 | * 0.340 | 0.294 | 0.266 |

图 10.18 – 综合最佳分类器

根据我们所看到的，我们可以得出几个一般性的观察：

+   各种算法的性能差异并不大。对于每个数据集和每个设置配置，最佳分类器的性能非常相似，因此在选择分类器时，考虑训练时间和各种指标上的得分可能是明智的。特别是，没有哪个分类器在所有情况下都是最佳的，有时，非常简单的算法（LEX 和朴素贝叶斯）与更复杂的算法一样好，甚至更好。

+   对于可以分配零个、一个或多个标签的推文数据集来说，比每个推文只分配一个标签的数据集更具挑战性。实际上，对于这些数据集，为每个推文分配恰好一个标签的分类器的性能有一个明显的上限，并且通过重新考虑分类器使用的方式可以获得最佳结果。有些分类器比其他分类器更适合这类任务，在选择这类数据集的分类器时必须考虑这一点。再次强调，在选择时考虑训练时间是有价值的：训练单个分类器然后设置*N*个单独的阈值比训练*N*个分类器要快得多，并且在至少某些情况下，性能差异很小。

+   我们还研究了各种预处理步骤，包括使用不同的标记化器和词干提取器，并考虑使用可以建议“相似”词语来替换目标推文中训练数据中未出现的词语的算法。所有这些调整在某些情况下是有效的，而在其他情况下则不是。

我们不能过分强调这一点：**没有万能的解决方案**。不同的任务需要不同的分类器，在决定使用哪个分类器之前，你应该调查一系列的分类器。特别是，如果你正在处理多标签数据集，你应该考虑本章中提到的算法之一。

在训练分类器时，查看它分配的标签的混淆矩阵是一个好主意。特别是对于有大量零分配的数据集，一些分类器只需在每个情况下选择最常见类别（即**中立**！）就能产生相当好的 F1 和 Jaccard 分数。在选择分类器时，考虑分类器所需完成的具体任务也是一个好主意。如果你想要的只是对某个话题的意见有一个感觉，而不太关心个别推文对此说了什么，那么使用比例作为指标可以是一个有用的工具。我们将在下一章中使用这个工具，我们将探讨推文中表达的情感与一定时期内真实生活中的事件之间的联系。

# 第四部分：案例研究

*第三部分* 讨论了执行算法（EA）的多种方法，并在一组标准数据集上比较了它们的有效性。在本部分的最后，我们调查了这些方法在未与标准集相连的真实世界数据上的表现，观察了推文中表达的情感变化如何反映关键的真实世界事件。我们还检查了各种方法在应用于新数据时的鲁棒性，展示了当测试数据来自与训练数据相同的人群时表现良好的方法，在应用于新数据时可能会变得脆弱。

本部分包含以下章节：

+   *第十一章*，*案例研究 – 卡塔尔封锁*
