# 第三章：机器学习算法巡礼

在本章中，我们将探讨对**机器学习**（**ML**）能够完成的任务类型的不同分类方法，并对 ML 算法本身进行分类。组织 ML 领域的方法有很多种；我们可以根据我们提供给它们的训练数据类型来分类算法，我们可以根据我们期望从算法中获得的结果类型来分类，我们可以根据它们的特定方法和策略来分类算法，我们可以根据它们处理的数据格式来分类，等等。

在本章中，我们将讨论不同类型和类别的 ML 任务和算法，同时也会介绍你将在本书中遇到的一些算法。本章将只讨论算法的高级概念，以便我们在后面的章节中深入探讨。本章将涵盖以下主题：

+   机器学习简介

+   学习类型——无监督学习、监督学习和强化学习

+   算法类别——聚类、分类、回归、降维、优化、自然语言处理和图像处理

在本章结束时，你应该对监督学习和无监督学习有一个理解，并且应该了解我们将在这本书中应用的整体算法景观。

# 机器学习简介

通常，ML 是我们对让计算机在没有明确编程算法洞察力的情况下学习的实践所赋予的名字。相反的实践——即用一组指令编程算法，使其能够应用于数据集——通常被称为**启发式**。这是我们算法的第一种分类：机器学习与启发式算法。如果你在管理防火墙时手动维护一个要阻止的 IP 地址范围的黑名单，那么可以说你已经为你的防火墙开发了一个启发式方法。另一方面，如果你开发了一个分析网络流量模式、从这些模式中推断并自动维护你的黑名单的算法，那么可以说你已经开发了一种针对防火墙的 ML 方法。

我们当然可以进一步细分我们的 ML 防火墙方法。如果你的算法设计时没有**先验知识**（事先的知识），也就是说，如果算法**从头开始**，那么它可以被称为**无监督学习**算法。另一方面，如果你通过展示应该被阻止的源请求的示例来训练算法，并期望它通过示例进行学习，那么这个算法可以被称为**监督学习**算法。

你实施的特定算法也可能属于另一个子类别。你的算法可能依赖于*聚类*相似请求以确定给定请求可能属于哪个簇，或者你的算法可能使用贝叶斯统计来确定请求应该被**分类**为好或坏的几率，或者你的算法可能使用聚类、分类和启发式等技术的组合！像许多其他分类系统一样，在分类特殊情况时往往存在模糊性，但就大部分而言，算法可以被分为不同的类别。

# 学习类型

所有机器学习算法都消耗数据作为输入，并期望生成见解、预测、分类或分析作为输出。一些算法有一个额外的*训练*步骤，在这个步骤中，算法在某个数据上被训练，测试以确保它们已经从训练数据中学习，然后在未来的某个日期给出一个你希望获得见解的新数据点或数据集。

所有使用训练数据的机器学习算法都期望数据是*标记的*，或者以某种方式标记出该数据的期望结果。例如，当构建垃圾邮件过滤器时，你必须首先教会或训练算法垃圾邮件与正常消息（称为**ham**）的外观区别。你必须首先在一系列消息上训练垃圾邮件过滤器，每条消息都标记为*spam*或*ham*，这样算法才能学会区分两者。一旦算法被训练，你就可以向它展示一条新的、以前从未见过的消息，并期望它能猜测该消息是 ham 还是 spam。在这个例子中，你用来训练算法的消息集被称为**训练数据**或**训练集**，使用的标签是*spam*和*ham*，而算法进行的猜测工作被称为**推理**。这种在一系列预标记的训练数据上训练算法的实践被称为**监督学习**。

其他算法不需要训练，或者可以在没有任何标签的数据集上检查数据，并直接从数据中得出见解。这被称为**无监督学习**，这种分类的特点是数据上没有标签。如果你在科学实验室工作，正在开发一个图像处理算法来检查培养皿中细菌培养物的图片，目的是让算法告诉你照片中可以看到多少不同的细菌菌落，那么你已经开发了一个无监督学习算法。在这种情况下，你不需要用带有预标记菌落数量的训练数据来训练算法；算法预计将从零开始寻找数据中的模式和结构。输入和输出与监督学习示例相似，即你将数据提供给算法，并期望得到见解作为输出，但不同之处在于没有训练步骤或算法需要的*先验*知识。

在监督学习和无监督学习之间，还存在进一步的分类，这些分类位于一个光谱上。例如，在*半监督学习*中，算法接收一个预标记的训练集，但并非每个标签都由训练数据表示。在这种情况下，算法预计将示例拟合到适用的已训练标签，但也预计在适当的时候生成新的标签。

另一种学习模式是**强化学习**。强化学习在许多方面与监督学习和无监督学习相似。在强化学习中，训练数据没有明确的标签，但算法生成的结果可能与某种惩罚或奖励相关；算法的目标是最终优化其结果，以使惩罚最小化。强化学习通常与监督学习结合使用。一个算法可能最初在带有标记的训练数据上训练，但随后预计将根据其对所做决策的反馈来更新其模型。

在大多数情况下，你会发现监督学习和无监督学习是两种主要的算法类别。

# 无监督学习

在无监督学习中，目标是无需对数据进行任何先前的标记，就从数据中推断结构或模式。由于数据未标记，通常无法评估学习算法的准确性，这是与监督学习的一个主要区别。无监督学习算法通常不会获得关于数据的任何*先验*知识，除非可能是通过算法本身给出的调整参数间接获得。

无监督学习通常用于可能通过肉眼解决的数据维度非常少的问题，但由于数据的维度很大，这使得人类推断变得不可能或非常困难。无监督学习也可以用于可能通过直觉解决的低维问题，但在需要处理大量数据的情况下，手动处理是不合理的。

假设你正在编写一个算法，该算法查看卫星图像数据，任务是识别建筑物并将它们聚类成地理位置分离的社区。如果你只有一张图像，或者只有几张图像，手动完成这项任务很容易。研究人员会在照片上标记所有建筑物，并视觉检查照片以确定建筑物的集群。然后，研究人员记录社区中心的纬度和经度，并将结果放入电子表格中。太好了，首席科学家说，还有三百万张图像要处理！这是一个低维问题（只有两个维度，*纬度*和*经度*需要考虑）的例子，但由于任务的庞大体积而变得不切实际。显然需要一个更复杂的解决方案。

为了开发一种无监督学习方法来解决此问题，研究人员可能会将问题分为两个阶段：**预处理**和**分析**。在预处理步骤中，每张图像都应该通过一个算法来检测照片中的建筑物并返回它们的纬度/经度坐标。这个预处理步骤可以通过几种方式来管理：一种方法是将图像发送给一组实习生进行手动标记；另一种方法可能是一个非机器学习的边缘检测算法，它寻找矩形形状；第三种方法可能是一个**卷积神经网络**（**CNN**），它被训练来识别建筑物的图像。

一旦完成预处理并手头有一份建筑物坐标列表，就可以将这些坐标通过无监督聚类算法，如我们稍后将要探讨的 k-means 算法，进行运行。无监督算法不需要知道*建筑物*是什么，它不需要了解任何现有的社区或建筑物集群，也不需要任何其他*先验*知识。该算法只需能够读取数百万或数十亿个纬度/经度坐标，并将它们分组成以地理位置为中心的集群。

由于无监督算法无法判断其结果的准确性，因此无法保证该算法将生成与人口普查数据相匹配的邻域，或者该算法对“邻域”的概念在语义上是正确的。例如，如果一条宽阔的高速公路将城镇的两个部分分开，那么一个城镇或邻域可能被视为两个独立的邻域。同样，如果两个邻域之间没有明显的分隔，算法可能将两个被认为是不同的邻域合并成一个单一的群集。

在许多情况下，这种语义错误是可以接受的；这种方法解决问题的好处是它可以快速处理数百万或数十亿个数据点，并至少提供一种逻辑上的群集感。无监督群集的结果可以通过另一种算法进一步后处理，或者手动审查，以向结果添加语义信息。

无监督算法也可以在人类无法直观可视化的高维数据集中找到模式。在建筑群集问题中，研究人员很容易通过视觉检查二维地图并凭肉眼识别群集。现在想象一下，你有一组数据点，每个数据点存在于一个 100 维的空间中（即具有 100 个不同特征的数据）。如果你拥有的数据量非同寻常，例如超过 100 或 1,000 个数据点，对于人类来说几乎不可能解释这些数据，因为特征之间的关系在 100 维空间中难以可视化。

作为上述问题的虚构例子，想象你是一位心理学家，你的任务是解释给参与者的一千份调查问卷，问卷中有 100 个不同的问题，每个问题都是 1-10 分的评分。每个问题都是为了评估参与者的不同性格方面。你的目标是确定有多少不同的性格类型由受访者代表。

通过手工处理仅 1,000 个数据点当然是可以实现的，这在许多领域都是常见的做法。然而，在这种情况下，数据的高度维度使得发现模式变得非常困难。两位受访者可能对某些问题的回答非常相似，但对其他问题的回答却不同；这两位受访者是否足够相似，可以被认为是同一性格类型？而且这种性格类型与其他任何给定的性格类型有多相似？我们之前用来检测建筑群集的相同算法可以应用于这个问题，以便检测受访者的群集及其性格类型（对于阅读此文的任何实际心理学家表示歉意；我知道我极大地简化了这个问题！）。

在这种情况下，无监督聚类算法在*可视化*涉及到的 100 个维度上没有任何困难，其表现将与二维邻域聚类问题相似。同样需要注意：不能保证算法检测到的聚类在心理上是正确的，也不能保证问题本身被设计得正确，以适当捕捉所有不同的个性类型。这个算法唯一做出的承诺是，它将识别出相似数据点的聚类。

在第二章“数据探索”中，我们讨论了在将数据提供给机器学习算法之前预处理数据的重要性。我们现在开始理解后处理和解释结果的重要性，尤其是在查看无监督算法时。因为无监督算法只能判断它们的整体统计分布（即在这种情况下，任何点到其聚类中心的平均距离），而不是它们的语义错误（即有多少数据点是实际**正确**的），因此算法不能对其语义正确性做出任何断言。查看诸如均方根误差或标准差之类的指标可能会给你一些关于算法表现如何的线索，但这不能用作判断算法准确性的依据，而只能用来描述数据集的统计特性。查看这些指标不会告诉你结果是否正确，只会告诉你数据是聚集的还是分散的（某些邻域稀疏，其他邻域密集，等等）。

到目前为止，我们已经在聚类算法的背景下考虑了无监督学习，这确实是无监督学习算法的一个主要家族，但还有许多其他算法。例如，我们在第二章“数据探索”中对异常值检测的讨论就属于无监督学习的范畴；我们正在查看没有*先验*知识的无标签数据，并试图从这些数据中获取洞察。

无监督学习技术的另一个流行例子是**主成分分析**（PCA），我们在第二章“数据探索”中简要介绍了它。PCA 是一种常用的无监督学习算法，通常用于预处理中的特征检测和降维，这个算法适用于解释高维数据的使用场景。与旨在告诉你在数据集中有多少逻辑数据点聚类的聚类算法不同，PCA 旨在告诉你可以将数据集的哪些特征或维度整洁地组合成具有统计意义的派生特征。在某种程度上，PCA 可以被视为特征或维度的聚类，而不是数据点的聚类。

像 PCA 这样的算法并不一定需要专门用于预处理，实际上它可以作为你想要从中获得洞察的主要机器学习算法。

让我们回到我们的心理调查示例。与其对调查受访者进行聚类，我们可能更愿意用 PCA 分析问题本身。算法的结果会告诉你哪些调查问题彼此之间相关性最大，这种洞察可以帮助你重新编写实际的调查问题，以便更好地针对你想要研究的个性特征。此外，PCA 提供的降维可以帮助研究人员可视化问题、受访者和结果之间的关系。该算法会将你的 100 维、高度互联的特征空间转换为可以实际绘制和视觉检查的独立、低维空间。

与所有无监督学习算法一样，无法保证主成分算法在语义上是正确的，只能保证算法能够从统计上确定特征之间的关系。这意味着一些结果可能看起来没有意义或不直观；算法可能会将看起来结合在一起没有直观意义的题目组合在一起。在这种情况下，研究人员需要后处理和解释分析结果，可能需要修改问题或改变他们在下一轮调查中的方法。

无监督学习算法还有许多其他例子，包括将在后续章节中讨论的自动编码器神经网络。无监督学习算法最重要的特征是其输入数据中没有标签，这导致无法确定其结果的语义正确性。然而，不要犯将无监督学习算法视为比其他算法*低级*的错误，因为它们在数据预处理和许多其他类型的数据探索任务中非常重要。正如扳手和螺丝刀一样，每个工具在机器学习的世界中都有其位置和用途。

# 监督学习

与无监督学习一样，监督学习算法的目标是解释输入数据并生成输出作为洞察。与无监督学习不同，监督学习算法首先在标记的训练示例上进行训练。训练示例被算法用来构建*模型*，即数据属性与其标签之间关系的内部表示，然后该模型被应用于你希望从中获得洞察的新、未标记的数据点。

监督学习通常对机器学习学生来说更有趣，因为这个类别的算法旨在提供语义正确的结果。当监督学习算法运行良好时，结果几乎看起来像是魔法！你可以在 1,000 个预标记的数据点上训练一个算法，然后使用该模型处理数百万未来的数据点，并对结果中的语义准确性有一定的期望。

由于监督学习算法旨在提供语义正确的结果，我们首先必须讨论如何衡量这种正确性。首先，我们必须介绍*真正例*、*假正例*、*真反例*和*假反例*的概念，然后我们将介绍准确率、精确率和召回率的概念。

# 准确率测量

想象一下，你正在为你的博客开发的一个评论系统开发垃圾邮件过滤器。垃圾邮件过滤器是一种监督学习算法，因为算法必须首先被告知什么是垃圾邮件，什么是正常邮件。你在许多垃圾邮件和正常邮件的例子上训练你的垃圾邮件系统，然后将其投入生产，并允许它对所有新的评论进行分类，自动阻止垃圾邮件，让真正的正常邮件通过。

让我们把一个*正例*想象成算法识别为垃圾邮件的评论（我们称之为*正例*，因为我们把算法称为垃圾邮件过滤器；这只是一个语义上的区别，因为我们也可以把过滤器称为*正常邮件过滤器*，并用*正例*来表示可疑的正常邮件）。让我们把一个*反例*想象成被识别为真正的（正常）邮件的评论。

如果你的算法将一条评论分类为垃圾邮件（正例），并且这样做是语义正确的（也就是说，当你阅读消息时，你也确定它是垃圾邮件），那么算法就生成了一个*真正例*，或者是一个真正且正确的结果。相反，如果一条真正的评论被错误地识别为垃圾邮件并被阻止，这被认为是*假正例*，或者是一个实际上不是正例的正例。同样，被识别为正常邮件的真正正常邮件是一个*真反例*，而被识别为正常邮件并通过的垃圾邮件被认为是*假反例*。期望算法提供 100%正确的结果是不合理的，所以在实践中总会存在一定数量的假正例和假反例。

如果我们考虑我们的四种结果准确度分类，我们可以计算每个分类的实例数量，并为每个分类确定一个比率：我们可以轻松地计算出误报率、真正率、误判率和真正率。然而，如果我们独立地讨论这四个比率，可能会显得有些笨拙，因此我们也可以将这些比率组合成其他类别。

例如，算法的*召回率*或*灵敏度*是其真正阳性的比率，或者说是正分类为真正阳性的百分比。在我们的垃圾邮件示例中，召回率因此指的是在所有实际垃圾邮件中正确识别的垃圾邮件百分比。这可以计算为*真正阳性除以实际阳性*，或者也可以是*真正阳性除以真正阳性加上假阴性*（记住，假阴性是实际上是垃圾邮件但被错误地识别为正常邮件的评论）。在这种情况下，召回率指的是算法正确检测垃圾邮件评论的能力，或者简单地说，*在所有实际的垃圾邮件中，我们识别了多少？*

特异性与召回率相似，但表示算法的真正阴性率。特异性询问的问题是：*在所有实际的正常邮件中，我们正确识别了多少？*

另一方面，精确度定义为真正阳性数除以真正阳性数和假阳性数之和。在我们的垃圾邮件示例中，精确度回答了这样一个问题：*在我们认为的垃圾邮件中，我们有多少猜测是正确的？*这两个指标之间的区别在于，我们是否在考虑所有*实际*的垃圾邮件，或者考虑我们认为的垃圾邮件。

准确度与精确度和召回率都不同，它关注整体正确结果。它被定义为真正阳性和真正阴性率除以总试验次数（即，总体上有多少猜测是正确的）。机器学习的学生常犯的一个错误是只关注准确度，因为它直观上更容易理解，但准确度在评估算法性能时通常是不够的。

为了证明这一点，我们必须考虑我们的垃圾邮件过滤器对现实世界结果的影响。在某些情况下，你可能希望有一个垃圾邮件过滤器永远不会让任何一条垃圾邮件通过，即使这意味着错误地阻止了一些正常邮件。在其他情况下，确保所有正常邮件都能通过可能更好，即使这意味着一些垃圾邮件会绕过你的过滤器。两个不同的垃圾邮件过滤器可能有相同的*准确度*，但精确度和召回率的特征却完全不同。因此，尽管准确度非常有用，但它不能总是你考虑的唯一性能指标。

由于之前的数学定义可能有点难以理解，让我们用数字来举例。假设有 100 条消息，其中 70 条是真正的正常邮件，30 条是真正的垃圾邮件：

|  | **30** 实际垃圾邮件（阳性） | **70** 实际正常邮件（阴性） |
| --- | --- | --- |
| **26** 猜测的垃圾邮件 | 22（真正阳性） | 4（假阳性） |
| **74** 猜测的正常邮件 | 8（假阴性） | 66（真正阴性） |

为了计算算法的准确率，我们将正确的猜测相加：`22`个真阳性（true positives）和`66`个真阴性（true negatives），总共是 88 个正确的猜测。因此，我们的准确率是 88%。

顺便说一句：88%的准确率对于复杂问题上的高级算法来说非常好，但对于垃圾邮件过滤器来说稍微有点差。

算法的召回率或灵敏度是**真阳性率**，即我们在查看实际上是垃圾邮件的示例时正确猜测的次数。这意味着我们只考虑前面表格中的左侧列。算法的召回率是实际正性中的真阳性数，即真阳性除以真阳性和假阴性的总和。在这种情况下，我们有 22 个真阳性和 30 个实际的垃圾邮件消息，因此我们算法的召回率是 22/30，或 73%。

算法的精确度与实际是垃圾邮件的消息无关，而是与我们猜测是垃圾邮件的消息有关。在这种情况下，我们只考虑最上面一行，即真阳性除以真阳性和假阳性的总和；也就是说，真阳性除以猜测的正性。在我们的例子中，有 22 个真阳性和 26 个总猜测的正性，因此我们的精确度是 22/26，或 84%。

注意，这个算法比它敏感。这意味着当它猜测垃圾邮件时，垃圾邮件的猜测是 84%正确的，但该算法也有倾向于猜测正常邮件，并且会错过很多实际的垃圾邮件。此外，总准确率是 88%，但它的精确度和召回率都低于这个数字。

另一种直观地思考这些性能指标的方法如下：精确度（precision）是算法在猜测为正时正确猜测的能力，而召回率（recall）是算法记住垃圾邮件样式的记忆能力。高精确度和低召回率意味着算法在猜测邮件是垃圾邮件时非常挑剔；算法在将邮件识别为垃圾邮件之前，必须确信该邮件是垃圾邮件。

该算法在说一条消息是垃圾邮件时非常**精确**。

因此，它可能会牺牲一些垃圾邮件的误判，而让一些正常的邮件通过。另一方面，低精确度、高召回率的算法倾向于更积极地识别邮件为垃圾邮件，然而，它也会错误地阻止一些正常的邮件（该算法更好地“回忆”垃圾邮件的样子，对垃圾邮件更敏感，因此认为更多的邮件是垃圾邮件，并相应地采取行动）。

当然，一些算法可以具有高准确率、精确度和召回率——但更现实的是，你训练算法的方式将涉及精确度和召回率之间的权衡，你必须根据你系统的预期目标来平衡这些权衡。

# 监督学习算法

现在我们已经对准确率、精确率和召回率有了理解，我们可以继续讨论当前的主题：监督学习算法。监督学习和无监督学习算法之间的关键区别是有预标记数据的存在，通常在算法的训练阶段引入。一个监督学习算法应该能够从标记的训练数据中学习，然后分析一个新的、未标记的数据点并猜测该数据的标签。

监督学习算法进一步分为两个子类别：**分类**和**回归**。分类算法旨在根据从训练数据中学到的泛化模式预测未见数据点的标签，如前所述。回归算法旨在预测新点的值，同样基于它在训练期间学到的泛化模式。虽然分类和回归在实践中感觉不同，但前面的描述揭示了这两个类别实际上是多么相似；两者之间的主要区别是回归算法通常处理连续数据，例如时间序列或坐标数据。然而，在本节的剩余部分，我们将仅讨论分类任务。

因为算法是从标记数据中构建模型的，所以预期该算法可以生成*语义上*正确的结果，这与无监督算法生成的*统计上*正确的成果形成对比。一个语义上正确的成果是指能够经得起外部审查的结果，使用与训练数据标记相同的技巧。在垃圾邮件过滤器中，一个语义上正确的成果是算法做出的一个人类会同意的猜测。

生成语义上正确结果的能力是由预标记的训练数据实现的。训练数据本身代表了问题的语义，这是算法学习生成其语义上正确结果的方式。请注意，整个讨论——以及准确率、精确率和召回率的整个讨论——都取决于向模型引入外部验证信息的能力。只有当外部实体独立验证结果时，你才能知道单个猜测是否正确，而且只有当外部实体提供了足够的数据点及其正确的标签来训练算法时，你才能教会算法做出语义上正确的猜测。你可以将监督学习算法的训练数据视为所有猜测起源的真理之源。

当监督学习算法运行良好时，它们确实可能看起来像是魔法，但存在许多潜在的陷阱。因为训练数据对算法至关重要，你的结果将仅与你的训练数据和训练方法一样好。训练数据中的某些噪声通常可以容忍，但如果训练数据中存在系统性的错误来源，你的结果也将存在系统性的错误。这些可能很难检测，因为模型的验证通常使用你预留的训练数据的一个子集——包含系统错误的相同数据被用来验证模型，所以你会认为模型运行得很好！

另一个潜在的陷阱是训练数据不足。如果你正在解决的问题高度多维，你需要相应的大量训练数据；训练数据必须足够，以便实际上向机器学习算法展示所有各种模式。你不应该期望只用 10 封邮件来训练垃圾邮件过滤器，并期望得到很好的结果。

这些因素通常会给监督学习带来一种启动成本。在获取或生成适当数量的训练示例以及其分布方面，需要投入一定量的投资。通常情况下，尽管并非总是如此，训练数据需要通过人类知识和评估来生成。这可能很昂贵，尤其是在图像处理和目标检测的情况下，通常需要许多标记的训练示例。在一个机器学习算法变得越来越容易获取的世界里，真正的竞争在于拥有最好的数据来工作。

在我们垃圾邮件过滤器的例子中，对训练数据的需求意味着你不仅需要编写和发布垃圾邮件过滤器，还需要花一些时间手动记录哪些邮件是垃圾邮件和正常邮件（或者让你的用户报告这一点）。在部署垃圾邮件过滤器之前，你应该确保你有足够的训练数据来训练和验证算法，这可能意味着你必须等到你有数百或数千个由人类标记的垃圾邮件示例。

假设你拥有适当数量的高质量训练数据，也可能在训练过程中管理不当，导致即使数据良好也会产生不良结果。机器学习新手常常认为更多的训练总是更好的，但这并不正确。

在这一点上，需要介绍两个新的概念：**偏差**和**方差**。在训练机器学习模型时，你的希望是模型能够学习训练数据的**一般**属性，并能够从中进行外推。如果一个算法对数据的结构做出了重大错误的假设，可以说它具有高度的偏差，因此**欠拟合**。另一方面，一个模型可以表现出高方差，即对训练数据中的微小差异高度敏感。这被称为**过拟合**，可以理解为算法学习识别个别示例，或者个别示例中的特定噪声，而不是数据的总体趋势。

过度训练模型很容易导致过拟合。想象一下，你每天使用同一台键盘 10 年，但实际上这台键盘是一个布局奇特、有很多怪癖的奇怪模型。在这么长时间后，你能够非常熟练地在这样的键盘上打字是可以预料的。然后，出乎意料的是，键盘坏了，你得到了一台新的标准键盘，却发现你不知道如何在上面打字！你经过十年打字训练的肌肉记忆已经习惯了键盘上的标点符号位置恰到好处，字母“o”稍微向右偏移一点，等等。在使用新键盘时，你会发现你打不出一个没有错别字的单词。十年在糟糕键盘上的过度训练只教会了你如何在那个键盘上打字，而你并没有将你的技能推广到其他键盘上。模型过拟合的概念与此相同：你的算法非常擅长识别你的训练数据，而无法识别其他任何数据。

因此，训练一个模型并不像插入训练数据然后让算法任意时间训练那样简单。在这个过程中，一个关键步骤是将你的训练数据分成两部分：一部分用于训练算法，另一部分仅用于验证模型的结果。你不应该在验证数据上训练算法，因为这样你可能会训练模型去识别你的验证数据，而不是训练后再使用验证数据独立验证算法的准确性。需要验证集会增加生成训练数据的成本。如果你确定你需要 1,000 个示例来训练你的算法，你可能实际上需要生成总共 1,500 个示例，以便有一个合理的验证集。

验证数据不仅仅用于测试算法的整体准确性。你通常还会使用验证数据来确定何时*停止*训练。在训练过程中，你应该定期使用你的验证数据测试算法。随着时间的推移，你会发现验证的准确性会如预期地增加，然后在某个时刻，验证的准确性可能会实际上*下降*。这种方向的变化就是你的模型开始对你的训练数据过拟合的点。当你向算法展示训练集中的例子（这些是它直接学习的例子）时，算法总是会继续变得更加准确，但一旦模型开始对训练数据过拟合，它就会开始失去泛化的能力，因此在它未训练过的数据上表现会更差——而不是更好。因此，维护一个独立的验证数据集至关重要。如果你训练了一个算法，并且在测试自己的训练数据时它达到了 100%的准确率，那么你很可能已经过拟合了数据，并且它在未见过的数据上可能表现非常糟糕。算法已经超越了学习数据中的普遍趋势，开始记住具体的例子，包括数据中的各种噪声。

除了维护一个验证集之外，适当的数据预处理也会对抗过拟合。我们在第二章*数据探索*中讨论的各种噪声减少、特征选择、特征提取和降维技术都将有助于泛化你的模型并避免过拟合。

最后，因为你的算法推断的语义正确性只能由外部来源确定，所以通常无法知道一个猜测是否实际上正确（除非你收到关于特定猜测的用户反馈）。最好的情况是，你只能从你在训练和验证阶段计算出的精确度、召回率和准确率值中推断出算法的整体有效性。幸运的是，许多监督学习算法以概率方式呈现他们的结果（例如，*我认为有 92%的可能性这是垃圾邮件*），这样你可以对算法在推断上的信心有所了解。然而，当你将这种置信水平与模型的精确度和召回率以及你的训练数据可能存在的系统性错误结合起来时，即使是推断带来的置信水平也是值得怀疑的。

尽管存在这些潜在的陷阱，监督学习是一个非常强大的技术。从复杂问题域中只有几千个训练示例中推断出，并快速对数百万未见过的数据点进行推断的能力既令人印象深刻又非常有价值。

与无监督学习一样，监督学习算法也有很多种类型，每种都有其自身的优点和缺点。神经网络、贝叶斯分类器、k-最近邻、决策树和随机森林都是监督学习技术的例子。

# 强化学习

虽然监督学习和无监督学习是机器学习算法的两个主要子分类，但实际上它们是光谱的一部分，还有其他的学习模式。在本书的背景下，下一个最重要的学习模式是强化学习，它在某些方面可以被认为是监督学习和无监督学习的混合体；然而，大多数人会将强化学习归类为无监督学习算法。这就是分类变得有些模糊的那些情况之一！

在无监督学习中，几乎对要处理的数据一无所知，算法必须从一张白纸中推断出模式。在监督学习中，大量的资源被用于在已知示例上训练算法。在强化学习中，关于数据的信息（或可以知道的信息）是已知的（或可以知道的），但数据的知识并不是一个明确的标签或分类。相反，已知（或可以知道）的信息是基于使用数据做出的决策采取行动的结果。强化学习被许多人视为无监督学习算法，因为算法是从零开始的，然而强化学习也“闭合循环”，并基于自己的行动不断重新训练自己，这有一些类似于监督学习中的训练。

为了举一个荒谬且牵强的例子，想象你正在编写一个算法，该算法旨在取代政府的功能。该算法将接收国家的当前状况作为输入，并且必须作为输出，制定新的政策和法律，以优化国家在多个维度上的表现：公民幸福、经济健康、低犯罪率等等。强化学习对这一问题的处理是从零开始，对它的法律和政策将如何影响国家一无所知。然后，算法实施一项或一系列法律；因为它刚刚开始，实施的法律将是完全随机的。在法律实施一段时间并对其社会产生影响后，算法将再次阅读国家的状况，可能会发现它已经将国家变成了一个混乱的荒地。算法从这种反馈中学习，调整自己，并实施一套新的法律。随着时间的推移，并使用它最初实施的法律作为实验，算法将开始理解其政策的因果关系，并开始优化。如果给足够的时间，这种方法可能会发展出一个近乎完美的社会——前提是它不会因为最初的失败实验而意外地破坏社会。

强化学习技术与监督和无监督算法不同，它们直接与环境互动并监控其决策的影响，以便更新其模型。强化学习的目标不是检测模式或对数据进行分类，而是优化环境中的某些成本或奖励。相关环境可以是现实世界环境，如控制系统领域常见的情况，也可以是虚拟环境，如遗传算法的情况。在两种情况下，算法都必须有一种方法来表征整体的*成本*/*惩罚*或*奖励*，并努力优化该值。强化学习是一种重要的优化技术，特别是在高维问题空间中，因为 brute-force trial-and-error 方法通常无法在合理的时间内实现。

强化学习算法的例子包括遗传算法，我们将在后面的章节中深入讨论，还有蒙特卡洛方法和梯度下降（我们将与神经网络一起讨论）。

# 算法分类

我们已经根据学习模式对机器学习算法进行了分类，但这并不是唯一分类算法的方法。另一种方法是按任务或功能对它们进行分类。在本节中，我们将简要介绍机器学习算法的基本功能并列举一些示例算法。

# 聚类

聚类算法旨在识别彼此相似的数据点组。*相似*的定义取决于数据的类型、问题域和使用的算法。直观理解聚类算法的最简单方法是可视化*x/y*网格上的点。聚类算法的目标通常是围绕相似点组画圆；每个画圈的点集被视为一个簇。簇通常事先未知，因此聚类算法通常被归类为无监督学习问题。

聚类算法的一些例子包括：

+   k-means，以及其变体如 k-medians

+   高斯混合模型

+   均值漂移

# 分类

分类是监督学习算法一个非常广泛（也非常受欢迎）的类别，其目标是尝试识别一个数据点属于某个分类（垃圾邮件或正常邮件；男性或女性；动物、矿物或植物等）。存在许多用于分类的算法，包括：

+   k-最近邻

+   逻辑回归

+   简单贝叶斯分类器

+   支持向量机

+   （大多数）神经网络

+   决策树

+   随机森林

# 回归

回归算法旨在确定和描述变量之间的关系。在最简单的二维线性回归案例中，算法的目标是确定一条可以通过一组点的线，然而，更高阶和更高维的回归可以产生重要的见解并预测复杂数据。因为这些算法必然需要已知的数据点，所以它们被认为是监督学习算法。一些例子包括：

+   线性回归

+   多项式回归

+   贝叶斯线性回归

+   最小绝对偏差

# 维度降低

维度降低是一系列技术，其目的是将高维数据转换为低维数据。作为一个通用术语，这可以意味着完全丢弃维度（例如特征选择），或者创建新的单个维度，同时代表多个原始维度，但会损失一些分辨率（例如特征提取）。

一些可用于维度降低的算法包括：

+   各种类型的回归

+   主成分分析（PCA）

+   图像变换（例如，将图像转换为灰度）

+   词干提取和词形还原（在自然语言处理中）

# 优化

优化算法的目标是选择一组参数，或者一组参数的值，使得系统的成本或误差最小化（或者，使得系统的奖励最大化）。特征选择和特征提取实际上是一种优化形式；你是在修改参数，目的是在保留重要数据的同时降低维度。在最基本的优化技术中，穷举搜索，你只需尝试所有可能的参数组合，并选择结果最好的组合。在实践中，大多数问题都足够复杂，以至于穷举搜索可能需要不合理的时间（即在现代计算机上可能需要数百万年）。一些优化技术包括：

+   穷举搜索（也称为穷尽搜索）

+   梯度下降

+   模拟退火

+   遗传算法

# 自然语言处理

**自然语言处理**（**NLP**）是一个独立的领域，包含许多在机器学习中不被考虑的技术。然而，NLP 通常与 ML 算法结合使用，因为这两个领域的结合是实现通用人工智能所必需的。许多 ML 分类算法在文本上操作而不是在数字上（例如我们的垃圾邮件过滤器），在这些情况下，我们依赖于 NLP 领域的技巧：特别是词干提取是一种快速且简单的文本分类器的维度降低技术。与 ML 相关的某些 NLP 技术包括：

+   分词

+   字符串距离

+   词干提取或词形还原

+   TF-IDF

# 图像处理

与自然语言处理类似，图像处理是一个独立的研究领域，它与机器学习有重叠，但并不完全包含在机器学习之中。与自然语言处理一样，我们可能经常使用图像处理技术来降低图像的维度，然后再将机器学习算法应用于图像。一些与机器学习相关的图像处理技术包括：

+   边缘检测

+   尺度不变变换

+   颜色空间转换

+   目标检测

+   循环神经网络

# 摘要

在本章中，我们讨论了我们可以如何对机器学习技术进行分类。特别是，我们讨论了无监督学习、监督学习和强化学习之间的区别，并展示了每个类别的各种示例。

我们还讨论了判断机器学习算法准确性的不同方法，特别是将准确率、精确率和召回率等概念应用于监督学习技术。我们还讨论了监督学习算法中训练步骤的重要性，并阐述了偏差、方差、泛化和过拟合的概念。

最后，我们探讨了机器学习算法可以根据任务或技术而不是学习模式进行分类，并介绍了一系列适合于聚类、分类、回归、降维、自然语言处理和图像处理类别的算法。

在下一章中，我们将深入探讨聚类算法。
