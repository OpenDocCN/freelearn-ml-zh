# 第十一章：在实时应用中使用机器学习

在本书中，你已经学习了许多机器学习算法和技术。然而，剩下的工作是将这些算法部署到现实世界的应用中。本章专门讨论与在现实世界、实际应用和生产环境中使用机器学习相关的建议。

理想化的机器学习算法使用与实际使用之间存在许多差异。在我们的示例中，我们一步训练和执行模型，响应一个命令。我们假设模型不需要以任何方式序列化、保存或重新加载。我们没有考虑用户界面的响应性、在移动设备上执行或构建客户端和服务器之间的 API 接口。

真实应用的范围可能比我们讨论的例子大几个数量级。你如何在一个包含数十亿数据点的数据集中训练一个人工神经网络（ANN）？你如何收集、存储和处理这么多的信息？

在本章中，我们将讨论以下主题：

+   前端架构

+   后端架构

+   数据管道

+   可以用来构建生产级机器学习系统的工具和服务

# 序列化模型

本书中的示例仅构建、训练和测试模型，然后在毫秒后将其销毁。我们之所以能够这样做，是因为我们的示例使用的是有限的训练数据，最坏的情况也只需要几分钟就能完成训练。在实际应用中，通常会使用更多的数据，并且需要更多的时间来训练。在生产应用中，训练好的模型本身是一项宝贵的资产，应该根据需要存储、保存和加载。换句话说，我们的模型必须是可序列化的。

序列化本身通常不是一个难题。模型本质上是对训练数据的压缩版本。一些模型确实可能非常大，但它们仍然只是训练它们的数据大小的一小部分。使序列化问题变得具有挑战性的是，它引发了许多其他架构问题，你必须考虑的第一个问题就是模型存储的位置和方式。

令人失望的是，没有正确答案。模型可以根据其大小、复杂性、使用频率、可用技术等因素存储在几乎任何地方。朴素贝叶斯分类器只需要存储标记和文档计数，并且仅使用键/值查找，没有高级查询，因此单个 Redis 服务器可以托管一个在数十亿文档上训练的巨大分类器。非常大的模型可以序列化到一个专用数据库中，甚至可能是一个专用的图数据库集群。中等大小的模型可以序列化为 JSON 或二进制格式，并存储在数据库的 BLOB 字段中，托管在文件服务器或 API（如 Amazon S3）上，或者如果足够小，可以存储在浏览器本地存储中。

大多数机器学习库都内置了序列化和反序列化功能，因为最终这种功能依赖于库的实现细节。大多数库包括`save()`和`load()`等方法，但你仍需参考你所使用的特定库的文档。

确保在编写自己的库时包含序列化功能。如果你想支持多个存储后端，最好将序列化功能与核心逻辑解耦，并实现一个驱动程序和接口架构。

这只是我们现在需要回答的第一个问题，因为我们已经有一个可序列化的模型。可序列化模型也是可移植的，这意味着它们可以从一台机器移动到另一台机器。例如，你可以将预训练模型下载到智能手机上进行离线使用。你的 JavaScript 应用程序可以使用 Web Worker 下载并维护一个用于语音检测的现成模型，请求麦克风权限，并通过 Chrome 扩展仅通过语音命令使网站可导航。

在本节中，我们将讨论一旦模型可序列化和可移植后出现的各种架构考虑因素。

# 在服务器上训练模型

由于训练复杂模型涉及的时间、数据、处理能力和内存需求，通常在服务器上而不是在客户端训练模型是可取的。根据用例，模型的评估也可能需要在服务器上完成。

在考虑模型训练和评估的位置方面，有几个范例需要考虑。一般来说，你的选择将是完全在服务器上训练和评估，完全在客户端训练和评估，或者是在服务器上训练但在客户端评估。让我们探讨每个范例的一些示例。

最简单的实现方式是在服务器上同时训练和评估模型。这种方法的优点在于你可以决定并控制模型的整个执行环境。你可以轻松分析训练和执行模型所需的服务器负载，并根据需要调整服务器规模。由于数据很可能存储在你也控制的数据库中，因此完全控制的服务器更容易访问大量训练数据。你不必担心客户端运行的是哪种版本的 JavaScript，或者你是否能够访问客户端的 GPU 进行训练。在服务器上训练和执行模型还意味着由于模型的存在，客户端机器不会增加额外的负载。

完全服务器端方法的缺点主要是需要设计良好的、健壮的 API。如果你有一个需要快速响应时间的模型评估的应用，你需要确保你的 API 能够快速且可靠地提供服务。这种方法还意味着无法进行离线模型评估；客户端需要连接到你的服务器才能使任何操作生效。大多数被称为**软件即服务**（**SaaS**）的应用或产品将使用服务器端模型，如果你在向客户提供付费服务，这种方法应该是你首先考虑的。

相反，模型也可以在客户端完全进行训练和评估。在这种情况下，客户端本身需要访问训练数据，并且需要足够的处理能力来训练模型。这种方法通常不适用于需要大量训练集或长时间训练时间的模型，因为没有办法确保客户端的设备能够处理数据。你还得应对那些可能没有 GPU 或处理能力训练甚至简单模型的旧设备。

然而，对于训练数据来自设备本身且需要高度数据隐私或数据所有权的应用来说，客户端训练和评估是一个很好的方法。将处理限制在客户端设备上可以确保用户数据不会被传输到任何第三方服务器，并且可以直接由用户删除。指纹扫描、生物识别分析、位置数据分析、电话分析等应用是采用完全客户端方法的良好候选者。这种方法还确保了模型可以在离线状态下进行训练和评估，无需互联网连接。

在某些情况下，混合方法可以将两者的优点结合起来。需要大量训练数据的高级模型可以在服务器上训练并序列化。客户端在首次连接到你的应用时，可以下载并存储训练好的模型以供离线使用。客户端本身负责评估模型，但在此情况下不需要训练模型。

混合方法允许你在服务器上训练和定期更新复杂模型。序列化模型比原始训练数据小得多，因此可以发送到客户端进行离线评估。只要客户端和服务器使用兼容的库或算法（即，两边都使用`TensorFlow.js`），客户端就可以利用服务器的处理能力进行训练，但在对评估步骤要求较低的情况下，使用自己的离线处理能力。

混合模型的示例用例包括语音或图像识别，可能是用于人工智能助手或**增强现实（AR**）应用程序。在 AR 应用程序的情况下，服务器负责维护数百万个训练图像并训练（例如）一个 RNN 来分类物体。一旦训练完成，这个模型就可以被序列化、存储并由客户端下载。

让我们想象一个增强现实（AR）应用程序，该程序连接到设备的摄像头并显示一个标注的视频流，用于识别物体。当应用程序首次启动时，客户端会下载 AR RNN 模型并将其存储在设备的本地存储中，同时存储版本信息。当视频流首次启动时，应用程序从存储中检索模型并将其反序列化到客户端自己的 RNN 实现中。理想情况下，客户端的 RNN 实现将使用与服务器上相同的库和版本。

为了对视频的每一帧进行分类和标注，客户端需要在仅仅 16 毫秒内（对于 60 FPS 的视频）完成所有必要的工作。这是可行的，但在实践中并非每一帧都用于分类；每 3 帧中就有 1 帧（相隔 50 毫秒）就足够了。混合方法在这里表现出色；如果视频的每一帧都需要上传到服务器、评估然后返回，应用程序将遭受严重的性能损失。即使模型性能非常出色——例如，模型评估需要 5 毫秒——你也可能因为 HTTP 请求所需的往返时间而额外体验 100 毫秒的延迟。

在混合方法下，客户端不需要将图像发送到服务器进行评估，而是可以直接根据现在加载到内存中的先前训练模型立即评估图像。一个设计良好的客户端会定期检查服务器以获取模型更新，并在必要时更新它，但仍然允许过时的模型离线运行。当应用程序“正常工作”时，用户最满意，混合模型为你提供了性能和弹性。服务器仅用于可以异步进行的任务，例如下载更新模型或将信息发送回服务器。

因此，混合方法最适合需要大型、复杂模型但模型评估需要非常快速或离线进行的用例。当然，这不是一个绝对规则。还有许多其他情况下，混合方法最为合理；如果你有多个客户端且无法承担服务器资源来处理所有他们的评估，你可能使用混合方法来卸载你的处理责任。

在设计执行模型训练或评估的客户端应用程序时，必须格外小心。虽然评估比训练快得多，但如果实现不当，它仍然是非平凡的，可能会在客户端引起 UI 性能问题。在下一节中，我们将探讨一个现代网络浏览器功能，称为 **web workers**，它可以用于在独立线程中执行处理，保持你的 UI 响应。

# Web workers

如果你正在为网络浏览器应用程序开发，你当然会想使用 web worker 在后台管理模型。Web workers 是一个浏览器特定功能，旨在允许后台处理，这正是我们在处理大型模型时想要的。

Web workers 可以与 `XMLHttpRequest`、`IndexedDB` 和 `postMessage` 交互。Web worker 可以使用 `XMLHttpRequest` 从服务器下载模型，使用 `IndexedDB` 本地存储它，并使用 `postMessage` 与 UI 线程通信。这三个工具结合使用，为响应式、高性能以及可能离线体验提供了完整的基础。其他 JavaScript 平台，如 React Native，也具有类似的 HTTP 请求、数据存储和进程间通信功能。

Web workers 可以与其他浏览器特定功能（如 **service workers** 和设备 API）结合使用，以提供完整的离线体验。Service workers 可以缓存特定资产以供离线使用，或智能地在在线和离线评估之间切换。浏览器扩展平台以及如 React Native 这样的移动平台也提供了一系列机制来支持缓存数据、后台线程和离线使用。

不论是哪个平台，概念都是相同的：当有互联网连接时，应用程序应该异步下载和上传数据；应用程序应该缓存（并版本控制）它需要运行的任何内容，如预训练模型；并且应用程序应该独立于 UI 评估模型。

容易错误地假设模型足够小且运行速度快，可以与 UI 在同一线程中运行。如果你的平均评估时间仅为 5 毫秒，并且你每 50 毫秒只需要进行一次评估，那么可能会变得自满，并跳过在单独线程中评估模型的额外细节。然而，市场上各种设备的范围使得你甚至不能假设性能上有数量级的相似性。例如，如果你在一个带有 GPU 的现代手机上测试了你的应用程序，你可能无法准确评估它在旧手机 CPU 上的性能。评估时间可能会从 5 毫秒跳到 100 毫秒。在设计不良的应用程序中，这会导致 UI 延迟或冻结，但在设计良好的应用程序中，UI 将保持响应，但更新频率较低。

幸运的是，Web Worker 和`postMessage` API 使用简单。`IndexedDB` API 是一个低级 API，最初可能难以使用，但有许多用户友好的库可以抽象出细节。你下载和存储预训练模型的具体方式完全取决于你应用程序的实现细节和所选的具体机器学习算法。较小的模型可以序列化为 JSON 并存储在`IndexedDB`中；更高级的模型可以直接集成到`IndexedDB`中。确保在你的服务器端 API 中包含一个比较版本信息的机制；你应该有一种方法可以询问服务器当前模型的版本，并将其与自己的副本进行比较，以便可以使其无效并更新模型。

在设计你的 Web Worker 的消息传递 API 时也要多加思考。你将使用`postMessage`API（在所有主流浏览器中都可用）来在 UI 线程和后台线程之间进行通信。这种通信至少应该包括检查模型状态的方法以及向模型发送数据点以供评估的方法。但你也会希望展望未来的功能，并使你的 API 灵活且具有前瞻性。

你可能需要计划的功能示例包括持续改进的模型，这些模型根据用户反馈重新训练，以及针对每个用户的模型，这些模型学习单个用户的行为或偏好。

# 持续改进和针对每个用户的模型

在你应用程序的生命周期中，最终用户很可能会以某种方式与你的模型进行交互。通常，这种交互可以用作进一步训练模型的反馈。这种交互还可以用来根据用户的需求定制模型，以适应他们的兴趣和行为。

两个概念的良例是垃圾邮件过滤器。垃圾邮件过滤器应该随着用户将消息标记为垃圾邮件而不断改进。当垃圾邮件过滤器拥有大量数据点用于训练时，它们最为强大，而这些数据可以来自应用程序的其他用户。每当用户将一条消息标记为垃圾邮件时，这种知识应该应用于模型，并且其他用户也应该能够享受到他们自己垃圾邮件过滤器的自动改进。

垃圾邮件过滤器也是应该针对每个用户定制的模型的良例。我认为是垃圾邮件的东西可能和你认为的不同。我积极地标记那些我没有注册的营销邮件和新闻通讯为垃圾邮件，但其他用户可能希望在自己的收件箱中看到这些类型的消息。同时，有些消息是每个人都同意是垃圾邮件的，因此设计我们的应用程序以使用一个中央、持续更新的模型会很好，这个模型可以本地优化以更好地适应特定用户的行为。

贝叶斯分类器非常适合这种描述，因为贝叶斯定理是为了通过新信息进行更新而设计的。在第五章，“分类算法”中，我们讨论了 Naive Bayes 分类器的实现，该实现能够优雅地处理稀有词汇。在该方案中，一个权重因子将词汇概率偏向中性，这样稀有词汇就不会对模型产生过强的干扰。一个针对用户的垃圾邮件过滤器可以使用同样的技术，但不是将词汇偏向中性，而是偏向中心模型的概率。

在这种用法中，稀有词汇的权重因子变成了一个平衡中心模型和本地模型的权重因子。你使权重因子越大，中心模型就越重要，用户影响本地模型所需的时间就越长。较小的权重因子将更敏感于用户反馈，但也可能导致性能的不规律。在典型的稀有词汇实现中，权重因子在 3 到 10 的范围内。然而，在针对用户的模型中，权重因子应该更大——可能是 50 到 1,000，考虑到中心模型是由数百万个示例训练的，不应该轻易被少量本地示例所覆盖。

在将数据发送回服务器以进行持续模型改进时，必须小心谨慎。你不应该将电子邮件消息发送回服务器，因为这会创建一个不必要的安全风险——*尤其是*如果你的产品不是一个电子邮件托管服务提供商，而只是一个电子邮件客户端。如果你也是电子邮件托管服务提供商，那么你可以简单地发送电子邮件 ID 回服务器，将其标记为垃圾邮件并供模型训练；客户端和服务器将分别维护自己的模型。如果你不是电子邮件托管服务提供商，那么你应该格外小心，确保用户数据的安全。如果你必须将令牌流发送回服务器，那么你应该在传输过程中对其进行加密，并对其进行匿名化。你也可以考虑使用一个在分词和词干提取后对令牌进行盐化和散列的标记器（例如，使用 sha1 或 hmac）。分类器在处理散列数据时与处理可读数据一样有效，但会添加一个额外的混淆层。最后，确保不要记录 HTTP 请求和原始令牌数据。一旦数据以令牌计数的形式进入模型，它就足够匿名化了，但请确保间谍无法将特定的令牌流与特定的用户联系起来。

当然，朴素贝叶斯分类器并不是唯一可以持续更新或根据用户定制的模型。大多数机器学习算法都支持模型的持续更新。如果一个用户指出一个循环神经网络（RNN）在图像分类上犯了错误，那么这个用户的数据点可以被添加到模型的训练集中，模型可以定期完全重新训练，或者可以与新训练示例一起批量更新。

一些算法支持真正实时的模型更新。朴素贝叶斯分类器只需要更新标记和文档计数，这些甚至可能存储在内存中。knn 和 k-means 算法类似地允许在任何时候将数据点添加到模型中。一些用于强化学习的 ANN（人工神经网络）也依赖于实时反馈。

其他算法更适合定期批量更新。这些算法通常依赖于梯度下降或随机方法，并在训练期间需要许多示例的反馈循环；例如，ANN 和随机森林。确实可以使用单个数据点重新训练 ANN 模型，但批量训练更有效。在更新模型时，请注意不要过拟合模型；过多的训练并不总是好事。

在某些情况下，最好基于更新的训练集完全重新训练模型。这样做的一个原因是为了避免训练数据中的短期趋势过拟合。通过完全重新训练模型，你可以确保最近的训练示例与旧的训练示例具有相同的权重；这可能是或可能不是所希望的。如果模型定期自动重新训练，请确保训练算法正在查看正确的信号。它应该能够平衡准确性、损失和方差，以开发可靠的模型。由于机器学习训练在很大程度上是随机的，因此不能保证两次训练运行将以相同的质量或相似的时间完成。你的训练算法应该控制这些因素，并在必要时能够丢弃不良模型，例如，如果在最大训练轮数限制内没有达到目标准确性或损失。

在这一点上，一个新的问题出现了：你如何收集、存储和处理数 GB 或 TB 的训练数据？你如何以及在哪里存储和分发序列化模型给客户？你如何从数百万用户那里收集新的训练示例？这个话题被称为数据管道，我们将在下一节讨论。

# 数据管道

在开发生产级 ML 系统时，你不太可能得到以可处理格式提供的训练数据。生产级 ML 系统通常是更大应用程序系统的一部分，你使用的数据可能来自多个不同的来源。ML 算法的训练集可能是你更大数据库的一个子集，结合存储在**内容分发网络**（**CDN**）上的图像和来自 Elasticsearch 服务器的的事件数据。在我们的示例中，我们得到了一个隔离的训练集，但在现实世界中，我们需要以自动化和可重复的方式生成训练集。

将数据引导通过生命周期各个阶段的过程被称为**数据管道**。数据管道可能包括运行 SQL 或 Elasticsearch 查询的对象选择器，允许基于事件或日志的数据流入的事件订阅，聚合，连接，将数据与第三方 API 的数据结合，净化，标准化和存储。

在理想的实现中，数据管道充当了更大应用程序环境和 ML 过程之间的抽象层。ML 算法应该能够读取数据管道的输出，而不需要了解数据的原始来源，类似于我们的示例。在这种方法下，ML 算法不需要了解应用程序的实现细节；管道本身负责知道应用程序是如何构建的。

由于可能存在许多可能的数据源和无限多的应用程序架构方式，没有一种数据管道可以适用于所有情况。然而，大多数数据管道将包含以下组件，我们将在接下来的章节中讨论：

+   数据查询和事件订阅

+   数据连接或聚合

+   转换和标准化

+   存储和交付

让我们来看看这些概念，并介绍一些可以实现它们的工具和技术。

# 数据查询

想象一下像 Disqus 这样的应用程序，它是一个可嵌入的评论表单，网站所有者可以使用它来为博客文章或其他页面添加评论功能。Disqus 的主要功能是允许用户对帖子进行点赞或留言，然而，作为一个额外的功能和收入来源，Disqus 可以提供内容推荐并在赞助内容旁边展示它们。内容推荐系统是一个 ML 系统的例子，它是更大应用程序的一个功能。

在 Disqus 这样的应用中的内容推荐系统并不一定需要与评论数据交互，但可能会使用用户的喜欢历史来生成与当前页面类似的推荐。这样的系统还需要分析喜欢页面的文本内容，并将其与网络中所有页面的文本内容进行比较，以便做出推荐。Disqus 不需要帖子的内容来提供评论功能，但需要在数据库中存储关于页面的元数据（如 URL 和标题）。因此，帖子内容可能不会存储在应用程序的主数据库中，尽管喜欢和页面元数据可能会存储在那里。

建立在 Disqus 推荐系统周围的数据管道首先需要查询主数据库以获取用户喜欢的页面——或者喜欢当前页面的用户所喜欢的页面——并返回它们的元数据。然而，为了找到类似的内容，系统将需要使用每个喜欢帖子的文本内容。这些数据可能存储在单独的系统，比如 MongoDB 或 Elasticsearch 这样的二级数据库，或者 Amazon S3 或其他数据仓库中。该管道需要根据主数据库返回的元数据检索文本内容，并将内容与元数据关联起来。

这是在数据管道早期阶段的一个多数据选择器或数据源的例子。一个数据源是主要应用程序数据，它存储帖子和喜欢元数据。另一个数据源是二级服务器，它存储帖子的文本内容。

该管道的下一步可能涉及找到与用户喜欢的帖子相似的一批候选帖子，这可能通过请求 Elasticsearch 或其他能够找到相似内容的服务来实现。然而，相似的内容并不一定是正确的内容来提供，因此这些候选文章最终将由一个（假设的）人工神经网络（ANN）进行排名，以确定要显示的最佳内容。在这个例子中，数据管道的输入是当前页面，输出是数据管道的一个列表，例如 200 个相似的页面，然后 ANN 将对这些页面进行排名。

如果所有必要的数据都驻留在主数据库中，整个管道可以通过一个 SQL 语句和一些 JOIN 操作来实现。即使在这种情况下，也应该在机器学习算法和数据管道之间开发一定程度的抽象，因为您可能决定在未来更新应用程序的架构。然而，在其他情况下，数据将驻留在不同的位置，因此需要开发一个更周全的管道。

构建这个数据管道有许多方法。你可以开发一个执行所有管道任务的 JavaScript 模块，在某些情况下，你甚至可以使用标准的 Unix 工具编写 bash 脚本来完成任务。在复杂性的另一端，有专门用于数据管道的工具，如 *Apache Kafka* 和 *AWS Pipeline*。这些系统设计为模块化，允许你定义特定的数据源、查询、转换和聚合模块，以及连接它们的流程。例如，在 AWS Pipeline 中，你定义 *数据节点*，这些节点了解如何与你的应用程序中的各种数据源进行交互。

管道的最早阶段通常是某种数据查询操作。必须从更大的数据库中提取训练示例，同时考虑到数据库中的每条记录并不一定是训练示例。例如，在垃圾邮件过滤器的情况下，你应该只选择被用户标记为垃圾邮件或非垃圾邮件的消息。那些被垃圾邮件过滤器自动标记为垃圾邮件的消息可能不应该用于训练，因为这可能会引起正反馈循环，最终导致不可接受的误报率。

类似地，你可能想阻止被你的系统阻止或禁止的用户影响你的模型训练。一个恶意行为者可能会通过对自己数据进行不适当的行为来故意误导机器学习模型，因此你应该将这些数据点作为训练示例排除。

或者，如果你的应用程序要求最近的数据点应该比旧的数据点优先考虑，你的数据查询操作可能需要对用于训练的数据设置基于时间限制，或者选择一个按时间顺序逆序排列的固定限制。无论情况如何，确保你仔细考虑你的数据查询，因为它们是你数据管道中的基本第一步。

然而，并非所有数据都需要来自数据库查询。许多应用程序使用 *pub/sub* 或事件订阅架构来捕获流数据。这些数据可能是来自多个服务器的活动日志聚合，或者来自多个来源的实时交易数据。在这些情况下，事件订阅者将是你的数据管道的早期部分。请注意，事件订阅和数据查询不是互斥的操作。通过 pub/sub 系统传入的事件仍然可以根据各种标准进行过滤；这仍然是一种数据查询的形式。

当事件订阅模型与批量训练方案结合时，可能会出现一个潜在问题。如果你需要 5,000 个数据点，但每秒只收到 100 个，你的管道需要维护一个数据点的缓冲区，直到达到目标大小。有各种消息队列系统可以协助完成这项工作，例如 RabbitMQ 或 Redis。需要这种功能的管道可能会在队列中保留消息，直到达到 5,000 条消息的目标，然后才将消息释放到管道的其余部分进行批量处理。

如果数据是从多个来源收集的，它很可能需要以某种方式连接或聚合。现在让我们看看需要将数据与外部 API 数据连接的情况。

# 数据连接和聚合

让我们回到我们的 Disqus 内容推荐系统示例。想象一下，数据管道能够直接从主数据库查询点赞和帖子元数据，但没有系统在应用程序中存储帖子的文本内容。相反，开发了一个以 API 形式存在的微服务，该 API 接受帖子 ID 或 URL，并返回页面的净化文本内容。

在这种情况下，数据管道需要与微服务 API 交互，以获取每个帖子的文本内容。这种方法是完全有效的，尽管如果帖子内容请求的频率很高，可能需要实施一些缓存或存储。

数据管道需要采用与事件订阅模型中消息缓冲类似的方法。管道可以使用消息队列来排队仍需要内容的帖子，并对队列中的每个帖子向内容微服务发出请求，直到队列耗尽。随着每个帖子内容的检索，它被添加到帖子元数据中，并存储在单独的队列中，用于完成请求。只有当源队列耗尽且目标队列满时，管道才应继续下一步。

数据连接不一定需要涉及微服务 API。如果管道从两个需要合并的独立来源收集数据，可以采用类似的方法。管道是唯一需要理解两个数据源和格式之间关系的组件，让数据源和机器学习算法独立于这些细节进行操作。

当需要数据聚合时，队列方法也工作得很好。这种情况的一个例子是，输入是流式输入数据，输出是标记计数或值聚合的管道。在这些情况下，使用消息队列是可取的，因为大多数消息队列确保消息只能被消费一次，从而防止聚合器产生任何重复。当事件流非常高频时，这一点尤其有价值，因为将每个事件作为它到来时进行标记可能会导致备份或服务器过载。

由于消息队列确保每条消息只被消费一次，高频事件数据可以直接流入一个队列，其中消息由多个并行工作的进程消费。每个工作进程可能负责对事件数据进行分词，然后将分词流推送到不同的消息队列。消息队列软件确保没有两个工作进程处理相同的消息，每个工作进程可以作为独立单元运行，只关注分词。

当分词器将结果推送到新的消息队列时，另一个工作进程可以消费这些消息并汇总分词计数，每秒、每分钟或每 1,000 个事件（以适用于应用程序的方式）将自身的结果传递到管道的下一步。这种风格管道的输出可能被输入到一个持续更新的贝叶斯模型中，例如。

以这种方式设计的数据管道的一个好处是性能。如果您试图订阅高频事件数据，对每条消息进行分词，汇总分词计数，并更新模型，您可能被迫使用一个非常强大（且昂贵）的单个服务器。服务器同时需要高性能 CPU、大量 RAM 和高吞吐量网络连接。

然而，通过将管道分解为阶段，您可以针对每个阶段的特定任务和负载条件进行优化。接收源事件流的消息队列只需要接收事件流，但不需要处理它。分词工作进程不一定是高性能服务器，因为它们可以并行运行。汇总队列和工作进程将处理大量数据，但不需要保留数据超过几秒钟，因此可能不需要太多 RAM。最终的模型，即源数据的压缩版本，可以存储在更普通的机器上。由于数据管道鼓励模块化设计，因此数据管道的许多组件可以用通用硬件构建。

在许多情况下，您需要在管道中从一种格式转换数据到另一种格式。这可能意味着将原生数据结构转换为 JSON，转置或插值值，或对值进行哈希处理。现在让我们讨论在数据管道中可能发生的几种数据转换类型。

# 转换和归一化

当您的数据通过管道传输时，可能需要将其转换为与算法输入层兼容的结构。在管道中的数据可以进行许多可能的转换。例如，为了在数据到达基于分词的分类器之前保护敏感用户数据，您可能需要对分词应用加密哈希函数，这样它们就不再是人类可读的。

更典型的情况是，转换类型将与清理、归一化或转置相关。清理操作可能涉及删除不必要的空白或 HTML 标签，从标记流中删除电子邮件地址，以及从数据结构中删除不必要的字段。如果你的管道已订阅事件流作为数据源，并且事件流将源服务器 IP 地址附加到事件数据中，那么从数据结构中移除这些值是一个好主意，这样既可以节省空间，也可以最大限度地减少潜在数据泄露的表面积。

类似地，如果你的分类算法不需要电子邮件地址，那么管道应该移除这些数据，以便它与尽可能少的服务器和系统交互。如果你设计了一个垃圾邮件过滤器，你可能想考虑只使用电子邮件地址的域名部分而不是完全合格的地址。或者，电子邮件地址或域名可以通过管道进行哈希处理，这样分类器仍然可以识别它们，但人类却不能。

确保审查数据中的其他潜在安全和隐私问题。如果你的应用程序在事件流中收集最终用户的 IP 地址，但分类器不需要这些数据，那么应尽早将其从管道中移除。随着新欧洲隐私法律的实施，这些考虑因素变得越来越重要，每个开发者都应该意识到隐私和合规问题。

数据转换的常见类别之一是归一化。当处理给定字段或特征的数值范围时，通常希望将范围归一化，使其具有已知的最小和最大边界。一种方法是将同一字段的全部值归一化到[0,1]的范围内，使用遇到的最高值作为除数（例如，序列*1, 2, 4*可以归一化为*0.25, 0.5, 1*）。数据是否需要以这种方式归一化完全取决于消耗数据的算法。

另一种归一化的方法是转换值成为百分位数。在这个方案中，非常大的异常值不会使算法产生太大的偏差。如果大多数值位于 0 到 100 之间，但少数点包括像 50,000 这样的值，算法可能会给予大值过大的优先级。然而，如果数据以百分位数归一化，那么你保证不会有任何超过 100 的值，异常值也会被纳入与数据其他部分相同的范围。这好不好取决于算法。

数据管道也是计算派生或二阶特征的好地方。想象一个随机森林分类器，它使用 Instagram 个人资料数据来确定个人资料属于人类还是机器人。Instagram 个人资料数据将包括用户的关注者数量、朋友数量、帖子数量、网站、简介和用户名。然而，随机森林分类器在使用这些字段的原有表示时可能会遇到困难，但是通过应用一些简单的数据转换，你可以达到 90%的准确率。

在 Instagram 的情况下，一种有用的数据转换是计算比率。关注者数量和粉丝数量作为单独的特征或信号，可能对分类器没有太大帮助，因为它们被处理得相对独立。但是，朋友与关注者的比率可能成为一个非常强烈的信号，可能会暴露出机器人用户。一个有 1,000 个朋友的 Instagram 用户不会引起任何警报，同样，一个有 50 个粉丝的 Instagram 用户也不会；独立处理，这些特征不是强烈的信号。然而，一个朋友与关注者比率为 20（或 1,000/50）的 Instagram 用户几乎肯定是一个设计来关注其他用户的机器人。同样，像帖子与关注者比或帖子与朋友比这样的比率可能最终比任何单独的特征都强。

文本内容，如 Instagram 用户的个人资料简介、网站或用户名，通过从它们中提取二阶特征也能变得有用。分类器可能无法对网站的 URL 做任何事情，但也许可以用一个布尔值特征*has_profile_website*作为信号。如果在你的研究中，你注意到机器人的用户名中往往有很多数字，你可以从用户名本身提取特征。一个特征可以计算用户名中字母与数字的比例，另一个布尔值特征可以表示用户名是否以数字开头或结尾，一个更高级的特征可以确定用户名中是否使用了字典中的单词（因此区分`@themachinelearningwriter`和像`@panatoe234`这样的乱码）。

提取的特征可以是任何复杂度或简单度。另一个简单的特征可能是 Instagram 个人资料是否在个人资料简介字段中包含 URL（与专门的网站字段相对）；这可以通过正则表达式检测，布尔值用作特征。一个更高级的特征可以自动检测用户内容中使用的语言是否与用户指定的地区设置相同。如果用户声称他们在法国，但总是用俄语写标题，这确实可能是一个住在法国的俄罗斯人，但结合其他信号，如关注者与粉丝的比例远非 1，这些信息可能表明是一个机器人用户。

还有一些低级转换可能需要应用于管道中的数据。如果源数据是 XML 格式，但分类器需要 JSON 格式，则管道应负责解析和格式转换。

还可以应用其他数学转换。如果数据的原生格式是面向行的，但分类器需要面向列的数据，则管道可以在处理过程中执行向量转置操作。

同样，管道可以使用数学插值来填充缺失值。如果你的管道订阅了实验室环境中一套传感器发出的事件，并且单个传感器在几次测量中离线，那么在两个已知值之间进行插值以填充缺失数据可能是合理的。在其他情况下，缺失值可以用总体均值或中位数来替换。用均值或中位数替换缺失值通常会导致分类器优先考虑该数据点的特征，而不是通过提供一个空值来破坏分类器。

通常，在数据管道中的转换和归一化方面，有两个方面需要考虑。第一个是源数据和目标格式的机械细节：XML 数据必须转换为 JSON，行必须转换为列，图像必须从 JPEG 格式转换为 BMP 格式，等等。这些机械细节并不太复杂，因为你已经知道系统所需的源和目标格式。

另一个考虑因素是您数据的语义或数学转换。这是一个特征选择和特征工程练习，并不像机械转换那样直接。确定要推导出哪些二阶特征既是一门艺术也是一门科学。艺术在于提出新的衍生特征想法，而科学在于严格测试和实验你的工作。以我在 Instagram 机器人检测方面的经验为例，我发现 Instagram 用户名中的字母与数字比例是一个非常微弱的信号。经过一些实验后，我放弃了这个想法，以避免给问题添加不必要的维度。

到目前为止，我们有一个假设的数据管道，它收集数据，将其连接和聚合，处理它，并将其归一化。我们几乎完成了，但数据仍需要交付给算法本身。一旦算法被训练，我们可能还希望序列化模型并存储它以供以后使用。在下一节中，我们将讨论在传输和存储训练数据或序列化模型时需要考虑的一些因素。

# 存储和交付数据

一旦你的数据处理管道完成了所有必要的处理和转换，它剩下的任务就是将数据传递给你的算法。理想情况下，算法不需要了解数据管道的实现细节。算法应该有一个单一的位置可以与之交互，以获取完全处理过的数据。这个位置可能是一个磁盘上的文件，一个消息队列，一个如 Amazon S3 这样的服务，一个数据库，或者一个 API 端点。你选择的方法将取决于你可用的资源，你的服务器系统的拓扑或架构，以及数据的格式和大小。

只定期训练的模型通常是处理起来最简单的情况。如果你正在开发一个图像识别 RNN，它学习大量图像的标签，并且只需要每几个月重新训练一次，一个很好的方法是将所有图像以及一个清单文件（将图像名称与标签相关联）存储在 Amazon S3 或磁盘上的专用路径上。算法首先加载并解析清单文件，然后根据需要从存储服务加载图像。

类似地，一个 Instagram 机器人检测算法可能只需要每周或每月重新训练一次。算法可以直接从数据库表、存储在 S3 或本地磁盘上的 JSON 或 CSV 文件中读取训练数据。

这种情况很少发生，但在一些特殊的数据管道实现中，你也可以为算法提供一个作为微服务构建的专用 API 端点；算法会首先查询 API 端点以获取训练点引用的列表，然后依次从 API 请求每个引用。

需要在线更新或近似实时更新的模型，另一方面，最好通过消息队列来提供服务。如果一个贝叶斯分类器需要实时更新，算法可以订阅消息队列，并在更新到来时应用它们。即使使用复杂的分阶段管道，如果你设计好了所有组件，处理新数据和更新模型也可能在几秒钟内完成。

回到垃圾邮件过滤器示例，我们可以设计一个高性能的数据管道，如下所示：首先，一个 API 端点接收用户的反馈。为了保持用户界面的响应性，这个 API 端点只负责将用户的反馈放入消息队列，并且可以在不到一毫秒内完成其任务。然后，数据处理管道订阅消息队列，在另几个毫秒内就会知道有新消息。管道随后对消息应用一些简单的转换，如分词、词干提取，甚至可能对标记进行散列。

管道下一步将把标记流转换成标记及其计数的哈希表（例如，从 *hey hey there* 转换为 *{hey: 2, there: 1}*）；这样可以避免分类器需要多次更新同一个标记的计数。这一处理阶段在最坏的情况下也只需额外几毫秒。最后，完全处理后的数据被放置在一个单独的消息队列中，分类器会订阅这个队列。一旦分类器意识到数据，它就可以立即将更新应用到模型上。如果分类器由 Redis 支持，例如，这一最终阶段也只需几毫秒。

我们所描述的整个过程，从用户反馈到达 API 服务器到模型更新的时间，可能只需要 20 毫秒。考虑到互联网（或任何其他方式）的通信速度受光速限制，纽约和旧金山之间 TCP 数据包往返的最佳情况场景是 40 毫秒；在实际操作中，良好互联网连接的平均跨国家延迟约为 80 毫秒。因此，我们的数据管道和模型能够在用户甚至收到他们的 HTTP 响应之前 20 毫秒就根据用户反馈进行自我更新。

并非每个应用程序都需要实时处理。为 API、数据管道、消息队列、Redis 存储和分类器托管分别管理服务器，在努力和预算方面可能都是过度的。您需要确定最适合您用例的方案。

最后要考虑的不是数据管道相关的问题，而是模型本身的存储和交付，特别是在混合方法中，模型在服务器上训练但在客户端评估的情况下。首先要问自己的问题是模型是否被认为是公共的还是私有的。例如，私有模型不应存储在公共的 Amazon S3 存储桶中；相反，S3 存储桶应设置访问控制规则，并且您的应用程序需要获取一个带有过期时间的签名下载链接（S3 API 可以帮助完成这项工作）。

下一个考虑因素是模型的大小以及客户端下载模型的频率。如果公共模型经常被下载但更新不频繁，使用 CDN 以利用边缘缓存可能是最好的选择。例如，如果您的模型存储在 Amazon S3 上，那么 Amazon CloudFront CDN 将是一个不错的选择。

当然，你总是可以构建自己的存储和交付解决方案。在本章中，我假设了一个云架构，然而如果你只有一个专用的或共址服务器，你可能只想将序列化的模型存储在磁盘上，并通过你的网络服务器软件或应用程序的 API 提供服务。在处理大型模型时，确保考虑如果许多用户同时尝试下载模型会发生什么。如果太多人同时请求文件，你可能会无意中饱和服务器的网络连接，你可能会超出服务器 ISP 设置的任何带宽限制，或者你可能会发现服务器的 CPU 在移动数据时陷入 I/O 等待状态。

如前所述，没有一种适合所有情况的数据管道解决方案。如果你是一个为了乐趣或仅仅为几个用户开发应用程序的爱好者，你有很多数据存储和交付的选择。然而，如果你在一个大型企业项目中以专业身份工作，你将不得不考虑数据管道的所有方面以及它们如何影响应用程序的性能。

我将给阅读这一部分的爱好者提供一条最后的建议。虽然对于爱好项目来说，你确实不需要一个复杂的、实时的数据处理管道，但你仍然应该构建一个。能够设计和构建实时的数据处理管道是一项非常具有市场价值和稀缺的技能，而且很多人都不具备这项技能。如果你愿意投入实践去学习机器学习算法，那么你也应该练习构建性能良好的数据处理管道。我并不是说你应该为每一个爱好项目都构建一个庞大而复杂的数据处理管道——只是说你应该尝试几次，使用几种不同的方法，直到你不仅对概念感到舒适，也对实现感到舒适。熟能生巧，而实践意味着亲自动手。

# 摘要

在本章中，我们讨论了与生产中机器学习应用相关的许多实际问题。学习机器学习算法当然是构建机器学习应用的核心，但构建应用远不止简单地实现算法。应用最终需要与各种设备上的用户进行交互，因此，仅仅考虑你的应用能做什么是不够的——你还必须计划它将如何以及在哪里被使用。

我们本章开始时讨论了可序列化和可移植的模型，并学习了模型训练和评估的不同架构方法。我们讨论了完全服务器端的方法（常见于 SaaS 产品），完全客户端的方法（对于敏感数据很有用），以及一种混合方法，即模型在服务器上训练但在客户端评估。你还学习了关于 Web Workers 的内容，这是一个有用的浏览器特定功能，你可以使用它来确保在客户端评估模型时有一个性能良好且响应迅速的用户界面。

我们还讨论了持续更新或定期重新训练的模型，以及客户端和服务器之间传递反馈的各种方法。你还学习了关于按用户模型，或者可以由一个中心真实来源训练但可以通过个别用户的特定行为进行优化的算法。

最后，你学习了关于数据管道以及各种管理数据从一系统到下一系统收集、组合、转换和交付的机制。在我们对数据管道的讨论中，一个中心主题是使用数据管道作为机器学习算法和其余生产系统之间的一层抽象。

我想要讨论的最后一个话题是许多机器学习学生都好奇的：你究竟是如何为特定问题选择正确的机器学习算法的？机器学习专家通常发展出一种指导他们决策的直觉，但这种直觉可能需要数年才能形成。在下一章中，我们将讨论你可以使用的实用技术，以缩小针对任何给定问题的适当机器学习算法的选择范围。
