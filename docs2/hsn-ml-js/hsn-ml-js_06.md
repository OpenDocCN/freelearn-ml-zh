# 关联规则算法

关联规则学习，或称关联规则挖掘，是一种相对较新的无监督学习技术，最初用于在杂货店发现购买商品之间的关联。关联规则挖掘的目标是发现商品集合之间的有趣关系，例如，发现为应对飓风做准备的人通常会购买 Pop-Tarts、瓶装水、电池和手电筒。

在第五章，“分类算法”中，我们介绍了条件概率的概念。在本章中，我们将把这一概念进一步拓展，并将其应用于关联规则学习。回想一下，条件概率询问（并回答）的问题是：如果我们知道某事，另一件事发生的概率是多少？或者，如果某人买了瓶装水和电池，他们购买 Pop-Tarts 的概率是多少？这个概率很高，正如我们很快就会看到的。

在关联规则学习中，我们的目标是查看交易或事件数据库，并通过概率将最常见的子集相互关联。这可以通过一个例子更容易理解。想象你经营一家电子商务商店，你的任务是创建一个个性化的主页小部件，向购物者推荐产品。你可以使用他们完整的订单历史数据库，你必须使用购物者的浏览历史来推荐他们很可能购买的商品。

自然地，解决这个问题有几种方法。没有理由你不能在商店整个订单历史上训练一个神经网络来推荐新产品——除了时间和复杂性。在数百万笔交易上训练神经网络既耗时又非常难以直观地检查和理解。另一方面，关联规则学习为我们提供了一个简单快捷的工具，这个工具基于基本的概率概念。

假设你的电子商务商店是一家销售精品、精选家居装饰和家具的直邮业务。你的目标是确定最常一起购买的商品组合，例如：90%购买躺椅和茶几的人也购买了脚凳，80%购买巨型挂钟的人也购买了干墙安装锚固件套装。

如果你有一种快速有效的方法来搜索数百万笔以前的订单以找到这些关系，你可以将当前购物者的浏览历史与其他购物者的购买历史进行比较，并显示购物者最有可能购买的商品。

关联规则学习不仅限于电子商务。另一个明显的应用是实体店，比如你当地的超市。如果 90%购买牛奶和鸡蛋的购物者也会购买面包，那么把面包放在附近可能会让购物者更容易找到它。或者，你可能想把面包放在商店的*对面*，因为你知道购物者将不得不走过很多通道，并且可能在这个过程中购买更多商品。如何使用这些数据取决于你，这取决于你想要优化什么：购物者的便利性还是整个购物篮的价值。

初看起来，这似乎是一个容易编写的算法——毕竟我们只是在计算概率。然而，在大型数据库和大量可能的商品选择中，检查每个商品组合的频率会变得非常耗时，因此我们需要比暴力穷举搜索方法更复杂一些的方法。

在本章中，我们将讨论：

+   从数学角度的关联规则学习

+   Apriori 算法的描述

+   关联规则学习的各种应用

+   各种关联规则算法的工作示例

让我们从数学的角度来探讨关联规则学习。

# 数学角度的描述

关联规则学习假设你有一个*事务数据库*来学习。这并不指代任何特定的技术，而是指存储事务的数据库概念——数据库可以是内存中的数组、Excel 文件，或者你生产环境中的 MySQL 或 PostgreSQL 实例中的表。由于关联规则学习最初是为超市中的产品开发的，原始的事务数据库是每个购物者在一次购物过程中购买的商品列表——本质上是一个收银通道的收据档案。然而，事务数据库可以是任何单次会话中发生的商品或事件的列表，无论这个会话是购物之旅、网站访问还是去看医生。目前，我们将考虑超市的例子。我们将在后面的章节中讨论关联规则的其他用途。

事务数据库是一个行代表会话、列代表*商品*的数据库。考虑以下：

| **收据** | **鸡蛋** | **牛奶** | **面包** | **奶酪** | **洗发水** |
| --- | --- | --- | --- | --- | --- |
| 1 | 是 | 是 | 否 | 是 | 否 |
| 2 | 否 | 否 | 是 | 是 | 否 |
| 3 | 否 | 否 | 否 | 否 | 是 |
| 4 | 是 | 是 | 是 | 是 | 否 |
| 5 | 是 | 是 | 否 | 是 | 否 |

这样的表格可以被视为一个事务数据库。请注意，我们并没有记录每个商品购买的数量，只是记录商品是否被购买。在大多数关联规则学习中，通常忽略商品的数量和顺序。

根据表中的信息，我们可以组合出各种事件发生的概率。例如，购物者购买洗发水的概率，或*P(E[Shampoo])*，是 20%。购物者同时购买奶酪和面包的概率是 40%，因为有两位购物者同时购买了奶酪和面包。

从数学上讲，*牛奶*和*面包*被称为**项集**，通常写作`{milk, bread}`。项集类似于我们在第五章“分类算法”中引入的概率*事件*的概念，但项集专门用于这种情况，而事件是概率中更一般的概念。

在关联规则学习中，一个项集作为交易的一部分出现的概率被称为该项集的**支持度**。刚才我们提到，某人购买牛奶和面包的概率是 40%；这是另一种说法，即`{milk, bread}`项集的支持度为 40%。用数学表示，我们可以写成`supp({milk, bread}) = 40%`。

然而，计算项集的支持度并不能让我们完全达到关联规则学习。我们首先需要定义什么是关联规则。关联规则的形式是 X -> Y，其中*X*和*Y*都是项集。完整写出来，一个示例关联规则可以是`{eggs, milk} -> {cheese}`，这关联了购买鸡蛋和牛奶与购买奶酪。尽管左侧可以有任意数量的项目，但关联规则几乎总是只有右侧有一个项目。关联规则本身并不能告诉我们关于关联的信息；我们还需要查看各种指标，如关联的*置信度*和*提升度*，以了解关联有多强。

对于关联规则来说，最重要的指标是其*置信度*，这本质上是指规则被发现为真的频率。置信度也恰好是条件概率*P(E[Y]|E[X])*，或给定某人购买了`X`中的项目，他们购买`Y`中项目的概率。

使用我们在第五章“分类算法”中关于条件概率的知识，以及关联规则学习中的新概念“支持”和“置信度”，让我们写出一些等价式，这将帮助我们巩固这些数学概念。

首先，让我们假设项集`X`是鸡蛋和牛奶，或`X = {eggs, milk}`，而`Y = {cheese}`。

`X`的支持，或`supp(X)`，等同于在交易中找到`X`中项目的概率，或*P(E[X])*。在这种情况下，鸡蛋和牛奶出现在五笔交易中的三笔，因此其支持度为 60%。同样，`Y`（仅奶酪）的支持度为 80%。

关联规则 `X -> Y` 的置信度定义为 `conf(X -> Y) = supp(X ∪ Y) / supp(X)`。另一种说法是，规则的置信度是规则中所有项的支持度除以左侧的支持度。在概率论中，∪ 符号表示 *并集*——基本上是一个布尔 OR 操作。因此，`X` 和 `Y` 项集的 *并集* 是出现在 X 或 Y 中的任何项。在我们的例子中，并集是鸡蛋、牛奶和奶酪。

如果 `supp(X) = P(EX)`，那么 `supp(X ∪ Y) = P(EX ∩ XY)`。回想一下，∩ 是 *交集* 的符号，或者说本质上是一个布尔 AND 操作。这是项集语义与概率事件语义不同的一种情况——两个项集的 *并集* 与包含这些项集的两个事件的 *交集* 有关。尽管符号有点令人困惑，但我们想要表达的是：当我们开始将关联规则符号翻译成标准的概率符号时，这个 *置信度* 公式开始看起来非常像条件概率的公式。

由于在条件概率中，*P(E[Y] | E[X]) = P(E[X] ∩ E[Y]) / P(E[X])* 这个关系定义了条件概率，并且我们知道 `supp(X ∪ Y) = P(E[X] ∩ E[Y])`，我们还知道 *P(E[X]) = supp(X)*，我们发现关联规则的置信度就是它的条件概率。

回到我们的示例规则 `{eggs, milk} ⇒ {cheese}`，我们发现这个规则的置信度为 1.0。*X* 和 *Y*（或 `{eggs, milk, cheese}`）的并集在五笔交易中出现了三次，其支持度为 0.6。我们将这个支持度除以左侧的支持度，即 `supp ({eggs, milk})`，我们也在五笔交易中找到了它。将 0.6 除以 0.6 得到 1.0，这是可能的最大置信值。每次购物者购买鸡蛋和牛奶时，他们也会购买奶酪。或者，用条件概率的说法，给定他们购买了鸡蛋和牛奶，购买奶酪的概率是 100%。与购买奶酪的概率只有 80% 相比，我们明显看到鸡蛋、牛奶和奶酪之间存在正相关关系。

这种偶然关系可以通过一个称为**提升度**的概念进一步探索。提升度定义为组合项的支持度除以左侧和右侧各自的支持度（即，假设它们是独立的）。公式是 `提升度(X -> Y) = supp(X ∪ Y) / ( supp(X) * supp(Y) )`。这个公式本质上衡量了`X`和`Y`相互之间是依赖还是独立。如果`X`和`Y`一起的支持度与`X`和`Y`分别的支持度相同，那么规则的提升度将是 1，`X`和`Y`可以被认为是完全相互独立的。随着两个项集的相互依赖性增加，提升度的值也会增加。在我们的例子中，`{鸡蛋，牛奶，奶酪}`的支持度再次是 0.6，`{鸡蛋，牛奶}`的支持度是 0.6，而`{奶酪}`的支持度是 0.8。将这些值与提升度公式结合起来，我们得到 `提升度(X -> Y) = 0.6 / (0.6 * 0.8) = 1.25`。这个规则据说有 25%的提升度，这表明`{鸡蛋，牛奶}`和`{奶酪}`之间存在某种依赖关系。

在开发关联规则时，研究人员可以使用几种其他指标，尽管在我们的示例中我们不会遇到这些指标。例如有*信念度*、*杠杆作用*和*集体力量*等指标，但大部分情况下，熟悉的支持度、置信度和提升度概念就足够了。

如果你从这个部分学到了什么，让它成为这一点：许多计算机科学和机器学习中的现代问题都可以用几个世纪的概率理论来解决。关联规则学习是在 20 世纪 90 年代开发的，但其核心概念可以追溯到数百年前。正如我们在第五章中看到的，*分类算法*，我们可以使用概率理论来开发强大的**机器学习**（**ML**）算法，关联规则学习也是提高你对概率理论知识的另一个论据。

现在我们来探讨分析事务型数据库的挑战，以及关联规则算法可能的工作方式。

# 算法视角

我们现在面临的是一个更加困难的任务，即在数据库中识别频繁项集。一旦我们知道我们想要为哪些项集和关联生成规则，计算规则的支持度和置信度就相当容易了。然而，困难在于自动发现数百万笔交易中数以千计的可能项的频繁且有趣的项集。

假设你的电子商务商店只有 100 种独特的商品。显然，你的客户在会话期间可以购买任意数量的商品。让我们说一个购物者只买了两种商品——从你的目录中考虑两种商品的不同组合有 4,950 种。但你还需要考虑购买三种商品的购物者，这其中有 161,700 种组合需要搜索。如果你的产品目录包含 1,000 种商品，在搜索频繁项集时，你需要考虑的三个商品组合有 1,660 万种。

显然，需要一个更高级的算法来搜索事务数据库中的频繁项集。请注意，频繁项集搜索只是解决方案的一半；一旦找到频繁项集，你仍然必须从它们中生成关联规则。然而，由于频繁项集搜索比生成关联规则要困难得多，因此项集搜索成为大多数算法的关键焦点。

在本节中，我们将描述一种原始的频繁项集搜索算法：Apriori 算法。我们这样做只是为了教育目的；你不太可能需要实现自己的 Apriori 算法版本，因为现在有更新、更快的频繁项集搜索算法可用。然而，我认为研究并理解这些经典算法很重要，特别是那些解决非常广大搜索空间的算法。大多数搜索非常广大空间的算法都使用某种公理化或启发式证明的技巧来极大地减少搜索空间，Apriori 也不例外。

Apriori 算法首先扫描事务数据库，并记录每个单独物品的支持度（或频率）。结果是物品列表或哈希表，例如鸡蛋 = 0.6，牛奶 = 0.6，洗发水 = 0.2。

下一步是找到两个物品的组合并确定它们在数据库中的支持度（或频率）。这一步骤的结果可能类似于 `{鸡蛋, 牛奶} = 0.6`，`{鸡蛋, 面包} = 0.2`，`{鸡蛋, 奶酪} = 0.6`，`{鸡蛋, 洗发水} = 0.0`，等等。暴力搜索、穷举搜索方法的问题从这一步开始。如果你目录中有 100 个物品，你需要计算 4,950 对的支持度。如果你目录中有 1,000 个物品，你必须计算近 500,000 对的支持度。我不知道亚马逊（[`www.amazon.com/`](https://www.amazon.com/））卖了多少产品（2017 年 1 月的最新报告称有 3.68 亿），但假设他们现在有 4 亿个产品，有 8 x 10¹⁶对物品需要考虑（那是八十万亿对物品）。而且这只是物品的*对*。我们还需要查看每个物品的三元组、四元组，等等。

Apriori 用来减少搜索空间的巧妙技巧是通过最小支持度或最小感兴趣频率来过滤唯一产品列表。例如，如果我们设定最小支持度为 0.25，我们会发现`{洗发水}`不符合条件，因此洗发水永远不会成为我们的频繁项集分析的一部分，因为它简单地没有频繁购买。

如果洗发水本身购买频率不够高，不足以被认为是频繁的，那么任何包含洗发水的项目对也将同样不足以被考虑。如果洗发水出现在 20%的购买中，那么`{鸡蛋, 洗发水}`这对必须出现在（或等于）20%的购买中更少（或等于）的频率。我们不仅可以从搜索中排除洗发水，还可以从考虑中排除任何包含洗发水的集合。如果洗发水本身购买频率足够低以至于我们可以忽略它，那么`{鸡蛋, 洗发水}`、`{面包, 洗发水}`和`{鸡蛋, 面包, 洗发水}`也将同样足够低以至于我们可以忽略它们。这大大减少了我们的搜索空间。

我们可以在检查更大组合的项目时将这种方法进一步深化。在我们的例子中，`{鸡蛋}`的支持度为 60%，而`{面包}`的支持度为 40%。如果我们设定的最小支持度为 25%，这两个项目单独都符合条件，应该在我们的频繁数据集分析中考虑。然而，`{鸡蛋, 面包}`的组合支持度仅为 20%，可以被舍弃。同样地，我们能够从二级搜索中消除任何包含`{洗发水}`的组合，现在我们也可以从三级搜索中消除任何包含`{鸡蛋, 面包}`的组合。因为鸡蛋和面包一起出现的频率很低，所以任何包含鸡蛋和面包的三个或更多项目的组合也必须很少见。因此，我们可以从考虑中排除像`{鸡蛋, 面包, 奶酪}`、`{鸡蛋, 面包, 牛奶}`和`{鸡蛋, 面包, 洗发水}`这样的组合，因为它们都包含了罕见的`鸡蛋`和`面包`组合。

虽然这种方法大大减少了寻找频繁项集所需的时间，但你应该谨慎使用这种方法，因为可能会意外地跳过一些有趣但相对罕见的组合。大多数 Apriori 实现都将允许你为生成的关联规则设置最小支持和最小置信度。如果你将最小支持度设定为高值，你的搜索将会更快，但你可能会得到更明显或不太有趣的结果；如果你将支持度设定得较低，你可能会在等待搜索完成上花费很长时间。通常，关联规则是在找到频繁项集之后生成的，所以你设定的任何最小置信度水平都不会影响搜索时间——只有最小支持度变量会对搜索时间产生重大影响。

还应注意的是，对于频繁项集搜索，存在更多高级且更快的算法。特别是，我们将在本章后面实验 FP-Growth 算法。然而，Apriori 算法是理解实际中频繁项集搜索如何工作的绝佳起点。

在我们实现库之前，让我们看看一些可能有助于关联规则的场景。

# 关联规则应用

关联规则算法的原始用途是市场篮子分析，例如我们在本章中一直使用的杂货店示例。这是关联规则挖掘的一个明确应用。市场篮子分析可以用于实体店和电子商务店，并且可以根据不同的星期日、季节或甚至特定罕见事件（如即将到来的音乐会或飓风）维护不同的模型。

事实上，在 2004 年，《纽约时报》（以及其他媒体）报道说，沃尔玛使用关联规则挖掘来提前了解如何为飓风储备商店。沃尔玛发现，在飓风来临前的最高提升关联并不是瓶装水或手电筒，而是草莓 Pop-Tarts。另一个具有高置信度的关联是啤酒。我对啤酒并不感到太惊讶，但草莓 Pop-Tarts 这种洞察力只能从机器学习中真正获得！

想象一下，如果你在 2004 年的沃尔玛担任数据科学家。查看不同时间段各种产品的单个销售量很容易。可能草莓 Pop-Tarts 作为一种小额商品，在飓风期间相对销售量的百分比变化非常小。这就是你可能自然忽略的、看似不重要的数据点。Pop-Tarts 销量略有上升，那又如何？但如果你挖掘频繁项集和关联规则的数据，你可能会发现`{瓶装水，电池} -> {草莓 Pop-Tarts}`规则在飓风来临前的几天出现了异常强的置信度和大约 8.0 的提升（提升值非常高）。在飓风季节之外，这种关联可能不存在或太弱而无法被选中。但当飓风即将来临，草莓 Pop-Tarts 成为必需的飓风补给品，几乎肯定是因为它们的长期保质期以及它们能让孩子们和成年人快乐的特性。看到这个关联，你会告诉商店增加草莓 Pop-Tarts 的库存，并将它们放在商店最前面——紧挨着瓶装水和电池——从而在 Pop-Tarts 销售上大赚一笔。

虽然这种类型的场景是关联规则设计的目的，但你可以将频繁项集挖掘和关联规则应用于任何事务数据库。如果你将网站会话视为一个事务，并且如果你可以捕获采取的行动（例如 *登录*，*加入愿望清单的商品*，*下载案例研究*）作为你的项目，你就可以将相同的算法和关联规则挖掘应用于网站访客行为。你可以开发关联规则，例如 `{下载案例研究, 查看定价页面} -> {输入信用卡}`，来模拟访客行为并优化你网站的布局和功能，以鼓励你希望的行为。

请记住，关联规则不仅在它们为正时才有价值。当它们为负时，同样有价值。很多时候，你需要冷酷、硬性的事实来改变你对之前顽固信念的看法。在对数据集进行关联规则挖掘时，如果没有看到你预期看到的关联，这可以与发现意外的关联一样强大。看到你直觉上认为的强关联的置信度实际上非常低，或者低于你的阈值，这可以帮助你放弃可能阻碍你或你的产品的过时思维。

有许多关于关联规则挖掘在许多和不同领域被使用的例子。是的，关联规则可以用来在飓风来临之前最大化 Pop-Tarts 的利润，但关联规则也可以用来根据其特征和功率输出来描述飓风本身。尽管关联规则学习是为篮子分析开发的，但其基于条件概率的基础使其适用于几乎任何可以用项目和事务表示的统计系统。

以医疗诊断为例。如果每位医生的诊断被视为一个事务，每种医疗状况或环境因素被视为一个项目，我们可以应用关联规则挖掘来发现现有条件、环境因素和新诊断之间的惊人关联。你可能会发现 `{空气质量差，饮食差} -> {哮喘}` 规则具有高置信度或提升，这可以告知研究人员和医生如何治疗哮喘，也许可以通过更仔细地关注饮食来实现。

关联规则可以应用于许多其他领域，如遗传学、生物信息学和 IT 安全。由于这些方法可以如此广泛地使用，因此很难认识到何时应该应用关联规则。一个很好的经验法则是：如果你的数据集包含事务，或者如果你可以看到自己计算许多事件组合的条件概率，你可能需要考虑关联规则挖掘。

让我们来看看几个用于关联规则挖掘的 JavaScript 库。

# 示例 – 零售数据

在这个例子中，我们将使用 Apriori 算法来分析一个零售数据集。首先，为这个项目创建一个名为`Ch6-Apriori`的新文件夹，并添加以下`package.json`文件：

```py
{
  "name": "Ch6-Apriori",
  "version": "1.0.0",
  "description": "ML in JS Example for Chapter 6 - Association Rules",
  "main": "src/index.js",
  "author": "Burak Kanber",
  "license": "MIT",
  "scripts": {
    "build-web": "browserify src/index.js -o dist/index.js -t [ babelify --presets [ env ] ]",
    "build-cli": "browserify src/index.js --node -o dist/index.js -t [ babelify --presets [ env ] ]",
    "start": "yarn build-cli && node dist/index.js"
  },
  "dependencies": {
    "apriori": "¹.0.7",
    "babel-core": "⁶.26.0",
    "babel-plugin-transform-object-rest-spread": "⁶.26.0",
    "babel-preset-env": "¹.6.1",
    "babelify": "⁸.0.0",
    "browserify": "¹⁵.1.0",
    "node-fpgrowth": "¹.0.0"
  }
}
```

在添加`package.json`文件后，从命令行运行`yarn install`以安装依赖项。

接下来，创建一个`src`目录，并从本书的 GitHub 仓库下载所需的数据文件`retail-data.json`到文件夹中。

现在将`index.js`文件添加到`src`文件夹中，并添加以下代码：

```py
import receipts from './retail-data.json';
import Apriori  from 'apriori';
import {FPGrowth} from 'node-fpgrowth';

const results = (new Apriori.Algorithm(0.02, 0.9, false))
    .analyze(receipts.slice(0, 1000));

console.log(results.associationRules
    .sort((a, b) => a.confidence > b.confidence ? -1 : 1));
```

上述代码导入数据集和 Apriori 库。然后，使用最小支持度为`0.02`（2%）和最小规则置信度为 90%初始化一个新的 Apriori 求解器。我们还在数据集中仅分析前 1000 张收据；由于 Apriori 算法本质上比较慢，所以在最初实验时你可能想要限制数据集的大小。

使用`yarn start`运行程序，你应该会看到类似以下输出的结果。输出将比这里显示的更长；花点时间探索你自己的控制台输出：

```py
[ a {
 lhs:
 [ 'KNITTED UNION FLAG HOT WATER BOTTLE',
 'RED WOOLLY HOTTIE WHITE HEART.',
 'SET 7 BABUSHKA NESTING BOXES' ],
 rhs: [ 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 confidence: 1 },
 a {
 lhs:
 [ 'RETRO COFFEE MUGS ASSORTED',
 'SAVE THE PLANET MUG',
 'VINTAGE BILLBOARD DRINK ME MUG',
 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 rhs: [ 'KNITTED UNION FLAG HOT WATER BOTTLE' ],
 confidence: 1 },
 a {
 lhs:
 [ 'RETRO COFFEE MUGS ASSORTED',
 'SAVE THE PLANET MUG',
 'VINTAGE BILLBOARD DRINK ME MUG' ],
 rhs: [ 'WHITE HANGING HEART T-LIGHT HOLDER' ],
 confidence: 1 },
```

这些关联规则都具有 1.0 的置信度，这意味着右侧（标记为`rhs`）在左侧出现时 100%的情况下都会出现。

在结果中向下滚动一点，你可能会找到以下规则：

```py
 a {
 lhs: [ 'HAND WARMER BABUSHKA DESIGN', 'HAND WARMER RED RETROSPOT' ],
 rhs: [ 'HAND WARMER BIRD DESIGN' ],
 confidence: 0.9130434782608696 },
```

这个规则实际上告诉我们，当购物者购买 babushka 和红色复古设计的手暖器时，他们有 91%的可能性也会购买鸟形设计的手暖器。你有没有想过，当你在亚马逊购物时，为什么经常看到类似你刚刚购买或添加到购物车中的商品的建议？这就是原因——显然，购物者经常购买足够多的相似商品，以至于关联规则通过了它需要通过的各种阈值，尽管平均购物者可能不需要三个不同设计的手暖器。但迎合平均购物者并不总是目标；你想要迎合那些会花更多钱的购物者，而你可以通过统计数据找到这样的购物者。

尝试调整 Apriori 设置。如果你降低最小置信度会发生什么？如果你增加最小支持度会发生什么？

在保持最小支持度不变的同时降低最小置信度应该会给你更多的关联规则结果，而不会对执行时间产生实际影响。大部分执行时间都花在发现频繁项集上，此时置信度尚未是一个定义好的参数；置信度只在组合规则时发挥作用，不会影响单个项集。

提高最小支持度将加快算法的速度，然而，你会发现得到的结果不那么有趣。随着你提高最小支持度，你会发现规则的左侧变得更加简单。你以前会看到左侧有三个或四个项的规则，现在你将开始看到只有一项或可能两项的更简单的左侧项集。包含多个项的项集自然倾向于具有较低的支持值，所以随着你提高最小支持度，你最终会得到更简单的关联。

另一方面，降低最小支持度将大大增加执行时间，但也会产生更有趣的结果。请注意，可能存在支持度一般但置信度非常高的规则；这些规则通常成立，但发生频率较低。随着你降低最小支持度，你会发现新出现的规则在置信度值范围内均匀分布。

还可以尝试增加`receipts.slice`所给的限制。如果你保持最小支持度参数不变，不仅程序会变慢，而且输出中的规则也会更少。原因在于支持值取决于数据集的大小。一个在 1,000 笔交易中出现在 2%的项集*可能*只在 2,000 笔交易中的 1%出现，这取决于项的分布。如果你有非常多的项选择，或者如果你的项分布是指数衰减的（即，*长尾分布*），你会发现你需要随着考虑的项的数量成比例地调整最小支持度值。

为了演示这一点，我从一个最小支持度为 0.02、最小置信度为 0.9 以及从收据变量中选取 1,000 项的限制开始。在这些参数下，Apriori 算法找到了 67 条关联规则。当我将限制从 1,000 增加到 2,000 时，算法没有找到任何规则。在前 1,000 笔交易中的频繁项集与后 1,000 笔交易中的项集差异足够大，以至于当我增加限制时，大多数项集的支持值都降低了。

为了找到更多结果，我必须降低最小支持度。我首先尝试将最小支持度设置为 0.01，然而，在等待程序完成两个小时后，我不得不取消那次尝试。我再次尝试设置为 0.015。这次，程序在 70 秒内完成，并给了我 12 个结果。在 0.010 和 0.015 之间，必须存在某个点，使得项集的数量会急剧增加——确实，程序在最小支持度为 0.0125 时找到了 584 条规则。

项集的支持简单是其所有交易中的频率。我们可以用频率来重新表述与支持相关的一切。如果我们考虑 2,000 笔交易，支持值为 0.0125 对应于 25 次出现。换句话说，我刚刚生成的 584 条规则列表只包括在我的 2,000 笔交易数据集中至少被购买 25 次的商品。为了生成只购买过，比如说 5 次或更多次的产品规则，我需要设置最小支持值为 0.0025——一个我相当确信会烧毁我的笔记本电脑的值。

在这里，需要比 Apriori 更精细的算法变得明显。不幸的是，JavaScript 生态系统在这方面仍然缺乏。另一个流行的频繁项集挖掘算法 ECLAT 似乎没有任何 JavaScript 实现。

我们还有另一个可用的频繁项集挖掘算法：FP-Growth 算法。这个算法应该能够轻松地处理我们的任务，然而，我们可用的库只执行频繁项集搜索，并不生成关联规则。一旦发现了频繁项集，生成关联规则就变得容易多了，但我将这个练习留给读者。现在，让我们看看 FP-Growth 库。

在`index.js`文件中，你可以取消与 Apriori 求解器相关的现有行的注释，并添加以下代码：

```py
const fpgrowth = new FPGrowth(0.01);
fpgrowth.exec(receipts)
    .then(result => {
        console.log(result.itemsets);
        console.log("Completed in " + result.executionTime + "ms.");
    });
```

FP-Growth 实现不生成关联规则，因此它只接受最小支持值作为参数。在这个例子中，我们没有截断`receipts`交易数据库，因为算法应该能够处理更大的数据集。完整的交易数据库大约有 26,000 条记录，所以最小支持值为`0.01`对应于被购买至少`260`次的产品。

从命令行运行`yarn start`，你应该看到类似以下输出的内容：

```py
[ { items: [ 'DECORATIVE WICKER HEART LARGE' ], support: 260 },
 { items: [ 'MINIATURE ANTIQUE ROSE HOOK IVORY' ], support: 260 },
 { items: [ 'PINK HEART SHAPE EGG FRYING PAN' ], support: 260 },
 ... 965 more items ]
 Completed in 14659ms.
```

注意，支持值是以绝对值给出的，即项目在数据库中出现的次数。虽然这些只是频繁项集而不是关联规则，但它们仍然很有用。如果你看到以下类似的频繁项集，你可能想在用户浏览糖碗页面时展示玫瑰茶壶：

```py
{ items: [ 'REGENCY SUGAR BOWL GREEN', 'REGENCY TEAPOT ROSES ' ],
 support: 247 }
```

虽然我认为在 JavaScript 生态系统中，关联规则学习方面还有一些工作要做，但 Apriori 和 FP-Growth 算法都是可用且有用的。特别是 Apriori 的实现，在大多数现实世界的用例中应该很有用，这些用例通常包含较少的交易和较小的商品目录。虽然 FP-Growth 的实现不生成关联规则，但通过找到频繁出现的商品集合，你仍然可以做很多事情。

# 摘要

在本章中，我们讨论了关联规则学习，或是在事务数据库中寻找频繁项集的方法，并通过概率将它们相互关联。我们了解到，关联规则学习最初是为了市场篮子分析而发明的，但由于其背后的概率理论和事务数据库的概念都具有广泛的应用性，因此它在许多领域都有应用。

接着，我们深入探讨了关联规则学习的数学原理，并研究了频繁项集挖掘的典型算法方法：Apriori 算法。在尝试我们自己零售数据集上的示例之前，我们探讨了关联规则学习的其他可能应用。
