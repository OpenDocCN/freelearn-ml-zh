

# 使用谷歌云 ML 最佳实践

在本章中，我们将讨论在谷歌云中实施**机器学习**（**ML**）的最佳实践。我们将通过在 GCP 中实施一个客户训练的 ML 模型开发过程，并提供全程的建议。

在本章中，我们将涵盖以下主题：

+   ML 环境设置

+   ML 数据存储和处理

+   ML 模型训练

+   ML 模型部署

+   ML 工作流程编排

+   ML 模型持续监控

本章旨在将我们在这本书中学到的知识整合起来，并将其应用于客户训练的 ML 项目。我们将首先设置 ML 环境。

# ML 环境设置

在*第四章*“开发和部署 ML 模型”的*准备平台*部分，我们学习了云中的 ML 平台。然后，在*第七章*“探索谷歌云 Vertex AI”中，我们介绍了 Vertex AI 服务。对于客户训练的模型开发平台，我们推荐**Vertex AI Workbench 用户管理的笔记本**。让我们从性能、成本和安全的角度来看一下细节。

使用 Vertex AI Workbench 用户管理的笔记本，您有灵活性和选项来实现**性能卓越**。您可以使用预安装了最新 ML 和数据科学库以及最新加速器驱动程序的现有深度学习虚拟机镜像创建一个实例。根据您的数据、模型和工作负载，您可以选择合适的虚拟机实例类型以适应您的环境并优化性能，从通用计算（E2、N1、N2 和 N2D），到内存优化（M1 和 M2），到计算优化（C2），等等。您还可以基于自定义容器创建笔记本实例，以定制您的 ML 环境。

使用 Vertex AI Workbench 用户管理的笔记本，您可以遵循 GCP 最佳实践并**降低成本**。与任何谷歌云服务一样，将您的笔记本的虚拟机实例视为灵活且可丢弃的资源；当您在虚拟机实例上训练 ML 模型时，请确保将所有数据存储在云存储或 BigQuery 中，而不是存储在实例的本地存储中，例如持久磁盘，这样您就可以在完成 ML 实验或训练后停止或删除实例。在 ML 模型开发过程中，始终监控虚拟机实例的性能和成本，并根据工作负载进行扩展/缩减，同时利用谷歌的托管实例组（MIGs）。

**安全**始终是我们需要在云中解决的问题的重要领域。以下是一些最佳安全实践：

+   使用 Vertex AI 工作台用户管理的笔记本，我们建议为数据科学团队的每个成员创建一个用户管理的笔记本实例。如果团队成员参与多个项目，我们建议为该成员使用多个用户管理的笔记本实例，并将每个实例视为一个虚拟工作空间。

+   运行 Vertex AI 需要各种团队的协作，并且确定哪些团队或系统将负责哪些功能非常重要。从网络的角度来看，如果可能的话，应配置用户管理的笔记本使用共享 VPC，以最小化对笔记本实例的访问。还必须启用限制性防火墙规则，以限制对笔记本实例和其他 Vertex AI 资源的访问。

+   对于数据和模型存储，我们还建议将训练数据和训练模型存储在同一项目中，以提高可重复性。在具有多个文件夹和多个项目的 Google 组织中，最佳实践是利用 Google IAM 角色和组。

+   为了数据保护，我们建议使用 Google Cloud 组织策略和数据丢失预防（DLP）工具来保护个人信息（PII）数据。还建议在 Vertex AI 笔记本实例中存储数据时进行数据加密。Vertex AI 支持在其大多数组件中使用**客户管理的加密密钥**（**CMEK**）。

现在我们已经了解了环境设置，让我们转向数据存储和处理。

# 机器学习数据存储和处理

正如我们在*第四章*“开发和部署机器学习模型”中讨论的，存储数据涉及从各种数据源收集原始数据并将其存储在集中式存储库中。另一方面，数据处理包括数据工程和特征工程。数据工程是将原始数据（源数据形式的数据）转换为准备数据（准备好的数据集，用于输入到机器学习任务中）的过程。特征工程随后调整准备好的数据以创建机器学习模型所期望的特征。

对于结构化数据，我们建议使用**Google Cloud BQ**来存储和处理。对于非结构化数据，如视频、音频和图像数据，我们建议使用**Google Cloud**对象存储来存储它们，并使用**Google Cloud Dataflow**或**Dataproc**来处理它们。正如我们之前讨论的，**Dataflow**是一个托管服务，它使用**Apache Beam**编程模型将非结构化数据转换为二进制格式，可以提高数据摄取性能。Dataproc 是一个托管**Apache Spark**和**Apache Hadoop**服务，它利用开源数据工具进行批量处理、查询、流处理和机器学习。

对于需要标记数据集的监督式机器学习，我们推荐使用**Google Vertex AI 数据标注**服务，特别是对于非结构化数据。从安全角度考虑，我们推荐使用**Google Cloud IAM**来管理云存储和 BQ 中的数据访问，使用 GCP DLP 来管理 PII 和其他敏感数据，以及使用 GCP 密钥管理服务（KMS）进行数据加密密钥管理。

一旦数据预处理完成，我们建议使用 Vertex AI 管理的数据集来创建您数据和自定义训练模型之间的链接，并提供描述性统计信息以将数据分割成训练、验证和测试子集。

根据机器学习模型的特点，可以在特征工程中利用许多方法。我们推荐使用**Vertex AI 特征存储**，它可以用于从数据湖中创建新特征，安排数据处理和特征工程作业，将它们导入 Vertex 特征存储进行在线或批量服务，并在数据科学团队内部共享常用特征。

# 机器学习模型训练

机器学习模型训练是机器学习开发的关键阶段，这就是我们推荐使用 GCP Vertex AI 训练的原因。我们建议使用自动化的 Vertex AI 训练模型增强器来测试不同的超参数配置，而不是手动调整超参数进行多次训练以获得最佳值，并使用**Google Vertex AI TensorBoard**来跟踪、共享和比较模型指标，如损失函数，以可视化模型图。这允许您比较各种实验以进行参数调整和模型优化。

使用 Vertex AI Workbench 用户管理的笔记本，您可以方便且交互式地开发代码，我们建议将您的代码进行操作化以实现可重复性和可扩展性，并在 Vertex 训练或**Vertex AI Pipelines**中运行您的代码。

在模型训练后，建议您使用**Vertex 可解释 AI**来研究和了解特征贡献，并理解您模型的行为。Vertex 可解释 AI 帮助您理解模型输出——它告诉您数据中的每个特征对预测结果贡献了多少。然后，您可以使用这些信息来查看您的模型是否按预期运行，识别模型中的偏差（如果有），并获得一些改进模型和训练数据的想法。

# 机器学习模型部署

ML 模型部署指的是将模型投入生产。一旦 ML 模型被部署到生产环境中，它就可以用来预测新的数据。我们建议使用 Vertex AI 控制台或 API 来部署训练好的 ML 模型。使用 Vertex AI，我们可以通过批量预测在生产中提供服务；我们建议为您的模型指定合适的硬件，并确定如何将输入传递给模型。使用 Vertex AI，我们还可以通过在线端点预测来提供服务；我们建议使用 Vertex AI Feature Store 的在线服务 API，并开启至少两个节点的自动扩展。

# ML 工作流程编排

正如我们在*第七章*中讨论的，*探索 Google Cloud Vertex AI*，Vertex AI 管道是一个完全托管的服务，允许您根据需要重新训练模型，以便您能够适应变化并保持性能。我们推荐使用 Vertex AI 管道进行云 ML 工作流程编排。

如果您使用的是**Google TensorFlow 框架**，我们建议使用**TensorFlow Extended**来定义您的管道和每个步骤的操作，然后在 Vertex AI 的无服务器管道系统中执行它。TensorFlow 为 Vertex AI 工作流程中的常见步骤提供了预构建的组件，例如数据摄取、数据验证和训练。

如果您使用其他框架，我们建议使用**Kubeflow Pipeline**，它非常灵活，允许您使用简单的代码构建管道。Kubeflow Pipeline 还提供了 Google Cloud 管道组件，如 Vertex AI AutoML。

# ML 模型持续监控

一旦您将模型部署到生产环境中，您需要持续监控模型性能，以确保其按预期运行。我们建议使用 Vertex AI，它提供了两种监控您的 ML 模型的方法：

+   **倾斜检测**，寻找模型训练和生产数据之间的扭曲程度。

+   **漂移检测**，寻找生产数据中的漂移。漂移发生在输入和目标的统计属性随时间变化，导致预测随着时间的推移变得越来越不准确。

对于倾斜和漂移检测，我们建议通过提供一个指向您用于训练模型的训练数据的指针来设置模型监控作业，然后调整用于警报的阈值，以测量数据中发生的倾斜或漂移。

您还可以在 Vertex Explainable AI 中使用特征归因来检测数据漂移或倾斜，作为模型性能可能下降的早期指标。例如，假设您的模型最初依赖于五个特征在训练和测试数据中进行预测，但进入生产后，它开始完全依赖于不同的特征。

# 摘要

在本章中，我们讨论了在 Google Cloud 中实施 ML 的最佳实践，重点关注基于您的数据和代码的定制训练模型。

本章总结了本书的第三部分*，其中我们讨论了从结构化数据训练 ML 模型的 Google BQ 和 BQML，Google ML 训练框架如 TensorFlow 和 Keras，Google ML 训练套件 Vertex AI，Google Cloud ML API 以及 Google Cloud 中的最佳 ML 实践。

在本书的第四部分，我们将通过了解认证的要求并深入研究一些认证的实践问题来为 Google Cloud Certified Professional ML Engineer 认证做准备。

# 进一步阅读

要了解更多关于本章所涵盖的内容，请查看以下资源：

+   [`www.tensorflow.org/tfx`](https://www.tensorflow.org/tfx)

+   [`www.kubeflow.org/`](https://www.kubeflow.org/)

+   [`cloud.google.com/architecture/ml-on-gcp-best-practices`](https://cloud.google.com/architecture/ml-on-gcp-best-practices)

+   [`cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning`](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

# 第四部分：完成 GCP ML 认证

在这部分，我们专注于 Google Cloud Professional Machine Learning Engineer 认证。我们介绍了 GCP ML 认证和 Google 的官方指南。我们通过整合从书中学到的知识和技能来研究认证考试问题。

本部分包括以下章节：

+   *第十章*，实现 GCP ML 认证
